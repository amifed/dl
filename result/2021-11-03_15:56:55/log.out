Train Model: LeNet, Using device cuda:0

========== Train Epoch 1 ==========
Loss: 1.720	Accuracy: 48 %
Accurary for class bzx   is: 74.0 %
Accurary for class cwx   is: 9.3 %
Accurary for class hdx   is: 54.3 %
Accurary for class mtx   is: 13.0 %
Accurary for class nqx   is: 59.7 %
Accurary for class nzx   is: 69.0 %
Accurary for class qtx   is: 67.8 %
Accurary for class sjx   is: 62.7 %
Accurary for class zxx   is: 33.3 %

========== Train Epoch 2 ==========
Loss: 1.957	Accuracy: 38 %
Accurary for class bzx   is: 57.1 %
Accurary for class cwx   is: 62.7 %
Accurary for class hdx   is: 38.7 %
Accurary for class mtx   is: 0.0 %
Accurary for class nqx   is: 30.9 %
Accurary for class nzx   is: 47.6 %
Accurary for class qtx   is: 18.7 %
Accurary for class sjx   is: 49.0 %
Accurary for class zxx   is: 47.5 %

========== Train Epoch 3 ==========
Loss: 1.418	Accuracy: 47 %
Accurary for class bzx   is: 55.8 %
Accurary for class cwx   is: 51.6 %
Accurary for class hdx   is: 15.0 %
Accurary for class mtx   is: 56.8 %
Accurary for class nqx   is: 30.9 %
Accurary for class nzx   is: 81.4 %
Accurary for class qtx   is: 38.0 %
Accurary for class sjx   is: 60.1 %
Accurary for class zxx   is: 43.7 %

========== Train Epoch 4 ==========
Loss: 1.093	Accuracy: 53 %
Accurary for class bzx   is: 42.9 %
Accurary for class cwx   is: 53.4 %
Accurary for class hdx   is: 63.6 %
Accurary for class mtx   is: 40.2 %
Accurary for class nqx   is: 46.3 %
Accurary for class nzx   is: 88.3 %
Accurary for class qtx   is: 42.7 %
Accurary for class sjx   is: 44.4 %
Accurary for class zxx   is: 58.5 %

========== Train Epoch 5 ==========
Loss: 0.899	Accuracy: 62 %
Accurary for class bzx   is: 64.9 %
Accurary for class cwx   is: 37.9 %
Accurary for class hdx   is: 77.5 %
Accurary for class mtx   is: 44.4 %
Accurary for class nqx   is: 54.4 %
Accurary for class nzx   is: 65.5 %
Accurary for class qtx   is: 60.8 %
Accurary for class sjx   is: 75.8 %
Accurary for class zxx   is: 77.0 %
Finished training!!!

Min loss = inf in epoch 4, max Accuracy = 62.21% in epoch 4

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=9, bias=True)
)

batch_size = 100
epochs = 5
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
