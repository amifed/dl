Train Model: GhostNet, Using device cuda

========== Train Epoch 1 ==========
Loss: 1.938	Accuracy: 15 %	Time 177 s
Accuracy for class bzx   is: 0.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 0.0 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 100.0 %

========== Train Epoch 2 ==========
Loss: 1.921	Accuracy: 20 %	Time 177 s
Accuracy for class bzx   is: 100.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 0.0 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 0.0 %

========== Train Epoch 3 ==========
Loss: 1.897	Accuracy: 20 %	Time 180 s
Accuracy for class bzx   is: 0.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 100.0 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 0.0 %

========== Train Epoch 4 ==========
Loss: 1.883	Accuracy: 16 %	Time 179 s
Accuracy for class bzx   is: 0.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 0.0 %
Accuracy for class mtx   is: 100.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 0.0 %

========== Train Epoch 5 ==========
Loss: 1.860	Accuracy: 18 %	Time 180 s
Accuracy for class bzx   is: 0.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 20.5 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 6.2 %
Accuracy for class zxx   is: 89.9 %

========== Train Epoch 6 ==========
Loss: 1.875	Accuracy: 20 %	Time 173 s
Accuracy for class bzx   is: 97.4 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 0.0 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 0.0 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 5.6 %

========== Train Epoch 7 ==========
Loss: 1.851	Accuracy: 26 %	Time 180 s
Accuracy for class bzx   is: 69.6 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 31.6 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 35.2 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 7.9 %

========== Train Epoch 8 ==========
Loss: 1.813	Accuracy: 22 %	Time 175 s
Accuracy for class bzx   is: 0.0 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 39.3 %
Accuracy for class mtx   is: 66.0 %
Accuracy for class nqx   is: 11.3 %
Accuracy for class qtx   is: 0.0 %
Accuracy for class zxx   is: 15.7 %

========== Train Epoch 9 ==========
Loss: 1.796	Accuracy: 28 %	Time 181 s
Accuracy for class bzx   is: 77.4 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 35.0 %
Accuracy for class mtx   is: 0.0 %
Accuracy for class nqx   is: 14.1 %
Accuracy for class qtx   is: 31.2 %
Accuracy for class zxx   is: 6.7 %

========== Train Epoch 10 ==========
Loss: 1.755	Accuracy: 27 %	Time 173 s
Accuracy for class bzx   is: 62.6 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 10.3 %
Accuracy for class mtx   is: 6.4 %
Accuracy for class nqx   is: 16.9 %
Accuracy for class qtx   is: 60.4 %
Accuracy for class zxx   is: 31.5 %

========== Train Epoch 11 ==========
Loss: 1.738	Accuracy: 28 %	Time 177 s
Accuracy for class bzx   is: 58.3 %
Accuracy for class cwx   is: 5.9 %
Accuracy for class hdx   is: 20.5 %
Accuracy for class mtx   is: 34.0 %
Accuracy for class nqx   is: 26.8 %
Accuracy for class qtx   is: 10.4 %
Accuracy for class zxx   is: 15.7 %

========== Train Epoch 12 ==========
Loss: 1.714	Accuracy: 29 %	Time 176 s
Accuracy for class bzx   is: 47.8 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 47.9 %
Accuracy for class mtx   is: 21.3 %
Accuracy for class nqx   is: 18.3 %
Accuracy for class qtx   is: 12.5 %
Accuracy for class zxx   is: 16.9 %

========== Train Epoch 13 ==========
Loss: 1.691	Accuracy: 29 %	Time 177 s
Accuracy for class bzx   is: 69.6 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 19.7 %
Accuracy for class mtx   is: 13.8 %
Accuracy for class nqx   is: 29.6 %
Accuracy for class qtx   is: 29.2 %
Accuracy for class zxx   is: 20.2 %

========== Train Epoch 14 ==========
Loss: 1.684	Accuracy: 29 %	Time 182 s
Accuracy for class bzx   is: 43.5 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 9.4 %
Accuracy for class mtx   is: 50.0 %
Accuracy for class nqx   is: 26.8 %
Accuracy for class qtx   is: 22.9 %
Accuracy for class zxx   is: 31.5 %

========== Train Epoch 15 ==========
Loss: 1.676	Accuracy: 30 %	Time 180 s
Accuracy for class bzx   is: 21.7 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 41.0 %
Accuracy for class mtx   is: 51.1 %
Accuracy for class nqx   is: 25.4 %
Accuracy for class qtx   is: 45.8 %
Accuracy for class zxx   is: 14.6 %

========== Train Epoch 16 ==========
Loss: 1.652	Accuracy: 35 %	Time 178 s
Accuracy for class bzx   is: 57.4 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 16.2 %
Accuracy for class mtx   is: 33.0 %
Accuracy for class nqx   is: 39.4 %
Accuracy for class qtx   is: 52.1 %
Accuracy for class zxx   is: 36.0 %

========== Train Epoch 17 ==========
Loss: 1.637	Accuracy: 32 %	Time 179 s
Accuracy for class bzx   is: 42.6 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 15.4 %
Accuracy for class mtx   is: 67.0 %
Accuracy for class nqx   is: 4.2 %
Accuracy for class qtx   is: 18.8 %
Accuracy for class zxx   is: 48.3 %

========== Train Epoch 18 ==========
Loss: 1.596	Accuracy: 35 %	Time 173 s
Accuracy for class bzx   is: 41.7 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 5.1 %
Accuracy for class mtx   is: 58.5 %
Accuracy for class nqx   is: 7.0 %
Accuracy for class qtx   is: 45.8 %
Accuracy for class zxx   is: 70.8 %

========== Train Epoch 19 ==========
Loss: 1.523	Accuracy: 35 %	Time 179 s
Accuracy for class bzx   is: 52.2 %
Accuracy for class cwx   is: 5.9 %
Accuracy for class hdx   is: 29.1 %
Accuracy for class mtx   is: 16.0 %
Accuracy for class nqx   is: 31.0 %
Accuracy for class qtx   is: 37.5 %
Accuracy for class zxx   is: 59.6 %

========== Train Epoch 20 ==========
Loss: 1.504	Accuracy: 36 %	Time 179 s
Accuracy for class bzx   is: 44.3 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 22.2 %
Accuracy for class mtx   is: 44.7 %
Accuracy for class nqx   is: 22.5 %
Accuracy for class qtx   is: 58.3 %
Accuracy for class zxx   is: 52.8 %

========== Train Epoch 21 ==========
Loss: 1.467	Accuracy: 41 %	Time 182 s
Accuracy for class bzx   is: 47.8 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 30.8 %
Accuracy for class mtx   is: 60.6 %
Accuracy for class nqx   is: 18.3 %
Accuracy for class qtx   is: 68.8 %
Accuracy for class zxx   is: 48.3 %

========== Train Epoch 22 ==========
Loss: 1.399	Accuracy: 39 %	Time 179 s
Accuracy for class bzx   is: 28.7 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 17.9 %
Accuracy for class mtx   is: 71.3 %
Accuracy for class nqx   is: 39.4 %
Accuracy for class qtx   is: 60.4 %
Accuracy for class zxx   is: 51.7 %

========== Train Epoch 23 ==========
Loss: 1.340	Accuracy: 42 %	Time 175 s
Accuracy for class bzx   is: 55.7 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 29.9 %
Accuracy for class mtx   is: 69.1 %
Accuracy for class nqx   is: 12.7 %
Accuracy for class qtx   is: 58.3 %
Accuracy for class zxx   is: 44.9 %

========== Train Epoch 24 ==========
Loss: 1.279	Accuracy: 45 %	Time 181 s
Accuracy for class bzx   is: 62.6 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 23.1 %
Accuracy for class mtx   is: 50.0 %
Accuracy for class nqx   is: 25.4 %
Accuracy for class qtx   is: 68.8 %
Accuracy for class zxx   is: 66.3 %

========== Train Epoch 25 ==========
Loss: 1.246	Accuracy: 45 %	Time 180 s
Accuracy for class bzx   is: 45.2 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 29.1 %
Accuracy for class mtx   is: 71.3 %
Accuracy for class nqx   is: 36.6 %
Accuracy for class qtx   is: 47.9 %
Accuracy for class zxx   is: 65.2 %

========== Train Epoch 26 ==========
Loss: 1.189	Accuracy: 46 %	Time 180 s
Accuracy for class bzx   is: 57.4 %
Accuracy for class cwx   is: 0.0 %
Accuracy for class hdx   is: 35.9 %
Accuracy for class mtx   is: 58.5 %
Accuracy for class nqx   is: 33.8 %
Accuracy for class qtx   is: 64.6 %
Accuracy for class zxx   is: 51.7 %

========== Train Epoch 27 ==========
Loss: 1.154	Accuracy: 50 %	Time 181 s
Accuracy for class bzx   is: 63.5 %
Accuracy for class cwx   is: 14.7 %
Accuracy for class hdx   is: 39.3 %
Accuracy for class mtx   is: 47.9 %
Accuracy for class nqx   is: 49.3 %
Accuracy for class qtx   is: 66.7 %
Accuracy for class zxx   is: 56.2 %

========== Train Epoch 28 ==========
Loss: 1.109	Accuracy: 49 %	Time 182 s
Accuracy for class bzx   is: 68.7 %
Accuracy for class cwx   is: 14.7 %
Accuracy for class hdx   is: 42.7 %
Accuracy for class mtx   is: 41.5 %
Accuracy for class nqx   is: 35.2 %
Accuracy for class qtx   is: 52.1 %
Accuracy for class zxx   is: 62.9 %

========== Train Epoch 29 ==========
Loss: 1.023	Accuracy: 54 %	Time 181 s
Accuracy for class bzx   is: 78.3 %
Accuracy for class cwx   is: 2.9 %
Accuracy for class hdx   is: 52.1 %
Accuracy for class mtx   is: 45.7 %
Accuracy for class nqx   is: 49.3 %
Accuracy for class qtx   is: 79.2 %
Accuracy for class zxx   is: 47.2 %

========== Train Epoch 30 ==========
Loss: 1.004	Accuracy: 49 %	Time 181 s
Accuracy for class bzx   is: 59.1 %
Accuracy for class cwx   is: 8.8 %
Accuracy for class hdx   is: 47.9 %
Accuracy for class mtx   is: 56.4 %
Accuracy for class nqx   is: 43.7 %
Accuracy for class qtx   is: 60.4 %
Accuracy for class zxx   is: 43.8 %

========== Train Epoch 31 ==========
Loss: 0.954	Accuracy: 54 %	Time 182 s
Accuracy for class bzx   is: 67.8 %
Accuracy for class cwx   is: 23.5 %
Accuracy for class hdx   is: 49.6 %
Accuracy for class mtx   is: 33.0 %
Accuracy for class nqx   is: 53.5 %
Accuracy for class qtx   is: 77.1 %
Accuracy for class zxx   is: 67.4 %

========== Train Epoch 32 ==========
Loss: 0.826	Accuracy: 55 %	Time 179 s
Accuracy for class bzx   is: 79.1 %
Accuracy for class cwx   is: 35.3 %
Accuracy for class hdx   is: 26.5 %
Accuracy for class mtx   is: 47.9 %
Accuracy for class nqx   is: 49.3 %
Accuracy for class qtx   is: 81.2 %
Accuracy for class zxx   is: 73.0 %

========== Train Epoch 33 ==========
Loss: 0.877	Accuracy: 57 %	Time 183 s
Accuracy for class bzx   is: 62.6 %
Accuracy for class cwx   is: 32.4 %
Accuracy for class hdx   is: 56.4 %
Accuracy for class mtx   is: 51.1 %
Accuracy for class nqx   is: 45.1 %
Accuracy for class qtx   is: 75.0 %
Accuracy for class zxx   is: 66.3 %

========== Train Epoch 34 ==========
Loss: 0.734	Accuracy: 58 %	Time 181 s
Accuracy for class bzx   is: 64.3 %
Accuracy for class cwx   is: 8.8 %
Accuracy for class hdx   is: 59.0 %
Accuracy for class mtx   is: 56.4 %
Accuracy for class nqx   is: 50.7 %
Accuracy for class qtx   is: 79.2 %
Accuracy for class zxx   is: 66.3 %

========== Train Epoch 35 ==========
Loss: 0.654	Accuracy: 56 %	Time 183 s
Accuracy for class bzx   is: 64.3 %
Accuracy for class cwx   is: 26.5 %
Accuracy for class hdx   is: 40.2 %
Accuracy for class mtx   is: 43.6 %
Accuracy for class nqx   is: 81.7 %
Accuracy for class qtx   is: 75.0 %
Accuracy for class zxx   is: 61.8 %

========== Train Epoch 36 ==========
Loss: 0.607	Accuracy: 58 %	Time 183 s
Accuracy for class bzx   is: 66.1 %
Accuracy for class cwx   is: 38.2 %
Accuracy for class hdx   is: 35.0 %
Accuracy for class mtx   is: 61.7 %
Accuracy for class nqx   is: 62.0 %
Accuracy for class qtx   is: 79.2 %
Accuracy for class zxx   is: 67.4 %

========== Train Epoch 37 ==========
Loss: 0.560	Accuracy: 58 %	Time 178 s
Accuracy for class bzx   is: 66.1 %
Accuracy for class cwx   is: 38.2 %
Accuracy for class hdx   is: 52.1 %
Accuracy for class mtx   is: 53.2 %
Accuracy for class nqx   is: 39.4 %
Accuracy for class qtx   is: 64.6 %
Accuracy for class zxx   is: 85.4 %

========== Train Epoch 38 ==========
Loss: 0.517	Accuracy: 57 %	Time 180 s
Accuracy for class bzx   is: 73.9 %
Accuracy for class cwx   is: 32.4 %
Accuracy for class hdx   is: 51.3 %
Accuracy for class mtx   is: 53.2 %
Accuracy for class nqx   is: 42.3 %
Accuracy for class qtx   is: 77.1 %
Accuracy for class zxx   is: 62.9 %

========== Train Epoch 39 ==========
Loss: 0.470	Accuracy: 64 %	Time 177 s
Accuracy for class bzx   is: 67.0 %
Accuracy for class cwx   is: 26.5 %
Accuracy for class hdx   is: 58.1 %
Accuracy for class mtx   is: 78.7 %
Accuracy for class nqx   is: 56.3 %
Accuracy for class qtx   is: 77.1 %
Accuracy for class zxx   is: 67.4 %

========== Train Epoch 40 ==========
Loss: 0.376	Accuracy: 58 %	Time 181 s
Accuracy for class bzx   is: 69.6 %
Accuracy for class cwx   is: 23.5 %
Accuracy for class hdx   is: 48.7 %
Accuracy for class mtx   is: 46.8 %
Accuracy for class nqx   is: 49.3 %
Accuracy for class qtx   is: 72.9 %
Accuracy for class zxx   is: 82.0 %

========== Train Epoch 41 ==========
Loss: 0.440	Accuracy: 59 %	Time 180 s
Accuracy for class bzx   is: 66.1 %
Accuracy for class cwx   is: 55.9 %
Accuracy for class hdx   is: 45.3 %
Accuracy for class mtx   is: 56.4 %
Accuracy for class nqx   is: 43.7 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 73.0 %

========== Train Epoch 42 ==========
Loss: 0.306	Accuracy: 63 %	Time 181 s
Accuracy for class bzx   is: 60.9 %
Accuracy for class cwx   is: 38.2 %
Accuracy for class hdx   is: 55.6 %
Accuracy for class mtx   is: 77.7 %
Accuracy for class nqx   is: 60.6 %
Accuracy for class qtx   is: 75.0 %
Accuracy for class zxx   is: 68.5 %

========== Train Epoch 43 ==========
Loss: 0.239	Accuracy: 62 %	Time 182 s
Accuracy for class bzx   is: 69.6 %
Accuracy for class cwx   is: 58.8 %
Accuracy for class hdx   is: 59.0 %
Accuracy for class mtx   is: 55.3 %
Accuracy for class nqx   is: 54.9 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 62.9 %

========== Train Epoch 44 ==========
Loss: 0.229	Accuracy: 62 %	Time 180 s
Accuracy for class bzx   is: 59.1 %
Accuracy for class cwx   is: 41.2 %
Accuracy for class hdx   is: 42.7 %
Accuracy for class mtx   is: 76.6 %
Accuracy for class nqx   is: 52.1 %
Accuracy for class qtx   is: 81.2 %
Accuracy for class zxx   is: 83.1 %

========== Train Epoch 45 ==========
Loss: 0.273	Accuracy: 62 %	Time 180 s
Accuracy for class bzx   is: 62.6 %
Accuracy for class cwx   is: 52.9 %
Accuracy for class hdx   is: 67.5 %
Accuracy for class mtx   is: 42.6 %
Accuracy for class nqx   is: 46.5 %
Accuracy for class qtx   is: 89.6 %
Accuracy for class zxx   is: 76.4 %

========== Train Epoch 46 ==========
Loss: 0.298	Accuracy: 64 %	Time 178 s
Accuracy for class bzx   is: 67.8 %
Accuracy for class cwx   is: 52.9 %
Accuracy for class hdx   is: 58.1 %
Accuracy for class mtx   is: 61.7 %
Accuracy for class nqx   is: 59.2 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 69.7 %

========== Train Epoch 47 ==========
Loss: 0.146	Accuracy: 65 %	Time 178 s
Accuracy for class bzx   is: 76.5 %
Accuracy for class cwx   is: 38.2 %
Accuracy for class hdx   is: 55.6 %
Accuracy for class mtx   is: 69.1 %
Accuracy for class nqx   is: 54.9 %
Accuracy for class qtx   is: 81.2 %
Accuracy for class zxx   is: 69.7 %

========== Train Epoch 48 ==========
Loss: 0.101	Accuracy: 63 %	Time 180 s
Accuracy for class bzx   is: 62.6 %
Accuracy for class cwx   is: 50.0 %
Accuracy for class hdx   is: 59.8 %
Accuracy for class mtx   is: 51.1 %
Accuracy for class nqx   is: 64.8 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 73.0 %

========== Train Epoch 49 ==========
Loss: 0.097	Accuracy: 63 %	Time 175 s
Accuracy for class bzx   is: 59.1 %
Accuracy for class cwx   is: 50.0 %
Accuracy for class hdx   is: 62.4 %
Accuracy for class mtx   is: 53.2 %
Accuracy for class nqx   is: 60.6 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 76.4 %

========== Train Epoch 50 ==========
Loss: 0.136	Accuracy: 63 %	Time 182 s
Accuracy for class bzx   is: 73.9 %
Accuracy for class cwx   is: 23.5 %
Accuracy for class hdx   is: 70.1 %
Accuracy for class mtx   is: 66.0 %
Accuracy for class nqx   is: 42.3 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 59.6 %

========== Train Epoch 51 ==========
Loss: 0.107	Accuracy: 64 %	Time 182 s
Accuracy for class bzx   is: 73.0 %
Accuracy for class cwx   is: 52.9 %
Accuracy for class hdx   is: 59.8 %
Accuracy for class mtx   is: 58.5 %
Accuracy for class nqx   is: 49.3 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 73.0 %

========== Train Epoch 52 ==========
Loss: 0.073	Accuracy: 67 %	Time 178 s
Accuracy for class bzx   is: 73.9 %
Accuracy for class cwx   is: 38.2 %
Accuracy for class hdx   is: 55.6 %
Accuracy for class mtx   is: 79.8 %
Accuracy for class nqx   is: 54.9 %
Accuracy for class qtx   is: 87.5 %
Accuracy for class zxx   is: 70.8 %

========== Train Epoch 53 ==========
Loss: 0.067	Accuracy: 67 %	Time 181 s
Accuracy for class bzx   is: 67.8 %
Accuracy for class cwx   is: 52.9 %
Accuracy for class hdx   is: 64.1 %
Accuracy for class mtx   is: 68.1 %
Accuracy for class nqx   is: 62.0 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 70.8 %

========== Train Epoch 54 ==========
Loss: 0.088	Accuracy: 65 %	Time 183 s
Accuracy for class bzx   is: 60.0 %
Accuracy for class cwx   is: 41.2 %
Accuracy for class hdx   is: 67.5 %
Accuracy for class mtx   is: 70.2 %
Accuracy for class nqx   is: 56.3 %
Accuracy for class qtx   is: 77.1 %
Accuracy for class zxx   is: 74.2 %

========== Train Epoch 55 ==========
Loss: 0.100	Accuracy: 64 %	Time 182 s
Accuracy for class bzx   is: 82.6 %
Accuracy for class cwx   is: 55.9 %
Accuracy for class hdx   is: 50.4 %
Accuracy for class mtx   is: 56.4 %
Accuracy for class nqx   is: 59.2 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 65.2 %

========== Train Epoch 56 ==========
Loss: 0.151	Accuracy: 62 %	Time 176 s
Accuracy for class bzx   is: 63.5 %
Accuracy for class cwx   is: 47.1 %
Accuracy for class hdx   is: 61.5 %
Accuracy for class mtx   is: 34.0 %
Accuracy for class nqx   is: 71.8 %
Accuracy for class qtx   is: 87.5 %
Accuracy for class zxx   is: 75.3 %

========== Train Epoch 57 ==========
Loss: 0.115	Accuracy: 65 %	Time 181 s
Accuracy for class bzx   is: 67.8 %
Accuracy for class cwx   is: 44.1 %
Accuracy for class hdx   is: 57.3 %
Accuracy for class mtx   is: 69.1 %
Accuracy for class nqx   is: 56.3 %
Accuracy for class qtx   is: 87.5 %
Accuracy for class zxx   is: 70.8 %

========== Train Epoch 58 ==========
Loss: 0.071	Accuracy: 68 %	Time 180 s
Accuracy for class bzx   is: 76.5 %
Accuracy for class cwx   is: 44.1 %
Accuracy for class hdx   is: 60.7 %
Accuracy for class mtx   is: 75.5 %
Accuracy for class nqx   is: 53.5 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 71.9 %

========== Train Epoch 59 ==========
Loss: 0.075	Accuracy: 65 %	Time 174 s
Accuracy for class bzx   is: 65.2 %
Accuracy for class cwx   is: 47.1 %
Accuracy for class hdx   is: 54.7 %
Accuracy for class mtx   is: 84.0 %
Accuracy for class nqx   is: 59.2 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 65.2 %

========== Train Epoch 60 ==========
Loss: 0.078	Accuracy: 63 %	Time 180 s
Accuracy for class bzx   is: 77.4 %
Accuracy for class cwx   is: 50.0 %
Accuracy for class hdx   is: 42.7 %
Accuracy for class mtx   is: 58.5 %
Accuracy for class nqx   is: 69.0 %
Accuracy for class qtx   is: 83.3 %
Accuracy for class zxx   is: 70.8 %

========== Train Epoch 61 ==========
Loss: 0.063	Accuracy: 68 %	Time 177 s
Accuracy for class bzx   is: 67.8 %
Accuracy for class cwx   is: 58.8 %
Accuracy for class hdx   is: 60.7 %
Accuracy for class mtx   is: 77.7 %
Accuracy for class nqx   is: 60.6 %
Accuracy for class qtx   is: 87.5 %
Accuracy for class zxx   is: 67.4 %

========== Train Epoch 62 ==========
Loss: 0.086	Accuracy: 67 %	Time 181 s
Accuracy for class bzx   is: 67.0 %
Accuracy for class cwx   is: 52.9 %
Accuracy for class hdx   is: 56.4 %
Accuracy for class mtx   is: 75.5 %
Accuracy for class nqx   is: 64.8 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 71.9 %

========== Train Epoch 63 ==========
Loss: 0.045	Accuracy: 69 %	Time 178 s
Accuracy for class bzx   is: 76.5 %
Accuracy for class cwx   is: 61.8 %
Accuracy for class hdx   is: 63.2 %
Accuracy for class mtx   is: 62.8 %
Accuracy for class nqx   is: 67.6 %
Accuracy for class qtx   is: 87.5 %
Accuracy for class zxx   is: 69.7 %

========== Train Epoch 64 ==========
Loss: 0.024	Accuracy: 69 %	Time 177 s
Accuracy for class bzx   is: 65.2 %
Accuracy for class cwx   is: 61.8 %
Accuracy for class hdx   is: 67.5 %
Accuracy for class mtx   is: 68.1 %
Accuracy for class nqx   is: 67.6 %
Accuracy for class qtx   is: 85.4 %
Accuracy for class zxx   is: 75.3 %
Finished training!!!

Min loss = 0.546 in epoch 63, max Accuracy = 69.54% in epoch 63

GhostNet(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)
            (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)
            (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (2): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential(
          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)
            (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential(
        (0): Sequential(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (1): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(24, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
            (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(72, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)
            (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (4): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(24, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)
            (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential(
          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)
          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=72, out_features=18, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=18, out_features=72, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(72, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
            (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential(
        (0): Sequential(
          (0): Conv2d(24, 24, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (1): Conv2d(24, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(40, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)
            (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=120, out_features=30, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=30, out_features=120, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
            (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (6): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential(
          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential(
        (0): Sequential(
          (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (1): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(80, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=100, bias=False)
            (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(200, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (8): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(80, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(92, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=92, bias=False)
            (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(184, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (9): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(80, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(92, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=92, bias=False)
            (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(184, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (10): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=480, out_features=120, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=120, out_features=480, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(480, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (1): Conv2d(80, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(112, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)
            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=672, out_features=168, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=168, out_features=672, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(672, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)
            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (12): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(112, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)
            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential(
          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)
          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=672, out_features=168, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=168, out_features=672, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential(
        (0): Sequential(
          (0): Conv2d(112, 112, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=112, bias=False)
          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sequential()
        )
        (1): Conv2d(112, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (14): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=960, out_features=240, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=240, out_features=960, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (15): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): Sequential()
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
    (16): GhostBottleneck(
      (conv): Sequential(
        (0): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (cheap_operation): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (1): Sequential()
        (2): SELayer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=960, out_features=240, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=240, out_features=960, bias=True)
          )
        )
        (3): GhostModule(
          (primary_conv): Sequential(
            (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
          (cheap_operation): Sequential(
            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Sequential()
          )
        )
      )
      (shortcut): Sequential()
    )
  )
  (squeeze): Sequential(
    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): Sequential(
    (0): Linear(in_features=960, out_features=1280, bias=False)
    (1): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1280, out_features=7, bias=True)
  )
)

batch_size = 100
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
