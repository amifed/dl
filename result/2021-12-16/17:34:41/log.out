dataset_path: /home/djy/dataset/dataset
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset
msg: ca_cbam_spp_resnet_alexnet dynamic_lr concat
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 120
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.905	Accuracy: 30.32%	Cost 31s

========== Train Epoch 2 ==========
Loss: 1.706	Accuracy: 35.64%	Cost 30s

========== Train Epoch 3 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 32s

========== Train Epoch 4 ==========
Loss: 1.679	Accuracy: 36.70%	Cost 32s

========== Train Epoch 5 ==========
Loss: 1.684	Accuracy: 36.70%	Cost 32s

========== Train Epoch 6 ==========
Loss: 1.671	Accuracy: 36.70%	Cost 33s

========== Train Epoch 7 ==========
Loss: 1.667	Accuracy: 36.70%	Cost 32s

========== Train Epoch 8 ==========
Loss: 1.677	Accuracy: 36.70%	Cost 32s

========== Train Epoch 9 ==========
Loss: 1.681	Accuracy: 36.70%	Cost 32s

========== Train Epoch 10 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 33s

========== Train Epoch 11 ==========
Loss: 1.667	Accuracy: 36.70%	Cost 33s

========== Train Epoch 12 ==========
Loss: 1.670	Accuracy: 37.23%	Cost 34s

========== Train Epoch 13 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 33s

========== Train Epoch 14 ==========
Loss: 1.671	Accuracy: 37.23%	Cost 32s

========== Train Epoch 15 ==========
Loss: 1.673	Accuracy: 37.23%	Cost 34s

========== Train Epoch 16 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 33s

========== Train Epoch 17 ==========
Loss: 1.685	Accuracy: 37.23%	Cost 33s

========== Train Epoch 18 ==========
Loss: 1.682	Accuracy: 37.23%	Cost 32s

========== Train Epoch 19 ==========
Loss: 1.677	Accuracy: 36.70%	Cost 32s

========== Train Epoch 20 ==========
Loss: 1.673	Accuracy: 36.70%	Cost 34s

========== Train Epoch 21 ==========
Loss: 1.674	Accuracy: 36.70%	Cost 33s

========== Train Epoch 22 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 32s

========== Train Epoch 23 ==========
Loss: 1.678	Accuracy: 37.23%	Cost 33s

========== Train Epoch 24 ==========
Loss: 1.681	Accuracy: 36.70%	Cost 32s

========== Train Epoch 25 ==========
Loss: 1.677	Accuracy: 37.23%	Cost 31s

========== Train Epoch 26 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 31s

========== Train Epoch 27 ==========
Loss: 1.667	Accuracy: 36.70%	Cost 32s

========== Train Epoch 28 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 31s

========== Train Epoch 29 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 32s

========== Train Epoch 30 ==========
Loss: 1.683	Accuracy: 36.70%	Cost 33s

========== Train Epoch 31 ==========
Loss: 1.678	Accuracy: 37.23%	Cost 33s

========== Train Epoch 32 ==========
Loss: 1.667	Accuracy: 37.23%	Cost 33s

========== Train Epoch 33 ==========
Loss: 1.673	Accuracy: 36.70%	Cost 33s

========== Train Epoch 34 ==========
Loss: 1.682	Accuracy: 36.70%	Cost 33s

========== Train Epoch 35 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 32s

========== Train Epoch 36 ==========
Loss: 1.682	Accuracy: 37.23%	Cost 31s

========== Train Epoch 37 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 33s

========== Train Epoch 38 ==========
Loss: 1.667	Accuracy: 36.17%	Cost 33s

========== Train Epoch 39 ==========
Loss: 1.671	Accuracy: 37.23%	Cost 32s

========== Train Epoch 40 ==========
Loss: 1.674	Accuracy: 37.23%	Cost 32s

========== Train Epoch 41 ==========
Loss: 1.669	Accuracy: 36.70%	Cost 33s

========== Train Epoch 42 ==========
Loss: 1.666	Accuracy: 36.70%	Cost 32s

========== Train Epoch 43 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 32s

========== Train Epoch 44 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 32s

========== Train Epoch 45 ==========
Loss: 1.663	Accuracy: 36.70%	Cost 32s

========== Train Epoch 46 ==========
Loss: 1.674	Accuracy: 36.70%	Cost 33s

========== Train Epoch 47 ==========
Loss: 1.676	Accuracy: 37.23%	Cost 33s

========== Train Epoch 48 ==========
Loss: 1.677	Accuracy: 37.23%	Cost 31s

========== Train Epoch 49 ==========
Loss: 1.668	Accuracy: 36.70%	Cost 34s

========== Train Epoch 50 ==========
Loss: 1.675	Accuracy: 37.23%	Cost 31s

========== Train Epoch 51 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 32s

========== Train Epoch 52 ==========
Loss: 1.670	Accuracy: 37.23%	Cost 33s

========== Train Epoch 53 ==========
Loss: 1.672	Accuracy: 37.23%	Cost 32s

========== Train Epoch 54 ==========
Loss: 1.661	Accuracy: 36.70%	Cost 32s

========== Train Epoch 55 ==========
Loss: 1.666	Accuracy: 37.23%	Cost 32s

========== Train Epoch 56 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 33s

========== Train Epoch 57 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 33s

========== Train Epoch 58 ==========
Loss: 1.668	Accuracy: 36.17%	Cost 33s

========== Train Epoch 59 ==========
Loss: 1.672	Accuracy: 36.70%	Cost 33s

========== Train Epoch 60 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 33s

========== Train Epoch 61 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 32s

========== Train Epoch 62 ==========
Loss: 1.670	Accuracy: 36.70%	Cost 32s

========== Train Epoch 63 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 31s

========== Train Epoch 64 ==========
Loss: 1.669	Accuracy: 37.23%	Cost 32s

========== Train Epoch 65 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 34s

========== Train Epoch 66 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 30s

========== Train Epoch 67 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 33s

========== Train Epoch 68 ==========
Loss: 1.683	Accuracy: 37.23%	Cost 33s

========== Train Epoch 69 ==========
Loss: 1.668	Accuracy: 37.23%	Cost 33s

========== Train Epoch 70 ==========
Loss: 1.682	Accuracy: 37.23%	Cost 34s

========== Train Epoch 71 ==========
Loss: 1.666	Accuracy: 36.70%	Cost 32s

========== Train Epoch 72 ==========
Loss: 1.672	Accuracy: 36.70%	Cost 34s

========== Train Epoch 73 ==========
Loss: 1.684	Accuracy: 36.70%	Cost 34s

========== Train Epoch 74 ==========
Loss: 1.680	Accuracy: 36.17%	Cost 32s

========== Train Epoch 75 ==========
Loss: 1.668	Accuracy: 36.17%	Cost 33s

========== Train Epoch 76 ==========
Loss: 1.680	Accuracy: 37.23%	Cost 33s

========== Train Epoch 77 ==========
Loss: 1.679	Accuracy: 36.70%	Cost 32s

========== Train Epoch 78 ==========
Loss: 1.672	Accuracy: 36.70%	Cost 34s

========== Train Epoch 79 ==========
Loss: 1.671	Accuracy: 36.70%	Cost 32s

========== Train Epoch 80 ==========
Loss: 1.664	Accuracy: 36.70%	Cost 33s

========== Train Epoch 81 ==========
Loss: 1.674	Accuracy: 37.23%	Cost 32s

========== Train Epoch 82 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 33s

========== Train Epoch 83 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 34s

========== Train Epoch 84 ==========
Loss: 1.669	Accuracy: 37.23%	Cost 33s

========== Train Epoch 85 ==========
Loss: 1.679	Accuracy: 36.70%	Cost 35s

========== Train Epoch 86 ==========
Loss: 1.674	Accuracy: 36.70%	Cost 31s

========== Train Epoch 87 ==========
Loss: 1.677	Accuracy: 37.23%	Cost 34s

========== Train Epoch 88 ==========
Loss: 1.677	Accuracy: 36.70%	Cost 32s

========== Train Epoch 89 ==========
Loss: 1.674	Accuracy: 36.70%	Cost 32s

========== Train Epoch 90 ==========
Loss: 1.682	Accuracy: 36.70%	Cost 33s

========== Train Epoch 91 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 31s

========== Train Epoch 92 ==========
Loss: 1.680	Accuracy: 37.23%	Cost 34s

========== Train Epoch 93 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 34s

========== Train Epoch 94 ==========
Loss: 1.692	Accuracy: 37.23%	Cost 32s

========== Train Epoch 95 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 34s

========== Train Epoch 96 ==========
Loss: 1.666	Accuracy: 36.70%	Cost 33s

========== Train Epoch 97 ==========
Loss: 1.671	Accuracy: 36.70%	Cost 33s

========== Train Epoch 98 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 34s

========== Train Epoch 99 ==========
Loss: 1.674	Accuracy: 36.17%	Cost 31s

========== Train Epoch 100 ==========
Loss: 1.678	Accuracy: 36.70%	Cost 33s

========== Train Epoch 101 ==========
Loss: 1.681	Accuracy: 36.70%	Cost 31s

========== Train Epoch 102 ==========
Loss: 1.684	Accuracy: 37.23%	Cost 31s

========== Train Epoch 103 ==========
Loss: 1.665	Accuracy: 36.70%	Cost 33s

========== Train Epoch 104 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 32s

========== Train Epoch 105 ==========
Loss: 1.691	Accuracy: 36.70%	Cost 32s

========== Train Epoch 106 ==========
Loss: 1.666	Accuracy: 36.70%	Cost 32s

========== Train Epoch 107 ==========
Loss: 1.671	Accuracy: 36.70%	Cost 31s

========== Train Epoch 108 ==========
Loss: 1.672	Accuracy: 36.70%	Cost 34s

========== Train Epoch 109 ==========
Loss: 1.670	Accuracy: 37.23%	Cost 32s

========== Train Epoch 110 ==========
Loss: 1.679	Accuracy: 37.23%	Cost 34s

========== Train Epoch 111 ==========
Loss: 1.680	Accuracy: 36.70%	Cost 33s

========== Train Epoch 112 ==========
Loss: 1.666	Accuracy: 37.23%	Cost 31s

========== Train Epoch 113 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 33s

========== Train Epoch 114 ==========
Loss: 1.679	Accuracy: 36.70%	Cost 33s

========== Train Epoch 115 ==========
Loss: 1.673	Accuracy: 36.70%	Cost 31s

========== Train Epoch 116 ==========
Loss: 1.666	Accuracy: 36.70%	Cost 32s

========== Train Epoch 117 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 34s

========== Train Epoch 118 ==========
Loss: 1.672	Accuracy: 37.23%	Cost 34s

========== Train Epoch 119 ==========
Loss: 1.675	Accuracy: 36.70%	Cost 32s

========== Train Epoch 120 ==========
Loss: 1.676	Accuracy: 36.70%	Cost 34s

Finished training!!!

Min Loss = 1.661 in epoch 53;
    Max Accuracy = 37.23% in epoch 11;
    Total Cost 66 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): CoordAtt(
          (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))
          (pool_w): AdaptiveAvgPool2d(output_size=(1, None))
          (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))
          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act): h_swish(
            (sigmoid): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
          (conv_h): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))
          (conv_w): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP(
    (pool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    (pool2): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)
    (pool3): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
  )
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.30319148936170215, 0.35638297872340424, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3617021276595745, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3617021276595745, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3617021276595745, 0.3617021276595745, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3617021276595745, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3723404255319149, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3670212765957447, 0.3723404255319149, 0.3670212765957447, 0.3670212765957447]
