dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset1
msg: cbam spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.807	Accuracy: 32.97%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.4286    0.4667    0.4468        45
         zxx     0.2696    0.7949    0.4026        39

    accuracy                         0.3297       185
   macro avg     0.2826    0.2613    0.2243       185
weighted avg     0.2896    0.3297    0.2590       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.612	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2917    0.6774    0.4078        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4912    0.6222    0.5490        45
         zxx     0.4314    0.5641    0.4889        39

    accuracy                         0.4000       185
   macro avg     0.4116    0.2868    0.2437       185
weighted avg     0.4413    0.4000    0.3342       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.514	Accuracy: 26.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.7143    0.1111    0.1923        45
         zxx     0.2317    0.9744    0.3744        39

    accuracy                         0.2649       185
   macro avg     0.3304    0.1919    0.1406       185
weighted avg     0.4067    0.2649    0.1795       185


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.387	Accuracy: 35.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3571    0.1613    0.2222        31
         cwx     0.2759    0.3636    0.3137        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.1667    0.3333    0.2222        12
         qtx     0.3333    0.6444    0.4394        45
         zxx     0.6333    0.4872    0.5507        39

    accuracy                         0.3568       185
   macro avg     0.3952    0.2918    0.2640       185
weighted avg     0.4208    0.3568    0.3222       185


========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.296	Accuracy: 43.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.5000    0.2273    0.3125        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.3333    0.7500    0.4615        12
         qtx     0.6667    0.3556    0.4638        45
         zxx     0.4130    0.9744    0.5802        39

    accuracy                         0.4378       185
   macro avg     0.4377    0.4058    0.3633       185
weighted avg     0.4785    0.4378    0.3971       185


========== Train Epoch 6 ==========
Loss: 1.200	Accuracy: 46.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.3000    0.4091    0.3462        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.4853    0.7333    0.5841        45
         zxx     0.4932    0.9231    0.6429        39

    accuracy                         0.4649       185
   macro avg     0.5576    0.3494    0.3165       185
weighted avg     0.5300    0.4649    0.3905       185


========== Train Epoch 7 ==========
Loss: 1.100	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3774    0.6452    0.4762        31
         cwx     0.2941    0.4545    0.3571        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5135       185
   macro avg     0.5269    0.4356    0.4203       185
weighted avg     0.5560    0.5135    0.4905       185


========== Train Epoch 8 ==========
Loss: 0.969	Accuracy: 43.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3958    0.6129    0.4810        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.4471    0.8444    0.5846        45
         zxx     1.0000    0.1538    0.2667        39

    accuracy                         0.4324       185
   macro avg     0.4939    0.3666    0.3593       185
weighted avg     0.5342    0.4324    0.3912       185


========== Train Epoch 9 ==========
Loss: 0.872	Accuracy: 52.43%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3438    0.9167    0.5000        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.4605    0.8974    0.6087        39

    accuracy                         0.5243       185
   macro avg     0.6289    0.4915    0.4410       185
weighted avg     0.6509    0.5243    0.4932       185


========== Train Epoch 10 ==========
Loss: 0.733	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.8667    0.5909    0.7027        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.8889    0.6667    0.7619        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.6162       185
   macro avg     0.6397    0.5682    0.5833       185
weighted avg     0.6460    0.6162    0.6118       185


========== Train Epoch 11 ==========
Loss: 0.575	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6792    0.8000    0.7347        45
         zxx     0.5902    0.9231    0.7200        39

    accuracy                         0.6270       185
   macro avg     0.6373    0.5614    0.5564       185
weighted avg     0.6524    0.6270    0.6027       185


========== Train Epoch 12 ==========
Loss: 0.472	Accuracy: 54.05%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.2759    0.4211    0.3333        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.9412    0.3556    0.5161        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.5405       185
   macro avg     0.5502    0.5528    0.5053       185
weighted avg     0.6275    0.5405    0.5371       185


========== Train Epoch 13 ==========
Loss: 0.368	Accuracy: 51.35%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.3095    0.5909    0.4063        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2368    0.4737    0.3158        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.6727    0.8222    0.7400        45
         zxx     0.8276    0.6154    0.7059        39

    accuracy                         0.5135       185
   macro avg     0.5322    0.4460    0.4360       185
weighted avg     0.5987    0.5135    0.5056       185


========== Train Epoch 14 ==========
Loss: 0.276	Accuracy: 51.89%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.8000    0.1290    0.2222        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.2791    0.6316    0.3871        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.6400    0.7111    0.6737        45
         zxx     0.8400    0.5385    0.6562        39

    accuracy                         0.5189       185
   macro avg     0.5502    0.5153    0.4762       185
weighted avg     0.6228    0.5189    0.5125       185


========== Train Epoch 15 ==========
Loss: 0.214	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8333    0.5556    0.6667        45
         zxx     0.5070    0.9231    0.6545        39

    accuracy                         0.5784       185
   macro avg     0.5775    0.5523    0.5378       185
weighted avg     0.6048    0.5784    0.5611       185


========== Train Epoch 16 ==========
Loss: 0.196	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.8000    0.1290    0.2222        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.4933    0.9487    0.6491        39

    accuracy                         0.5838       185
   macro avg     0.6138    0.5589    0.5202       185
weighted avg     0.6463    0.5838    0.5455       185


========== Train Epoch 17 ==========
Loss: 0.142	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.6167    0.9487    0.7475        39

    accuracy                         0.6486       185
   macro avg     0.6772    0.6150    0.5847       185
weighted avg     0.7038    0.6486    0.6268       185


========== Train Epoch 18 ==========
Loss: 0.097	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3906    0.8065    0.5263        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.8966    0.6667    0.7647        39

    accuracy                         0.6162       185
   macro avg     0.6408    0.5670    0.5626       185
weighted avg     0.6631    0.6162    0.6041       185


========== Train Epoch 19 ==========
Loss: 0.074	Accuracy: 67.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.6957    0.7273    0.7111        22
         hdx     0.6000    0.5294    0.5625        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4783    0.9167    0.6286        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.7447    0.8974    0.8140        39

    accuracy                         0.6703       185
   macro avg     0.6278    0.6559    0.6279       185
weighted avg     0.6829    0.6703    0.6664       185


========== Train Epoch 20 ==========
Loss: 0.080	Accuracy: 60.00%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.5000    0.6818    0.5769        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.2750    0.5789    0.3729        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6000       185
   macro avg     0.6360    0.5645    0.5667       185
weighted avg     0.6746    0.6000    0.6068       185


========== Train Epoch 21 ==========
Loss: 0.072	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8000    0.1290    0.2222        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.5000    0.5789    0.5366        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6102    0.8000    0.6923        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.5838       185
   macro avg     0.6417    0.5368    0.5235       185
weighted avg     0.6412    0.5838    0.5404       185


========== Train Epoch 22 ==========
Loss: 0.088	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4865    0.8182    0.6102        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6378       185
   macro avg     0.6194    0.6057    0.5833       185
weighted avg     0.6503    0.6378    0.6210       185


========== Train Epoch 23 ==========
Loss: 0.056	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7091    0.8667    0.7800        45
         zxx     0.5211    0.9487    0.6727        39

    accuracy                         0.6162       185
   macro avg     0.6428    0.5405    0.5383       185
weighted avg     0.6395    0.6162    0.5782       185


========== Train Epoch 24 ==========
Loss: 0.051	Accuracy: 64.32%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.9000    0.4091    0.5625        22
         hdx     0.3448    0.5882    0.4348        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8718    0.7556    0.8095        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6432       185
   macro avg     0.6308    0.6172    0.5950       185
weighted avg     0.6770    0.6432    0.6378       185


========== Train Epoch 25 ==========
Loss: 0.098	Accuracy: 51.89%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4444    0.1290    0.2000        31
         cwx     0.4359    0.7727    0.5574        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2558    0.9167    0.4000        12
         qtx     0.8333    0.5556    0.6667        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5189       185
   macro avg     0.5211    0.5182    0.4473       185
weighted avg     0.5805    0.5189    0.4937       185


========== Train Epoch 26 ==========
Loss: 0.093	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4762    0.6452    0.5479        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6324       185
   macro avg     0.6305    0.5851    0.5723       185
weighted avg     0.6469    0.6324    0.6111       185


========== Train Epoch 27 ==========
Loss: 0.050	Accuracy: 60.54%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.8750    0.6364    0.7368        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.3235    0.9167    0.4783        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.6054       185
   macro avg     0.5978    0.6078    0.5780       185
weighted avg     0.6533    0.6054    0.6153       185


========== Train Epoch 28 ==========
Loss: 0.086	Accuracy: 55.14%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.3956    0.9231    0.5538        39

    accuracy                         0.5514       185
   macro avg     0.6446    0.4867    0.5101       185
weighted avg     0.6365    0.5514    0.5420       185


========== Train Epoch 29 ==========
Loss: 0.074	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3443    0.6774    0.4565        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5784       185
   macro avg     0.6672    0.5273    0.5157       185
weighted avg     0.6736    0.5784    0.5617       185


========== Train Epoch 30 ==========
Loss: 0.091	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.7778    0.4118    0.5385        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.5000    0.9487    0.6549        39

    accuracy                         0.6216       185
   macro avg     0.6474    0.5770    0.5847       185
weighted avg     0.6579    0.6216    0.6106       185


========== Train Epoch 31 ==========
Loss: 0.073	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.9286    0.5909    0.7222        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.3438    0.9167    0.5000        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5946       185
   macro avg     0.6046    0.5538    0.5215       185
weighted avg     0.6328    0.5946    0.5769       185


========== Train Epoch 32 ==========
Loss: 0.069	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.3056    0.6471    0.4151        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.6108       185
   macro avg     0.6370    0.5926    0.5823       185
weighted avg     0.6736    0.6108    0.6122       185


========== Train Epoch 33 ==========
Loss: 0.054	Accuracy: 52.43%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.8182    0.4091    0.5455        22
         hdx     0.1972    0.8235    0.3182        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5243       185
   macro avg     0.6939    0.4579    0.4417       185
weighted avg     0.6929    0.5243    0.5214       185


========== Train Epoch 34 ==========
Loss: 0.053	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7273    0.2581    0.3810        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.2500    0.4211    0.3137        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.7400    0.9487    0.8315        39

    accuracy                         0.6378       185
   macro avg     0.6243    0.6039    0.5895       185
weighted avg     0.6742    0.6378    0.6295       185


========== Train Epoch 35 ==========
Loss: 0.043	Accuracy: 65.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.4783    0.6471    0.5500        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6541       185
   macro avg     0.6529    0.6195    0.5970       185
weighted avg     0.6739    0.6541    0.6341       185


========== Train Epoch 36 ==========
Loss: 0.036	Accuracy: 68.65%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.6429    0.5294    0.5806        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6167    0.9487    0.7475        39

    accuracy                         0.6865       185
   macro avg     0.6831    0.6558    0.6611       185
weighted avg     0.6970    0.6865    0.6808       185


========== Train Epoch 37 ==========
Loss: 0.030	Accuracy: 68.11%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.6774    0.5753        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.7500    0.5294    0.6207        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.7907    0.8718    0.8293        39

    accuracy                         0.6811       185
   macro avg     0.6880    0.6626    0.6320       185
weighted avg     0.7139    0.6811    0.6664       185


========== Train Epoch 38 ==========
Loss: 0.027	Accuracy: 68.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.6429    0.5294    0.5806        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8718    0.7556    0.8095        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6865       185
   macro avg     0.6439    0.6658    0.6464       185
weighted avg     0.6960    0.6865    0.6856       185


========== Train Epoch 39 ==========
Loss: 0.025	Accuracy: 69.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.6296    0.7727    0.6939        22
         hdx     0.6429    0.5294    0.5806        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8333    0.7778    0.8046        45
         zxx     0.6923    0.9231    0.7912        39

    accuracy                         0.6973       185
   macro avg     0.6658    0.6713    0.6505       185
weighted avg     0.6959    0.6973    0.6819       185


========== Train Epoch 40 ==========
Loss: 0.025	Accuracy: 70.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.8000    0.7273    0.7619        22
         hdx     0.6471    0.6471    0.6471        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.6545    0.9231    0.7660        39

    accuracy                         0.7081       185
   macro avg     0.7071    0.6861    0.6764       185
weighted avg     0.7262    0.7081    0.6999       185


========== Train Epoch 41 ==========
Loss: 0.020	Accuracy: 67.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.5455    0.8182    0.6545        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.7292    0.8974    0.8046        39

    accuracy                         0.6703       185
   macro avg     0.6454    0.6376    0.6131       185
weighted avg     0.6834    0.6703    0.6557       185


========== Train Epoch 42 ==========
Loss: 0.018	Accuracy: 65.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.7778    0.6364    0.7000        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.5714    0.9231    0.7059        39

    accuracy                         0.6541       185
   macro avg     0.6475    0.6249    0.6225       185
weighted avg     0.6644    0.6541    0.6440       185


========== Train Epoch 43 ==========
Loss: 0.019	Accuracy: 67.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.5806    0.8182    0.6792        22
         hdx     0.7500    0.5294    0.6207        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.7115    0.8222    0.7629        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6757       185
   macro avg     0.6718    0.6556    0.6292       185
weighted avg     0.6921    0.6757    0.6586       185


========== Train Epoch 44 ==========
Loss: 0.019	Accuracy: 68.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.8095    0.7727    0.7907        22
         hdx     0.4783    0.6471    0.5500        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.6545    0.9231    0.7660        39

    accuracy                         0.6865       185
   macro avg     0.6907    0.6697    0.6431       185
weighted avg     0.7110    0.6865    0.6687       185


========== Train Epoch 45 ==========
Loss: 0.019	Accuracy: 70.27%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.6667    0.5882    0.6250        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.9167    0.7333    0.8148        45
         zxx     0.7200    0.9231    0.8090        39

    accuracy                         0.7027       185
   macro avg     0.6674    0.6884    0.6641       185
weighted avg     0.7162    0.7027    0.6973       185


========== Train Epoch 46 ==========
Loss: 0.018	Accuracy: 69.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.6923    0.5294    0.6000        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8718    0.7556    0.8095        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.6973       185
   macro avg     0.6657    0.6664    0.6539       185
weighted avg     0.7027    0.6973    0.6899       185


========== Train Epoch 47 ==========
Loss: 0.017	Accuracy: 67.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.7273    0.7273    0.7273        22
         hdx     0.7273    0.4706    0.5714        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.5902    0.9231    0.7200        39

    accuracy                         0.6757       185
   macro avg     0.6755    0.6471    0.6452       185
weighted avg     0.6891    0.6757    0.6663       185


========== Train Epoch 48 ==========
Loss: 0.018	Accuracy: 67.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.8667    0.5909    0.7027        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.6102    0.9231    0.7347        39

    accuracy                         0.6757       185
   macro avg     0.6639    0.6424    0.6389       185
weighted avg     0.6905    0.6757    0.6685       185


========== Train Epoch 49 ==========
Loss: 0.019	Accuracy: 69.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7917    0.6129    0.6909        31
         cwx     0.5862    0.7727    0.6667        22
         hdx     0.5882    0.5882    0.5882        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8684    0.7333    0.7952        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.6973       185
   macro avg     0.6668    0.6837    0.6554       185
weighted avg     0.7163    0.6973    0.6926       185


========== Train Epoch 50 ==========
Loss: 0.018	Accuracy: 66.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.5000    0.5882    0.5405        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.6649       185
   macro avg     0.6588    0.6407    0.6280       185
weighted avg     0.6847    0.6649    0.6521       185


========== Train Epoch 51 ==========
Loss: 0.023	Accuracy: 66.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6649       185
   macro avg     0.6506    0.6380    0.6198       185
weighted avg     0.6745    0.6649    0.6530       185


========== Train Epoch 52 ==========
Loss: 0.037	Accuracy: 40.54%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.8824    0.3333    0.4839        45
         zxx     0.2857    0.9744    0.4419        39

    accuracy                         0.4054       185
   macro avg     0.6306    0.3465    0.3613       185
weighted avg     0.6159    0.4054    0.3805       185


========== Train Epoch 53 ==========
Loss: 0.046	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.8750    0.6364    0.7368        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.4800    0.9231    0.6316        39

    accuracy                         0.6270       185
   macro avg     0.6798    0.5956    0.6058       185
weighted avg     0.6817    0.6270    0.6213       185


========== Train Epoch 54 ==========
Loss: 0.066	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.4000    0.8182    0.5373        22
         hdx     0.8750    0.4118    0.5600        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.7170    0.8444    0.7755        45
         zxx     0.5846    0.9744    0.7308        39

    accuracy                         0.5946       185
   macro avg     0.6975    0.4989    0.4694       185
weighted avg     0.6732    0.5946    0.5334       185


========== Train Epoch 55 ==========
Loss: 0.153	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4324    0.7273    0.5424        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5784       185
   macro avg     0.6018    0.5344    0.5067       185
weighted avg     0.6275    0.5784    0.5618       185


========== Train Epoch 56 ==========
Loss: 0.122	Accuracy: 54.05%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3810    0.7742    0.5106        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6429    0.8000    0.7129        45
         zxx     0.8824    0.3846    0.5357        39

    accuracy                         0.5405       185
   macro avg     0.5773    0.5001    0.5013       185
weighted avg     0.5998    0.5405    0.5278       185


========== Train Epoch 57 ==========
Loss: 0.085	Accuracy: 52.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4524    0.6129    0.5205        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.2000    0.6842    0.3095        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.7061    0.4644    0.4723       185
weighted avg     0.7158    0.5243    0.5395       185


========== Train Epoch 58 ==========
Loss: 0.063	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5526    0.6774    0.6087        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.4400    0.6471    0.5238        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6378       185
   macro avg     0.6603    0.6159    0.6024       185
weighted avg     0.6738    0.6378    0.6265       185


========== Train Epoch 59 ==========
Loss: 0.040	Accuracy: 65.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.5902    0.9231    0.7200        39

    accuracy                         0.6541       185
   macro avg     0.6438    0.6153    0.6076       185
weighted avg     0.6616    0.6541    0.6388       185


========== Train Epoch 60 ==========
Loss: 0.025	Accuracy: 67.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4091    0.4737    0.4390        19
         nqx     0.6875    0.9167    0.7857        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.7857    0.8462    0.8148        39

    accuracy                         0.6703       185
   macro avg     0.6368    0.6642    0.6456       185
weighted avg     0.6784    0.6703    0.6700       185


========== Train Epoch 61 ==========
Loss: 0.021	Accuracy: 65.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.6667    0.5882    0.6250        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.6541       185
   macro avg     0.6369    0.6436    0.6232       185
weighted avg     0.6664    0.6541    0.6446       185


========== Train Epoch 62 ==========
Loss: 0.020	Accuracy: 66.49%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5484    0.7727    0.6415        22
         hdx     0.5882    0.5882    0.5882        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6649       185
   macro avg     0.6644    0.6550    0.6300       185
weighted avg     0.6819    0.6649    0.6517       185


========== Train Epoch 63 ==========
Loss: 0.017	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.6471    0.6471    0.6471        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.5211    0.9487    0.6727        39

    accuracy                         0.6324       185
   macro avg     0.6657    0.6216    0.5967       185
weighted avg     0.6770    0.6324    0.6093       185


========== Train Epoch 64 ==========
Loss: 0.016	Accuracy: 68.65%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.6250    0.5882    0.6061        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7059    0.9231    0.8000        39

    accuracy                         0.6865       185
   macro avg     0.6549    0.6687    0.6379       185
weighted avg     0.6922    0.6865    0.6713       185


Finished training!!!

Min Loss = 0.016 in epoch 63;
Max Accuracy = 70.81% in epoch 39;
Total Cost 33 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP(
    (pool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    (pool2): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)
    (pool3): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
  )
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.32972972972972975, 0.4, 0.2648648648648649, 0.3567567567567568, 0.43783783783783786, 0.4648648648648649, 0.5135135135135135, 0.43243243243243246, 0.5243243243243243, 0.6162162162162163, 0.6270270270270271, 0.5405405405405406, 0.5135135135135135, 0.518918918918919, 0.5783783783783784, 0.5837837837837838, 0.6486486486486487, 0.6162162162162163, 0.6702702702702703, 0.6, 0.5837837837837838, 0.6378378378378379, 0.6162162162162163, 0.6432432432432432, 0.518918918918919, 0.6324324324324324, 0.6054054054054054, 0.5513513513513514, 0.5783783783783784, 0.6216216216216216, 0.5945945945945946, 0.6108108108108108, 0.5243243243243243, 0.6378378378378379, 0.654054054054054, 0.6864864864864865, 0.6810810810810811, 0.6864864864864865, 0.6972972972972973, 0.7081081081081081, 0.6702702702702703, 0.654054054054054, 0.6756756756756757, 0.6864864864864865, 0.7027027027027027, 0.6972972972972973, 0.6756756756756757, 0.6756756756756757, 0.6972972972972973, 0.6648648648648648, 0.6648648648648648, 0.40540540540540543, 0.6270270270270271, 0.5945945945945946, 0.5783783783783784, 0.5405405405405406, 0.5243243243243243, 0.6378378378378379, 0.654054054054054, 0.6702702702702703, 0.654054054054054, 0.6648648648648648, 0.6324324324324324, 0.6864864864864865]
