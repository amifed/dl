dataset_path: /home/djy/dataset/dataset
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset
msg: cbam spp resnet18_alexnet
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.856	Accuracy: 31.91%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        21
         cwx     0.0000    0.0000    0.0000        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.0476    0.0625    0.0541        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.0000    0.0000    0.0000        31
         zxx     0.3533    0.9672    0.5175        61

    accuracy                         0.3191       188
   macro avg     0.0573    0.1471    0.0817       188
weighted avg     0.1187    0.3191    0.1725       188


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.662	Accuracy: 38.30%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        21
         cwx     0.0000    0.0000    0.0000        21
         hdx     0.0500    0.0526    0.0513        19
         mtx     0.5000    0.0625    0.1111        16
         nqx     0.3684    0.3684    0.3684        19
         qtx     0.4286    0.4839    0.4545        31
         zxx     0.4286    0.7869    0.5549        61

    accuracy                         0.3830       188
   macro avg     0.2537    0.2506    0.2200       188
weighted avg     0.2946    0.3830    0.3069       188


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.531	Accuracy: 43.62%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2083    0.4762    0.2899        21
         cwx     0.5333    0.3810    0.4444        21
         hdx     0.5000    0.0526    0.0952        19
         mtx     0.2222    0.2500    0.2353        16
         nqx     0.4286    0.1579    0.2308        19
         qtx     0.4510    0.7419    0.5610        31
         zxx     0.7021    0.5410    0.6111        61

    accuracy                         0.4362       188
   macro avg     0.4351    0.3715    0.3525       188
weighted avg     0.4978    0.4362    0.4258       188


========== Train Epoch 4 ==========
Loss: 1.382	Accuracy: 48.40%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1905    0.1905    0.1905        21
         cwx     0.5625    0.4286    0.4865        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.1667    0.0625    0.0909        16
         nqx     0.5882    0.5263    0.5556        19
         qtx     0.8000    0.5161    0.6275        31
         zxx     0.4857    0.8361    0.6145        61

    accuracy                         0.4840       188
   macro avg     0.3991    0.3657    0.3665       188
weighted avg     0.4473    0.4840    0.4423       188


========== Train Epoch 5 ==========
Loss: 1.257	Accuracy: 52.13%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4615    0.5714    0.5106        21
         cwx     0.8571    0.2857    0.4286        21
         hdx     0.0833    0.0526    0.0645        19
         mtx     0.2105    0.5000    0.2963        16
         nqx     0.4062    0.6842    0.5098        19
         qtx     0.6471    0.7097    0.6769        31
         zxx     0.9231    0.5902    0.7200        61

    accuracy                         0.5213       188
   macro avg     0.5127    0.4848    0.4581       188
weighted avg     0.6209    0.5213    0.5334       188


========== Train Epoch 6 ==========
Loss: 1.135	Accuracy: 39.89%	Cost 32s
              precision    recall  f1-score   support

         bzx     1.0000    0.0952    0.1739        21
         cwx     0.6000    0.2857    0.3871        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.1750    0.4375    0.2500        16
         nqx     0.4074    0.5789    0.4783        19
         qtx     0.3553    0.8710    0.5047        31
         zxx     0.7857    0.3607    0.4944        61

    accuracy                         0.3989       188
   macro avg     0.4748    0.3756    0.3269       188
weighted avg     0.5483    0.3989    0.3759       188


========== Train Epoch 7 ==========
Loss: 1.020	Accuracy: 55.85%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3571    0.4762    0.4082        21
         cwx     0.3939    0.6190    0.4815        21
         hdx     0.1765    0.1579    0.1667        19
         mtx     0.2500    0.0625    0.1000        16
         nqx     0.8000    0.4211    0.5517        19
         qtx     0.7143    0.6452    0.6780        31
         zxx     0.7353    0.8197    0.7752        61

    accuracy                         0.5585       188
   macro avg     0.4896    0.4574    0.4516       188
weighted avg     0.5602    0.5585    0.5438       188


========== Train Epoch 8 ==========
Loss: 0.877	Accuracy: 52.13%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.4286    0.4615        21
         cwx     1.0000    0.1905    0.3200        21
         hdx     0.1176    0.2105    0.1509        19
         mtx     0.2333    0.4375    0.3043        16
         nqx     0.4444    0.6316    0.5217        19
         qtx     0.6471    0.7097    0.6769        31
         zxx     0.9756    0.6557    0.7843        61

    accuracy                         0.5213       188
   macro avg     0.5597    0.4663    0.4600       188
weighted avg     0.6675    0.5213    0.5473       188


========== Train Epoch 9 ==========
Loss: 0.698	Accuracy: 64.36%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.4839    0.7143    0.5769        21
         hdx     0.3000    0.4737    0.3673        19
         mtx     0.2857    0.2500    0.2667        16
         nqx     0.8462    0.5789    0.6875        19
         qtx     0.7353    0.8065    0.7692        31
         zxx     0.9400    0.7705    0.8468        61

    accuracy                         0.6436       188
   macro avg     0.6023    0.5814    0.5793       188
weighted avg     0.6903    0.6436    0.6557       188


========== Train Epoch 10 ==========
Loss: 0.622	Accuracy: 46.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2143    0.8571    0.3429        21
         cwx     0.7857    0.5238    0.6286        21
         hdx     0.1429    0.0526    0.0769        19
         mtx     0.2000    0.1250    0.1538        16
         nqx     1.0000    0.1053    0.1905        19
         qtx     1.0000    0.1290    0.2286        31
         zxx     0.7463    0.8197    0.7813        61

    accuracy                         0.4681       188
   macro avg     0.5842    0.3732    0.3432       188
weighted avg     0.6513    0.4681    0.4398       188


========== Train Epoch 11 ==========
Loss: 0.500	Accuracy: 58.51%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7000    0.3333    0.4516        21
         cwx     0.4815    0.6190    0.5417        21
         hdx     0.4000    0.1053    0.1667        19
         mtx     0.2500    0.6250    0.3571        16
         nqx     0.6667    0.1053    0.1818        19
         qtx     0.5714    0.9032    0.7000        31
         zxx     0.8889    0.7869    0.8348        61

    accuracy                         0.5851       188
   macro avg     0.5655    0.4969    0.4620       188
weighted avg     0.6437    0.5851    0.5629       188


========== Train Epoch 12 ==========
Loss: 0.364	Accuracy: 54.26%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4074    0.5238    0.4583        21
         cwx     1.0000    0.1429    0.2500        21
         hdx     0.2292    0.5789    0.3284        19
         mtx     0.6000    0.1875    0.2857        16
         nqx     0.4667    0.7368    0.5714        19
         qtx     1.0000    0.2581    0.4103        31
         zxx     0.7761    0.8525    0.8125        61

    accuracy                         0.5426       188
   macro avg     0.6399    0.4686    0.4452       188
weighted avg     0.6953    0.5426    0.5257       188


========== Train Epoch 13 ==========
Loss: 0.260	Accuracy: 63.83%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4250    0.8095    0.5574        21
         cwx     1.0000    0.3810    0.5517        21
         hdx     0.3571    0.2632    0.3030        19
         mtx     0.2414    0.4375    0.3111        16
         nqx     0.5556    0.5263    0.5405        19
         qtx     0.8286    0.9355    0.8788        31
         zxx     1.0000    0.7213    0.8381        61

    accuracy                         0.6383       188
   macro avg     0.6297    0.5820    0.5687       188
weighted avg     0.7331    0.6383    0.6525       188


========== Train Epoch 14 ==========
Loss: 0.169	Accuracy: 62.23%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.2857    0.4000        21
         cwx     0.4651    0.9524    0.6250        21
         hdx     0.2400    0.3158    0.2727        19
         mtx     0.3043    0.4375    0.3590        16
         nqx     1.0000    0.1053    0.1905        19
         qtx     0.8182    0.8710    0.8438        31
         zxx     0.9245    0.8033    0.8596        61

    accuracy                         0.6223       188
   macro avg     0.6313    0.5387    0.5072       188
weighted avg     0.7125    0.6223    0.6099       188


========== Train Epoch 15 ==========
Loss: 0.101	Accuracy: 65.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8000    0.3810    0.5161        21
         cwx     0.8000    0.7619    0.7805        21
         hdx     1.0000    0.0526    0.1000        19
         mtx     0.2041    0.6250    0.3077        16
         nqx     0.7500    0.4737    0.5806        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.8154    0.8689    0.8413        61

    accuracy                         0.6543       188
   macro avg     0.7440    0.5717    0.5664       188
weighted avg     0.7758    0.6543    0.6511       188


========== Train Epoch 16 ==========
Loss: 0.107	Accuracy: 61.17%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8750    0.3333    0.4828        21
         cwx     0.3704    0.9524    0.5333        21
         hdx     0.3200    0.4211    0.3636        19
         mtx     0.4000    0.1250    0.1905        16
         nqx     0.8750    0.3684    0.5185        19
         qtx     0.6500    0.8387    0.7324        31
         zxx     0.9375    0.7377    0.8257        61

    accuracy                         0.6117       188
   macro avg     0.6326    0.5395    0.5210       188
weighted avg     0.7053    0.6117    0.6075       188


========== Train Epoch 17 ==========
Loss: 0.179	Accuracy: 60.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3810    0.7619    0.5079        21
         cwx     0.5667    0.8095    0.6667        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.2258    0.4375    0.2979        16
         nqx     0.5000    0.1053    0.1739        19
         qtx     0.7742    0.7742    0.7742        31
         zxx     0.9400    0.7705    0.8468        61

    accuracy                         0.6011       188
   macro avg     0.4839    0.5227    0.4668       188
weighted avg     0.6083    0.6011    0.5766       188


========== Train Epoch 18 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.108	Accuracy: 60.11%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7143    0.2381    0.3571        21
         cwx     0.8750    0.3333    0.4828        21
         hdx     0.2000    0.2632    0.2273        19
         mtx     0.5000    0.0625    0.1111        16
         nqx     0.3953    0.8947    0.5484        19
         qtx     0.6364    0.9032    0.7467        31
         zxx     0.8475    0.8197    0.8333        61

    accuracy                         0.6011       188
   macro avg     0.5955    0.5021    0.4724       188
weighted avg     0.6602    0.6011    0.5752       188


========== Train Epoch 19 ==========
Loss: 0.059	Accuracy: 67.55%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.3810    0.4848        21
         cwx     0.5357    0.7143    0.6122        21
         hdx     0.2917    0.3684    0.3256        19
         mtx     0.4286    0.3750    0.4000        16
         nqx     0.8333    0.5263    0.6452        19
         qtx     0.7500    0.8710    0.8060        31
         zxx     0.8710    0.8852    0.8780        61

    accuracy                         0.6755       188
   macro avg     0.6253    0.5887    0.5931       188
weighted avg     0.6908    0.6755    0.6725       188


========== Train Epoch 20 ==========
Loss: 0.046	Accuracy: 64.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5217    0.5714    0.5455        21
         cwx     1.0000    0.4286    0.6000        21
         hdx     0.4286    0.1579    0.2308        19
         mtx     0.2812    0.5625    0.3750        16
         nqx     0.6923    0.4737    0.5625        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.7397    0.8852    0.8060        61

    accuracy                         0.6489       188
   macro avg     0.6432    0.5597    0.5655       188
weighted avg     0.6855    0.6489    0.6398       188


========== Train Epoch 21 ==========
Loss: 0.041	Accuracy: 67.02%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3864    0.8095    0.5231        21
         cwx     0.7500    0.7143    0.7317        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.5000    0.3125    0.3846        16
         nqx     0.8000    0.4211    0.5517        19
         qtx     0.8125    0.8387    0.8254        31
         zxx     0.8387    0.8525    0.8455        61

    accuracy                         0.6702       188
   macro avg     0.6268    0.5866    0.5813       188
weighted avg     0.6868    0.6702    0.6600       188


========== Train Epoch 22 ==========
Loss: 0.029	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5833    0.6667    0.6222        21
         cwx     0.7500    0.7143    0.7317        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.3000    0.3750    0.3333        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.6429    0.8710    0.7397        31
         zxx     0.8814    0.8525    0.8667        61

    accuracy                         0.6755       188
   macro avg     0.6038    0.5948    0.5894       188
weighted avg     0.6745    0.6755    0.6669       188


========== Train Epoch 23 ==========
Loss: 0.026	Accuracy: 67.55%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.4762    0.5556        21
         cwx     0.4255    0.9524    0.5882        21
         hdx     0.5000    0.2105    0.2963        19
         mtx     0.5000    0.3125    0.3846        16
         nqx     0.8333    0.5263    0.6452        19
         qtx     0.8333    0.8065    0.8197        31
         zxx     0.8030    0.8689    0.8346        61

    accuracy                         0.6755       188
   macro avg     0.6517    0.5933    0.5892       188
weighted avg     0.6973    0.6755    0.6616       188


========== Train Epoch 24 ==========
Loss: 0.029	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8667    0.6190    0.7222        21
         cwx     0.3725    0.9048    0.5278        21
         hdx     0.4000    0.5263    0.4545        19
         mtx     0.4545    0.3125    0.3704        16
         nqx     0.9000    0.4737    0.6207        19
         qtx     0.9524    0.6452    0.7692        31
         zxx     0.9273    0.8361    0.8793        61

    accuracy                         0.6755       188
   macro avg     0.6962    0.6168    0.6206       188
weighted avg     0.7664    0.6755    0.6920       188


========== Train Epoch 25 ==========
Loss: 0.024	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4048    0.8095    0.5397        21
         cwx     0.8462    0.5238    0.6471        21
         hdx     0.2857    0.3158    0.3000        19
         mtx     0.5000    0.2500    0.3333        16
         nqx     0.7857    0.5789    0.6667        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.8814    0.8525    0.8667        61

    accuracy                         0.6755       188
   macro avg     0.6489    0.5956    0.5989       188
weighted avg     0.7148    0.6755    0.6781       188


========== Train Epoch 26 ==========
Loss: 0.013	Accuracy: 69.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7222    0.6190    0.6667        21
         cwx     0.6538    0.8095    0.7234        21
         hdx     0.3571    0.2632    0.3030        19
         mtx     0.2759    0.5000    0.3556        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.7941    0.8710    0.8308        31
         zxx     0.9444    0.8361    0.8870        61

    accuracy                         0.6968       188
   macro avg     0.6453    0.6322    0.6273       188
weighted avg     0.7284    0.6968    0.7041       188


========== Train Epoch 27 ==========
Loss: 0.011	Accuracy: 71.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6087    0.6667    0.6364        21
         cwx     0.6800    0.8095    0.7391        21
         hdx     0.5000    0.3684    0.4242        19
         mtx     0.4000    0.3750    0.3871        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.8182    0.8710    0.8438        31
         zxx     0.8308    0.8852    0.8571        61

    accuracy                         0.7181       188
   macro avg     0.6581    0.6432    0.6447       188
weighted avg     0.7107    0.7181    0.7099       188


========== Train Epoch 28 ==========
Loss: 0.017	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5833    0.6667    0.6222        21
         cwx     0.7857    0.5238    0.6286        21
         hdx     0.2500    0.4737    0.3273        19
         mtx     0.3636    0.2500    0.2963        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.7568    0.9032    0.8235        31
         zxx     0.9623    0.8361    0.8947        61

    accuracy                         0.6755       188
   macro avg     0.6387    0.5971    0.6025       188
weighted avg     0.7239    0.6755    0.6873       188


========== Train Epoch 29 ==========
Loss: 0.012	Accuracy: 69.68%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6400    0.7619    0.6957        21
         cwx     0.7273    0.7619    0.7442        21
         hdx     0.4444    0.2105    0.2857        19
         mtx     0.2667    0.5000    0.3478        16
         nqx     1.0000    0.3158    0.4800        19
         qtx     0.7568    0.9032    0.8235        31
         zxx     0.8983    0.8689    0.8833        61

    accuracy                         0.6968       188
   macro avg     0.6762    0.6175    0.6086       188
weighted avg     0.7377    0.6968    0.6902       188


========== Train Epoch 30 ==========
Loss: 0.018	Accuracy: 57.45%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3421    0.6190    0.4407        21
         cwx     1.0000    0.5714    0.7273        21
         hdx     0.6667    0.1053    0.1818        19
         mtx     0.2105    0.7500    0.3288        16
         nqx     1.0000    0.1053    0.1905        19
         qtx     0.7812    0.8065    0.7937        31
         zxx     0.9545    0.6885    0.8000        61

    accuracy                         0.5745       188
   macro avg     0.7079    0.5209    0.4947       188
weighted avg     0.7748    0.5745    0.5865       188


========== Train Epoch 31 ==========
Loss: 0.018	Accuracy: 64.36%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5625    0.4286    0.4865        21
         cwx     0.5000    0.9048    0.6441        21
         hdx     0.2759    0.4211    0.3333        19
         mtx     0.2857    0.2500    0.2667        16
         nqx     0.7500    0.4737    0.5806        19
         qtx     0.8333    0.8065    0.8197        31
         zxx     0.9592    0.7705    0.8545        61

    accuracy                         0.6436       188
   macro avg     0.5952    0.5793    0.5693       188
weighted avg     0.6953    0.6436    0.6538       188


========== Train Epoch 32 ==========
Loss: 0.029	Accuracy: 59.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7273    0.3810    0.5000        21
         cwx     0.8750    0.3333    0.4828        21
         hdx     0.3333    0.0526    0.0909        19
         mtx     0.2500    0.3125    0.2778        16
         nqx     0.3125    0.7895    0.4478        19
         qtx     0.7941    0.8710    0.8308        31
         zxx     0.7656    0.8033    0.7840        61

    accuracy                         0.5957       188
   macro avg     0.5797    0.5062    0.4877       188
weighted avg     0.6449    0.5957    0.5792       188


========== Train Epoch 33 ==========
Loss: 0.130	Accuracy: 52.66%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6364    0.3333    0.4375        21
         cwx     0.9000    0.4286    0.5806        21
         hdx     0.1667    0.0526    0.0800        19
         mtx     0.1731    0.5625    0.2647        16
         nqx     0.3409    0.7895    0.4762        19
         qtx     0.8000    0.7742    0.7869        31
         zxx     0.9714    0.5574    0.7083        61

    accuracy                         0.5266       188
   macro avg     0.5698    0.4997    0.4763       188
weighted avg     0.6848    0.5266    0.5521       188


========== Train Epoch 34 ==========
Loss: 0.167	Accuracy: 34.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        21
         cwx     0.0000    0.0000    0.0000        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.5000    0.0625    0.1111        16
         nqx     1.0000    0.1053    0.1905        19
         qtx     1.0000    0.0323    0.0625        31
         zxx     0.3333    1.0000    0.5000        61

    accuracy                         0.3457       188
   macro avg     0.4048    0.1714    0.1234       188
weighted avg     0.4167    0.3457    0.2012       188


========== Train Epoch 35 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.140	Accuracy: 57.98%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.2812    0.8571    0.4235        21
         cwx     0.6000    0.7143    0.6522        21
         hdx     0.5000    0.1579    0.2400        19
         mtx     0.2500    0.0625    0.1000        16
         nqx     0.6250    0.2632    0.3704        19
         qtx     0.7188    0.7419    0.7302        31
         zxx     0.8980    0.7213    0.8000        61

    accuracy                         0.5798       188
   macro avg     0.5533    0.5026    0.4737       188
weighted avg     0.6433    0.5798    0.5703       188


========== Train Epoch 36 ==========
Loss: 0.058	Accuracy: 67.02%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8571    0.2857    0.4286        21
         cwx     0.5556    0.7143    0.6250        21
         hdx     0.4231    0.5789    0.4889        19
         mtx     1.0000    0.1250    0.2222        16
         nqx     0.7333    0.5789    0.6471        19
         qtx     0.7931    0.7419    0.7667        31
         zxx     0.7073    0.9508    0.8112        61

    accuracy                         0.6702       188
   macro avg     0.7242    0.5679    0.5699       188
weighted avg     0.7201    0.6702    0.6410       188


========== Train Epoch 37 ==========
Loss: 0.055	Accuracy: 66.49%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5385    0.6667    0.5957        21
         cwx     0.5484    0.8095    0.6538        21
         hdx     0.7500    0.1579    0.2609        19
         mtx     0.2727    0.5625    0.3673        16
         nqx     1.0000    0.1579    0.2727        19
         qtx     0.8000    0.9032    0.8485        31
         zxx     0.9107    0.8361    0.8718        61

    accuracy                         0.6649       188
   macro avg     0.6886    0.5848    0.5530       188
weighted avg     0.7489    0.6649    0.6476       188


========== Train Epoch 38 ==========
Loss: 0.054	Accuracy: 66.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.7143    0.6522        21
         cwx     0.5152    0.8095    0.6296        21
         hdx     0.3750    0.1579    0.2222        19
         mtx     0.3750    0.5625    0.4500        16
         nqx     0.6000    0.3158    0.4138        19
         qtx     0.7000    0.9032    0.7887        31
         zxx     0.9792    0.7705    0.8624        61

    accuracy                         0.6649       188
   macro avg     0.5920    0.6048    0.5741       188
weighted avg     0.6882    0.6649    0.6556       188


========== Train Epoch 39 ==========
Loss: 0.020	Accuracy: 70.74%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.7000    0.6667    0.6829        21
         hdx     0.5714    0.4211    0.4848        19
         mtx     0.5385    0.4375    0.4828        16
         nqx     0.7222    0.6842    0.7027        19
         qtx     0.8235    0.9032    0.8615        31
         zxx     0.7260    0.8689    0.7910        61

    accuracy                         0.7074       188
   macro avg     0.6724    0.6368    0.6495       188
weighted avg     0.6959    0.7074    0.6965       188


========== Train Epoch 40 ==========
Loss: 0.014	Accuracy: 68.09%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.5714    0.6154        21
         cwx     0.4500    0.8571    0.5902        21
         hdx     0.4545    0.2632    0.3333        19
         mtx     0.4167    0.3125    0.3571        16
         nqx     0.7273    0.4211    0.5333        19
         qtx     0.8125    0.8387    0.8254        31
         zxx     0.8438    0.8852    0.8640        61

    accuracy                         0.6809       188
   macro avg     0.6245    0.5927    0.5884       188
weighted avg     0.6874    0.6809    0.6691       188


========== Train Epoch 41 ==========
Loss: 0.008	Accuracy: 71.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6087    0.6667    0.6364        21
         cwx     0.7000    0.6667    0.6829        21
         hdx     0.3333    0.3158    0.3243        19
         mtx     0.3750    0.3750    0.3750        16
         nqx     0.8000    0.6316    0.7059        19
         qtx     0.8235    0.9032    0.8615        31
         zxx     0.8871    0.9016    0.8943        61

    accuracy                         0.7181       188
   macro avg     0.6468    0.6372    0.6400       188
weighted avg     0.7163    0.7181    0.7156       188


========== Train Epoch 42 ==========
Loss: 0.007	Accuracy: 68.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5556    0.7143    0.6250        21
         cwx     0.7368    0.6667    0.7000        21
         hdx     0.3125    0.2632    0.2857        19
         mtx     0.3333    0.4375    0.3784        16
         nqx     0.7143    0.5263    0.6061        19
         qtx     0.8000    0.9032    0.8485        31
         zxx     0.8929    0.8197    0.8547        61

    accuracy                         0.6862       188
   macro avg     0.6208    0.6187    0.6140       188
weighted avg     0.6981    0.6862    0.6876       188


========== Train Epoch 43 ==========
Loss: 0.007	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.7619    0.6038        21
         cwx     0.6250    0.7143    0.6667        21
         hdx     0.2143    0.1579    0.1818        19
         mtx     0.2727    0.1875    0.2222        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.7568    0.9032    0.8235        31
         zxx     0.9123    0.8525    0.8814        61

    accuracy                         0.6755       188
   macro avg     0.5786    0.5862    0.5721       188
weighted avg     0.6691    0.6755    0.6641       188


========== Train Epoch 44 ==========
Loss: 0.005	Accuracy: 67.55%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5600    0.6667    0.6087        21
         cwx     0.6667    0.5714    0.6154        21
         hdx     0.2778    0.2632    0.2703        19
         mtx     0.3529    0.3750    0.3636        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.7778    0.9032    0.8358        31
         zxx     0.8525    0.8525    0.8525        61

    accuracy                         0.6755       188
   macro avg     0.6081    0.5940    0.5959       188
weighted avg     0.6777    0.6755    0.6726       188


========== Train Epoch 45 ==========
Loss: 0.006	Accuracy: 69.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6000    0.7143    0.6522        21
         cwx     0.6071    0.8095    0.6939        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.4286    0.3750    0.4000        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.7179    0.9032    0.8000        31
         zxx     0.8814    0.8525    0.8667        61

    accuracy                         0.6968       188
   macro avg     0.6149    0.6198    0.6064       188
weighted avg     0.6837    0.6968    0.6816       188


========== Train Epoch 46 ==========
Loss: 0.017	Accuracy: 61.70%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3036    0.8095    0.4416        21
         cwx     0.6364    0.3333    0.4375        21
         hdx     0.4706    0.4211    0.4444        19
         mtx     0.5000    0.1250    0.2000        16
         nqx     0.6429    0.4737    0.5455        19
         qtx     0.8667    0.8387    0.8525        31
         zxx     0.8393    0.7705    0.8034        61

    accuracy                         0.6170       188
   macro avg     0.6085    0.5388    0.5321       188
weighted avg     0.6753    0.6170    0.6165       188


========== Train Epoch 47 ==========
Loss: 0.082	Accuracy: 55.85%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.1905    0.2963        21
         cwx     0.2812    0.8571    0.4235        21
         hdx     0.5000    0.0526    0.0952        19
         mtx     0.6667    0.1250    0.2105        16
         nqx     0.7500    0.4737    0.5806        19
         qtx     0.8947    0.5484    0.6800        31
         zxx     0.6585    0.8852    0.7552        61

    accuracy                         0.5585       188
   macro avg     0.6311    0.4475    0.4345       188
weighted avg     0.6502    0.5585    0.5238       188


========== Train Epoch 48 ==========
Loss: 0.040	Accuracy: 60.11%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3214    0.8571    0.4675        21
         cwx     0.7500    0.4286    0.5455        21
         hdx     0.3333    0.2105    0.2581        19
         mtx     0.2500    0.1875    0.2143        16
         nqx     0.7143    0.2632    0.3846        19
         qtx     0.7576    0.8065    0.7812        31
         zxx     0.8750    0.8033    0.8376        61

    accuracy                         0.6011       188
   macro avg     0.5717    0.5081    0.4984       188
weighted avg     0.6557    0.6011    0.5969       188


========== Train Epoch 49 ==========
Loss: 0.028	Accuracy: 61.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3103    0.8571    0.4557        21
         cwx     0.9091    0.4762    0.6250        21
         hdx     0.5000    0.1053    0.1739        19
         mtx     0.2500    0.3125    0.2778        16
         nqx     0.7273    0.4211    0.5333        19
         qtx     0.8000    0.9032    0.8485        31
         zxx     0.9184    0.7377    0.8182        61

    accuracy                         0.6170       188
   macro avg     0.6307    0.5447    0.5332       188
weighted avg     0.7114    0.6170    0.6212       188


========== Train Epoch 50 ==========
Loss: 0.027	Accuracy: 60.64%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3019    0.7619    0.4324        21
         cwx     0.4375    0.6667    0.5283        21
         hdx     0.2000    0.0526    0.0833        19
         mtx     0.4000    0.1250    0.1905        16
         nqx     0.7273    0.4211    0.5333        19
         qtx     0.8519    0.7419    0.7931        31
         zxx     0.9091    0.8197    0.8621        61

    accuracy                         0.6064       188
   macro avg     0.5468    0.5127    0.4890       188
weighted avg     0.6458    0.6064    0.5963       188


========== Train Epoch 51 ==========
Loss: 0.015	Accuracy: 69.15%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5909    0.6190    0.6047        21
         cwx     0.5862    0.8095    0.6800        21
         hdx     0.3333    0.1053    0.1600        19
         mtx     0.4000    0.6250    0.4878        16
         nqx     0.7778    0.3684    0.5000        19
         qtx     0.7941    0.8710    0.8308        31
         zxx     0.8571    0.8852    0.8710        61

    accuracy                         0.6915       188
   macro avg     0.6199    0.6119    0.5906       188
weighted avg     0.6869    0.6915    0.6713       188


========== Train Epoch 52 ==========
Loss: 0.011	Accuracy: 71.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.7143    0.6522        21
         cwx     0.6400    0.7619    0.6957        21
         hdx     0.3103    0.4737    0.3750        19
         mtx     0.7500    0.1875    0.3000        16
         nqx     0.7143    0.7895    0.7500        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.9623    0.8361    0.8947        61

    accuracy                         0.7181       188
   macro avg     0.6879    0.6574    0.6438       188
weighted avg     0.7564    0.7181    0.7184       188


========== Train Epoch 53 ==========
Loss: 0.008	Accuracy: 70.74%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5789    0.5238    0.5500        21
         cwx     0.6000    0.7143    0.6522        21
         hdx     0.4091    0.4737    0.4390        19
         mtx     0.5000    0.3125    0.3846        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.8438    0.8710    0.8571        31
         zxx     0.8358    0.9180    0.8750        61

    accuracy                         0.7074       188
   macro avg     0.6481    0.6199    0.6261       188
weighted avg     0.7037    0.7074    0.6998       188


========== Train Epoch 54 ==========
Loss: 0.009	Accuracy: 69.15%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.7619    0.6038        21
         cwx     0.7778    0.6667    0.7179        21
         hdx     0.3333    0.1579    0.2143        19
         mtx     0.3182    0.4375    0.3684        16
         nqx     0.7222    0.6842    0.7027        19
         qtx     0.8000    0.9032    0.8485        31
         zxx     0.9074    0.8033    0.8522        61

    accuracy                         0.6915       188
   macro avg     0.6227    0.6307    0.6154       188
weighted avg     0.7028    0.6915    0.6881       188


========== Train Epoch 55 ==========
Loss: 0.020	Accuracy: 69.15%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5556    0.7143    0.6250        21
         cwx     0.5333    0.7619    0.6275        21
         hdx     0.4000    0.2105    0.2759        19
         mtx     0.5556    0.3125    0.4000        16
         nqx     0.7778    0.7368    0.7568        19
         qtx     0.8276    0.7742    0.8000        31
         zxx     0.8000    0.8525    0.8254        61

    accuracy                         0.6915       188
   macro avg     0.6357    0.6232    0.6158       188
weighted avg     0.6840    0.6915    0.6780       188


========== Train Epoch 56 ==========
Loss: 0.015	Accuracy: 65.96%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4643    0.6190    0.5306        21
         cwx     0.8000    0.3810    0.5161        21
         hdx     0.3043    0.3684    0.3333        19
         mtx     0.4444    0.2500    0.3200        16
         nqx     0.7500    0.6316    0.6857        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.7910    0.8689    0.8281        61

    accuracy                         0.6596       188
   macro avg     0.6179    0.5700    0.5760       188
weighted avg     0.6695    0.6596    0.6508       188


========== Train Epoch 57 ==========
Loss: 0.033	Accuracy: 40.43%	Cost 33s
              precision    recall  f1-score   support

         bzx     1.0000    0.0476    0.0909        21
         cwx     0.7500    0.2857    0.4138        21
         hdx     0.0667    0.0526    0.0588        19
         mtx     0.1250    0.5625    0.2045        16
         nqx     1.0000    0.1053    0.1905        19
         qtx     0.4590    0.9032    0.6087        31
         zxx     1.0000    0.4754    0.6444        61

    accuracy                         0.4043       188
   macro avg     0.6287    0.3475    0.3160       188
weighted avg     0.7141    0.4043    0.4085       188


========== Train Epoch 58 ==========
Loss: 0.095	Accuracy: 59.04%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6923    0.4286    0.5294        21
         cwx     0.3778    0.8095    0.5152        21
         hdx     0.5000    0.2632    0.3448        19
         mtx     0.2308    0.1875    0.2069        16
         nqx     0.8333    0.5263    0.6452        19
         qtx     0.9091    0.3226    0.4762        31
         zxx     0.6786    0.9344    0.7862        61

    accuracy                         0.5904       188
   macro avg     0.6031    0.4960    0.5005       188
weighted avg     0.6440    0.5904    0.5680       188


========== Train Epoch 59 ==========
Loss: 0.137	Accuracy: 50.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.2299    0.9524    0.3704        21
         hdx     0.2000    0.0526    0.0833        19
         mtx     0.5000    0.1875    0.2727        16
         nqx     1.0000    0.0526    0.1000        19
         qtx     0.6857    0.7742    0.7273        31
         zxx     0.9211    0.5738    0.7071        61

    accuracy                         0.5000       188
   macro avg     0.5945    0.4385    0.4002       188
weighted avg     0.6712    0.5000    0.4928       188


========== Train Epoch 60 ==========
Loss: 0.074	Accuracy: 65.96%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5769    0.7143    0.6383        21
         cwx     0.4500    0.8571    0.5902        21
         hdx     0.5000    0.1053    0.1739        19
         mtx     0.3333    0.2500    0.2857        16
         nqx     0.8000    0.2105    0.3333        19
         qtx     0.7000    0.9032    0.7887        31
         zxx     0.8689    0.8689    0.8689        61

    accuracy                         0.6596       188
   macro avg     0.6042    0.5585    0.5256       188
weighted avg     0.6718    0.6596    0.6248       188


========== Train Epoch 61 ==========
Loss: 0.042	Accuracy: 62.77%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5714    0.7619    0.6531        21
         cwx     0.6667    0.3810    0.4848        21
         hdx     0.5000    0.2105    0.2963        19
         mtx     0.1500    0.3750    0.2143        16
         nqx     0.6667    0.4211    0.5161        19
         qtx     0.8929    0.8065    0.8475        31
         zxx     0.8500    0.8361    0.8430        61

    accuracy                         0.6277       188
   macro avg     0.6139    0.5417    0.5507       188
weighted avg     0.6920    0.6277    0.6407       188


========== Train Epoch 62 ==========
Loss: 0.026	Accuracy: 66.49%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7500    0.2857    0.4138        21
         cwx     0.7500    0.7143    0.7317        21
         hdx     0.3226    0.5263    0.4000        19
         mtx     0.2333    0.4375    0.3043        16
         nqx     0.7857    0.5789    0.6667        19
         qtx     0.8667    0.8387    0.8525        31
         zxx     0.9091    0.8197    0.8621        61

    accuracy                         0.6649       188
   macro avg     0.6596    0.6002    0.6044       188
weighted avg     0.7373    0.6649    0.6819       188


========== Train Epoch 63 ==========
Loss: 0.017	Accuracy: 71.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4848    0.7619    0.5926        21
         cwx     0.6923    0.8571    0.7660        21
         hdx     0.5000    0.4211    0.4571        19
         mtx     0.5000    0.2500    0.3333        16
         nqx     0.7333    0.5789    0.6471        19
         qtx     0.8182    0.8710    0.8438        31
         zxx     0.8947    0.8361    0.8644        61

    accuracy                         0.7181       188
   macro avg     0.6605    0.6537    0.6435       188
weighted avg     0.7239    0.7181    0.7113       188


========== Train Epoch 64 ==========
Loss: 0.021	Accuracy: 62.77%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4359    0.8095    0.5667        21
         cwx     0.9000    0.4286    0.5806        21
         hdx     0.1818    0.2105    0.1951        19
         mtx     0.2500    0.3125    0.2778        16
         nqx     0.8333    0.5263    0.6452        19
         qtx     0.7500    0.8710    0.8060        31
         zxx     0.9388    0.7541    0.8364        61

    accuracy                         0.6277       188
   macro avg     0.6128    0.5589    0.5582       188
weighted avg     0.7014    0.6277    0.6410       188


Finished training!!!

Min Loss = 0.005 in epoch 43;
Max Accuracy = 71.81% in epoch 26;
Total Cost 35 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP(
    (pool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    (pool2): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)
    (pool3): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
  )
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.3191489361702128, 0.3829787234042553, 0.43617021276595747, 0.48404255319148937, 0.5212765957446809, 0.39893617021276595, 0.5585106382978723, 0.5212765957446809, 0.6436170212765957, 0.46808510638297873, 0.5851063829787234, 0.5425531914893617, 0.6382978723404256, 0.6223404255319149, 0.6542553191489362, 0.6117021276595744, 0.601063829787234, 0.601063829787234, 0.675531914893617, 0.648936170212766, 0.6702127659574468, 0.675531914893617, 0.675531914893617, 0.675531914893617, 0.675531914893617, 0.6968085106382979, 0.7180851063829787, 0.675531914893617, 0.6968085106382979, 0.574468085106383, 0.6436170212765957, 0.5957446808510638, 0.526595744680851, 0.34574468085106386, 0.5797872340425532, 0.6702127659574468, 0.6648936170212766, 0.6648936170212766, 0.7074468085106383, 0.6808510638297872, 0.7180851063829787, 0.6861702127659575, 0.675531914893617, 0.675531914893617, 0.6968085106382979, 0.6170212765957447, 0.5585106382978723, 0.601063829787234, 0.6170212765957447, 0.6063829787234043, 0.6914893617021277, 0.7180851063829787, 0.7074468085106383, 0.6914893617021277, 0.6914893617021277, 0.6595744680851063, 0.40425531914893614, 0.5904255319148937, 0.5, 0.6595744680851063, 0.6276595744680851, 0.6648936170212766, 0.7180851063829787, 0.6276595744680851]
