dataset_path: /home/djy/dataset/dataset
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset
msg: cbam spp resnet18_alexnet
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.816	Accuracy: 32.45%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        21
         cwx     0.0000    0.0000    0.0000        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.0000    0.0000    0.0000        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.0000    0.0000    0.0000        31
         zxx     0.3297    1.0000    0.4959        61

    accuracy                         0.3245       188
   macro avg     0.0471    0.1429    0.0708       188
weighted avg     0.1070    0.3245    0.1609       188


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.606	Accuracy: 36.17%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4000    0.1905    0.2581        21
         cwx     0.3333    0.0952    0.1481        21
         hdx     0.2000    0.2105    0.2051        19
         mtx     0.0000    0.0000    0.0000        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.3143    0.7097    0.4356        31
         zxx     0.4444    0.5902    0.5070        61

    accuracy                         0.3617       188
   macro avg     0.2417    0.2566    0.2220       188
weighted avg     0.2982    0.3617    0.3025       188


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.484	Accuracy: 40.96%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2174    0.4762    0.2985        21
         cwx     0.5000    0.1429    0.2222        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.1000    0.0625    0.0769        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.8000    0.3871    0.5217        31
         zxx     0.4857    0.8361    0.6145        61

    accuracy                         0.4096       188
   macro avg     0.3004    0.2721    0.2477       188
weighted avg     0.3782    0.4096    0.3501       188


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.355	Accuracy: 53.72%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.4074    0.5238    0.4583        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.3077    0.2500    0.2759        16
         nqx     0.3824    0.6842    0.4906        19
         qtx     0.7000    0.4516    0.5490        31
         zxx     0.6765    0.7541    0.7132        61

    accuracy                         0.5372       188
   macro avg     0.4856    0.4711    0.4621       188
weighted avg     0.5454    0.5372    0.5275       188


========== Train Epoch 5 ==========
Loss: 1.268	Accuracy: 57.45%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.7143    0.2381    0.3571        21
         hdx     0.5000    0.0526    0.0952        19
         mtx     0.4444    0.2500    0.3200        16
         nqx     0.3500    0.7368    0.4746        19
         qtx     0.7241    0.6774    0.7000        31
         zxx     0.6235    0.8689    0.7260        61

    accuracy                         0.5745       188
   macro avg     0.5688    0.4714    0.4591       188
weighted avg     0.5951    0.5745    0.5361       188


========== Train Epoch 6 ==========
Loss: 1.181	Accuracy: 56.38%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4848    0.7619    0.5926        21
         cwx     0.7500    0.1429    0.2400        21
         hdx     0.0714    0.0526    0.0606        19
         mtx     0.2500    0.5000    0.3333        16
         nqx     0.4783    0.5789    0.5238        19
         qtx     0.8261    0.6129    0.7037        31
         zxx     0.8136    0.7869    0.8000        61

    accuracy                         0.5638       188
   macro avg     0.5249    0.4909    0.4649       188
weighted avg     0.6150    0.5638    0.5560       188


========== Train Epoch 7 ==========
Loss: 1.062	Accuracy: 53.72%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4828    0.6667    0.5600        21
         cwx     0.6667    0.1905    0.2963        21
         hdx     0.0769    0.1579    0.1034        19
         mtx     0.2308    0.1875    0.2069        16
         nqx     0.7857    0.5789    0.6667        19
         qtx     0.8235    0.4516    0.5833        31
         zxx     0.7429    0.8525    0.7939        61

    accuracy                         0.5372       188
   macro avg     0.5442    0.4408    0.4586       188
weighted avg     0.6120    0.5372    0.5449       188


========== Train Epoch 8 ==========
Loss: 0.973	Accuracy: 55.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4783    0.5238    0.5000        21
         cwx     0.5000    0.2381    0.3226        21
         hdx     0.1429    0.0526    0.0769        19
         mtx     0.1923    0.3125    0.2381        16
         nqx     0.4103    0.8421    0.5517        19
         qtx     0.8889    0.5161    0.6531        31
         zxx     0.7692    0.8197    0.7937        61

    accuracy                         0.5532       188
   macro avg     0.4831    0.4721    0.4480       188
weighted avg     0.5777    0.5532    0.5409       188


========== Train Epoch 9 ==========
Loss: 0.821	Accuracy: 52.13%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4706    0.3810    0.4211        21
         cwx     0.6667    0.2857    0.4000        21
         hdx     0.2000    0.0526    0.0833        19
         mtx     0.2759    0.5000    0.3556        16
         nqx     0.7500    0.1579    0.2609        19
         qtx     0.9333    0.4516    0.6087        31
         zxx     0.5321    0.9508    0.6824        61

    accuracy                         0.5213       188
   macro avg     0.5469    0.3971    0.4017       188
weighted avg     0.5731    0.5213    0.4785       188


========== Train Epoch 10 ==========
Loss: 0.699	Accuracy: 55.85%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3478    0.7619    0.4776        21
         cwx     0.4333    0.6190    0.5098        21
         hdx     0.2500    0.3158    0.2791        19
         mtx     0.3333    0.2500    0.2857        16
         nqx     0.6875    0.5789    0.6286        19
         qtx     0.8276    0.7742    0.8000        31
         zxx     1.0000    0.5082    0.6739        61

    accuracy                         0.5585       188
   macro avg     0.5542    0.5440    0.5221       188
weighted avg     0.6713    0.5585    0.5769       188


========== Train Epoch 11 ==========
Loss: 0.600	Accuracy: 54.79%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7500    0.1429    0.2400        21
         cwx     0.8889    0.3810    0.5333        21
         hdx     0.2273    0.2632    0.2439        19
         mtx     0.1842    0.4375    0.2593        16
         nqx     0.4194    0.6842    0.5200        19
         qtx     0.8500    0.5484    0.6667        31
         zxx     0.7812    0.8197    0.8000        61

    accuracy                         0.5479       188
   macro avg     0.5859    0.4681    0.4662       188
weighted avg     0.6577    0.5479    0.5552       188


========== Train Epoch 12 ==========
Loss: 0.461	Accuracy: 63.83%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5152    0.8095    0.6296        21
         cwx     0.6667    0.3810    0.4848        21
         hdx     0.1333    0.1053    0.1176        19
         mtx     0.3182    0.4375    0.3684        16
         nqx     0.6250    0.5263    0.5714        19
         qtx     0.7222    0.8387    0.7761        31
         zxx     0.9259    0.8197    0.8696        61

    accuracy                         0.6383       188
   macro avg     0.5581    0.5597    0.5454       188
weighted avg     0.6553    0.6383    0.6356       188


========== Train Epoch 13 ==========
Loss: 0.357	Accuracy: 64.89%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6522    0.7143    0.6818        21
         cwx     0.6667    0.5714    0.6154        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.2727    0.5625    0.3673        16
         nqx     0.5217    0.6316    0.5714        19
         qtx     0.8000    0.7742    0.7869        31
         zxx     0.9259    0.8197    0.8696        61

    accuracy                         0.6489       188
   macro avg     0.5485    0.5820    0.5561       188
weighted avg     0.6556    0.6489    0.6458       188


========== Train Epoch 14 ==========
Loss: 0.288	Accuracy: 60.11%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6923    0.4286    0.5294        21
         cwx     0.6190    0.6190    0.6190        21
         hdx     0.2667    0.2105    0.2353        19
         mtx     0.3333    0.2500    0.2857        16
         nqx     0.3636    0.8421    0.5079        19
         qtx     0.8889    0.5161    0.6531        31
         zxx     0.7846    0.8361    0.8095        61

    accuracy                         0.6011       188
   macro avg     0.5641    0.5289    0.5200       188
weighted avg     0.6397    0.6011    0.5981       188


========== Train Epoch 15 ==========
Loss: 0.247	Accuracy: 51.60%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3846    0.7143    0.5000        21
         cwx     0.6000    0.1429    0.2308        21
         hdx     0.1064    0.2632    0.1515        19
         mtx     0.3333    0.1250    0.1818        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.7600    0.6129    0.6786        31
         zxx     0.8030    0.8689    0.8346        61

    accuracy                         0.5160       188
   macro avg     0.4268    0.3896    0.3682       188
weighted avg     0.5350    0.5160    0.4951       188


========== Train Epoch 16 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.158	Accuracy: 54.26%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7059    0.5714    0.6316        21
         cwx     0.7500    0.2857    0.4138        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.1512    0.8125    0.2549        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     1.0000    0.5806    0.7347        31
         zxx     0.8983    0.8689    0.8833        61

    accuracy                         0.5426       188
   macro avg     0.5008    0.4456    0.4169       188
weighted avg     0.6319    0.5426    0.5462       188


========== Train Epoch 17 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.131	Accuracy: 61.17%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6471    0.5238    0.5789        21
         cwx     0.6111    0.5238    0.5641        21
         hdx     0.4286    0.1579    0.2308        19
         mtx     0.2000    0.7500    0.3158        16
         nqx     0.7500    0.1579    0.2609        19
         qtx     0.8333    0.8065    0.8197        31
         zxx     0.9615    0.8197    0.8850        61

    accuracy                         0.6117       188
   macro avg     0.6331    0.5342    0.5222       188
weighted avg     0.7261    0.6117    0.6265       188


========== Train Epoch 18 ==========
Loss: 0.103	Accuracy: 65.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6087    0.6667    0.6364        21
         cwx     0.7333    0.5238    0.6111        21
         hdx     0.4286    0.1579    0.2308        19
         mtx     0.2439    0.6250    0.3509        16
         nqx     0.7778    0.3684    0.5000        19
         qtx     0.9259    0.8065    0.8621        31
         zxx     0.8030    0.8689    0.8346        61

    accuracy                         0.6543       188
   macro avg     0.6459    0.5739    0.5751       188
weighted avg     0.7058    0.6543    0.6560       188


========== Train Epoch 19 ==========
Loss: 0.105	Accuracy: 63.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6154    0.7619    0.6809        21
         cwx     0.5517    0.7619    0.6400        21
         hdx     0.2500    0.0526    0.0870        19
         mtx     0.2759    0.5000    0.3556        16
         nqx     1.0000    0.0526    0.1000        19
         qtx     0.6136    0.8710    0.7200        31
         zxx     0.9091    0.8197    0.8621        61

    accuracy                         0.6330       188
   macro avg     0.6022    0.5457    0.4922       188
weighted avg     0.6763    0.6330    0.5951       188


========== Train Epoch 20 ==========
Loss: 0.096	Accuracy: 67.02%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5789    0.5238    0.5500        21
         cwx     0.4857    0.8095    0.6071        21
         hdx     0.3333    0.0526    0.0909        19
         mtx     0.4286    0.3750    0.4000        16
         nqx     0.9091    0.5263    0.6667        19
         qtx     0.7941    0.8710    0.8308        31
         zxx     0.7500    0.8852    0.8120        61

    accuracy                         0.6702       188
   macro avg     0.6114    0.5776    0.5654       188
weighted avg     0.6553    0.6702    0.6403       188


========== Train Epoch 21 ==========
Loss: 0.049	Accuracy: 63.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.9091    0.4762    0.6250        21
         cwx     0.6154    0.3810    0.4706        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.3478    0.5000    0.4103        16
         nqx     0.7692    0.5263    0.6250        19
         qtx     0.8571    0.7742    0.8136        31
         zxx     0.6222    0.9180    0.7417        61

    accuracy                         0.6330       188
   macro avg     0.6316    0.5334    0.5561       188
weighted avg     0.6512    0.6330    0.6162       188


========== Train Epoch 22 ==========
Loss: 0.050	Accuracy: 63.83%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.4762    0.5556        21
         cwx     0.4615    0.5714    0.5106        21
         hdx     0.5000    0.0526    0.0952        19
         mtx     0.3333    0.3125    0.3226        16
         nqx     0.5882    0.5263    0.5556        19
         qtx     0.8056    0.9355    0.8657        31
         zxx     0.6883    0.8689    0.7681        61

    accuracy                         0.6383       188
   macro avg     0.5777    0.5348    0.5248       188
weighted avg     0.6205    0.6383    0.6043       188


========== Train Epoch 23 ==========
Loss: 0.058	Accuracy: 60.64%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6250    0.4762    0.5405        21
         cwx     0.8750    0.3333    0.4828        21
         hdx     0.2195    0.4737    0.3000        19
         mtx     0.2000    0.3125    0.2439        16
         nqx     0.8000    0.4211    0.5517        19
         qtx     0.8000    0.7742    0.7869        31
         zxx     0.8793    0.8361    0.8571        61

    accuracy                         0.6064       188
   macro avg     0.6284    0.5181    0.5376       188
weighted avg     0.7048    0.6064    0.6290       188


========== Train Epoch 24 ==========
Loss: 0.053	Accuracy: 68.09%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.5714    0.6154        21
         cwx     0.6667    0.6667    0.6667        21
         hdx     0.2500    0.3684    0.2979        19
         mtx     0.4444    0.2500    0.3200        16
         nqx     0.6500    0.6842    0.6667        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.8525    0.8525    0.8525        61

    accuracy                         0.6809       188
   macro avg     0.6241    0.6046    0.6083       188
weighted avg     0.6926    0.6809    0.6828       188


========== Train Epoch 25 ==========
Loss: 0.060	Accuracy: 64.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7857    0.5238    0.6286        21
         cwx     0.7500    0.5714    0.6486        21
         hdx     1.0000    0.0526    0.1000        19
         mtx     0.2558    0.6875    0.3729        16
         nqx     0.7273    0.4211    0.5333        19
         qtx     0.8621    0.8065    0.8333        31
         zxx     0.7297    0.8852    0.8000        61

    accuracy                         0.6489       188
   macro avg     0.7301    0.5640    0.5595       188
weighted avg     0.7468    0.6489    0.6354       188


========== Train Epoch 26 ==========
Loss: 0.042	Accuracy: 67.02%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7273    0.7619    0.7442        21
         cwx     0.6087    0.6667    0.6364        21
         hdx     0.2667    0.2105    0.2353        19
         mtx     0.2500    0.5000    0.3333        16
         nqx     0.7143    0.5263    0.6061        19
         qtx     0.8065    0.8065    0.8065        31
         zxx     0.9608    0.8033    0.8750        61

    accuracy                         0.6702       188
   macro avg     0.6192    0.6107    0.6052       188
weighted avg     0.7144    0.6702    0.6845       188


========== Train Epoch 27 ==========
Loss: 0.028	Accuracy: 68.09%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7692    0.4762    0.5882        21
         cwx     0.7143    0.4762    0.5714        21
         hdx     0.3333    0.3684    0.3500        19
         mtx     0.3529    0.3750    0.3636        16
         nqx     0.5000    0.8947    0.6415        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.9444    0.8361    0.8870        61

    accuracy                         0.6809       188
   macro avg     0.6265    0.6139    0.6028       188
weighted avg     0.7136    0.6809    0.6834       188


========== Train Epoch 28 ==========
Loss: 0.027	Accuracy: 63.83%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.7619    0.7111        21
         cwx     0.8750    0.3333    0.4828        21
         hdx     0.1667    0.0526    0.0800        19
         mtx     0.1667    0.5000    0.2500        16
         nqx     0.8462    0.5789    0.6875        19
         qtx     0.9231    0.7742    0.8421        31
         zxx     0.8413    0.8689    0.8548        61

    accuracy                         0.6383       188
   macro avg     0.6408    0.5528    0.5583       188
weighted avg     0.7139    0.6383    0.6484       188


========== Train Epoch 29 ==========
Loss: 0.024	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6842    0.6190    0.6500        21
         cwx     0.5714    0.7619    0.6531        21
         hdx     0.4000    0.1053    0.1667        19
         mtx     0.3333    0.3750    0.3529        16
         nqx     0.7143    0.5263    0.6061        19
         qtx     0.7368    0.9032    0.8116        31
         zxx     0.7879    0.8525    0.8189        61

    accuracy                         0.6755       188
   macro avg     0.6040    0.5919    0.5799       188
weighted avg     0.6584    0.6755    0.6532       188


========== Train Epoch 30 ==========
Loss: 0.013	Accuracy: 67.02%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7500    0.5714    0.6486        21
         cwx     0.7143    0.7143    0.7143        21
         hdx     0.2222    0.2105    0.2162        19
         mtx     0.2778    0.3125    0.2941        16
         nqx     0.6667    0.6316    0.6486        19
         qtx     0.8125    0.8387    0.8254        31
         zxx     0.8000    0.8525    0.8254        61

    accuracy                         0.6702       188
   macro avg     0.6062    0.5902    0.5961       188
weighted avg     0.6706    0.6702    0.6686       188


========== Train Epoch 31 ==========
Loss: 0.014	Accuracy: 68.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7500    0.7143    0.7317        21
         cwx     0.6957    0.7619    0.7273        21
         hdx     0.5000    0.1579    0.2400        19
         mtx     0.3182    0.4375    0.3684        16
         nqx     0.7500    0.4737    0.5806        19
         qtx     0.6222    0.9032    0.7368        31
         zxx     0.8500    0.8361    0.8430        61

    accuracy                         0.6862       188
   macro avg     0.6409    0.6121    0.6040       188
weighted avg     0.6933    0.6862    0.6723       188


========== Train Epoch 32 ==========
Loss: 0.012	Accuracy: 67.02%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.5714    0.6154        21
         cwx     0.7647    0.6190    0.6842        21
         hdx     0.2727    0.1579    0.2000        19
         mtx     0.2414    0.4375    0.3111        16
         nqx     0.6875    0.5789    0.6286        19
         qtx     0.8438    0.8710    0.8571        31
         zxx     0.8154    0.8689    0.8413        61

    accuracy                         0.6702       188
   macro avg     0.6132    0.5864    0.5911       188
weighted avg     0.6812    0.6702    0.6697       188


========== Train Epoch 33 ==========
Loss: 0.017	Accuracy: 68.09%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8125    0.6190    0.7027        21
         cwx     0.5926    0.7619    0.6667        21
         hdx     0.2500    0.1579    0.1935        19
         mtx     0.2857    0.3750    0.3243        16
         nqx     0.7333    0.5789    0.6471        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.8387    0.8525    0.8455        61

    accuracy                         0.6809       188
   macro avg     0.6120    0.6023    0.5997       188
weighted avg     0.6800    0.6809    0.6748       188


========== Train Epoch 34 ==========
Loss: 0.087	Accuracy: 59.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4800    0.5714    0.5217        21
         cwx     0.7500    0.4286    0.5455        21
         hdx     0.1622    0.3158    0.2143        19
         mtx     0.5000    0.3750    0.4286        16
         nqx     0.8333    0.2632    0.4000        19
         qtx     0.8148    0.7097    0.7586        31
         zxx     0.7536    0.8525    0.8000        61

    accuracy                         0.5957       188
   macro avg     0.6134    0.5023    0.5241       188
weighted avg     0.6594    0.5957    0.6024       188


========== Train Epoch 35 ==========
Loss: 0.120	Accuracy: 63.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5172    0.7143    0.6000        21
         cwx     0.6667    0.7619    0.7111        21
         hdx     0.0000    0.0000    0.0000        19
         mtx     0.2059    0.4375    0.2800        16
         nqx     1.0000    0.2105    0.3478        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.8475    0.8197    0.8333        61

    accuracy                         0.6330       188
   macro avg     0.5727    0.5450    0.5129       188
weighted avg     0.6530    0.6330    0.6107       188


========== Train Epoch 36 ==========
Loss: 0.099	Accuracy: 59.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8182    0.4286    0.5625        21
         cwx     0.4857    0.8095    0.6071        21
         hdx     0.2500    0.1053    0.1481        19
         mtx     0.2000    0.6875    0.3099        16
         nqx     1.0000    0.1579    0.2727        19
         qtx     0.9500    0.6129    0.7451        31
         zxx     0.9107    0.8361    0.8718        61

    accuracy                         0.5957       188
   macro avg     0.6592    0.5197    0.5025       188
weighted avg     0.7411    0.5957    0.6053       188


========== Train Epoch 37 ==========
Loss: 0.055	Accuracy: 63.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     1.0000    0.2857    0.4444        21
         cwx     0.8667    0.6190    0.7222        21
         hdx     0.1667    0.0526    0.0800        19
         mtx     0.1860    0.5000    0.2712        16
         nqx     0.5357    0.7895    0.6383        19
         qtx     0.9259    0.8065    0.8621        31
         zxx     0.8095    0.8361    0.8226        61

    accuracy                         0.6330       188
   macro avg     0.6415    0.5556    0.5487       188
weighted avg     0.7107    0.6330    0.6350       188


========== Train Epoch 38 ==========
Loss: 0.056	Accuracy: 63.83%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8462    0.5238    0.6471        21
         cwx     0.7273    0.3810    0.5000        21
         hdx     0.1951    0.4211    0.2667        19
         mtx     0.4000    0.5000    0.4444        16
         nqx     0.7143    0.5263    0.6061        19
         qtx     0.8065    0.8065    0.8065        31
         zxx     0.8621    0.8197    0.8403        61

    accuracy                         0.6383       188
   macro avg     0.6502    0.5683    0.5873       188
weighted avg     0.7144    0.6383    0.6598       188


========== Train Epoch 39 ==========
Loss: 0.044	Accuracy: 61.70%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8750    0.6667    0.7568        21
         cwx     0.7000    0.3333    0.4516        21
         hdx     0.1818    0.5263    0.2703        19
         mtx     0.3182    0.4375    0.3684        16
         nqx     0.8000    0.4211    0.5517        19
         qtx     0.9130    0.6774    0.7778        31
         zxx     0.9423    0.8033    0.8673        61

    accuracy                         0.6170       188
   macro avg     0.6758    0.5522    0.5777       188
weighted avg     0.7585    0.6170    0.6591       188


========== Train Epoch 40 ==========
Loss: 0.049	Accuracy: 61.70%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8750    0.3333    0.4828        21
         cwx     0.6250    0.4762    0.5405        21
         hdx     0.2222    0.3158    0.2609        19
         mtx     0.2000    0.3125    0.2439        16
         nqx     0.5172    0.7895    0.6250        19
         qtx     0.8182    0.8710    0.8438        31
         zxx     0.9200    0.7541    0.8288        61

    accuracy                         0.6170       188
   macro avg     0.5968    0.5503    0.5465       188
weighted avg     0.6927    0.6170    0.6326       188


========== Train Epoch 41 ==========
Loss: 0.073	Accuracy: 53.72%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6429    0.4286    0.5143        21
         cwx     0.6250    0.4762    0.5405        21
         hdx     0.1818    0.1053    0.1333        19
         mtx     0.1493    0.6250    0.2410        16
         nqx     0.6667    0.4211    0.5161        19
         qtx     0.8400    0.6774    0.7500        31
         zxx     0.9535    0.6721    0.7885        61

    accuracy                         0.5372       188
   macro avg     0.5799    0.4865    0.4977       188
weighted avg     0.6880    0.5372    0.5835       188


========== Train Epoch 42 ==========
Loss: 0.122	Accuracy: 41.49%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3261    0.7143    0.4478        21
         cwx     0.2090    0.6667    0.3182        21
         hdx     0.0435    0.0526    0.0476        19
         mtx     0.0000    0.0000    0.0000        16
         nqx     0.0000    0.0000    0.0000        19
         qtx     0.9444    0.5484    0.6939        31
         zxx     1.0000    0.5082    0.6739        61

    accuracy                         0.4149       188
   macro avg     0.3604    0.3557    0.3116       188
weighted avg     0.5444    0.4149    0.4234       188


========== Train Epoch 43 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.064	Accuracy: 64.36%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.4762    0.5556        21
         cwx     0.8889    0.3810    0.5333        21
         hdx     0.2857    0.1053    0.1538        19
         mtx     0.2500    0.5000    0.3333        16
         nqx     0.7333    0.5789    0.6471        19
         qtx     0.9615    0.8065    0.8772        31
         zxx     0.6786    0.9344    0.7862        61

    accuracy                         0.6436       188
   macro avg     0.6378    0.5403    0.5552       188
weighted avg     0.6768    0.6436    0.6307       188


========== Train Epoch 44 ==========
Loss: 0.025	Accuracy: 68.09%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.6667    0.6667        21
         cwx     0.6250    0.7143    0.6667        21
         hdx     0.2667    0.2105    0.2353        19
         mtx     0.2500    0.1875    0.2143        16
         nqx     0.5556    0.7895    0.6522        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.9259    0.8197    0.8696        61

    accuracy                         0.6809       188
   macro avg     0.5802    0.6084    0.5890       188
weighted avg     0.6763    0.6809    0.6739       188


========== Train Epoch 45 ==========
Loss: 0.013	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7857    0.5238    0.6286        21
         cwx     0.6667    0.6667    0.6667        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.2857    0.3750    0.3243        16
         nqx     0.6190    0.6842    0.6500        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.8030    0.8689    0.8346        61

    accuracy                         0.6755       188
   macro avg     0.6045    0.5925    0.5899       188
weighted avg     0.6672    0.6755    0.6646       188


========== Train Epoch 46 ==========
Loss: 0.009	Accuracy: 65.96%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6316    0.5714    0.6000        21
         cwx     0.5000    0.7143    0.5882        21
         hdx     0.3333    0.1579    0.2143        19
         mtx     0.2800    0.4375    0.3415        16
         nqx     0.7647    0.6842    0.7222        19
         qtx     1.0000    0.6452    0.7843        31
         zxx     0.7941    0.8852    0.8372        61

    accuracy                         0.6596       188
   macro avg     0.6148    0.5851    0.5840       188
weighted avg     0.6838    0.6596    0.6574       188


========== Train Epoch 47 ==========
Loss: 0.006	Accuracy: 68.09%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5882    0.4762    0.5263        21
         cwx     0.7000    0.6667    0.6829        21
         hdx     0.3750    0.1579    0.2222        19
         mtx     0.3333    0.4375    0.3784        16
         nqx     0.7222    0.6842    0.7027        19
         qtx     0.7714    0.8710    0.8182        31
         zxx     0.7826    0.8852    0.8308        61

    accuracy                         0.6809       188
   macro avg     0.6104    0.5970    0.5945       188
weighted avg     0.6643    0.6809    0.6652       188


========== Train Epoch 48 ==========
Loss: 0.007	Accuracy: 68.62%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6471    0.5238    0.5789        21
         cwx     0.7647    0.6190    0.6842        21
         hdx     0.4286    0.1579    0.2308        19
         mtx     0.3158    0.3750    0.3429        16
         nqx     0.6842    0.6842    0.6842        19
         qtx     0.7778    0.9032    0.8358        31
         zxx     0.7534    0.9016    0.8209        61

    accuracy                         0.6862       188
   macro avg     0.6245    0.5950    0.5968       188
weighted avg     0.6697    0.6862    0.6669       188


========== Train Epoch 49 ==========
Loss: 0.007	Accuracy: 69.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7059    0.5714    0.6316        21
         cwx     0.6522    0.7143    0.6818        21
         hdx     0.3750    0.1579    0.2222        19
         mtx     0.3636    0.5000    0.4211        16
         nqx     0.7647    0.6842    0.7222        19
         qtx     0.7000    0.9032    0.7887        31
         zxx     0.8525    0.8525    0.8525        61

    accuracy                         0.6968       188
   macro avg     0.6306    0.6262    0.6172       188
weighted avg     0.6898    0.6968    0.6846       188


========== Train Epoch 50 ==========
Loss: 0.004	Accuracy: 67.55%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6471    0.5238    0.5789        21
         cwx     0.7000    0.6667    0.6829        21
         hdx     0.2500    0.1579    0.1935        19
         mtx     0.3636    0.5000    0.4211        16
         nqx     0.7857    0.5789    0.6667        19
         qtx     0.7179    0.9032    0.8000        31
         zxx     0.8125    0.8525    0.8320        61

    accuracy                         0.6755       188
   macro avg     0.6110    0.5976    0.5964       188
weighted avg     0.6681    0.6755    0.6656       188


========== Train Epoch 51 ==========
Loss: 0.004	Accuracy: 69.15%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.5714    0.6154        21
         cwx     0.7000    0.6667    0.6829        21
         hdx     0.2308    0.1579    0.1875        19
         mtx     0.3333    0.5000    0.4000        16
         nqx     0.8125    0.6842    0.7429        19
         qtx     0.8438    0.8710    0.8571        31
         zxx     0.8154    0.8689    0.8413        61

    accuracy                         0.6915       188
   macro avg     0.6289    0.6171    0.6182       188
weighted avg     0.6902    0.6915    0.6874       188


========== Train Epoch 52 ==========
Loss: 0.006	Accuracy: 70.74%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6842    0.6190    0.6500        21
         cwx     0.7143    0.7143    0.7143        21
         hdx     0.2500    0.1579    0.1935        19
         mtx     0.3200    0.5000    0.3902        16
         nqx     0.8125    0.6842    0.7429        19
         qtx     0.8485    0.9032    0.8750        31
         zxx     0.8548    0.8689    0.8618        61

    accuracy                         0.7074       188
   macro avg     0.6406    0.6354    0.6325       188
weighted avg     0.7081    0.7074    0.7041       188


========== Train Epoch 53 ==========
Loss: 0.020	Accuracy: 61.17%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6000    0.4286    0.5000        21
         cwx     0.3810    0.7619    0.5079        21
         hdx     1.0000    0.0526    0.1000        19
         mtx     0.3571    0.3125    0.3333        16
         nqx     0.7273    0.4211    0.5333        19
         qtx     0.8000    0.6452    0.7143        31
         zxx     0.7000    0.9180    0.7943        61

    accuracy                         0.6117       188
   macro avg     0.6522    0.5057    0.4976       188
weighted avg     0.6736    0.6117    0.5805       188


========== Train Epoch 54 ==========
Loss: 0.020	Accuracy: 54.79%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8571    0.2857    0.4286        21
         cwx     0.2273    0.9524    0.3670        21
         hdx     1.0000    0.0526    0.1000        19
         mtx     0.3636    0.2500    0.2963        16
         nqx     1.0000    0.2105    0.3478        19
         qtx     0.8519    0.7419    0.7931        31
         zxx     0.9000    0.7377    0.8108        61

    accuracy                         0.5479       188
   macro avg     0.7428    0.4616    0.4491       188
weighted avg     0.7867    0.5479    0.5532       188


========== Train Epoch 55 ==========
Loss: 0.020	Accuracy: 68.09%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5833    0.6667    0.6222        21
         cwx     0.7222    0.6190    0.6667        21
         hdx     0.4000    0.2105    0.2759        19
         mtx     0.3333    0.3750    0.3529        16
         nqx     0.7500    0.6316    0.6857        19
         qtx     0.6905    0.9355    0.7945        31
         zxx     0.8333    0.8197    0.8264        61

    accuracy                         0.6809       188
   macro avg     0.6161    0.6083    0.6035       188
weighted avg     0.6747    0.6809    0.6704       188


========== Train Epoch 56 ==========
Loss: 0.013	Accuracy: 68.09%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8333    0.4762    0.6061        21
         cwx     0.7059    0.5714    0.6316        21
         hdx     0.4000    0.3158    0.3529        19
         mtx     0.2903    0.5625    0.3830        16
         nqx     0.7647    0.6842    0.7222        19
         qtx     0.7647    0.8387    0.8000        31
         zxx     0.8387    0.8525    0.8455        61

    accuracy                         0.6809       188
   macro avg     0.6568    0.6145    0.6202       188
weighted avg     0.7126    0.6809    0.6858       188


========== Train Epoch 57 ==========
Loss: 0.004	Accuracy: 68.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6154    0.3810    0.4706        21
         cwx     0.6818    0.7143    0.6977        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.4667    0.4375    0.4516        16
         nqx     0.7647    0.6842    0.7222        19
         qtx     0.7073    0.9355    0.8056        31
         zxx     0.7714    0.8852    0.8244        61

    accuracy                         0.6862       188
   macro avg     0.6153    0.5994    0.5970       188
weighted avg     0.6592    0.6862    0.6632       188


========== Train Epoch 58 ==========
Loss: 0.005	Accuracy: 69.15%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6875    0.5238    0.5946        21
         cwx     0.6364    0.6667    0.6512        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.4444    0.5000    0.4706        16
         nqx     0.7647    0.6842    0.7222        19
         qtx     0.7000    0.9032    0.7887        31
         zxx     0.8154    0.8689    0.8413        61

    accuracy                         0.6915       188
   macro avg     0.6212    0.6150    0.6108       188
weighted avg     0.6733    0.6915    0.6761       188


========== Train Epoch 59 ==========
Loss: 0.004	Accuracy: 69.68%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6500    0.6190    0.6341        21
         cwx     0.6000    0.7143    0.6522        21
         hdx     0.3333    0.2105    0.2581        19
         mtx     0.3500    0.4375    0.3889        16
         nqx     0.7368    0.7368    0.7368        19
         qtx     0.8182    0.8710    0.8438        31
         zxx     0.8644    0.8361    0.8500        61

    accuracy                         0.6968       188
   macro avg     0.6218    0.6322    0.6234       188
weighted avg     0.6930    0.6968    0.6923       188


========== Train Epoch 60 ==========
Loss: 0.005	Accuracy: 68.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.5714    0.6154        21
         cwx     0.6667    0.6667    0.6667        21
         hdx     0.3333    0.1579    0.2143        19
         mtx     0.2800    0.4375    0.3415        16
         nqx     0.8125    0.6842    0.7429        19
         qtx     0.8000    0.9032    0.8485        31
         zxx     0.8125    0.8525    0.8320        61

    accuracy                         0.6862       188
   macro avg     0.6245    0.6105    0.6087       188
weighted avg     0.6841    0.6862    0.6789       188


========== Train Epoch 61 ==========
Loss: 0.004	Accuracy: 65.43%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.4286    0.5000        21
         cwx     0.6818    0.7143    0.6977        21
         hdx     0.2857    0.2105    0.2424        19
         mtx     0.2727    0.3750    0.3158        16
         nqx     0.7857    0.5789    0.6667        19
         qtx     0.7879    0.8387    0.8125        31
         zxx     0.7647    0.8525    0.8062        61

    accuracy                         0.6543       188
   macro avg     0.5969    0.5712    0.5773       188
weighted avg     0.6527    0.6543    0.6481       188


========== Train Epoch 62 ==========
Loss: 0.006	Accuracy: 64.36%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6923    0.4286    0.5294        21
         cwx     0.6667    0.6667    0.6667        21
         hdx     0.3333    0.1053    0.1600        19
         mtx     0.2632    0.6250    0.3704        16
         nqx     0.6667    0.5263    0.5882        19
         qtx     0.8000    0.7742    0.7869        31
         zxx     0.8000    0.8525    0.8254        61

    accuracy                         0.6436       188
   macro avg     0.6032    0.5684    0.5610       188
weighted avg     0.6667    0.6436    0.6383       188


========== Train Epoch 63 ==========
Loss: 0.009	Accuracy: 63.83%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4000    0.6667    0.5000        21
         cwx     0.7857    0.5238    0.6286        21
         hdx     0.2500    0.0526    0.0870        19
         mtx     0.3077    0.2500    0.2759        16
         nqx     0.7500    0.4737    0.5806        19
         qtx     0.7500    0.7742    0.7619        31
         zxx     0.7308    0.9344    0.8201        61

    accuracy                         0.6383       188
   macro avg     0.5677    0.5251    0.5220       188
weighted avg     0.6205    0.6383    0.6088       188


========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 65.43%	Cost 32s
              precision    recall  f1-score   support

         bzx     1.0000    0.2857    0.4444        21
         cwx     0.6250    0.7143    0.6667        21
         hdx     0.3000    0.1579    0.2069        19
         mtx     0.3529    0.3750    0.3636        16
         nqx     0.6000    0.6316    0.6154        19
         qtx     0.8387    0.8387    0.8387        31
         zxx     0.6875    0.9016    0.7801        61

    accuracy                         0.6543       188
   macro avg     0.6292    0.5578    0.5594       188
weighted avg     0.6639    0.6543    0.6296       188


Finished training!!!

Min Loss = 0.004 in epoch 58;
Max Accuracy = 70.74% in epoch 51;
Total Cost 35 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP(
    (pool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    (pool2): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)
    (pool3): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
  )
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.324468085106383, 0.3617021276595745, 0.4095744680851064, 0.5372340425531915, 0.574468085106383, 0.5638297872340425, 0.5372340425531915, 0.5531914893617021, 0.5212765957446809, 0.5585106382978723, 0.5478723404255319, 0.6382978723404256, 0.648936170212766, 0.601063829787234, 0.5159574468085106, 0.5425531914893617, 0.6117021276595744, 0.6542553191489362, 0.6329787234042553, 0.6702127659574468, 0.6329787234042553, 0.6382978723404256, 0.6063829787234043, 0.6808510638297872, 0.648936170212766, 0.6702127659574468, 0.6808510638297872, 0.6382978723404256, 0.675531914893617, 0.6702127659574468, 0.6861702127659575, 0.6702127659574468, 0.6808510638297872, 0.5957446808510638, 0.6329787234042553, 0.5957446808510638, 0.6329787234042553, 0.6382978723404256, 0.6170212765957447, 0.6170212765957447, 0.5372340425531915, 0.4148936170212766, 0.6436170212765957, 0.6808510638297872, 0.675531914893617, 0.6595744680851063, 0.6808510638297872, 0.6861702127659575, 0.6968085106382979, 0.675531914893617, 0.6914893617021277, 0.7074468085106383, 0.6117021276595744, 0.5478723404255319, 0.6808510638297872, 0.6808510638297872, 0.6861702127659575, 0.6914893617021277, 0.6968085106382979, 0.6861702127659575, 0.6542553191489362, 0.6436170212765957, 0.6382978723404256, 0.6542553191489362]
