dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: cbam spp resnet18_alexnet
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.845	Accuracy: 30.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     0.2000    0.1818    0.1905        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1818    0.3333    0.2353        12
         qtx     0.3750    0.4667    0.4158        45
         zxx     0.3250    0.6667    0.4370        39

    accuracy                         0.3081       185
   macro avg     0.1954    0.2447    0.1977       185
weighted avg     0.2432    0.3081    0.2488       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.667	Accuracy: 29.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2727    0.1935    0.2264        31
         cwx     0.1346    0.3182    0.1892        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.3571    0.4444    0.3960        45
         zxx     0.4286    0.3846    0.4054        39

    accuracy                         0.2973       185
   macro avg     0.2970    0.2617    0.2535       185
weighted avg     0.3191    0.2973    0.2879       185


========== Train Epoch 3 ==========
Loss: 1.518	Accuracy: 42.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.2812    0.4091    0.3333        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.4630    0.5556    0.5051        45
         zxx     0.5200    0.6667    0.5843        39

    accuracy                         0.4216       185
   macro avg     0.3709    0.3478    0.3429       185
weighted avg     0.4072    0.4216    0.4013       185


========== Train Epoch 4 ==========
Loss: 1.427	Accuracy: 43.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2973    0.9167    0.4490        12
         qtx     0.4800    0.5333    0.5053        45
         zxx     0.4638    0.8205    0.5926        39

    accuracy                         0.4324       185
   macro avg     0.5085    0.4061    0.3412       185
weighted avg     0.5019    0.4324    0.3799       185


========== Train Epoch 5 ==========
Loss: 1.312	Accuracy: 45.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3158    0.5806    0.4091        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.8214    0.5111    0.6301        45
         zxx     0.4459    0.8462    0.5841        39

    accuracy                         0.4541       185
   macro avg     0.4217    0.3816    0.3336       185
weighted avg     0.4805    0.4541    0.4025       185


========== Train Epoch 6 ==========
Loss: 1.232	Accuracy: 27.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.1772    0.6364    0.2772        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.1951    0.6667    0.3019        12
         qtx     0.3617    0.3778    0.3696        45
         zxx     0.8889    0.2051    0.3333        39

    accuracy                         0.2757       185
   macro avg     0.3747    0.2908    0.2199       185
weighted avg     0.4442    0.2757    0.2497       185


========== Train Epoch 7 ==========
Loss: 1.145	Accuracy: 46.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3529    0.7742    0.4848        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7586    0.4889    0.5946        45
         zxx     0.5192    0.6923    0.5934        39

    accuracy                         0.4649       185
   macro avg     0.4550    0.4066    0.3739       185
weighted avg     0.5048    0.4649    0.4307       185


========== Train Epoch 8 ==========
Loss: 1.042	Accuracy: 43.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3529    0.7742    0.4848        31
         cwx     0.4412    0.6818    0.5357        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.1538    0.2105    0.1778        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.8824    0.3333    0.4839        45
         zxx     0.9286    0.3333    0.4906        39

    accuracy                         0.4378       185
   macro avg     0.5209    0.4419    0.4273       185
weighted avg     0.6004    0.4378    0.4423       185


========== Train Epoch 9 ==========
Loss: 0.899	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3210    0.8387    0.4643        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.8500    0.4359    0.5763        39

    accuracy                         0.4811       185
   macro avg     0.5590    0.4241    0.4381       185
weighted avg     0.5859    0.4811    0.4855       185


========== Train Epoch 10 ==========
Loss: 0.791	Accuracy: 56.76%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.3750    0.8182    0.5143        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5676       185
   macro avg     0.5281    0.5343    0.4940       185
weighted avg     0.5942    0.5676    0.5486       185


========== Train Epoch 11 ==========
Loss: 0.609	Accuracy: 57.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3939    0.8387    0.5361        31
         cwx     0.5000    0.1364    0.2143        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5730       185
   macro avg     0.5708    0.5297    0.5151       185
weighted avg     0.6053    0.5730    0.5531       185


========== Train Epoch 12 ==========
Loss: 0.518	Accuracy: 46.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.1639    0.5882    0.2564        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5818    0.7111    0.6400        45
         zxx     0.8485    0.7179    0.7778        39

    accuracy                         0.4649       185
   macro avg     0.6103    0.4053    0.3948       185
weighted avg     0.6280    0.4649    0.4584       185


========== Train Epoch 13 ==========
Loss: 0.442	Accuracy: 60.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3077    0.6316    0.4138        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.9062    0.7436    0.8169        39

    accuracy                         0.6054       185
   macro avg     0.6569    0.5491    0.5598       185
weighted avg     0.6751    0.6054    0.6058       185


========== Train Epoch 14 ==========
Loss: 0.347	Accuracy: 64.86%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5106    0.7742    0.6154        31
         cwx     0.5000    0.7727    0.6071        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6486       185
   macro avg     0.6618    0.6216    0.5961       185
weighted avg     0.7063    0.6486    0.6421       185


========== Train Epoch 15 ==========
Loss: 0.249	Accuracy: 67.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.4348    0.9091    0.5882        22
         hdx     0.6429    0.5294    0.5806        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6757       185
   macro avg     0.6864    0.6567    0.6540       185
weighted avg     0.7202    0.6757    0.6820       185


========== Train Epoch 16 ==========
Loss: 0.190	Accuracy: 62.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.5135    0.8636    0.6441        22
         hdx     0.3226    0.5882    0.4167        17
         mtx     0.4737    0.4737    0.4737        19
         nqx     1.0000    0.6667    0.8000        12
         qtx     0.9583    0.5111    0.6667        45
         zxx     0.9062    0.7436    0.8169        39

    accuracy                         0.6216       185
   macro avg     0.6678    0.6279    0.6202       185
weighted avg     0.7122    0.6216    0.6374       185


========== Train Epoch 17 ==========
Loss: 0.144	Accuracy: 52.97%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3333    0.7727    0.4658        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.6607    0.8222    0.7327        45
         zxx     0.8276    0.6154    0.7059        39

    accuracy                         0.5297       185
   macro avg     0.5059    0.4908    0.4565       185
weighted avg     0.5102    0.5297    0.4920       185


========== Train Epoch 18 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.124	Accuracy: 59.46%	Cost 33s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     1.0000    0.2105    0.3478        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.4805    0.9487    0.6379        39

    accuracy                         0.5946       185
   macro avg     0.7193    0.5650    0.5290       185
weighted avg     0.7251    0.5946    0.5441       185


========== Train Epoch 19 ==========
Loss: 0.098	Accuracy: 57.84%	Cost 32s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3750    0.7895    0.5085        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5784       185
   macro avg     0.6495    0.5885    0.5217       185
weighted avg     0.7103    0.5784    0.5432       185


========== Train Epoch 20 ==========
Loss: 0.099	Accuracy: 60.54%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3243    0.7059    0.4444        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.9655    0.6222    0.7568        45
         zxx     0.6000    0.9231    0.7273        39

    accuracy                         0.6054       185
   macro avg     0.6119    0.5912    0.5691       185
weighted avg     0.6554    0.6054    0.5961       185


========== Train Epoch 21 ==========
Loss: 0.085	Accuracy: 65.41%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.1935    0.3243        31
         cwx     0.4419    0.8636    0.5846        22
         hdx     0.6250    0.5882    0.6061        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.7400    0.8222    0.7789        45
         zxx     0.7255    0.9487    0.8222        39

    accuracy                         0.6541       185
   macro avg     0.6900    0.6002    0.5849       185
weighted avg     0.7167    0.6541    0.6229       185


========== Train Epoch 22 ==========
Loss: 0.072	Accuracy: 61.08%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.8889    0.3636    0.5161        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.3182    0.7368    0.4444        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.6108       185
   macro avg     0.6633    0.5656    0.5682       185
weighted avg     0.6767    0.6108    0.6043       185


========== Train Epoch 23 ==========
Loss: 0.077	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.9130    0.4667    0.6176        45
         zxx     0.5132    1.0000    0.6783        39

    accuracy                         0.6054       185
   macro avg     0.6484    0.5982    0.5935       185
weighted avg     0.6624    0.6054    0.5932       185


========== Train Epoch 24 ==========
Loss: 0.075	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4250    0.5484    0.4789        31
         cwx     1.0000    0.2727    0.4286        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.5000    0.5263    0.5128        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.9444    0.3778    0.5397        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.5297       185
   macro avg     0.6247    0.5272    0.5007       185
weighted avg     0.6484    0.5297    0.5095       185


========== Train Epoch 25 ==========
Loss: 0.093	Accuracy: 56.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4286    0.5806    0.4932        31
         cwx     0.5714    0.7273    0.6400        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.3200    0.4211    0.3636        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.9474    0.4000    0.5625        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5676       185
   macro avg     0.6336    0.5399    0.5407       185
weighted avg     0.6507    0.5676    0.5642       185


========== Train Epoch 26 ==========
Loss: 0.065	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.3000    0.9545    0.4565        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.5676       185
   macro avg     0.5992    0.5023    0.4943       185
weighted avg     0.6572    0.5676    0.5678       185


========== Train Epoch 27 ==========
Loss: 0.054	Accuracy: 67.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5333    0.7273    0.6154        22
         hdx     0.5000    0.6471    0.5641        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     1.0000    0.5000    0.6667        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.7778    0.8974    0.8333        39

    accuracy                         0.6757       185
   macro avg     0.6912    0.6201    0.6227       185
weighted avg     0.6923    0.6757    0.6628       185


========== Train Epoch 28 ==========
Loss: 0.046	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7000    0.2258    0.3415        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.3750    0.7059    0.4898        17
         mtx     0.5200    0.6842    0.5909        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6432       185
   macro avg     0.6596    0.6591    0.6249       185
weighted avg     0.6961    0.6432    0.6313       185


========== Train Epoch 29 ==========
Loss: 0.035	Accuracy: 73.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.8095    0.7727    0.7907        22
         hdx     0.6111    0.6471    0.6286        17
         mtx     0.5714    0.6316    0.6000        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.8372    0.8000    0.8182        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.7351       185
   macro avg     0.7224    0.7174    0.7180       185
weighted avg     0.7367    0.7351    0.7338       185


========== Train Epoch 30 ==========
Loss: 0.033	Accuracy: 69.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.8095    0.7727    0.7907        22
         hdx     0.5000    0.6471    0.5641        17
         mtx     1.0000    0.3684    0.5385        19
         nqx     1.0000    0.9167    0.9565        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.6919       185
   macro avg     0.7594    0.6844    0.6918       185
weighted avg     0.7348    0.6919    0.6864       185


========== Train Epoch 31 ==========
Loss: 0.043	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.3396    0.8182    0.4800        22
         hdx     0.4286    0.7059    0.5333        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.5946       185
   macro avg     0.6573    0.5531    0.5268       185
weighted avg     0.6910    0.5946    0.5733       185


========== Train Epoch 32 ==========
Loss: 0.042	Accuracy: 59.46%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.3725    0.8636    0.5205        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3077    0.6316    0.4138        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.9600    0.6154    0.7500        39

    accuracy                         0.5946       185
   macro avg     0.6198    0.5692    0.5497       185
weighted avg     0.7038    0.5946    0.6082       185


========== Train Epoch 33 ==========
Loss: 0.074	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.2708    0.6842    0.3881        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.5189       185
   macro avg     0.6560    0.4750    0.4550       185
weighted avg     0.6632    0.5189    0.4974       185


========== Train Epoch 34 ==========
Loss: 0.109	Accuracy: 43.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.1728    0.8235    0.2857        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.6364    0.7778    0.7000        45
         zxx     1.0000    0.2564    0.4082        39

    accuracy                         0.4378       185
   macro avg     0.6663    0.4258    0.3959       185
weighted avg     0.7190    0.4378    0.4260       185


========== Train Epoch 35 ==========
Loss: 0.075	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.2364    0.6842    0.3514        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.9310    0.6000    0.7297        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.5784       185
   macro avg     0.6319    0.5844    0.5676       185
weighted avg     0.6799    0.5784    0.5860       185


========== Train Epoch 36 ==========
Loss: 0.068	Accuracy: 56.22%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.4000    0.7273    0.5161        22
         hdx     0.4074    0.6471    0.5000        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5429    0.9744    0.6972        39

    accuracy                         0.5622       185
   macro avg     0.6453    0.5145    0.4735       185
weighted avg     0.6427    0.5622    0.5092       185


========== Train Epoch 37 ==========
Loss: 0.078	Accuracy: 54.59%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.3333    0.7368    0.4590        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.9200    0.5111    0.6571        45
         zxx     0.4800    0.9231    0.6316        39

    accuracy                         0.5459       185
   macro avg     0.6848    0.5169    0.4945       185
weighted avg     0.6920    0.5459    0.5208       185


========== Train Epoch 38 ==========
Loss: 0.059	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.3611    0.6842    0.4727        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.6727    0.9487    0.7872        39

    accuracy                         0.6162       185
   macro avg     0.6348    0.5830    0.5482       185
weighted avg     0.6843    0.6162    0.5885       185


========== Train Epoch 39 ==========
Loss: 0.047	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.5128    0.9091    0.6557        22
         hdx     0.5556    0.5882    0.5714        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.9655    0.6222    0.7568        45
         zxx     0.5625    0.9231    0.6990        39

    accuracy                         0.6378       185
   macro avg     0.6725    0.6270    0.5959       185
weighted avg     0.6973    0.6378    0.6154       185


========== Train Epoch 40 ==========
Loss: 0.024	Accuracy: 69.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.5200    0.7647    0.6190        17
         mtx     0.4074    0.5789    0.4783        19
         nqx     0.6875    0.9167    0.7857        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.7727    0.8718    0.8193        39

    accuracy                         0.6919       185
   macro avg     0.6807    0.6980    0.6737       185
weighted avg     0.7214    0.6919    0.6929       185


========== Train Epoch 41 ==========
Loss: 0.026	Accuracy: 67.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.4583    0.6471    0.5366        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.7447    0.8974    0.8140        39

    accuracy                         0.6703       185
   macro avg     0.6482    0.6567    0.6405       185
weighted avg     0.6721    0.6703    0.6594       185


========== Train Epoch 42 ==========
Loss: 0.023	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     1.0000    0.3158    0.4800        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.4625    0.9487    0.6218        39

    accuracy                         0.6108       185
   macro avg     0.7014    0.5940    0.5994       185
weighted avg     0.7012    0.6108    0.6062       185


========== Train Epoch 43 ==========
Loss: 0.020	Accuracy: 67.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8333    0.3226    0.4651        31
         cwx     0.7826    0.8182    0.8000        22
         hdx     0.3824    0.7647    0.5098        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6703       185
   macro avg     0.6606    0.6739    0.6353       185
weighted avg     0.7078    0.6703    0.6602       185


========== Train Epoch 44 ==========
Loss: 0.021	Accuracy: 67.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7778    0.2258    0.3500        31
         cwx     0.7200    0.8182    0.7660        22
         hdx     0.4783    0.6471    0.5500        17
         mtx     0.6923    0.4737    0.5625        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.5968    0.9487    0.7327        39

    accuracy                         0.6757       185
   macro avg     0.6942    0.6686    0.6482       185
weighted avg     0.7074    0.6757    0.6533       185


========== Train Epoch 45 ==========
Loss: 0.023	Accuracy: 69.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.5500    0.6471    0.5946        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7872    0.8222    0.8043        45
         zxx     0.7255    0.9487    0.8222        39

    accuracy                         0.6973       185
   macro avg     0.6701    0.6707    0.6460       185
weighted avg     0.7042    0.6973    0.6770       185


========== Train Epoch 46 ==========
Loss: 0.017	Accuracy: 68.65%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.6667    0.7273    0.6957        22
         hdx     0.5238    0.6471    0.5789        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7778    0.8974    0.8333        39

    accuracy                         0.6865       185
   macro avg     0.6488    0.6817    0.6560       185
weighted avg     0.6874    0.6865    0.6797       185


========== Train Epoch 47 ==========
Loss: 0.027	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.4444    0.7059    0.5455        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.6486       185
   macro avg     0.6412    0.6501    0.6359       185
weighted avg     0.6666    0.6486    0.6498       185


========== Train Epoch 48 ==========
Loss: 0.018	Accuracy: 68.11%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.6957    0.7273    0.7111        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.7857    0.9167    0.8462        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.7872    0.9487    0.8605        39

    accuracy                         0.6811       185
   macro avg     0.6525    0.6715    0.6551       185
weighted avg     0.6743    0.6811    0.6707       185


========== Train Epoch 49 ==========
Loss: 0.022	Accuracy: 67.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.5862    0.7727    0.6667        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5000    0.5263    0.5128        19
         nqx     0.9167    0.9167    0.9167        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.8205    0.8205    0.8205        39

    accuracy                         0.6757       185
   macro avg     0.6639    0.6708    0.6635       185
weighted avg     0.6909    0.6757    0.6786       185


========== Train Epoch 50 ==========
Loss: 0.019	Accuracy: 66.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.7273    0.7273    0.7273        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6852    0.9487    0.7957        39

    accuracy                         0.6649       185
   macro avg     0.6430    0.6532    0.6281       185
weighted avg     0.6767    0.6649    0.6510       185


========== Train Epoch 51 ==========
Loss: 0.022	Accuracy: 69.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7368    0.4516    0.5600        31
         cwx     0.7826    0.8182    0.8000        22
         hdx     0.5789    0.6471    0.6111        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.5968    0.9487    0.7327        39

    accuracy                         0.6919       185
   macro avg     0.7157    0.6708    0.6674       185
weighted avg     0.7096    0.6919    0.6756       185


========== Train Epoch 52 ==========
Loss: 0.021	Accuracy: 69.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.6129    0.8636    0.7170        22
         hdx     0.6250    0.5882    0.6061        17
         mtx     0.6875    0.5789    0.6286        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.7955    0.8974    0.8434        39

    accuracy                         0.6973       185
   macro avg     0.6853    0.7016    0.6816       185
weighted avg     0.6938    0.6973    0.6840       185


========== Train Epoch 53 ==========
Loss: 0.018	Accuracy: 68.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7778    0.4516    0.5714        31
         cwx     0.7727    0.7727    0.7727        22
         hdx     0.3448    0.5882    0.4348        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.8333    0.8974    0.8642        39

    accuracy                         0.6865       185
   macro avg     0.6778    0.6798    0.6648       185
weighted avg     0.7088    0.6865    0.6854       185


========== Train Epoch 54 ==========
Loss: 0.022	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.7273    0.7273    0.7273        22
         hdx     0.5789    0.6471    0.6111        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     1.0000    0.9167    0.9565        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.4933    0.9487    0.6491        39

    accuracy                         0.6486       185
   macro avg     0.7537    0.6330    0.6264       185
weighted avg     0.7235    0.6486    0.6273       185


========== Train Epoch 55 ==========
Loss: 0.053	Accuracy: 42.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.1491    0.8947    0.2556        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.4270       185
   macro avg     0.7639    0.3885    0.3947       185
weighted avg     0.7843    0.4270    0.4638       185


========== Train Epoch 56 ==========
Loss: 0.166	Accuracy: 37.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.9091    0.2222    0.3571        45
         zxx     0.2847    1.0000    0.4432        39

    accuracy                         0.3730       185
   macro avg     0.5705    0.3632    0.3311       185
weighted avg     0.5511    0.3730    0.3085       185


========== Train Epoch 57 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.159	Accuracy: 52.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.3774    0.9091    0.5333        22
         hdx     0.8889    0.4706    0.6154        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6400    0.7111    0.6737        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.4028    0.4380    0.3828       185
weighted avg     0.4591    0.5243    0.4563       185


========== Train Epoch 58 ==========
Loss: 0.160	Accuracy: 48.65%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.5962    0.6889    0.6392        45
         zxx     0.4458    0.9487    0.6066        39

    accuracy                         0.4865       185
   macro avg     0.4440    0.4390    0.3854       185
weighted avg     0.4450    0.4865    0.4122       185


========== Train Epoch 59 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.069	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.6290    0.8667    0.7290        45
         zxx     0.9091    0.7692    0.8333        39

    accuracy                         0.6432       185
   macro avg     0.6358    0.5943    0.5933       185
weighted avg     0.6580    0.6432    0.6317       185


========== Train Epoch 60 ==========
Loss: 0.044	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.3953    0.7727    0.5231        22
         hdx     0.3438    0.6471    0.4490        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.5676       185
   macro avg     0.5790    0.5472    0.5024       185
weighted avg     0.6418    0.5676    0.5387       185


========== Train Epoch 61 ==========
Loss: 0.063	Accuracy: 50.81%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.9091    0.4545    0.6061        22
         hdx     0.2258    0.8235    0.3544        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     1.0000    0.3333    0.5000        39

    accuracy                         0.5081       185
   macro avg     0.6168    0.5533    0.5131       185
weighted avg     0.6980    0.5081    0.5322       185


========== Train Epoch 62 ==========
Loss: 0.034	Accuracy: 67.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6000    0.8182    0.6923        22
         hdx     0.7692    0.5882    0.6667        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.9000    0.7500    0.8182        12
         qtx     0.8182    0.8000    0.8090        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.6757       185
   macro avg     0.7113    0.6376    0.6371       185
weighted avg     0.6939    0.6757    0.6547       185


========== Train Epoch 63 ==========
Loss: 0.024	Accuracy: 69.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.6667    0.5882    0.6250        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8684    0.7333    0.7952        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.6919       185
   macro avg     0.6652    0.6748    0.6581       185
weighted avg     0.7003    0.6919    0.6838       185


========== Train Epoch 64 ==========
Loss: 0.018	Accuracy: 69.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.5238    0.6471    0.5789        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7115    0.9487    0.8132        39

    accuracy                         0.6973       185
   macro avg     0.6824    0.6745    0.6700       185
weighted avg     0.6931    0.6973    0.6869       185


Finished training!!!

Min Loss = 0.017 in epoch 45;
Max Accuracy = 73.51% in epoch 28;
Total Cost 33 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP(
    (pool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    (pool2): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)
    (pool3): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
  )
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.3081081081081081, 0.2972972972972973, 0.42162162162162165, 0.43243243243243246, 0.4540540540540541, 0.2756756756756757, 0.4648648648648649, 0.43783783783783786, 0.4810810810810811, 0.5675675675675675, 0.572972972972973, 0.4648648648648649, 0.6054054054054054, 0.6486486486486487, 0.6756756756756757, 0.6216216216216216, 0.5297297297297298, 0.5945945945945946, 0.5783783783783784, 0.6054054054054054, 0.654054054054054, 0.6108108108108108, 0.6054054054054054, 0.5297297297297298, 0.5675675675675675, 0.5675675675675675, 0.6756756756756757, 0.6432432432432432, 0.7351351351351352, 0.6918918918918919, 0.5945945945945946, 0.5945945945945946, 0.518918918918919, 0.43783783783783786, 0.5783783783783784, 0.5621621621621622, 0.5459459459459459, 0.6162162162162163, 0.6378378378378379, 0.6918918918918919, 0.6702702702702703, 0.6108108108108108, 0.6702702702702703, 0.6756756756756757, 0.6972972972972973, 0.6864864864864865, 0.6486486486486487, 0.6810810810810811, 0.6756756756756757, 0.6648648648648648, 0.6918918918918919, 0.6972972972972973, 0.6864864864864865, 0.6486486486486487, 0.42702702702702705, 0.372972972972973, 0.5243243243243243, 0.4864864864864865, 0.6432432432432432, 0.5675675675675675, 0.5081081081081081, 0.6756756756756757, 0.6918918918918919, 0.6972972972972973]
