dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: resnet18_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.836	Accuracy: 33.51%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2105    0.5455    0.3038        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1739    0.3333    0.2286        12
         qtx     0.4493    0.6889    0.5439        45
         zxx     0.4839    0.3846    0.4286        39

    accuracy                         0.3351       185
   macro avg     0.1882    0.2789    0.2150       185
weighted avg     0.2476    0.3351    0.2736       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.542	Accuracy: 32.43%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3333    0.0323    0.0588        31
         cwx     0.5000    0.1818    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2609    0.5000    0.3429        12
         qtx     0.6667    0.2667    0.3810        45
         zxx     0.2782    0.9487    0.4302        39

    accuracy                         0.3243       185
   macro avg     0.2913    0.2756    0.2114       185
weighted avg     0.3530    0.3243    0.2472       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.284	Accuracy: 42.16%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3966    0.7419    0.5169        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.2340    0.9167    0.3729        12
         qtx     0.5556    0.6667    0.6061        45
         zxx     0.5625    0.2308    0.3273        39

    accuracy                         0.4216       185
   macro avg     0.4539    0.4007    0.3172       185
weighted avg     0.4983    0.4216    0.3707       185


========== Train Epoch 4 ==========
Loss: 1.103	Accuracy: 21.62%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2500    0.0968    0.1395        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.5789    0.2292        19
         nqx     0.1600    1.0000    0.2759        12
         qtx     0.7500    0.2000    0.3158        45
         zxx     1.0000    0.0769    0.1429        39

    accuracy                         0.2162       185
   macro avg     0.3766    0.2919    0.1780       185
weighted avg     0.4998    0.2162    0.1887       185


========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.683	Accuracy: 23.78%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2667    0.9091    0.4124        22
         hdx     0.1354    0.7647    0.2301        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     1.0000    0.0222    0.0435        45
         zxx     1.0000    0.2564    0.4082        39

    accuracy                         0.2378       185
   macro avg     0.3432    0.2789    0.1563       185
weighted avg     0.4982    0.2378    0.1668       185


========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.370	Accuracy: 36.76%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2574    0.8387    0.3939        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.2727    0.6316    0.3810        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.7333    0.2444    0.3667        45
         zxx     0.8000    0.2051    0.3265        39

    accuracy                         0.3676       185
   macro avg     0.5845    0.3638    0.3429       185
weighted avg     0.6053    0.3676    0.3509       185


========== Train Epoch 7 ==========
Loss: 0.158	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4468    0.6774    0.5385        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.2727    0.5294    0.3600        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5622       185
   macro avg     0.5758    0.5065    0.5081       185
weighted avg     0.6021    0.5622    0.5580       185


========== Train Epoch 8 ==========
Loss: 0.114	Accuracy: 40.00%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.1458    0.4118    0.2154        17
         mtx     0.2308    0.3158    0.2667        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.4800    0.5333    0.5053        45
         zxx     1.0000    0.0769    0.1429        39

    accuracy                         0.4000       185
   macro avg     0.5307    0.4158    0.4010       185
weighted avg     0.5770    0.4000    0.3936       185


========== Train Epoch 9 ==========
Loss: 0.077	Accuracy: 51.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5135    0.6129    0.5588        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.5385    0.6222    0.5773        45
         zxx     0.5682    0.6410    0.6024        39

    accuracy                         0.5189       185
   macro avg     0.4771    0.4686    0.4633       185
weighted avg     0.4947    0.5189    0.4993       185


========== Train Epoch 10 ==========
Loss: 0.050	Accuracy: 51.35%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.4186    0.9231    0.5760        39

    accuracy                         0.5135       185
   macro avg     0.5567    0.4415    0.4490       185
weighted avg     0.5646    0.5135    0.4914       185


========== Train Epoch 11 ==========
Loss: 0.045	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4655    0.8710    0.6067        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6042    0.6444    0.6237        45
         zxx     0.8636    0.4872    0.6230        39

    accuracy                         0.5514       185
   macro avg     0.5290    0.5226    0.4886       185
weighted avg     0.5776    0.5514    0.5293       185


========== Train Epoch 12 ==========
Loss: 0.045	Accuracy: 51.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3636    0.6452    0.4651        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5660    0.6667    0.6122        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5189       185
   macro avg     0.5926    0.4333    0.4320       185
weighted avg     0.5654    0.5189    0.4856       185


========== Train Epoch 13 ==========
Loss: 0.040	Accuracy: 26.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.1127    0.9412    0.2013        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     1.0000    0.1556    0.2692        45
         zxx     1.0000    0.1282    0.2273        39

    accuracy                         0.2649       185
   macro avg     0.6947    0.3339    0.3224       185
weighted avg     0.7582    0.2649    0.2920       185


========== Train Epoch 14 ==========
Loss: 0.041	Accuracy: 52.97%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8889    0.2581    0.4000        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.5135    0.8444    0.6387        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5297       185
   macro avg     0.6795    0.4351    0.4340       185
weighted avg     0.6334    0.5297    0.4838       185


========== Train Epoch 15 ==========
Loss: 0.043	Accuracy: 46.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3077    0.9032    0.4590        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.5556    0.6667    0.6061        45
         zxx     0.8421    0.4103    0.5517        39

    accuracy                         0.4649       185
   macro avg     0.6345    0.3975    0.3848       185
weighted avg     0.6330    0.4649    0.4304       185


========== Train Epoch 16 ==========
Loss: 0.034	Accuracy: 51.35%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.2763    0.9545    0.4286        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.9167    0.4889    0.6377        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5135       185
   macro avg     0.6247    0.4867    0.4661       185
weighted avg     0.6874    0.5135    0.5162       185


========== Train Epoch 17 ==========
Loss: 0.035	Accuracy: 38.38%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.2879    0.9744    0.4444        39

    accuracy                         0.3838       185
   macro avg     0.5193    0.3162    0.2903       185
weighted avg     0.5071    0.3838    0.3252       185


========== Train Epoch 18 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.028	Accuracy: 54.05%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5128    0.6452    0.5714        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.2778    0.5882    0.3774        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.5593    0.7333    0.6346        45
         zxx     0.8750    0.3590    0.5091        39

    accuracy                         0.5405       185
   macro avg     0.5912    0.5236    0.5178       185
weighted avg     0.6159    0.5405    0.5364       185


========== Train Epoch 19 ==========
Loss: 0.019	Accuracy: 57.84%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8571    0.3871    0.5333        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3030    0.5882    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.5784       185
   macro avg     0.6041    0.5648    0.5465       185
weighted avg     0.6584    0.5784    0.5731       185


========== Train Epoch 20 ==========
Loss: 0.022	Accuracy: 54.59%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.5789    0.7333    0.6471        45
         zxx     0.5000    0.7179    0.5895        39

    accuracy                         0.5459       185
   macro avg     0.5465    0.5040    0.4993       185
weighted avg     0.5480    0.5459    0.5254       185


========== Train Epoch 21 ==========
Loss: 0.020	Accuracy: 57.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.2759    0.4706    0.3478        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.5730       185
   macro avg     0.5377    0.5420    0.5179       185
weighted avg     0.5916    0.5730    0.5678       185


========== Train Epoch 22 ==========
Loss: 0.020	Accuracy: 50.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8750    0.2258    0.3590        31
         cwx     0.4706    0.7273    0.5714        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.7667    0.5111    0.6133        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.5081       185
   macro avg     0.6093    0.4548    0.4403       185
weighted avg     0.6163    0.5081    0.4836       185


========== Train Epoch 23 ==========
Loss: 0.017	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3600    0.7500    0.4865        12
         qtx     0.5645    0.7778    0.6542        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5440    0.5091    0.4883       185
weighted avg     0.5794    0.5622    0.5413       185


========== Train Epoch 24 ==========
Loss: 0.016	Accuracy: 45.95%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.2750    0.6471    0.3860        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8000    0.2667    0.4000        45
         zxx     0.4186    0.9231    0.5760        39

    accuracy                         0.4595       185
   macro avg     0.5713    0.4640    0.4356       185
weighted avg     0.6093    0.4595    0.4327       185


========== Train Epoch 25 ==========
Loss: 0.015	Accuracy: 52.97%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2667    0.4706    0.3404        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6304    0.6444    0.6374        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.5297       185
   macro avg     0.5441    0.4945    0.4793       185
weighted avg     0.5757    0.5297    0.5217       185


========== Train Epoch 26 ==========
Loss: 0.017	Accuracy: 55.14%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.9130    0.4667    0.6176        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5514       185
   macro avg     0.5799    0.5444    0.5161       185
weighted avg     0.6230    0.5514    0.5356       185


========== Train Epoch 27 ==========
Loss: 0.013	Accuracy: 60.54%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5897    0.7419    0.6571        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.7419    0.5897    0.6571        39

    accuracy                         0.6054       185
   macro avg     0.5732    0.5983    0.5710       185
weighted avg     0.6151    0.6054    0.6004       185


========== Train Epoch 28 ==========
Loss: 0.015	Accuracy: 57.84%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5784       185
   macro avg     0.5734    0.5342    0.5438       185
weighted avg     0.5879    0.5784    0.5735       185


========== Train Epoch 29 ==========
Loss: 0.014	Accuracy: 55.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7000    0.2258    0.3415        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.4861    0.8974    0.6306        39

    accuracy                         0.5568       185
   macro avg     0.5779    0.5284    0.5110       185
weighted avg     0.6016    0.5568    0.5342       185


========== Train Epoch 30 ==========
Loss: 0.016	Accuracy: 57.84%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.3000    0.7059    0.4211        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.6585    0.6923    0.6750        39

    accuracy                         0.5784       185
   macro avg     0.6020    0.5842    0.5644       185
weighted avg     0.6457    0.5784    0.5834       185


========== Train Epoch 31 ==========
Loss: 0.014	Accuracy: 57.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5556    0.6452    0.5970        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4074    0.9167    0.5641        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.7105    0.6923    0.7013        39

    accuracy                         0.5730       185
   macro avg     0.5426    0.5658    0.5261       185
weighted avg     0.6014    0.5730    0.5687       185


========== Train Epoch 32 ==========
Loss: 0.014	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.2727    0.5294    0.3600        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5514       185
   macro avg     0.5470    0.5066    0.4954       185
weighted avg     0.5969    0.5514    0.5427       185


========== Train Epoch 33 ==========
Loss: 0.013	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4286    0.4737    0.4500        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.5789    0.7333    0.6471        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5838       185
   macro avg     0.5721    0.5365    0.5465       185
weighted avg     0.5922    0.5838    0.5798       185


========== Train Epoch 34 ==========
Loss: 0.013	Accuracy: 55.68%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.2364    0.7647    0.3611        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7600    0.4222    0.5429        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.5568       185
   macro avg     0.6360    0.5773    0.5420       185
weighted avg     0.6696    0.5568    0.5605       185


========== Train Epoch 35 ==========
Loss: 0.013	Accuracy: 56.22%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5622       185
   macro avg     0.5690    0.5374    0.5421       185
weighted avg     0.5761    0.5622    0.5585       185


========== Train Epoch 36 ==========
Loss: 0.012	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5128    0.6452    0.5714        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.5345    0.6889    0.6019        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.5514       185
   macro avg     0.5266    0.4915    0.4999       185
weighted avg     0.5435    0.5514    0.5396       185


========== Train Epoch 37 ==========
Loss: 0.012	Accuracy: 51.89%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.2632    0.5882    0.3636        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8000    0.3556    0.4923        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.5189       185
   macro avg     0.5793    0.5223    0.4954       185
weighted avg     0.6113    0.5189    0.5053       185


========== Train Epoch 38 ==========
Loss: 0.010	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4444    0.6452    0.5263        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.2558    0.6471    0.3667        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7241    0.4667    0.5676        45
         zxx     0.7576    0.6410    0.6944        39

    accuracy                         0.5405       185
   macro avg     0.5875    0.5440    0.5252       185
weighted avg     0.6189    0.5405    0.5458       185


========== Train Epoch 39 ==========
Loss: 0.018	Accuracy: 44.86%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.3883    0.8889    0.5405        45
         zxx     0.7778    0.1795    0.2917        39

    accuracy                         0.4486       185
   macro avg     0.4998    0.4105    0.4049       185
weighted avg     0.5180    0.4486    0.4123       185


========== Train Epoch 40 ==========
Loss: 0.013	Accuracy: 45.95%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3750    0.5806    0.4557        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2034    0.7059    0.3158        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.6957    0.3556    0.4706        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.4595       185
   macro avg     0.5606    0.4490    0.4444       185
weighted avg     0.5833    0.4595    0.4715       185


========== Train Epoch 41 ==========
Loss: 0.012	Accuracy: 41.62%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.3145    1.0000    0.4785        39

    accuracy                         0.4162       185
   macro avg     0.4695    0.3744    0.3603       185
weighted avg     0.4785    0.4162    0.3685       185


========== Train Epoch 42 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.012	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2250    0.5294    0.3158        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.7308    0.4222    0.5352        45
         zxx     0.6364    0.7179    0.6747        39

    accuracy                         0.5027       185
   macro avg     0.5043    0.4769    0.4675       185
weighted avg     0.5506    0.5027    0.5049       185


========== Train Epoch 43 ==========
Loss: 0.011	Accuracy: 52.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.6122    0.6667    0.6383        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.5243       185
   macro avg     0.5701    0.4861    0.4828       185
weighted avg     0.5715    0.5243    0.4958       185


========== Train Epoch 44 ==========
Loss: 0.011	Accuracy: 59.46%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5946       185
   macro avg     0.5526    0.5418    0.5387       185
weighted avg     0.5883    0.5946    0.5842       185


========== Train Epoch 45 ==========
Loss: 0.014	Accuracy: 55.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     1.0000    0.1935    0.3243        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.5373    0.8000    0.6429        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5568       185
   macro avg     0.6298    0.5019    0.5019       185
weighted avg     0.6361    0.5568    0.5256       185


========== Train Epoch 46 ==========
Loss: 0.014	Accuracy: 51.89%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3205    0.8065    0.4587        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.6897    0.5128    0.5882        39

    accuracy                         0.5189       185
   macro avg     0.5735    0.4966    0.5026       185
weighted avg     0.5940    0.5189    0.5212       185


========== Train Epoch 47 ==========
Loss: 0.011	Accuracy: 52.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.1290    0.2286        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6200    0.6889    0.6526        45
         zxx     0.4286    0.8462    0.5690        39

    accuracy                         0.5243       185
   macro avg     0.6029    0.4815    0.4777       185
weighted avg     0.6127    0.5243    0.4929       185


========== Train Epoch 48 ==========
Loss: 0.013	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3068    0.8710    0.4538        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.7692    0.2564    0.3846        39

    accuracy                         0.4757       185
   macro avg     0.5455    0.4659    0.4567       185
weighted avg     0.5777    0.4757    0.4667       185


========== Train Epoch 49 ==========
Loss: 0.011	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.2903    0.4500        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.5286    0.8222    0.6435        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.5622       185
   macro avg     0.6576    0.4980    0.5137       185
weighted avg     0.6435    0.5622    0.5431       185


========== Train Epoch 50 ==========
Loss: 0.012	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8000    0.3556    0.4923        45
         zxx     0.4500    0.9231    0.6050        39

    accuracy                         0.5027       185
   macro avg     0.5208    0.4961    0.4639       185
weighted avg     0.5624    0.5027    0.4774       185


========== Train Epoch 51 ==========
Loss: 0.011	Accuracy: 57.84%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5784       185
   macro avg     0.5755    0.5628    0.5600       185
weighted avg     0.5898    0.5784    0.5724       185


========== Train Epoch 52 ==========
Loss: 0.011	Accuracy: 57.84%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.5686    0.7436    0.6444        39

    accuracy                         0.5784       185
   macro avg     0.5566    0.5482    0.5487       185
weighted avg     0.5777    0.5784    0.5737       185


========== Train Epoch 53 ==========
Loss: 0.011	Accuracy: 55.14%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4375    0.6774    0.5316        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.6571    0.5897    0.6216        39

    accuracy                         0.5514       185
   macro avg     0.5300    0.5346    0.5191       185
weighted avg     0.5617    0.5514    0.5440       185


========== Train Epoch 54 ==========
Loss: 0.010	Accuracy: 57.84%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5784       185
   macro avg     0.5622    0.5526    0.5275       185
weighted avg     0.5904    0.5784    0.5603       185


========== Train Epoch 55 ==========
Loss: 0.011	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.5000    0.8974    0.6422        39

    accuracy                         0.5568       185
   macro avg     0.5754    0.5313    0.5312       185
weighted avg     0.5990    0.5568    0.5494       185


========== Train Epoch 56 ==========
Loss: 0.012	Accuracy: 49.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     1.0000    0.2727    0.4286        22
         hdx     0.1765    0.7059    0.2824        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6571    0.5111    0.5750        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.4973       185
   macro avg     0.6304    0.4933    0.4934       185
weighted avg     0.6529    0.4973    0.5216       185


========== Train Epoch 57 ==========
Loss: 0.010	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.4595    0.8718    0.6018        39

    accuracy                         0.5351       185
   macro avg     0.5394    0.4902    0.4946       185
weighted avg     0.5509    0.5351    0.5200       185


========== Train Epoch 58 ==========
Loss: 0.011	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4255    0.6452    0.5128        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.5909    0.6667    0.6265        39

    accuracy                         0.5351       185
   macro avg     0.5237    0.5108    0.5103       185
weighted avg     0.5431    0.5351    0.5311       185


========== Train Epoch 59 ==========
Loss: 0.010	Accuracy: 52.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.2059    0.4118    0.2745        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.5870    0.6000    0.5934        45
         zxx     0.5870    0.6923    0.6353        39

    accuracy                         0.5243       185
   macro avg     0.5376    0.4899    0.4991       185
weighted avg     0.5518    0.5243    0.5272       185


========== Train Epoch 60 ==========
Loss: 0.010	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.1842    0.4118    0.2545        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.6364    0.4667    0.5385        45
         zxx     0.6190    0.6667    0.6420        39

    accuracy                         0.5081       185
   macro avg     0.5220    0.5031    0.4970       185
weighted avg     0.5487    0.5081    0.5158       185


========== Train Epoch 61 ==========
Loss: 0.011	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.4118    0.8974    0.5645        39

    accuracy                         0.5189       185
   macro avg     0.5476    0.4738    0.4799       185
weighted avg     0.5664    0.5189    0.5050       185


========== Train Epoch 62 ==========
Loss: 0.010	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5660    0.7692    0.6522        39

    accuracy                         0.5730       185
   macro avg     0.5651    0.5460    0.5401       185
weighted avg     0.5796    0.5730    0.5631       185


========== Train Epoch 63 ==========
Loss: 0.011	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.4706    0.8205    0.5981        39

    accuracy                         0.5297       185
   macro avg     0.5358    0.4795    0.4911       185
weighted avg     0.5476    0.5297    0.5209       185


========== Train Epoch 64 ==========
Loss: 0.010	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4348    0.6452    0.5195        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5568       185
   macro avg     0.5345    0.5342    0.5097       185
weighted avg     0.5616    0.5568    0.5381       185


Finished training!!!

Min Loss = 0.010 in epoch 58;
Max Accuracy = 60.54% in epoch 26;
Total Cost 35 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.33513513513513515, 0.32432432432432434, 0.42162162162162165, 0.21621621621621623, 0.23783783783783785, 0.3675675675675676, 0.5621621621621622, 0.4, 0.518918918918919, 0.5135135135135135, 0.5513513513513514, 0.518918918918919, 0.2648648648648649, 0.5297297297297298, 0.4648648648648649, 0.5135135135135135, 0.3837837837837838, 0.5405405405405406, 0.5783783783783784, 0.5459459459459459, 0.572972972972973, 0.5081081081081081, 0.5621621621621622, 0.4594594594594595, 0.5297297297297298, 0.5513513513513514, 0.6054054054054054, 0.5783783783783784, 0.5567567567567567, 0.5783783783783784, 0.572972972972973, 0.5513513513513514, 0.5837837837837838, 0.5567567567567567, 0.5621621621621622, 0.5513513513513514, 0.518918918918919, 0.5405405405405406, 0.4486486486486487, 0.4594594594594595, 0.41621621621621624, 0.5027027027027027, 0.5243243243243243, 0.5945945945945946, 0.5567567567567567, 0.518918918918919, 0.5243243243243243, 0.4756756756756757, 0.5621621621621622, 0.5027027027027027, 0.5783783783783784, 0.5783783783783784, 0.5513513513513514, 0.5783783783783784, 0.5567567567567567, 0.4972972972972973, 0.5351351351351351, 0.5351351351351351, 0.5243243243243243, 0.5081081081081081, 0.518918918918919, 0.572972972972973, 0.5297297297297298, 0.5567567567567567]
