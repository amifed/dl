dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: _alexnet
using model: AlexNet, _alexnet
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.951	Accuracy: 23.78%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.2222    0.0645    0.1000        31
         cwx     0.1364    0.1364    0.1364        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.0000    0.0000    0.0000        45
         zxx     0.2549    1.0000    0.4062        39

    accuracy                         0.2378       185
   macro avg     0.0876    0.1716    0.0918       185
weighted avg     0.1072    0.2378    0.1186       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.770	Accuracy: 23.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1193    0.6842    0.2031        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.4167    0.1111    0.1754        45
         zxx     0.4324    0.4103    0.4211        39

    accuracy                         0.2324       185
   macro avg     0.2356    0.2210    0.1756       185
weighted avg     0.2847    0.2324    0.2106       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.653	Accuracy: 26.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2167    0.4194    0.2857        31
         cwx     0.1515    0.2273    0.1818        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5000    0.0222    0.0426        45
         zxx     0.3371    0.7692    0.4688        39

    accuracy                         0.2649       185
   macro avg     0.1722    0.2054    0.1398       185
weighted avg     0.2470    0.2649    0.1787       185


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.549	Accuracy: 30.27%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.1917    0.7419    0.3046        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.6000    0.2667    0.3692        45
         zxx     0.4615    0.4615    0.4615        39

    accuracy                         0.3027       185
   macro avg     0.4647    0.2413    0.2173       185
weighted avg     0.4429    0.3027    0.2670       185


========== Train Epoch 5 ==========
Loss: 1.428	Accuracy: 41.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.2162    0.4706    0.2963        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6111    0.4889    0.5432        45
         zxx     0.4203    0.7436    0.5370        39

    accuracy                         0.4108       185
   macro avg     0.3534    0.3619    0.3345       185
weighted avg     0.3916    0.4108    0.3787       185


========== Train Epoch 6 ==========
Loss: 1.347	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.2143    0.1364    0.1667        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2273    0.2632    0.2439        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.3820    0.7556    0.5075        45
         zxx     0.9231    0.3077    0.4615        39

    accuracy                         0.4000       185
   macro avg     0.4919    0.3344    0.3473       185
weighted avg     0.4974    0.4000    0.3846       185


========== Train Epoch 7 ==========
Loss: 1.321	Accuracy: 36.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3387    0.6774    0.4516        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.1714    0.6316    0.2697        19
         nqx     1.0000    0.5000    0.6667        12
         qtx     0.7273    0.3556    0.4776        45
         zxx     0.7500    0.1538    0.2553        39

    accuracy                         0.3622       185
   macro avg     0.5254    0.3797    0.3605       185
weighted avg     0.5467    0.3622    0.3558       185


========== Train Epoch 8 ==========
Loss: 1.169	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4250    0.5484    0.4789        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2000    0.4118    0.2692        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.3448    0.8333    0.4878        12
         qtx     0.8421    0.3556    0.5000        45
         zxx     0.6053    0.5897    0.5974        39

    accuracy                         0.4432       185
   macro avg     0.4562    0.4528    0.4121       185
weighted avg     0.5330    0.4432    0.4467       185


========== Train Epoch 9 ==========
Loss: 1.162	Accuracy: 32.97%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.1333    0.7368    0.2258        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.7500    0.1333    0.2264        45
         zxx     0.6765    0.5897    0.6301        39

    accuracy                         0.3297       185
   macro avg     0.4907    0.3632    0.3349       185
weighted avg     0.5458    0.3297    0.3326       185


========== Train Epoch 10 ==========
Loss: 1.026	Accuracy: 36.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3243    0.3871    0.3529        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.1481    0.2353    0.1818        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8571    0.1333    0.2308        45
         zxx     0.4242    0.7179    0.5333        39

    accuracy                         0.3676       185
   macro avg     0.4214    0.3660    0.3449       185
weighted avg     0.4787    0.3676    0.3464       185


========== Train Epoch 11 ==========
Loss: 0.965	Accuracy: 32.97%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.3333    0.0968    0.1500        31
         cwx     0.2500    0.2727    0.2609        22
         hdx     0.2143    0.5294    0.3051        17
         mtx     0.1250    0.2632    0.1695        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4909    0.6000    0.5400        45
         zxx     0.7143    0.2564    0.3774        39

    accuracy                         0.3297       185
   macro avg     0.4468    0.3003    0.2795       185
weighted avg     0.4530    0.3297    0.3225       185


========== Train Epoch 12 ==========
Loss: 0.918	Accuracy: 36.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.4000    0.0909    0.1481        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8333    0.2222    0.3509        45
         zxx     0.3333    0.8462    0.4783        39

    accuracy                         0.3676       185
   macro avg     0.4096    0.3565    0.3151       185
weighted avg     0.4684    0.3676    0.3299       185


========== Train Epoch 13 ==========
Loss: 0.785	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.1111    0.1579    0.1304        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.5000    0.5556    0.5263        45
         zxx     0.6667    0.5641    0.6111        39

    accuracy                         0.4324       185
   macro avg     0.4340    0.4148    0.4116       185
weighted avg     0.4619    0.4324    0.4365       185


========== Train Epoch 14 ==========
Loss: 0.807	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.1935    0.3158    0.2400        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6170    0.6444    0.6304        45
         zxx     0.7917    0.4872    0.6032        39

    accuracy                         0.4865       185
   macro avg     0.4873    0.4949    0.4707       185
weighted avg     0.5346    0.4865    0.4929       185


========== Train Epoch 15 ==========
Loss: 0.679	Accuracy: 41.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.2903    0.3103        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.1250    0.1579    0.1395        19
         nqx     0.3200    0.6667    0.4324        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.6000    0.4615    0.5217        39

    accuracy                         0.4108       185
   macro avg     0.3819    0.3966    0.3776       185
weighted avg     0.4488    0.4108    0.4218       185


========== Train Epoch 16 ==========
Loss: 0.662	Accuracy: 35.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3235    0.3548    0.3385        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.2273    0.5882    0.3279        17
         mtx     0.1538    0.2105    0.1778        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.4792    0.5111    0.4946        45
         zxx     1.0000    0.0513    0.0976        39

    accuracy                         0.3514       185
   macro avg     0.4563    0.3967    0.3353       185
weighted avg     0.5138    0.3514    0.3225       185


========== Train Epoch 17 ==========
Loss: 0.557	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.2581    0.2909        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2667    0.7059    0.3871        17
         mtx     0.2000    0.2105    0.2051        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.5185    0.6222    0.5657        45
         zxx     0.7143    0.3846    0.5000        39

    accuracy                         0.4324       185
   macro avg     0.4683    0.4339    0.4213       185
weighted avg     0.4879    0.4324    0.4329       185


========== Train Epoch 18 ==========
Loss: 0.616	Accuracy: 38.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3571    0.3226    0.3390        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.1579    0.3158    0.2105        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.5778    0.5778    0.5778        45
         zxx     0.3800    0.4872    0.4270        39

    accuracy                         0.3892       185
   macro avg     0.4799    0.3584    0.3510       185
weighted avg     0.4799    0.3892    0.3778       185


========== Train Epoch 19 ==========
Loss: 0.488	Accuracy: 39.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.1250    0.4211    0.1928        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4746    0.6222    0.5385        45
         zxx     0.8889    0.4103    0.5614        39

    accuracy                         0.3946       185
   macro avg     0.6297    0.3345    0.3433       185
weighted avg     0.6157    0.3946    0.4032       185


========== Train Epoch 20 ==========
Loss: 0.449	Accuracy: 44.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.7742    0.4948        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2000    0.2632    0.2273        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.5778    0.5778    0.5778        45
         zxx     0.6429    0.4615    0.5373        39

    accuracy                         0.4486       185
   macro avg     0.5787    0.3963    0.3946       185
weighted avg     0.5658    0.4486    0.4315       185


========== Train Epoch 21 ==========
Loss: 0.423	Accuracy: 45.41%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3182    0.6774    0.4330        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.5918    0.6444    0.6170        45
         zxx     0.6000    0.4615    0.5217        39

    accuracy                         0.4541       185
   macro avg     0.4094    0.4084    0.3869       185
weighted avg     0.4356    0.4541    0.4245       185


========== Train Epoch 22 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.407	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.1667    0.5263    0.2532        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.8947    0.4359    0.5862        39

    accuracy                         0.4432       185
   macro avg     0.5950    0.4168    0.4175       185
weighted avg     0.6122    0.4432    0.4692       185


========== Train Epoch 23 ==========
Loss: 0.361	Accuracy: 47.57%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.1364    0.1579    0.1463        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.5385    0.6222    0.5773        45
         zxx     0.8333    0.5128    0.6349        39

    accuracy                         0.4757       185
   macro avg     0.4672    0.4679    0.4504       185
weighted avg     0.5154    0.4757    0.4798       185


========== Train Epoch 24 ==========
Loss: 0.317	Accuracy: 36.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.0645    0.1081        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.1471    0.2632    0.1887        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.3673    0.8000    0.5035        45
         zxx     1.0000    0.2821    0.4400        39

    accuracy                         0.3622       185
   macro avg     0.4184    0.3227    0.2977       185
weighted avg     0.4687    0.3622    0.3226       185


========== Train Epoch 25 ==========
Loss: 0.410	Accuracy: 34.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2358    0.8065    0.3650        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.1429    0.2105    0.1702        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5909    0.2889    0.3881        45
         zxx     0.7391    0.4359    0.5484        39

    accuracy                         0.3459       185
   macro avg     0.6012    0.2940    0.2899       185
weighted avg     0.5835    0.3459    0.3367       185


========== Train Epoch 26 ==========
Loss: 0.374	Accuracy: 45.41%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.2424    0.4211    0.3077        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.4286    0.8667    0.5735        45
         zxx     0.9412    0.4103    0.5714        39

    accuracy                         0.4541       185
   macro avg     0.5820    0.4078    0.3998       185
weighted avg     0.5948    0.4541    0.4266       185


========== Train Epoch 27 ==========
Loss: 0.302	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3692    0.7742    0.5000        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.1538    0.2105    0.1778        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5745    0.6000    0.5870        45
         zxx     0.6800    0.4359    0.5312        39

    accuracy                         0.4432       185
   macro avg     0.5163    0.3918    0.3718       185
weighted avg     0.5441    0.4432    0.4203       185


========== Train Epoch 28 ==========
Loss: 0.253	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3056    0.3548    0.3284        31
         cwx     0.5714    0.1818    0.2759        22
         hdx     0.2381    0.5882    0.3390        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6667    0.4889    0.5641        45
         zxx     0.5192    0.6923    0.5934        39

    accuracy                         0.4324       185
   macro avg     0.5226    0.3789    0.3654       185
weighted avg     0.5142    0.4324    0.4224       185


========== Train Epoch 29 ==========
Loss: 0.247	Accuracy: 45.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3030    0.3226    0.3125        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.4754    0.6444    0.5472        45
         zxx     0.7500    0.3846    0.5085        39

    accuracy                         0.4541       185
   macro avg     0.4834    0.4551    0.4584       185
weighted avg     0.4869    0.4541    0.4546       185


========== Train Epoch 30 ==========
Loss: 0.313	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5514       185
   macro avg     0.5583    0.5497    0.5410       185
weighted avg     0.5589    0.5514    0.5396       185


========== Train Epoch 31 ==========
Loss: 0.200	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3421    0.4194    0.3768        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.1935    0.3529    0.2500        17
         mtx     0.2500    0.5789    0.3492        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.7600    0.4222    0.5429        45
         zxx     0.7143    0.5128    0.5970        39

    accuracy                         0.4486       185
   macro avg     0.5348    0.4338    0.4408       185
weighted avg     0.5721    0.4486    0.4749       185


========== Train Epoch 32 ==========
Loss: 0.144	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3673    0.5806    0.4500        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.1500    0.1579    0.1538        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.5370    0.6444    0.5859        45
         zxx     0.7857    0.5641    0.6567        39

    accuracy                         0.4757       185
   macro avg     0.5617    0.4225    0.4389       185
weighted avg     0.5600    0.4757    0.4769       185


========== Train Epoch 33 ==========
Loss: 0.233	Accuracy: 46.49%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3784    0.4516    0.4118        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.2000    0.4211    0.2712        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.5075    0.7556    0.6071        45
         zxx     0.7619    0.4103    0.5333        39

    accuracy                         0.4649       185
   macro avg     0.5946    0.4098    0.4304       185
weighted avg     0.5729    0.4649    0.4648       185


========== Train Epoch 34 ==========
Loss: 0.163	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.0968    0.1500        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.1860    0.4211    0.2581        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.5397    0.7556    0.6296        45
         zxx     0.6765    0.5897    0.6301        39

    accuracy                         0.4703       185
   macro avg     0.4793    0.4443    0.4277       185
weighted avg     0.5002    0.4703    0.4525       185


========== Train Epoch 35 ==========
Loss: 0.174	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3231    0.6774    0.4375        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.2609    0.3529    0.3000        17
         mtx     0.2581    0.4211    0.3200        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8077    0.4667    0.5915        45
         zxx     0.6667    0.4615    0.5455        39

    accuracy                         0.4595       185
   macro avg     0.5849    0.4493    0.4527       185
weighted avg     0.6110    0.4595    0.4725       185


========== Train Epoch 36 ==========
Loss: 0.165	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.4141    0.9111    0.5694        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.4757       185
   macro avg     0.4896    0.3840    0.3894       185
weighted avg     0.5049    0.4757    0.4418       185


========== Train Epoch 37 ==========
Loss: 0.126	Accuracy: 44.32%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3500    0.4516    0.3944        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.1667    0.4118    0.2373        17
         mtx     0.2917    0.3684    0.3256        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.7778    0.5385    0.6364        39

    accuracy                         0.4432       185
   macro avg     0.5668    0.4059    0.4226       185
weighted avg     0.5693    0.4432    0.4614       185


========== Train Epoch 38 ==========
Loss: 0.134	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.4634    0.8444    0.5984        45
         zxx     0.9444    0.4359    0.5965        39

    accuracy                         0.5027       185
   macro avg     0.5262    0.4662    0.4583       185
weighted avg     0.5571    0.5027    0.4840       185


========== Train Epoch 39 ==========
Loss: 0.144	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.1290    0.1951        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.2703    0.5263    0.3571        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.5738    0.7778    0.6604        45
         zxx     0.6316    0.6154    0.6234        39

    accuracy                         0.5081       185
   macro avg     0.4973    0.4927    0.4647       185
weighted avg     0.5116    0.5081    0.4823       185


========== Train Epoch 40 ==========
Loss: 0.160	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.5806    0.4235        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2500    0.4211    0.3137        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.7619    0.4103    0.5333        39

    accuracy                         0.4865       185
   macro avg     0.5381    0.4874    0.4652       185
weighted avg     0.5909    0.4865    0.4965       185


========== Train Epoch 41 ==========
Loss: 0.116	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2424    0.4211    0.3077        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.5303    0.7778    0.6306        45
         zxx     0.8947    0.4359    0.5862        39

    accuracy                         0.5081       185
   macro avg     0.5594    0.4681    0.4848       185
weighted avg     0.5779    0.5081    0.5108       185


========== Train Epoch 42 ==========
Loss: 0.123	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.2903    0.3673        31
         cwx     0.3276    0.8636    0.4750        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7857    0.4889    0.6027        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.5027       185
   macro avg     0.5112    0.4887    0.4624       185
weighted avg     0.5551    0.5027    0.4939       185


========== Train Epoch 43 ==========
Loss: 0.135	Accuracy: 48.65%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5385    0.2258    0.3182        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.4458    0.8222    0.5781        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.4865       185
   macro avg     0.5025    0.4091    0.4213       185
weighted avg     0.4975    0.4865    0.4588       185


========== Train Epoch 44 ==========
Loss: 0.109	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3830    0.5806    0.4615        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3143    0.5789    0.4074        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.7368    0.3111    0.4375        45
         zxx     0.5000    0.7436    0.5979        39

    accuracy                         0.4595       185
   macro avg     0.5836    0.4211    0.4140       185
weighted avg     0.5749    0.4595    0.4464       185


========== Train Epoch 45 ==========
Loss: 0.147	Accuracy: 44.32%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.2778    0.2273    0.2500        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2381    0.2632    0.2500        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.4416    0.7556    0.5574        45
         zxx     0.7037    0.4872    0.5758        39

    accuracy                         0.4432       185
   macro avg     0.4342    0.4128    0.4010       185
weighted avg     0.4651    0.4432    0.4247       185


========== Train Epoch 46 ==========
Loss: 0.143	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4048    0.5484    0.4658        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.1739    0.2105    0.1905        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.5686    0.6444    0.6042        45
         zxx     0.7778    0.5385    0.6364        39

    accuracy                         0.4757       185
   macro avg     0.4851    0.4206    0.4375       185
weighted avg     0.5128    0.4757    0.4824       185


========== Train Epoch 47 ==========
Loss: 0.099	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     1.0000    0.2353    0.3810        17
         mtx     0.2500    0.3684    0.2979        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.4130    0.8444    0.5547        45
         zxx     0.7143    0.5128    0.5970        39

    accuracy                         0.4703       185
   macro avg     0.6141    0.3998    0.4235       185
weighted avg     0.5760    0.4703    0.4541       185


========== Train Epoch 48 ==========
Loss: 0.130	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.3226    0.5263    0.4000        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.4839    0.6667    0.5607        45
         zxx     0.8889    0.2051    0.3333        39

    accuracy                         0.4378       185
   macro avg     0.5137    0.4229    0.4100       185
weighted avg     0.5357    0.4378    0.4247       185


========== Train Epoch 49 ==========
Loss: 0.100	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3250    0.4194    0.3662        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2647    0.5294    0.3529        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.5306    0.5778    0.5532        45
         zxx     0.7083    0.4359    0.5397        39

    accuracy                         0.4595       185
   macro avg     0.5214    0.4404    0.4503       185
weighted avg     0.5157    0.4595    0.4665       185


========== Train Epoch 50 ==========
Loss: 0.093	Accuracy: 47.03%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3111    0.4516    0.3684        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2708    0.6842    0.3881        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6957    0.4103    0.5161        39

    accuracy                         0.4703       185
   macro avg     0.5128    0.4538    0.4443       185
weighted avg     0.5688    0.4703    0.4835       185


========== Train Epoch 51 ==========
Loss: 0.179	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.2703    0.5263    0.3571        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5645    0.7778    0.6542        45
         zxx     0.6279    0.6923    0.6585        39

    accuracy                         0.5081       185
   macro avg     0.5844    0.4201    0.4185       185
weighted avg     0.5604    0.5081    0.4841       185


========== Train Epoch 52 ==========
Loss: 0.200	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.2045    0.4737    0.2857        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.5660    0.6667    0.6122        45
         zxx     0.7241    0.5385    0.6176        39

    accuracy                         0.4649       185
   macro avg     0.4910    0.4562    0.4450       185
weighted avg     0.5132    0.4649    0.4625       185


========== Train Epoch 53 ==========
Loss: 0.132	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3019    0.5161    0.3810        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.5273    0.6444    0.5800        45
         zxx     0.7500    0.3846    0.5085        39

    accuracy                         0.4486       185
   macro avg     0.5214    0.4183    0.4251       185
weighted avg     0.5266    0.4486    0.4477       185


========== Train Epoch 54 ==========
Loss: 0.087	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.4194    0.3714        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.1667    0.2632    0.2041        19
         nqx     1.0000    0.5833    0.7368        12
         qtx     0.5370    0.6444    0.5859        45
         zxx     0.6333    0.4872    0.5507        39

    accuracy                         0.4595       185
   macro avg     0.5291    0.4300    0.4570       185
weighted avg     0.5159    0.4595    0.4703       185


========== Train Epoch 55 ==========
Loss: 0.078	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4082    0.6452    0.5000        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5088    0.6444    0.5686        45
         zxx     0.6757    0.6410    0.6579        39

    accuracy                         0.5189       185
   macro avg     0.5530    0.4579    0.4748       185
weighted avg     0.5505    0.5189    0.5102       185


========== Train Epoch 56 ==========
Loss: 0.064	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3774    0.6452    0.4762        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.4390    0.8000    0.5669        45
         zxx     0.7500    0.3077    0.4364        39

    accuracy                         0.4757       185
   macro avg     0.5846    0.4273    0.4329       185
weighted avg     0.5714    0.4757    0.4496       185


========== Train Epoch 57 ==========
Loss: 0.122	Accuracy: 45.41%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3438    0.7097    0.4632        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.8182    0.4000    0.5373        45
         zxx     0.4808    0.6410    0.5495        39

    accuracy                         0.4541       185
   macro avg     0.4869    0.4150    0.3972       185
weighted avg     0.5322    0.4541    0.4382       185


========== Train Epoch 58 ==========
Loss: 0.124	Accuracy: 41.62%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.3333    0.2581    0.2909        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.1818    0.3158    0.2308        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.4306    0.6889    0.5299        45
         zxx     0.7727    0.4359    0.5574        39

    accuracy                         0.4162       185
   macro avg     0.4517    0.3875    0.3793       185
weighted avg     0.4805    0.4162    0.4084       185


========== Train Epoch 59 ==========
Loss: 0.081	Accuracy: 45.95%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.7000    0.2258    0.3415        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.2353    0.3333    0.2759        12
         qtx     0.3861    0.8667    0.5342        45
         zxx     0.8636    0.4872    0.6230        39

    accuracy                         0.4595       185
   macro avg     0.4865    0.3935    0.3910       185
weighted avg     0.5383    0.4595    0.4368       185


========== Train Epoch 60 ==========
Loss: 0.094	Accuracy: 46.49%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.3810    0.5161    0.4384        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.2174    0.2632    0.2381        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.4684    0.8222    0.5968        45
         zxx     0.7368    0.3590    0.4828        39

    accuracy                         0.4649       185
   macro avg     0.5862    0.4006    0.4148       185
weighted avg     0.5614    0.4649    0.4475       185


========== Train Epoch 61 ==========
Loss: 0.087	Accuracy: 47.03%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.1579    0.1579    0.1579        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.4795    0.7778    0.5932        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.4703       185
   macro avg     0.4653    0.4077    0.4147       185
weighted avg     0.4922    0.4703    0.4600       185


========== Train Epoch 62 ==========
Loss: 0.058	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3077    0.2581    0.2807        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.1786    0.2632    0.2128        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5577    0.6444    0.5979        45
         zxx     0.6176    0.5385    0.5753        39

    accuracy                         0.4486       185
   macro avg     0.4387    0.4211    0.4178       185
weighted avg     0.4699    0.4486    0.4488       185


========== Train Epoch 63 ==========
Loss: 0.063	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4118    0.4516    0.4308        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2381    0.2632    0.2500        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.5556    0.6667    0.6061        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.4757       185
   macro avg     0.5055    0.3844    0.3837       185
weighted avg     0.4955    0.4757    0.4544       185


========== Train Epoch 64 ==========
Loss: 0.048	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.4928    0.7556    0.5965        45
         zxx     0.5532    0.6667    0.6047        39

    accuracy                         0.4865       185
   macro avg     0.4661    0.4108    0.4042       185
weighted avg     0.4856    0.4865    0.4554       185


Finished training!!!

Min Loss = 0.048 in epoch 63;
Max Accuracy = 55.14% in epoch 29;
Total Cost 47 minutes

AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (5): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))
  (relu1): ReLU(inplace=True)
  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (relu2): ReLU(inplace=True)
  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu3): ReLU(inplace=True)
  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu4): ReLU(inplace=True)
  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (relu5): ReLU(inplace=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))
  (classifier_): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=2304, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=7, bias=True)
  )
  (__classifier__): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=4608, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=7, bias=True)
  )
)

[0.23783783783783785, 0.23243243243243245, 0.2648648648648649, 0.3027027027027027, 0.41081081081081083, 0.4, 0.3621621621621622, 0.44324324324324327, 0.32972972972972975, 0.3675675675675676, 0.32972972972972975, 0.3675675675675676, 0.43243243243243246, 0.4864864864864865, 0.41081081081081083, 0.35135135135135137, 0.43243243243243246, 0.3891891891891892, 0.3945945945945946, 0.4486486486486487, 0.4540540540540541, 0.44324324324324327, 0.4756756756756757, 0.3621621621621622, 0.34594594594594597, 0.4540540540540541, 0.44324324324324327, 0.43243243243243246, 0.4540540540540541, 0.5513513513513514, 0.4486486486486487, 0.4756756756756757, 0.4648648648648649, 0.4702702702702703, 0.4594594594594595, 0.4756756756756757, 0.44324324324324327, 0.5027027027027027, 0.5081081081081081, 0.4864864864864865, 0.5081081081081081, 0.5027027027027027, 0.4864864864864865, 0.4594594594594595, 0.44324324324324327, 0.4756756756756757, 0.4702702702702703, 0.43783783783783786, 0.4594594594594595, 0.4702702702702703, 0.5081081081081081, 0.4648648648648649, 0.4486486486486487, 0.4594594594594595, 0.518918918918919, 0.4756756756756757, 0.4540540540540541, 0.41621621621621624, 0.4594594594594595, 0.4648648648648649, 0.4702702702702703, 0.4486486486486487, 0.4756756756756757, 0.4864864864864865]
