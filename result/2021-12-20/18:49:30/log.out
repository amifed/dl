dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet34
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.881	Accuracy: 22.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1158    0.5000    0.1880        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.3521    0.5556    0.4310        45
         zxx     0.4286    0.0769    0.1304        39

    accuracy                         0.2216       185
   macro avg     0.1566    0.1856    0.1330       185
weighted avg     0.2027    0.2216    0.1665       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.649	Accuracy: 33.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.3500    0.6222    0.4480        45
         zxx     0.3191    0.7692    0.4511        39

    accuracy                         0.3351       185
   macro avg     0.3507    0.2337    0.1794       185
weighted avg     0.3980    0.3351    0.2381       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.452	Accuracy: 35.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3243    0.3871    0.3529        31
         cwx     0.1818    0.1818    0.1818        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4737    0.4000    0.4337        45
         zxx     0.3902    0.8205    0.5289        39

    accuracy                         0.3568       185
   macro avg     0.1957    0.2556    0.2139       185
weighted avg     0.2735    0.3568    0.2978       185


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.166	Accuracy: 38.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2727    0.5455    0.3636        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2250    0.7500    0.3462        12
         qtx     0.5439    0.6889    0.6078        45
         zxx     0.8000    0.4103    0.5424        39

    accuracy                         0.3892       185
   macro avg     0.2903    0.3757    0.2958       185
weighted avg     0.3655    0.3892    0.3472       185


========== Train Epoch 5 ==========
Loss: 0.841	Accuracy: 30.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1833    0.9167    0.3056        12
         qtx     0.7692    0.2222    0.3448        45
         zxx     0.3153    0.8974    0.4667        39

    accuracy                         0.3027       185
   macro avg     0.1811    0.2909    0.1596       185
weighted avg     0.2655    0.3027    0.2021       185


========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.685	Accuracy: 36.76%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5000    0.1818    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.8947    0.2810        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6538    0.3778    0.4789        45
         zxx     0.6842    0.6667    0.6753        39

    accuracy                         0.3676       185
   macro avg     0.3499    0.3506    0.2975       185
weighted avg     0.4087    0.3676    0.3441       185


========== Train Epoch 7 ==========
Loss: 0.555	Accuracy: 40.54%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2533    0.8636    0.3918        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4500    0.8000    0.5760        45
         zxx     0.7500    0.3846    0.5085        39

    accuracy                         0.4054       185
   macro avg     0.4140    0.3381    0.2768       185
weighted avg     0.4034    0.4054    0.3321       185


========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.318	Accuracy: 39.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2391    0.5000    0.3235        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.1930    0.9167    0.3188        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5778    0.6667    0.6190        39

    accuracy                         0.3946       185
   macro avg     0.3196    0.3813    0.2817       185
weighted avg     0.3910    0.3946    0.3491       185


========== Train Epoch 9 ==========
Loss: 0.255	Accuracy: 46.49%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.8571    0.4000    0.5455        45
         zxx     0.4795    0.8974    0.6250        39

    accuracy                         0.4649       185
   macro avg     0.4366    0.4406    0.4081       185
weighted avg     0.4987    0.4649    0.4413       185


========== Train Epoch 10 ==========
Loss: 0.161	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3137    0.5161    0.3902        31
         cwx     0.3333    0.6818    0.4478        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7000    0.3111    0.4308        45
         zxx     0.7419    0.5897    0.6571        39

    accuracy                         0.4432       185
   macro avg     0.4516    0.4446    0.4063       185
weighted avg     0.5090    0.4432    0.4329       185


========== Train Epoch 11 ==========
Loss: 0.108	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.2364    0.5909    0.3377        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.6667    0.4444        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.4595       185
   macro avg     0.4674    0.4385    0.4036       185
weighted avg     0.5208    0.4595    0.4468       185


========== Train Epoch 12 ==========
Loss: 0.078	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2549    0.4194    0.3171        31
         cwx     0.5333    0.7273    0.6154        22
         hdx     0.2353    0.4706    0.3137        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.7419    0.5111    0.6053        45
         zxx     0.7241    0.5385    0.6176        39

    accuracy                         0.4703       185
   macro avg     0.5325    0.4349    0.4348       185
weighted avg     0.5628    0.4703    0.4815       185


========== Train Epoch 13 ==========
Loss: 0.056	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3714    0.4194    0.3939        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.6667    0.4000    0.5000        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4595       185
   macro avg     0.4641    0.4092    0.4119       185
weighted avg     0.4782    0.4595    0.4399       185


========== Train Epoch 14 ==========
Loss: 0.062	Accuracy: 42.70%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2500    0.2581    0.2540        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.2571    0.7500    0.3830        12
         qtx     0.5370    0.6444    0.5859        45
         zxx     0.9048    0.4872    0.6333        39

    accuracy                         0.4270       185
   macro avg     0.4092    0.4045    0.3769       185
weighted avg     0.4784    0.4270    0.4284       185


========== Train Epoch 15 ==========
Loss: 0.065	Accuracy: 46.49%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3488    0.4839    0.4054        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3200    0.4211    0.3636        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.9444    0.3778    0.5397        45
         zxx     0.4754    0.7436    0.5800        39

    accuracy                         0.4649       185
   macro avg     0.4924    0.4670    0.4214       185
weighted avg     0.5472    0.4649    0.4440       185


========== Train Epoch 16 ==========
Loss: 0.062	Accuracy: 45.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.3462    0.4737    0.4000        19
         nqx     0.2500    0.8333    0.3846        12
         qtx     0.6170    0.6444    0.6304        45
         zxx     0.6562    0.5385    0.5915        39

    accuracy                         0.4541       185
   macro avg     0.4216    0.4475    0.3877       185
weighted avg     0.4775    0.4541    0.4347       185


========== Train Epoch 17 ==========
Loss: 0.088	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.8065    0.4717        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.5351       185
   macro avg     0.5786    0.4885    0.4791       185
weighted avg     0.5975    0.5351    0.5175       185


========== Train Epoch 18 ==========
Loss: 0.118	Accuracy: 43.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3235    0.3548    0.3385        31
         cwx     0.3478    0.3636    0.3556        22
         hdx     0.1622    0.3529    0.2222        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.5800    0.6444    0.6105        45
         zxx     0.6571    0.5897    0.6216        39

    accuracy                         0.4324       185
   macro avg     0.3815    0.3651    0.3573       185
weighted avg     0.4290    0.4324    0.4219       185


========== Train Epoch 19 ==========
Loss: 0.132	Accuracy: 39.46%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.6667    0.4444    0.5333        45
         zxx     0.3398    0.8974    0.4930        39

    accuracy                         0.3946       185
   macro avg     0.3718    0.3336    0.3127       185
weighted avg     0.3790    0.3946    0.3437       185


========== Train Epoch 20 ==========
Loss: 0.157	Accuracy: 37.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.3066    0.9333    0.4615        45
         zxx     0.7391    0.4359    0.5484        39

    accuracy                         0.3730       185
   macro avg     0.3472    0.2584    0.2348       185
weighted avg     0.3923    0.3730    0.3055       185


========== Train Epoch 21 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.149	Accuracy: 38.92%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3077    0.1290    0.1818        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.2090    0.8235    0.3333        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.6538    0.3778    0.4789        45
         zxx     0.4821    0.6923    0.5684        39

    accuracy                         0.3892       185
   macro avg     0.4272    0.3657    0.3231       185
weighted avg     0.4608    0.3892    0.3663       185


========== Train Epoch 22 ==========
Loss: 0.170	Accuracy: 44.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.4308    0.6222    0.5091        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.4486       185
   macro avg     0.4704    0.3990    0.3643       185
weighted avg     0.4846    0.4486    0.4073       185


========== Train Epoch 23 ==========
Loss: 0.128	Accuracy: 44.86%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3333    0.1613    0.2174        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6562    0.4667    0.5455        45
         zxx     0.4103    0.8205    0.5470        39

    accuracy                         0.4486       185
   macro avg     0.4640    0.4391    0.3985       185
weighted avg     0.4833    0.4486    0.4147       185


========== Train Epoch 24 ==========
Loss: 0.183	Accuracy: 44.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.3636    0.5455    0.4364        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.5224    0.7778    0.6250        45
         zxx     0.6053    0.5897    0.5974        39

    accuracy                         0.4486       185
   macro avg     0.3886    0.3673    0.3482       185
weighted avg     0.4512    0.4486    0.4166       185


========== Train Epoch 25 ==========
Loss: 0.188	Accuracy: 40.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.4286    0.1364    0.2069        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.1667    0.2105    0.1860        19
         nqx     0.2963    0.6667    0.4103        12
         qtx     0.6071    0.3778    0.4658        45
         zxx     0.4286    0.8462    0.5690        39

    accuracy                         0.4000       185
   macro avg     0.3828    0.3687    0.3298       185
weighted avg     0.4298    0.4000    0.3699       185


========== Train Epoch 26 ==========
Loss: 0.124	Accuracy: 45.41%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2927    0.3871    0.3333        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6471    0.4889    0.5570        45
         zxx     0.4915    0.7436    0.5918        39

    accuracy                         0.4541       185
   macro avg     0.4347    0.4186    0.4129       185
weighted avg     0.4592    0.4541    0.4414       185


========== Train Epoch 27 ==========
Loss: 0.066	Accuracy: 46.49%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.2571    0.7500    0.3830        12
         qtx     0.5909    0.5778    0.5843        45
         zxx     0.4688    0.7692    0.5825        39

    accuracy                         0.4649       185
   macro avg     0.4829    0.4363    0.4042       185
weighted avg     0.5092    0.4649    0.4427       185


========== Train Epoch 28 ==========
Loss: 0.045	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2500    0.0968    0.1395        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.2500    0.4118    0.3111        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.6038    0.7111    0.6531        45
         zxx     0.6667    0.6154    0.6400        39

    accuracy                         0.4919       185
   macro avg     0.4422    0.4675    0.4392       185
weighted avg     0.4814    0.4919    0.4733       185


========== Train Epoch 29 ==========
Loss: 0.027	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.3871    0.3810        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.4571    0.8205    0.5872        39

    accuracy                         0.4865       185
   macro avg     0.4960    0.4585    0.4375       185
weighted avg     0.5388    0.4865    0.4731       185


========== Train Epoch 30 ==========
Loss: 0.024	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2667    0.1290    0.1739        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.1429    0.1176    0.1290        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.5741    0.6889    0.6263        45
         zxx     0.4828    0.7179    0.5773        39

    accuracy                         0.4703       185
   macro avg     0.4141    0.4309    0.4040       185
weighted avg     0.4385    0.4703    0.4373       185


========== Train Epoch 31 ==========
Loss: 0.027	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4703       185
   macro avg     0.4378    0.4533    0.4192       185
weighted avg     0.4824    0.4703    0.4513       185


========== Train Epoch 32 ==========
Loss: 0.019	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3529    0.3871    0.3692        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.6047    0.6667    0.6341        39

    accuracy                         0.4919       185
   macro avg     0.4515    0.4674    0.4492       185
weighted avg     0.4917    0.4919    0.4854       185


========== Train Epoch 33 ==========
Loss: 0.020	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5027       185
   macro avg     0.4678    0.4930    0.4636       185
weighted avg     0.5175    0.5027    0.4954       185


========== Train Epoch 34 ==========
Loss: 0.026	Accuracy: 49.19%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.4776    0.8205    0.6038        39

    accuracy                         0.4919       185
   macro avg     0.4623    0.4561    0.4359       185
weighted avg     0.5043    0.4919    0.4738       185


========== Train Epoch 35 ==========
Loss: 0.017	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.4571    0.8205    0.5872        39

    accuracy                         0.4757       185
   macro avg     0.4600    0.4448    0.4202       185
weighted avg     0.5089    0.4757    0.4604       185


========== Train Epoch 36 ==========
Loss: 0.016	Accuracy: 45.41%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3125    0.1613    0.2128        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6571    0.5111    0.5750        45
         zxx     0.4839    0.7692    0.5941        39

    accuracy                         0.4541       185
   macro avg     0.4087    0.4118    0.3935       185
weighted avg     0.4469    0.4541    0.4325       185


========== Train Epoch 37 ==========
Loss: 0.018	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.5027       185
   macro avg     0.4714    0.4708    0.4557       185
weighted avg     0.5089    0.5027    0.4895       185


========== Train Epoch 38 ==========
Loss: 0.015	Accuracy: 47.03%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.3846    0.1613    0.2273        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.2647    0.5294    0.3529        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.4703       185
   macro avg     0.4272    0.4424    0.4065       185
weighted avg     0.4818    0.4703    0.4484       185


========== Train Epoch 39 ==========
Loss: 0.014	Accuracy: 47.57%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2273    0.2941    0.2564        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.5085    0.7692    0.6122        39

    accuracy                         0.4757       185
   macro avg     0.4403    0.4381    0.4230       185
weighted avg     0.4755    0.4757    0.4605       185


========== Train Epoch 40 ==========
Loss: 0.011	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4286    0.1935    0.2667        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4703       185
   macro avg     0.4208    0.4339    0.4066       185
weighted avg     0.4712    0.4703    0.4480       185


========== Train Epoch 41 ==========
Loss: 0.015	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6765    0.5111    0.5823        45
         zxx     0.4776    0.8205    0.6038        39

    accuracy                         0.4703       185
   macro avg     0.4293    0.4334    0.4173       185
weighted avg     0.4683    0.4703    0.4521       185


========== Train Epoch 42 ==========
Loss: 0.011	Accuracy: 49.19%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.4919       185
   macro avg     0.4509    0.4497    0.4336       185
weighted avg     0.4930    0.4919    0.4755       185


========== Train Epoch 43 ==========
Loss: 0.011	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5357    0.7692    0.6316        39

    accuracy                         0.4811       185
   macro avg     0.4490    0.4436    0.4276       185
weighted avg     0.4996    0.4811    0.4739       185


========== Train Epoch 44 ==========
Loss: 0.011	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.2000    0.2941    0.2381        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4703       185
   macro avg     0.4349    0.4346    0.4126       185
weighted avg     0.4829    0.4703    0.4540       185


========== Train Epoch 45 ==========
Loss: 0.014	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.1935    0.2609        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.2000    0.3529    0.2553        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.4865       185
   macro avg     0.4393    0.4415    0.4200       185
weighted avg     0.4865    0.4865    0.4662       185


========== Train Epoch 46 ==========
Loss: 0.013	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3125    0.1613    0.2128        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.2000    0.2941    0.2381        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.4848    0.8205    0.6095        39

    accuracy                         0.4703       185
   macro avg     0.4366    0.4335    0.4185       185
weighted avg     0.4882    0.4703    0.4581       185


========== Train Epoch 47 ==========
Loss: 0.012	Accuracy: 48.65%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.4865       185
   macro avg     0.4503    0.4475    0.4273       185
weighted avg     0.5021    0.4865    0.4716       185


========== Train Epoch 48 ==========
Loss: 0.012	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4091    0.2903    0.3396        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.1500    0.1765    0.1622        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4811       185
   macro avg     0.4479    0.4410    0.4217       185
weighted avg     0.5077    0.4811    0.4711       185


========== Train Epoch 49 ==========
Loss: 0.011	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3333    0.2581    0.2909        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.1429    0.2353    0.1778        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.4811       185
   macro avg     0.4526    0.4438    0.4316       185
weighted avg     0.5063    0.4811    0.4792       185


========== Train Epoch 50 ==========
Loss: 0.013	Accuracy: 50.27%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.5027       185
   macro avg     0.4936    0.4651    0.4485       185
weighted avg     0.5287    0.5027    0.4853       185


========== Train Epoch 51 ==========
Loss: 0.012	Accuracy: 50.27%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5027       185
   macro avg     0.4714    0.4665    0.4458       185
weighted avg     0.5190    0.5027    0.4878       185


========== Train Epoch 52 ==========
Loss: 0.010	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.2400    0.3529    0.2857        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7857    0.4889    0.6027        45
         zxx     0.4521    0.8462    0.5893        39

    accuracy                         0.4649       185
   macro avg     0.4465    0.4385    0.4179       185
weighted avg     0.4912    0.4649    0.4476       185


========== Train Epoch 53 ==========
Loss: 0.011	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2000    0.2353    0.2162        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.4919       185
   macro avg     0.4604    0.4526    0.4370       185
weighted avg     0.5032    0.4919    0.4786       185


========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.2222    0.3529    0.2727        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4757       185
   macro avg     0.4444    0.4458    0.4196       185
weighted avg     0.4987    0.4757    0.4614       185


========== Train Epoch 55 ==========
Loss: 0.011	Accuracy: 48.65%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3600    0.2903    0.3214        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.1818    0.2353    0.2051        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.4865       185
   macro avg     0.4790    0.4484    0.4356       185
weighted avg     0.5208    0.4865    0.4788       185


========== Train Epoch 56 ==========
Loss: 0.012	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.4811       185
   macro avg     0.4525    0.4539    0.4334       185
weighted avg     0.5051    0.4811    0.4733       185


========== Train Epoch 57 ==========
Loss: 0.009	Accuracy: 49.19%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4286    0.2903    0.3462        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.1818    0.2353    0.2051        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.3333    0.6667    0.4444        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.4919       185
   macro avg     0.4674    0.4564    0.4378       185
weighted avg     0.5262    0.4919    0.4878       185


========== Train Epoch 58 ==========
Loss: 0.010	Accuracy: 48.65%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3529    0.1935    0.2500        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.2105    0.2353    0.2222        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.4865       185
   macro avg     0.4503    0.4484    0.4272       185
weighted avg     0.4976    0.4865    0.4698       185


========== Train Epoch 59 ==========
Loss: 0.009	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.4811       185
   macro avg     0.4641    0.4572    0.4352       185
weighted avg     0.5162    0.4811    0.4740       185


========== Train Epoch 60 ==========
Loss: 0.012	Accuracy: 47.03%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.2727    0.1935    0.2264        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.1786    0.2941    0.2222        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3333    0.6667    0.4444        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.4703       185
   macro avg     0.4482    0.4427    0.4244       185
weighted avg     0.5005    0.4703    0.4696       185


========== Train Epoch 61 ==========
Loss: 0.011	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.3200    0.6667    0.4324        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5091    0.7179    0.5957        39

    accuracy                         0.4811       185
   macro avg     0.4411    0.4439    0.4245       185
weighted avg     0.4903    0.4811    0.4719       185


========== Train Epoch 62 ==========
Loss: 0.012	Accuracy: 47.57%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.3333    0.2581    0.2909        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.2000    0.2353    0.2162        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.4918    0.7692    0.6000        39

    accuracy                         0.4757       185
   macro avg     0.4558    0.4412    0.4242       185
weighted avg     0.5050    0.4757    0.4684       185


========== Train Epoch 63 ==========
Loss: 0.011	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2692    0.2258    0.2456        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.5088    0.7436    0.6042        39

    accuracy                         0.4703       185
   macro avg     0.4584    0.4476    0.4289       185
weighted avg     0.5157    0.4703    0.4696       185


========== Train Epoch 64 ==========
Loss: 0.010	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5085    0.7692    0.6122        39

    accuracy                         0.4919       185
   macro avg     0.4678    0.4594    0.4421       185
weighted avg     0.5122    0.4919    0.4832       185


Finished training!!!

Min Loss = 0.009 in epoch 58;
Max Accuracy = 53.51% in epoch 16;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.22162162162162163, 0.33513513513513515, 0.3567567567567568, 0.3891891891891892, 0.3027027027027027, 0.3675675675675676, 0.40540540540540543, 0.3945945945945946, 0.4648648648648649, 0.44324324324324327, 0.4594594594594595, 0.4702702702702703, 0.4594594594594595, 0.42702702702702705, 0.4648648648648649, 0.4540540540540541, 0.5351351351351351, 0.43243243243243246, 0.3945945945945946, 0.372972972972973, 0.3891891891891892, 0.4486486486486487, 0.4486486486486487, 0.4486486486486487, 0.4, 0.4540540540540541, 0.4648648648648649, 0.4918918918918919, 0.4864864864864865, 0.4702702702702703, 0.4702702702702703, 0.4918918918918919, 0.5027027027027027, 0.4918918918918919, 0.4756756756756757, 0.4540540540540541, 0.5027027027027027, 0.4702702702702703, 0.4756756756756757, 0.4702702702702703, 0.4702702702702703, 0.4918918918918919, 0.4810810810810811, 0.4702702702702703, 0.4864864864864865, 0.4702702702702703, 0.4864864864864865, 0.4810810810810811, 0.4810810810810811, 0.5027027027027027, 0.5027027027027027, 0.4648648648648649, 0.4918918918918919, 0.4756756756756757, 0.4864864864864865, 0.4810810810810811, 0.4918918918918919, 0.4864864864864865, 0.4810810810810811, 0.4702702702702703, 0.4810810810810811, 0.4756756756756757, 0.4702702702702703, 0.4918918918918919]
