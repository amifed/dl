dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet34
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.900	Accuracy: 29.73%	Cost 39s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.2093    0.8182    0.3333        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3210    0.5778    0.4127        45
         zxx     0.7000    0.1795    0.2857        39

    accuracy                         0.2973       185
   macro avg     0.3798    0.2549    0.1920       185
weighted avg     0.4575    0.2973    0.2337       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.620	Accuracy: 37.84%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2059    0.6364    0.3111        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4000    0.6667    0.5000        45
         zxx     0.6970    0.5897    0.6389        39

    accuracy                         0.3784       185
   macro avg     0.2337    0.3061    0.2480       185
weighted avg     0.2903    0.3784    0.3118       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.396	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.3333    0.4545    0.3846        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.4737    0.2812        19
         nqx     0.3333    0.5000    0.4000        12
         qtx     0.7200    0.4000    0.5143        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.4486       185
   macro avg     0.3884    0.4181    0.3848       185
weighted avg     0.4780    0.4486    0.4440       185


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.222	Accuracy: 44.32%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4286    0.3871    0.4068        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.0769    0.0526    0.0625        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6667    0.3111    0.4242        45
         zxx     0.4390    0.9231    0.5950        39

    accuracy                         0.4432       185
   macro avg     0.4498    0.4227    0.3862       185
weighted avg     0.4827    0.4432    0.4083       185


========== Train Epoch 5 ==========
Loss: 0.901	Accuracy: 28.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.2600    0.5909    0.3611        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1443    0.7368    0.2414        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6667    0.2222    0.3333        45
         zxx     1.0000    0.2308    0.3750        39

    accuracy                         0.2865       185
   macro avg     0.4560    0.3231    0.2662       185
weighted avg     0.5599    0.2865    0.2758       185


========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.591	Accuracy: 36.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.1887    0.5263    0.2778        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.7778    0.3111    0.4444        45
         zxx     0.3564    0.9231    0.5143        39

    accuracy                         0.3622       185
   macro avg     0.4568    0.3043    0.2598       185
weighted avg     0.4459    0.3622    0.3034       185


========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.407	Accuracy: 24.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.1000    0.0323    0.0488        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1216    0.5294    0.1978        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1594    0.9167    0.2716        12
         qtx     0.8000    0.0889    0.1600        45
         zxx     0.7407    0.5128    0.6061        39

    accuracy                         0.2432       185
   macro avg     0.2745    0.2971    0.1835       185
weighted avg     0.3890    0.2432    0.2107       185


========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.367	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3846    0.8065    0.5208        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.2258    0.4118    0.2917        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.8077    0.5385    0.6462        39

    accuracy                         0.4919       185
   macro avg     0.5740    0.4527    0.4626       185
weighted avg     0.5798    0.4919    0.4967       185


========== Train Epoch 9 ==========
Loss: 0.209	Accuracy: 20.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1358    1.0000    0.2391        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5000    0.0444    0.0816        45
         zxx     1.0000    0.2308    0.3750        39

    accuracy                         0.2054       185
   macro avg     0.3051    0.2417    0.1643       185
weighted avg     0.3810    0.2054    0.1568       185


========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.203	Accuracy: 37.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.1786    0.5263    0.2667        19
         nqx     0.2174    0.8333    0.3448        12
         qtx     0.8000    0.3556    0.4923        45
         zxx     0.6571    0.5897    0.6216        39

    accuracy                         0.3784       185
   macro avg     0.4956    0.4008    0.3479       185
weighted avg     0.5735    0.3784    0.3878       185


========== Train Epoch 11 ==========
Loss: 0.180	Accuracy: 38.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3158    0.3871    0.3478        31
         cwx     0.2235    0.8636    0.3551        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     1.0000    0.2000    0.3333        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.3892       185
   macro avg     0.4798    0.3825    0.3446       185
weighted avg     0.5588    0.3892    0.3714       185


========== Train Epoch 12 ==========
Loss: 0.184	Accuracy: 39.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.2000    0.3529    0.2553        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.4286    0.8667    0.5735        45
         zxx     1.0000    0.1538    0.2667        39

    accuracy                         0.3946       185
   macro avg     0.4741    0.3485    0.3250       185
weighted avg     0.5264    0.3946    0.3507       185


========== Train Epoch 13 ==========
Loss: 0.154	Accuracy: 40.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3051    0.5806    0.4000        31
         cwx     0.3396    0.8182    0.4800        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7692    0.2222    0.3448        45
         zxx     0.7826    0.4615    0.5806        39

    accuracy                         0.4054       185
   macro avg     0.4270    0.4136    0.3660       185
weighted avg     0.5071    0.4054    0.3877       185


========== Train Epoch 14 ==========
Loss: 0.120	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.3889    0.6364    0.4828        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.2093    0.4737    0.2903        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8333    0.4444    0.5797        45
         zxx     0.6087    0.7179    0.6588        39

    accuracy                         0.4595       185
   macro avg     0.4878    0.4592    0.4283       185
weighted avg     0.5457    0.4595    0.4499       185


========== Train Epoch 15 ==========
Loss: 0.067	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.3226    0.8333    0.4651        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5622       185
   macro avg     0.5432    0.5523    0.5174       185
weighted avg     0.6038    0.5622    0.5627       185


========== Train Epoch 16 ==========
Loss: 0.051	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.4811       185
   macro avg     0.4260    0.4388    0.4196       185
weighted avg     0.4781    0.4811    0.4659       185


========== Train Epoch 17 ==========
Loss: 0.055	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.2800    0.3684    0.3182        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5135       185
   macro avg     0.5387    0.4606    0.4331       185
weighted avg     0.5981    0.5135    0.4797       185


========== Train Epoch 18 ==========
Loss: 0.047	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.2895    0.5000    0.3667        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.5882    0.6667    0.6250        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.5027       185
   macro avg     0.4881    0.4663    0.4385       185
weighted avg     0.5280    0.5027    0.4781       185


========== Train Epoch 19 ==========
Loss: 0.037	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3571    0.3226    0.3390        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5081       185
   macro avg     0.4887    0.4661    0.4511       185
weighted avg     0.5163    0.5081    0.4866       185


========== Train Epoch 20 ==========
Loss: 0.033	Accuracy: 54.59%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5459       185
   macro avg     0.5009    0.5075    0.4931       185
weighted avg     0.5498    0.5459    0.5398       185


========== Train Epoch 21 ==========
Loss: 0.022	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5622       185
   macro avg     0.4992    0.5236    0.5020       185
weighted avg     0.5536    0.5622    0.5505       185


========== Train Epoch 22 ==========
Loss: 0.026	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4130    0.6129    0.4935        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.7500    0.7692    0.7595        39

    accuracy                         0.5622       185
   macro avg     0.5153    0.5263    0.5118       185
weighted avg     0.5656    0.5622    0.5561       185


========== Train Epoch 23 ==========
Loss: 0.024	Accuracy: 53.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     0.4375    0.6364    0.5185        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.5373    0.9231    0.6792        39

    accuracy                         0.5351       185
   macro avg     0.5132    0.5053    0.4744       185
weighted avg     0.5493    0.5351    0.5023       185


========== Train Epoch 24 ==========
Loss: 0.021	Accuracy: 51.35%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3600    0.2903    0.3214        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5135       185
   macro avg     0.4621    0.4839    0.4631       185
weighted avg     0.5140    0.5135    0.5070       185


========== Train Epoch 25 ==========
Loss: 0.022	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5000    0.2258    0.3111        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     0.4795    0.8974    0.6250        39

    accuracy                         0.5297       185
   macro avg     0.5241    0.5227    0.4881       185
weighted avg     0.5650    0.5297    0.5069       185


========== Train Epoch 26 ==========
Loss: 0.020	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.6458    0.6889    0.6667        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5676       185
   macro avg     0.5585    0.5103    0.5120       185
weighted avg     0.5642    0.5676    0.5450       185


========== Train Epoch 27 ==========
Loss: 0.027	Accuracy: 47.57%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4444    0.1290    0.2000        31
         cwx     0.3167    0.8636    0.4634        22
         hdx     0.2400    0.3529    0.2857        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.4757       185
   macro avg     0.4863    0.4368    0.4074       185
weighted avg     0.5234    0.4757    0.4534       185


========== Train Epoch 28 ==========
Loss: 0.020	Accuracy: 53.51%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.5351       185
   macro avg     0.4847    0.4940    0.4771       185
weighted avg     0.5283    0.5351    0.5182       185


========== Train Epoch 29 ==========
Loss: 0.018	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.5000    0.7273    0.5926        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5568       185
   macro avg     0.4967    0.5015    0.4879       185
weighted avg     0.5583    0.5568    0.5446       185


========== Train Epoch 30 ==========
Loss: 0.013	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5351       185
   macro avg     0.4747    0.4807    0.4711       185
weighted avg     0.5345    0.5351    0.5268       185


========== Train Epoch 31 ==========
Loss: 0.016	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.5297       185
   macro avg     0.4793    0.4779    0.4687       185
weighted avg     0.5165    0.5297    0.5109       185


========== Train Epoch 32 ==========
Loss: 0.012	Accuracy: 56.22%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5781    0.9487    0.7184        39

    accuracy                         0.5622       185
   macro avg     0.5225    0.5308    0.5031       185
weighted avg     0.5683    0.5622    0.5399       185


========== Train Epoch 33 ==========
Loss: 0.015	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4286    0.1935    0.2667        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2414    0.3684    0.2917        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5351       185
   macro avg     0.4875    0.4802    0.4727       185
weighted avg     0.5276    0.5351    0.5190       185


========== Train Epoch 34 ==========
Loss: 0.016	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.2759    0.4706    0.3478        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.5968    0.9487    0.7327        39

    accuracy                         0.5568       185
   macro avg     0.5352    0.5366    0.5055       185
weighted avg     0.5982    0.5568    0.5422       185


========== Train Epoch 35 ==========
Loss: 0.016	Accuracy: 53.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.2857    0.3158    0.3000        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.5351       185
   macro avg     0.5067    0.5053    0.4937       185
weighted avg     0.5375    0.5351    0.5212       185


========== Train Epoch 36 ==========
Loss: 0.020	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3500    0.6774    0.4615        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.6279    0.6000    0.6136        45
         zxx     0.6944    0.6410    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4888    0.4707    0.4592       185
weighted avg     0.5156    0.5189    0.4997       185


========== Train Epoch 37 ==========
Loss: 0.035	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4615    0.1935    0.2727        31
         cwx     0.3590    0.6364    0.4590        22
         hdx     0.2105    0.2353    0.2222        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5027       185
   macro avg     0.4457    0.4751    0.4290       185
weighted avg     0.5189    0.5027    0.4801       185


========== Train Epoch 38 ==========
Loss: 0.026	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2955    0.4194    0.3467        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.0909    0.0588    0.0714        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.5000    0.8974    0.6422        39

    accuracy                         0.4919       185
   macro avg     0.5085    0.4446    0.4388       185
weighted avg     0.5435    0.4919    0.4772       185


========== Train Epoch 39 ==========
Loss: 0.097	Accuracy: 33.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.0323    0.0588        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1463    0.6316    0.2376        19
         nqx     0.1818    0.3333    0.2353        12
         qtx     0.6429    0.4000    0.4932        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.3351       185
   macro avg     0.3429    0.3240    0.2816       185
weighted avg     0.4383    0.3351    0.3345       185


========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.792	Accuracy: 27.57%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.1290    0.2000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.2059    0.4118    0.2745        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.2734    0.8444    0.4130        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.2757       185
   macro avg     0.3462    0.2173    0.1615       185
weighted avg     0.2950    0.2757    0.1787       185


========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.939	Accuracy: 36.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2500    0.0323    0.0571        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.1667    0.3333    0.2222        12
         qtx     0.6000    0.4000    0.4800        45
         zxx     0.3617    0.8718    0.5113        39

    accuracy                         0.3622       185
   macro avg     0.3137    0.3038    0.2681       185
weighted avg     0.3634    0.3622    0.3150       185


========== Train Epoch 42 ==========
Loss: 0.308	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.1290    0.1860        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.5455    0.9231    0.6857        39

    accuracy                         0.4811       185
   macro avg     0.4057    0.4103    0.3927       185
weighted avg     0.4576    0.4811    0.4500       185


========== Train Epoch 43 ==========
Loss: 0.147	Accuracy: 42.16%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.7895    0.3333    0.4688        45
         zxx     0.4833    0.7436    0.5859        39

    accuracy                         0.4216       185
   macro avg     0.4053    0.3916    0.3782       185
weighted avg     0.4666    0.4216    0.4135       185


========== Train Epoch 44 ==========
Loss: 0.058	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.2381    0.2632    0.2500        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6774    0.4667    0.5526        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.4811       185
   macro avg     0.4380    0.4276    0.4209       185
weighted avg     0.4845    0.4811    0.4659       185


========== Train Epoch 45 ==========
Loss: 0.048	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.1111    0.0323    0.0500        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.5405       185
   macro avg     0.4615    0.5217    0.4783       185
weighted avg     0.4970    0.5405    0.5078       185


========== Train Epoch 46 ==========
Loss: 0.036	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3043    0.2258    0.2593        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.5652    0.5778    0.5714        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5189       185
   macro avg     0.4768    0.4875    0.4782       185
weighted avg     0.4947    0.5189    0.5021       185


========== Train Epoch 47 ==========
Loss: 0.026	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.4919       185
   macro avg     0.4229    0.4611    0.4231       185
weighted avg     0.4622    0.4919    0.4546       185


========== Train Epoch 48 ==========
Loss: 0.020	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3600    0.2903    0.3214        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.5135       185
   macro avg     0.4618    0.4718    0.4624       185
weighted avg     0.5064    0.5135    0.5041       185


========== Train Epoch 49 ==========
Loss: 0.019	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2381    0.1613    0.1923        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.4811       185
   macro avg     0.4265    0.4452    0.4290       185
weighted avg     0.4641    0.4811    0.4642       185


========== Train Epoch 50 ==========
Loss: 0.018	Accuracy: 51.35%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3000    0.1935    0.2353        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.5800    0.6444    0.6105        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.5135       185
   macro avg     0.4659    0.4803    0.4698       185
weighted avg     0.4898    0.5135    0.4978       185


========== Train Epoch 51 ==========
Loss: 0.016	Accuracy: 48.11%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.2500    0.1935    0.2182        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.4811       185
   macro avg     0.4423    0.4427    0.4340       185
weighted avg     0.4665    0.4811    0.4628       185


========== Train Epoch 52 ==========
Loss: 0.016	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2800    0.2258    0.2500        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6774    0.4667    0.5526        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.4919       185
   macro avg     0.4529    0.4640    0.4425       185
weighted avg     0.4899    0.4919    0.4739       185


========== Train Epoch 53 ==========
Loss: 0.020	Accuracy: 50.81%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.5081       185
   macro avg     0.4668    0.4783    0.4633       185
weighted avg     0.4988    0.5081    0.4941       185


========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2857    0.1935    0.2308        31
         cwx     0.4000    0.5455    0.4615        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.5135       185
   macro avg     0.4511    0.4801    0.4560       185
weighted avg     0.4975    0.5135    0.4949       185


========== Train Epoch 55 ==========
Loss: 0.013	Accuracy: 50.81%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3529    0.1935    0.2500        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5081       185
   macro avg     0.4653    0.4724    0.4594       185
weighted avg     0.4998    0.5081    0.4926       185


========== Train Epoch 56 ==========
Loss: 0.017	Accuracy: 50.81%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3043    0.2258    0.2593        31
         cwx     0.3714    0.5909    0.4561        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6562    0.4667    0.5455        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.5081       185
   macro avg     0.4788    0.4817    0.4658       185
weighted avg     0.5024    0.5081    0.4889       185


========== Train Epoch 57 ==========
Loss: 0.012	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.2581    0.2909        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6571    0.5111    0.5750        45
         zxx     0.6140    0.8974    0.7292        39

    accuracy                         0.5135       185
   macro avg     0.4778    0.4809    0.4705       185
weighted avg     0.5057    0.5135    0.4988       185


========== Train Epoch 58 ==========
Loss: 0.011	Accuracy: 51.89%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6429    0.6000    0.6207        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5189       185
   macro avg     0.4639    0.4826    0.4677       185
weighted avg     0.5103    0.5189    0.5101       185


========== Train Epoch 59 ==========
Loss: 0.013	Accuracy: 49.19%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.4919       185
   macro avg     0.4291    0.4520    0.4353       185
weighted avg     0.4867    0.4919    0.4837       185


========== Train Epoch 60 ==========
Loss: 0.016	Accuracy: 48.11%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3214    0.2903    0.3051        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.4811       185
   macro avg     0.4257    0.4307    0.4244       185
weighted avg     0.4723    0.4811    0.4715       185


========== Train Epoch 61 ==========
Loss: 0.013	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.5135       185
   macro avg     0.4563    0.4706    0.4554       185
weighted avg     0.4905    0.5135    0.4929       185


========== Train Epoch 62 ==========
Loss: 0.012	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.6667    0.5778    0.6190        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.4919       185
   macro avg     0.4265    0.4378    0.4270       185
weighted avg     0.4821    0.4919    0.4805       185


========== Train Epoch 63 ==========
Loss: 0.013	Accuracy: 49.19%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.3478    0.3636    0.3556        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6000    0.6000    0.6000        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.4919       185
   macro avg     0.4270    0.4270    0.4227       185
weighted avg     0.4718    0.4919    0.4766       185


========== Train Epoch 64 ==========
Loss: 0.010	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5081       185
   macro avg     0.4691    0.4720    0.4621       185
weighted avg     0.5106    0.5081    0.4988       185


Finished training!!!

Min Loss = 0.010 in epoch 63;
Max Accuracy = 56.76% in epoch 25;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.2972972972972973, 0.3783783783783784, 0.4486486486486487, 0.44324324324324327, 0.2864864864864865, 0.3621621621621622, 0.24324324324324326, 0.4918918918918919, 0.20540540540540542, 0.3783783783783784, 0.3891891891891892, 0.3945945945945946, 0.40540540540540543, 0.4594594594594595, 0.5621621621621622, 0.4810810810810811, 0.5135135135135135, 0.5027027027027027, 0.5081081081081081, 0.5459459459459459, 0.5621621621621622, 0.5621621621621622, 0.5351351351351351, 0.5135135135135135, 0.5297297297297298, 0.5675675675675675, 0.4756756756756757, 0.5351351351351351, 0.5567567567567567, 0.5351351351351351, 0.5297297297297298, 0.5621621621621622, 0.5351351351351351, 0.5567567567567567, 0.5351351351351351, 0.518918918918919, 0.5027027027027027, 0.4918918918918919, 0.33513513513513515, 0.2756756756756757, 0.3621621621621622, 0.4810810810810811, 0.42162162162162165, 0.4810810810810811, 0.5405405405405406, 0.518918918918919, 0.4918918918918919, 0.5135135135135135, 0.4810810810810811, 0.5135135135135135, 0.4810810810810811, 0.4918918918918919, 0.5081081081081081, 0.5135135135135135, 0.5081081081081081, 0.5081081081081081, 0.5135135135135135, 0.518918918918919, 0.4918918918918919, 0.4810810810810811, 0.5135135135135135, 0.4918918918918919, 0.4918918918918919, 0.5081081081081081]
