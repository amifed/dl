dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.882	Accuracy: 27.03%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.1429    0.0455    0.0690        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2823    0.7778    0.4142        45
         zxx     0.2708    0.3333    0.2989        39

    accuracy                         0.2703       185
   macro avg     0.1708    0.1698    0.1204       185
weighted avg     0.2265    0.2703    0.1821       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.568	Accuracy: 33.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3238    0.7556    0.4533        45
         zxx     0.3231    0.5385    0.4038        39

    accuracy                         0.3351       185
   macro avg     0.2829    0.2247    0.1813       185
weighted avg     0.3541    0.3351    0.2530       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.381	Accuracy: 27.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2500    0.1935    0.2182        31
         cwx     0.1839    0.7273    0.2936        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.1111    0.1579    0.1304        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.5000    0.2889    0.3662        45
         zxx     0.8333    0.2564    0.3922        39

    accuracy                         0.2757       185
   macro avg     0.3636    0.2607    0.2440       185
weighted avg     0.4247    0.2757    0.2812       185


========== Train Epoch 4 ==========
Loss: 1.086	Accuracy: 36.76%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3333    0.0323    0.0588        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.3359    0.9778    0.5000        45
         zxx     0.5278    0.4872    0.5067        39

    accuracy                         0.3676       185
   macro avg     0.2150    0.2615    0.1979       185
weighted avg     0.2688    0.3676    0.2590       185


========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.826	Accuracy: 38.38%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2692    0.9032    0.4148        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2273    0.2632    0.2439        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     1.0000    0.1282    0.2273        39

    accuracy                         0.3838       185
   macro avg     0.5991    0.3326    0.3148       185
weighted avg     0.6190    0.3838    0.3568       185


========== Train Epoch 6 ==========
Loss: 0.509	Accuracy: 31.89%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4000    0.1290    0.1951        31
         cwx     0.1746    1.0000    0.2973        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6667    0.1333    0.2222        45
         zxx     0.6667    0.6667    0.6667        39

    accuracy                         0.3189       185
   macro avg     0.4154    0.2875    0.2193       185
weighted avg     0.4554    0.3189    0.2726       185


========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.248	Accuracy: 37.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.1639    0.5882    0.2564        17
         mtx     0.1200    0.1579    0.1364        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.8261    0.4222    0.5588        45
         zxx     0.5500    0.5641    0.5570        39

    accuracy                         0.3784       185
   macro avg     0.4492    0.3928    0.3501       185
weighted avg     0.5263    0.3784    0.3812       185


========== Train Epoch 8 ==========
Loss: 0.150	Accuracy: 44.32%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.1750    0.7368    0.2828        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6667    0.6667    0.6667        39

    accuracy                         0.4432       185
   macro avg     0.6590    0.4061    0.3834       185
weighted avg     0.6766    0.4432    0.4375       185


========== Train Epoch 9 ==========
Loss: 0.075	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3086    0.8065    0.4464        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.8400    0.4667    0.6000        45
         zxx     0.9333    0.3590    0.5185        39

    accuracy                         0.4595       185
   macro avg     0.4728    0.4522    0.4151       185
weighted avg     0.5671    0.4595    0.4522       185


========== Train Epoch 10 ==========
Loss: 0.071	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2871    0.9355    0.4394        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5455    1.0000    0.7059        12
         qtx     0.8000    0.4444    0.5714        45
         zxx     0.7500    0.5385    0.6269        39

    accuracy                         0.4757       185
   macro avg     0.5725    0.4578    0.3983       185
weighted avg     0.6024    0.4757    0.4404       185


========== Train Epoch 11 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.069	Accuracy: 45.95%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5556    0.1613    0.2500        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.2075    0.6471    0.3143        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.4595       185
   macro avg     0.5139    0.4314    0.4017       185
weighted avg     0.5388    0.4595    0.4326       185


========== Train Epoch 12 ==========
Loss: 0.070	Accuracy: 48.65%	Cost 48s
              precision    recall  f1-score   support

         bzx     1.0000    0.1290    0.2286        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.2075    0.9167    0.3385        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.4865       185
   macro avg     0.5633    0.4736    0.4189       185
weighted avg     0.6427    0.4865    0.4760       185


========== Train Epoch 13 ==========
Loss: 0.045	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.6296    0.7556    0.6869        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.5297       185
   macro avg     0.5103    0.4641    0.4681       185
weighted avg     0.5182    0.5297    0.5048       185


========== Train Epoch 14 ==========
Loss: 0.042	Accuracy: 46.49%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3158    0.5806    0.4091        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.2391    0.6471    0.3492        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.9048    0.4222    0.5758        45
         zxx     0.7600    0.4872    0.5938        39

    accuracy                         0.4649       185
   macro avg     0.5439    0.4838    0.4506       185
weighted avg     0.5998    0.4649    0.4701       185


========== Train Epoch 15 ==========
Loss: 0.053	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.4045    0.9231    0.5625        39

    accuracy                         0.4811       185
   macro avg     0.5956    0.4446    0.4303       185
weighted avg     0.6159    0.4811    0.4449       185


========== Train Epoch 16 ==========
Loss: 0.045	Accuracy: 32.43%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2132    0.9355    0.3473        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8125    0.2889    0.4262        45
         zxx     0.8750    0.1795    0.2979        39

    accuracy                         0.3243       185
   macro avg     0.4667    0.3156    0.2721       185
weighted avg     0.5450    0.3243    0.2900       185


========== Train Epoch 17 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.035	Accuracy: 47.03%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.3918    0.8444    0.5352        45
         zxx     0.5682    0.6410    0.6024        39

    accuracy                         0.4703       185
   macro avg     0.5241    0.3747    0.3839       185
weighted avg     0.4921    0.4703    0.4265       185


========== Train Epoch 18 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.027	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.8571    0.5333    0.6575        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.5297       185
   macro avg     0.5590    0.5218    0.4893       185
weighted avg     0.6061    0.5297    0.5161       185


========== Train Epoch 19 ==========
Loss: 0.026	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3750    0.4839    0.4225        31
         cwx     0.3611    0.5909    0.4483        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6275    0.7111    0.6667        45
         zxx     0.6897    0.5128    0.5882        39

    accuracy                         0.5027       185
   macro avg     0.4891    0.4648    0.4384       185
weighted avg     0.5224    0.5027    0.4831       185


========== Train Epoch 20 ==========
Loss: 0.029	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3286    0.7419    0.4554        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6774    0.5385    0.6000        39

    accuracy                         0.5297       185
   macro avg     0.4908    0.5011    0.4775       185
weighted avg     0.5449    0.5297    0.5166       185


========== Train Epoch 21 ==========
Loss: 0.036	Accuracy: 41.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8500    0.3778    0.5231        45
         zxx     0.3274    0.9487    0.4868        39

    accuracy                         0.4108       185
   macro avg     0.5704    0.3883    0.3509       185
weighted avg     0.6159    0.4108    0.3623       185


========== Train Epoch 22 ==========
Loss: 0.025	Accuracy: 48.11%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3243    0.7742    0.4571        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.1333    0.1053    0.1176        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.9231    0.3077    0.4615        39

    accuracy                         0.4811       185
   macro avg     0.5382    0.4610    0.4610       185
weighted avg     0.5808    0.4811    0.4803       185


========== Train Epoch 23 ==========
Loss: 0.023	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5342    0.5219    0.5046       185
weighted avg     0.5742    0.5622    0.5479       185


========== Train Epoch 24 ==========
Loss: 0.022	Accuracy: 47.57%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.2967    0.8710    0.4426        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7586    0.4889    0.5946        45
         zxx     0.8095    0.4359    0.5667        39

    accuracy                         0.4757       185
   macro avg     0.5007    0.4561    0.4351       185
weighted avg     0.5591    0.4757    0.4659       185


========== Train Epoch 25 ==========
Loss: 0.025	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.2353    0.4706    0.3137        17
         mtx     0.4444    0.4211    0.4324        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.5303    0.8974    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.6117    0.5007    0.4730       185
weighted avg     0.6592    0.5243    0.4948       185


========== Train Epoch 26 ==========
Loss: 0.019	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3158    0.7742    0.4486        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.8846    0.5111    0.6479        45
         zxx     0.7917    0.4872    0.6032        39

    accuracy                         0.5081       185
   macro avg     0.5460    0.4929    0.4830       185
weighted avg     0.6129    0.5081    0.5181       185


========== Train Epoch 27 ==========
Loss: 0.019	Accuracy: 46.49%	Cost 48s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.5000    0.1364    0.2143        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5362    0.8222    0.6491        45
         zxx     0.3846    0.8974    0.5385        39

    accuracy                         0.4649       185
   macro avg     0.6315    0.3593    0.3362       185
weighted avg     0.6151    0.4649    0.3868       185


========== Train Epoch 28 ==========
Loss: 0.020	Accuracy: 45.41%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2500    0.5294    0.3396        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.9000    0.4000    0.5538        45
         zxx     0.4231    0.8462    0.5641        39

    accuracy                         0.4541       185
   macro avg     0.5346    0.4441    0.4265       185
weighted avg     0.5849    0.4541    0.4417       185


========== Train Epoch 29 ==========
Loss: 0.020	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3830    0.5806    0.4615        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.8000    0.2353    0.3636        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.5763    0.7556    0.6538        45
         zxx     0.6486    0.6154    0.6316        39

    accuracy                         0.5243       185
   macro avg     0.5275    0.4563    0.4554       185
weighted avg     0.5309    0.5243    0.5001       185


========== Train Epoch 30 ==========
Loss: 0.018	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8214    0.5111    0.6301        45
         zxx     0.3830    0.9231    0.5414        39

    accuracy                         0.4919       185
   macro avg     0.6010    0.4724    0.4608       185
weighted avg     0.6136    0.4919    0.4696       185


========== Train Epoch 31 ==========
Loss: 0.018	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.2500    0.9167    0.3929        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.8077    0.5385    0.6462        39

    accuracy                         0.4973       185
   macro avg     0.5056    0.4970    0.4547       185
weighted avg     0.6014    0.4973    0.5156       185


========== Train Epoch 32 ==========
Loss: 0.015	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3673    0.5806    0.4500        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.5370    0.7436    0.6237        39

    accuracy                         0.5243       185
   macro avg     0.5400    0.4905    0.4751       185
weighted avg     0.5627    0.5243    0.5082       185


========== Train Epoch 33 ==========
Loss: 0.021	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7000    0.2258    0.3415        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.4105    0.8667    0.5571        45
         zxx     0.5510    0.6923    0.6136        39

    accuracy                         0.4865       185
   macro avg     0.5534    0.4021    0.4159       185
weighted avg     0.5324    0.4865    0.4472       185


========== Train Epoch 34 ==========
Loss: 0.014	Accuracy: 51.35%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.2093    0.5294    0.3000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5135       185
   macro avg     0.5323    0.4930    0.4729       185
weighted avg     0.5763    0.5135    0.5091       185


========== Train Epoch 35 ==========
Loss: 0.015	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.5730       185
   macro avg     0.5500    0.5365    0.5314       185
weighted avg     0.5753    0.5730    0.5658       185


========== Train Epoch 36 ==========
Loss: 0.018	Accuracy: 54.05%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.5606    0.8222    0.6667        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.5405       185
   macro avg     0.5479    0.4794    0.4934       185
weighted avg     0.5374    0.5405    0.5195       185


========== Train Epoch 37 ==========
Loss: 0.017	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.2258    0.4118    0.2917        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8571    0.4000    0.5455        45
         zxx     0.5000    0.7949    0.6139        39

    accuracy                         0.5081       185
   macro avg     0.5307    0.5037    0.4899       185
weighted avg     0.5768    0.5081    0.5079       185


========== Train Epoch 38 ==========
Loss: 0.011	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5263    0.7692    0.6250        39

    accuracy                         0.5459       185
   macro avg     0.5428    0.5164    0.5028       185
weighted avg     0.5706    0.5459    0.5354       185


========== Train Epoch 39 ==========
Loss: 0.015	Accuracy: 54.05%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.5405       185
   macro avg     0.4989    0.5059    0.4836       185
weighted avg     0.5364    0.5405    0.5235       185


========== Train Epoch 40 ==========
Loss: 0.016	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3750    0.4737    0.4186        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     1.0000    0.4444    0.6154        45
         zxx     0.3592    0.9487    0.5211        39

    accuracy                         0.4865       185
   macro avg     0.6151    0.4424    0.4518       185
weighted avg     0.6606    0.4865    0.4763       185


========== Train Epoch 41 ==========
Loss: 0.014	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5297       185
   macro avg     0.5182    0.5048    0.4938       185
weighted avg     0.5439    0.5297    0.5216       185


========== Train Epoch 42 ==========
Loss: 0.014	Accuracy: 54.05%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4000    0.3871    0.3934        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.5965    0.7556    0.6667        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.5405       185
   macro avg     0.5147    0.4884    0.4960       185
weighted avg     0.5296    0.5405    0.5299       185


========== Train Epoch 43 ==========
Loss: 0.012	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8214    0.5111    0.6301        45
         zxx     0.4337    0.9231    0.5902        39

    accuracy                         0.5081       185
   macro avg     0.4713    0.4678    0.4395       185
weighted avg     0.5167    0.5081    0.4755       185


========== Train Epoch 44 ==========
Loss: 0.012	Accuracy: 53.51%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.5351       185
   macro avg     0.4994    0.5033    0.4841       185
weighted avg     0.5407    0.5351    0.5206       185


========== Train Epoch 45 ==========
Loss: 0.012	Accuracy: 51.89%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.6383    0.6667    0.6522        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.5189       185
   macro avg     0.5042    0.4720    0.4745       185
weighted avg     0.5135    0.5189    0.5022       185


========== Train Epoch 46 ==========
Loss: 0.011	Accuracy: 51.89%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2333    0.4118    0.2979        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5224    0.8974    0.6604        39

    accuracy                         0.5189       185
   macro avg     0.5264    0.4794    0.4553       185
weighted avg     0.5803    0.5189    0.5029       185


========== Train Epoch 47 ==========
Loss: 0.013	Accuracy: 55.14%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5514       185
   macro avg     0.5450    0.4975    0.4976       185
weighted avg     0.5459    0.5514    0.5255       185


========== Train Epoch 48 ==========
Loss: 0.013	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5243       185
   macro avg     0.5376    0.5031    0.4700       185
weighted avg     0.5856    0.5243    0.5097       185


========== Train Epoch 49 ==========
Loss: 0.012	Accuracy: 54.05%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.6154    0.7111    0.6598        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5405       185
   macro avg     0.5451    0.4948    0.5061       185
weighted avg     0.5406    0.5405    0.5297       185


========== Train Epoch 50 ==========
Loss: 0.011	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5405       185
   macro avg     0.5222    0.5159    0.5027       185
weighted avg     0.5728    0.5405    0.5398       185


========== Train Epoch 51 ==========
Loss: 0.012	Accuracy: 52.43%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6200    0.6889    0.6526        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5243       185
   macro avg     0.4873    0.4668    0.4658       185
weighted avg     0.5143    0.5243    0.5068       185


========== Train Epoch 52 ==========
Loss: 0.012	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2105    0.4706    0.2909        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.2941    0.8333    0.4348        12
         qtx     0.7667    0.5111    0.6133        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.4919       185
   macro avg     0.5076    0.4843    0.4447       185
weighted avg     0.5789    0.4919    0.4950       185


========== Train Epoch 53 ==========
Loss: 0.010	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5297       185
   macro avg     0.5077    0.4817    0.4683       185
weighted avg     0.5271    0.5297    0.5043       185


========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4474    0.5484    0.4928        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.5189       185
   macro avg     0.5139    0.4973    0.4794       185
weighted avg     0.5500    0.5189    0.5139       185


========== Train Epoch 55 ==========
Loss: 0.011	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4107    0.7419    0.5287        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.6667    0.6154    0.6400        39

    accuracy                         0.5243       185
   macro avg     0.5101    0.4917    0.4726       185
weighted avg     0.5545    0.5243    0.5135       185


========== Train Epoch 56 ==========
Loss: 0.010	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.2812    0.5294    0.3673        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5405       185
   macro avg     0.5349    0.5167    0.4970       185
weighted avg     0.5677    0.5405    0.5254       185


========== Train Epoch 57 ==========
Loss: 0.011	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.6071    0.7556    0.6733        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.5459       185
   macro avg     0.5437    0.4940    0.5074       185
weighted avg     0.5479    0.5459    0.5368       185


========== Train Epoch 58 ==========
Loss: 0.011	Accuracy: 52.43%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.5243       185
   macro avg     0.5085    0.4928    0.4672       185
weighted avg     0.5393    0.5243    0.4979       185


========== Train Epoch 59 ==========
Loss: 0.010	Accuracy: 55.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6585    0.6923    0.6750        39

    accuracy                         0.5568       185
   macro avg     0.5240    0.5193    0.5117       185
weighted avg     0.5609    0.5568    0.5516       185


========== Train Epoch 60 ==========
Loss: 0.011	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.2000    0.5294    0.2903        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.5027       185
   macro avg     0.5089    0.4951    0.4749       185
weighted avg     0.5657    0.5027    0.5121       185


========== Train Epoch 61 ==========
Loss: 0.010	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5568       185
   macro avg     0.5615    0.5165    0.5108       185
weighted avg     0.5869    0.5568    0.5385       185


========== Train Epoch 62 ==========
Loss: 0.012	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4186    0.5806    0.4865        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.5882    0.7692    0.6667        39

    accuracy                         0.5459       185
   macro avg     0.5391    0.5132    0.4984       185
weighted avg     0.5640    0.5459    0.5313       185


========== Train Epoch 63 ==========
Loss: 0.010	Accuracy: 52.43%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.5243       185
   macro avg     0.5364    0.4844    0.4789       185
weighted avg     0.5551    0.5243    0.5055       185


========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.6452    0.5263        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6579    0.6410    0.6494        39

    accuracy                         0.5514       185
   macro avg     0.5109    0.5003    0.4955       185
weighted avg     0.5472    0.5514    0.5408       185


Finished training!!!

Min Loss = 0.010 in epoch 60;
Max Accuracy = 57.30% in epoch 34;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.2702702702702703, 0.33513513513513515, 0.2756756756756757, 0.3675675675675676, 0.3837837837837838, 0.31891891891891894, 0.3783783783783784, 0.44324324324324327, 0.4594594594594595, 0.4756756756756757, 0.4594594594594595, 0.4864864864864865, 0.5297297297297298, 0.4648648648648649, 0.4810810810810811, 0.32432432432432434, 0.4702702702702703, 0.5297297297297298, 0.5027027027027027, 0.5297297297297298, 0.41081081081081083, 0.4810810810810811, 0.5621621621621622, 0.4756756756756757, 0.5243243243243243, 0.5081081081081081, 0.4648648648648649, 0.4540540540540541, 0.5243243243243243, 0.4918918918918919, 0.4972972972972973, 0.5243243243243243, 0.4864864864864865, 0.5135135135135135, 0.572972972972973, 0.5405405405405406, 0.5081081081081081, 0.5459459459459459, 0.5405405405405406, 0.4864864864864865, 0.5297297297297298, 0.5405405405405406, 0.5081081081081081, 0.5351351351351351, 0.518918918918919, 0.518918918918919, 0.5513513513513514, 0.5243243243243243, 0.5405405405405406, 0.5405405405405406, 0.5243243243243243, 0.4918918918918919, 0.5297297297297298, 0.518918918918919, 0.5243243243243243, 0.5405405405405406, 0.5459459459459459, 0.5243243243243243, 0.5567567567567567, 0.5027027027027027, 0.5567567567567567, 0.5459459459459459, 0.5243243243243243, 0.5513513513513514]
