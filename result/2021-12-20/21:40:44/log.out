dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet34
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.877	Accuracy: 23.24%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1842    0.3182    0.2333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5385    0.1556    0.2414        45
         zxx     0.2417    0.7436    0.3648        39

    accuracy                         0.2324       185
   macro avg     0.1378    0.1739    0.1199       185
weighted avg     0.2038    0.2324    0.1634       185


========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.639	Accuracy: 30.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1000    0.0455    0.0625        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.4474    0.3778    0.4096        45
         zxx     0.2803    0.9487    0.4327        39

    accuracy                         0.3081       185
   macro avg     0.2135    0.2198    0.1674       185
weighted avg     0.2230    0.3081    0.2156       185


========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.447	Accuracy: 36.76%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2927    0.3871    0.3333        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1594    0.9167    0.2716        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.5122    0.5385    0.5250        39

    accuracy                         0.3676       185
   macro avg     0.2449    0.3394    0.2505       185
weighted avg     0.3498    0.3676    0.3358       185


========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.251	Accuracy: 34.59%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.7500    0.1364    0.2308        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.1429    0.6842    0.2364        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.5231    0.7556    0.6182        45
         zxx     1.0000    0.1026    0.1860        39

    accuracy                         0.3459       185
   macro avg     0.5523    0.3554    0.2779       185
weighted avg     0.5630    0.3459    0.2880       185


========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.936	Accuracy: 24.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.1879    1.0000    0.3163        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.9091    0.2222    0.3571        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.2486       185
   macro avg     0.3472    0.2233    0.1738       185
weighted avg     0.3571    0.2486    0.1828       185


========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.696	Accuracy: 31.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3125    0.1613    0.2128        31
         cwx     0.2289    0.8636    0.3619        22
         hdx     0.1707    0.4118    0.2414        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.0000    0.0000    0.0000        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.3189       185
   macro avg     0.3357    0.3320    0.2693       185
weighted avg     0.3124    0.3189    0.2707       185


========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.598	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4146    0.5484    0.4722        31
         cwx     0.2143    0.1364    0.1667        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.1667    0.2105    0.1860        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6667    0.3111    0.4242        45
         zxx     0.6190    0.6667    0.6420        39

    accuracy                         0.4378       185
   macro avg     0.4126    0.4419    0.4089       185
weighted avg     0.4661    0.4378    0.4301       185


========== Train Epoch 8 ==========
Loss: 0.399	Accuracy: 28.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.2500    0.0909    0.1333        22
         hdx     0.1429    0.7059    0.2376        17
         mtx     0.1190    0.2632    0.1639        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     1.0000    0.0889    0.1633        45
         zxx     0.6316    0.6154    0.6234        39

    accuracy                         0.2865       185
   macro avg     0.5384    0.3162    0.2691       185
weighted avg     0.6396    0.2865    0.2686       185


========== Train Epoch 9 ==========
Loss: 0.237	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3158    0.5806    0.4091        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.5614    0.7111    0.6275        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.4919       185
   macro avg     0.4252    0.4429    0.4132       185
weighted avg     0.4702    0.4919    0.4622       185


========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.143	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.5027       185
   macro avg     0.5190    0.4811    0.4500       185
weighted avg     0.5465    0.5027    0.4735       185


========== Train Epoch 11 ==========
Loss: 0.114	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.5000    0.7333    0.5946        45
         zxx     0.9333    0.3590    0.5185        39

    accuracy                         0.4811       185
   macro avg     0.5234    0.4628    0.4638       185
weighted avg     0.5510    0.4811    0.4792       185


========== Train Epoch 12 ==========
Loss: 0.123	Accuracy: 29.73%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1111    1.0000    0.2000        12
         qtx     0.6842    0.2889    0.4062        45
         zxx     0.5217    0.6154    0.5647        39

    accuracy                         0.2973       185
   macro avg     0.4739    0.3148    0.2370       185
weighted avg     0.5323    0.2973    0.2848       185


========== Train Epoch 13 ==========
Loss: 0.090	Accuracy: 45.41%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.5000    0.1818    0.2667        22
         hdx     0.2051    0.4706    0.2857        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.4541       185
   macro avg     0.4466    0.4230    0.3949       185
weighted avg     0.5117    0.4541    0.4456       185


========== Train Epoch 14 ==========
Loss: 0.063	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3148    0.5484    0.4000        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.5652    0.6667    0.6118        39

    accuracy                         0.5027       185
   macro avg     0.5179    0.4805    0.4589       185
weighted avg     0.5344    0.5027    0.4860       185


========== Train Epoch 15 ==========
Loss: 0.072	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.5962    0.6889    0.6392        45
         zxx     0.4133    0.7949    0.5439        39

    accuracy                         0.4865       185
   macro avg     0.5078    0.4419    0.4196       185
weighted avg     0.5196    0.4865    0.4494       185


========== Train Epoch 16 ==========
Loss: 0.041	Accuracy: 48.65%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3611    0.4194    0.3881        31
         cwx     0.4000    0.5455    0.4615        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.4865       185
   macro avg     0.4807    0.4500    0.4515       185
weighted avg     0.5452    0.4865    0.5030       185


========== Train Epoch 17 ==========
Loss: 0.034	Accuracy: 45.41%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.1429    0.1579    0.1500        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.4211    0.8205    0.5565        39

    accuracy                         0.4541       185
   macro avg     0.4753    0.4147    0.4100       185
weighted avg     0.5140    0.4541    0.4428       185


========== Train Epoch 18 ==========
Loss: 0.028	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3488    0.4839    0.4054        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.6765    0.5897    0.6301        39

    accuracy                         0.5027       185
   macro avg     0.4905    0.4766    0.4677       185
weighted avg     0.5390    0.5027    0.5075       185


========== Train Epoch 19 ==========
Loss: 0.023	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.1053    0.1053    0.1053        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5514       185
   macro avg     0.5165    0.4938    0.5006       185
weighted avg     0.5473    0.5514    0.5450       185


========== Train Epoch 20 ==========
Loss: 0.019	Accuracy: 48.65%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4091    0.2903    0.3396        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.2500    0.5882    0.3509        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.5167    0.7949    0.6263        39

    accuracy                         0.4865       185
   macro avg     0.5047    0.4591    0.4541       185
weighted avg     0.5299    0.4865    0.4822       185


========== Train Epoch 21 ==========
Loss: 0.023	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.3478    0.3636    0.3556        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.5075    0.7556    0.6071        45
         zxx     0.9130    0.5385    0.6774        39

    accuracy                         0.5027       185
   macro avg     0.4765    0.4617    0.4499       185
weighted avg     0.5249    0.5027    0.4926       185


========== Train Epoch 22 ==========
Loss: 0.021	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.4923    0.8205    0.6154        39

    accuracy                         0.4919       185
   macro avg     0.4656    0.4527    0.4411       185
weighted avg     0.4929    0.4919    0.4726       185


========== Train Epoch 23 ==========
Loss: 0.016	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.6275    0.7111    0.6667        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5459       185
   macro avg     0.5089    0.5018    0.5020       185
weighted avg     0.5261    0.5459    0.5322       185


========== Train Epoch 24 ==========
Loss: 0.015	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4054    0.4839    0.4412        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6585    0.6923    0.6750        39

    accuracy                         0.5351       185
   macro avg     0.4973    0.5123    0.4879       185
weighted avg     0.5555    0.5351    0.5336       185


========== Train Epoch 25 ==========
Loss: 0.016	Accuracy: 49.19%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2500    0.4118    0.3111        17
         mtx     0.1579    0.1579    0.1579        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.4919       185
   macro avg     0.4794    0.4655    0.4546       185
weighted avg     0.5162    0.4919    0.4839       185


========== Train Epoch 26 ==========
Loss: 0.016	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.4054    0.6818    0.5085        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.5405       185
   macro avg     0.5244    0.5022    0.5012       185
weighted avg     0.5525    0.5405    0.5368       185


========== Train Epoch 27 ==========
Loss: 0.013	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5253    0.5334    0.5184       185
weighted avg     0.5632    0.5622    0.5547       185


========== Train Epoch 28 ==========
Loss: 0.016	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5385    0.2258    0.3182        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.1522    0.3684    0.2154        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6042    0.6444    0.6237        45
         zxx     0.5349    0.5897    0.5610        39

    accuracy                         0.4486       185
   macro avg     0.4662    0.4225    0.4210       185
weighted avg     0.4930    0.4486    0.4492       185


========== Train Epoch 29 ==========
Loss: 0.023	Accuracy: 49.73%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.4416    0.7556    0.5574        45
         zxx     0.6944    0.6410    0.6667        39

    accuracy                         0.4973       185
   macro avg     0.4409    0.4275    0.4243       185
weighted avg     0.4643    0.4973    0.4680       185


========== Train Epoch 30 ==========
Loss: 0.017	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4286    0.1935    0.2667        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4545    0.8974    0.6034        39

    accuracy                         0.4649       185
   macro avg     0.4528    0.4273    0.3967       185
weighted avg     0.4835    0.4649    0.4300       185


========== Train Epoch 31 ==========
Loss: 0.015	Accuracy: 41.62%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.2317    0.8636    0.3654        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.5918    0.6444    0.6170        45
         zxx     0.9091    0.2564    0.4000        39

    accuracy                         0.4162       185
   macro avg     0.5395    0.3927    0.3857       185
weighted avg     0.5626    0.4162    0.4121       185


========== Train Epoch 32 ==========
Loss: 0.027	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.2955    0.5909    0.3939        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.1667    0.1579    0.1622        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.6765    0.5111    0.5823        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.4703       185
   macro avg     0.5127    0.4482    0.4300       185
weighted avg     0.5433    0.4703    0.4587       185


========== Train Epoch 33 ==========
Loss: 0.037	Accuracy: 39.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2604    0.8065    0.3937        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.5957    0.6222    0.6087        45
         zxx     1.0000    0.0769    0.1429        39

    accuracy                         0.3946       185
   macro avg     0.5536    0.3559    0.3454       185
weighted avg     0.5845    0.3946    0.3620       185


========== Train Epoch 34 ==========
Loss: 0.231	Accuracy: 24.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1696    0.8636    0.2836        22
         hdx     0.1290    0.2353    0.1667        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.0000    0.0000    0.0000        45
         zxx     0.5833    0.5385    0.5600        39

    accuracy                         0.2486       185
   macro avg     0.2331    0.2533    0.1772       185
weighted avg     0.2131    0.2486    0.1853       185


========== Train Epoch 35 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.051	Accuracy: 21.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.1807    0.9677    0.3046        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1667    0.0833    0.1111        12
         qtx     0.5556    0.1111    0.1852        45
         zxx     1.0000    0.0769    0.1429        39

    accuracy                         0.2108       185
   macro avg     0.2718    0.1770    0.1062       185
weighted avg     0.3870    0.2108    0.1334       185


========== Train Epoch 36 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.810	Accuracy: 43.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3243    0.3871    0.3529        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.1579    0.3158    0.2105        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5185    0.6222    0.5657        45
         zxx     0.8400    0.5385    0.6562        39

    accuracy                         0.4324       185
   macro avg     0.4376    0.3815    0.3924       185
weighted avg     0.4861    0.4324    0.4423       185


========== Train Epoch 37 ==========
Loss: 0.210	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.2439    0.5882    0.3448        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.5172    0.6667    0.5825        45
         zxx     0.5676    0.5385    0.5526        39

    accuracy                         0.4324       185
   macro avg     0.4327    0.4263    0.3666       185
weighted avg     0.4645    0.4324    0.3981       185


========== Train Epoch 38 ==========
Loss: 0.100	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.4722    0.8718    0.6126        39

    accuracy                         0.4865       185
   macro avg     0.4679    0.4507    0.4350       185
weighted avg     0.5251    0.4865    0.4729       185


========== Train Epoch 39 ==========
Loss: 0.063	Accuracy: 50.81%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.3333    0.1935    0.2449        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.5081       185
   macro avg     0.5130    0.4765    0.4630       185
weighted avg     0.5320    0.5081    0.4860       185


========== Train Epoch 40 ==========
Loss: 0.074	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5818    0.7111    0.6400        45
         zxx     0.8065    0.6410    0.7143        39

    accuracy                         0.4973       185
   macro avg     0.4481    0.4426    0.4418       185
weighted avg     0.5084    0.4973    0.4981       185


========== Train Epoch 41 ==========
Loss: 0.048	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2667    0.1290    0.1739        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.1739    0.2105    0.1905        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7500    0.4667    0.5753        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4432       185
   macro avg     0.4031    0.4245    0.3898       185
weighted avg     0.4540    0.4432    0.4214       185


========== Train Epoch 42 ==========
Loss: 0.034	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.1111    0.1053    0.1081        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5243       185
   macro avg     0.4615    0.4742    0.4587       185
weighted avg     0.5228    0.5243    0.5151       185


========== Train Epoch 43 ==========
Loss: 0.023	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.4865       185
   macro avg     0.4437    0.4502    0.4330       185
weighted avg     0.4840    0.4865    0.4722       185


========== Train Epoch 44 ==========
Loss: 0.021	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6250    0.6667    0.6452        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5027       185
   macro avg     0.4472    0.4671    0.4479       185
weighted avg     0.4934    0.5027    0.4914       185


========== Train Epoch 45 ==========
Loss: 0.013	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6222    0.6222    0.6222        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.5189       185
   macro avg     0.4776    0.4865    0.4799       185
weighted avg     0.5268    0.5189    0.5213       185


========== Train Epoch 46 ==========
Loss: 0.019	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.3871    0.3934        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5405       185
   macro avg     0.4954    0.4930    0.4894       185
weighted avg     0.5360    0.5405    0.5333       185


========== Train Epoch 47 ==========
Loss: 0.016	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2414    0.4118    0.3043        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5027       185
   macro avg     0.4707    0.4553    0.4522       185
weighted avg     0.5210    0.5027    0.5014       185


========== Train Epoch 48 ==========
Loss: 0.018	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.1923    0.2632    0.2222        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.5514       185
   macro avg     0.5072    0.5028    0.4994       185
weighted avg     0.5513    0.5514    0.5462       185


========== Train Epoch 49 ==========
Loss: 0.015	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4348    0.3226    0.3704        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5297       185
   macro avg     0.4947    0.4867    0.4815       185
weighted avg     0.5331    0.5297    0.5207       185


========== Train Epoch 50 ==========
Loss: 0.015	Accuracy: 52.97%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.2381    0.2632    0.2500        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5297       185
   macro avg     0.4806    0.4847    0.4770       185
weighted avg     0.5337    0.5297    0.5255       185


========== Train Epoch 51 ==========
Loss: 0.012	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.2083    0.2632    0.2326        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5135       185
   macro avg     0.4681    0.4642    0.4552       185
weighted avg     0.5173    0.5135    0.5041       185


========== Train Epoch 52 ==========
Loss: 0.015	Accuracy: 52.43%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4583    0.3548    0.4000        31
         cwx     0.5000    0.2273    0.3125        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.1818    0.2105    0.1951        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5243       185
   macro avg     0.4709    0.4431    0.4447       185
weighted avg     0.5123    0.5243    0.5065       185


========== Train Epoch 53 ==========
Loss: 0.013	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3600    0.2903    0.3214        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.1579    0.1579    0.1579        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6512    0.6222    0.6364        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.4865       185
   macro avg     0.4294    0.4227    0.4193       185
weighted avg     0.4719    0.4865    0.4711       185


========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4348    0.3226    0.3704        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.1739    0.2105    0.1905        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5081       185
   macro avg     0.4562    0.4497    0.4475       185
weighted avg     0.5124    0.5081    0.5042       185


========== Train Epoch 55 ==========
Loss: 0.012	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.2333    0.4118    0.2979        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6512    0.6222    0.6364        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5081       185
   macro avg     0.4727    0.4532    0.4417       185
weighted avg     0.5157    0.5081    0.4896       185


========== Train Epoch 56 ==========
Loss: 0.010	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.2414    0.4118    0.3043        17
         mtx     0.2222    0.2105    0.2162        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5027       185
   macro avg     0.4539    0.4466    0.4406       185
weighted avg     0.5129    0.5027    0.4978       185


========== Train Epoch 57 ==========
Loss: 0.010	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4737    0.2903    0.3600        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.1818    0.2105    0.1951        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5081       185
   macro avg     0.4601    0.4488    0.4442       185
weighted avg     0.5156    0.5081    0.5006       185


========== Train Epoch 58 ==========
Loss: 0.012	Accuracy: 51.35%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.2000    0.2105    0.2051        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6304    0.6444    0.6374        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.5135       185
   macro avg     0.4639    0.4548    0.4508       185
weighted avg     0.5222    0.5135    0.5107       185


========== Train Epoch 59 ==========
Loss: 0.010	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.2903    0.3673        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5297       185
   macro avg     0.4715    0.4650    0.4591       185
weighted avg     0.5157    0.5297    0.5114       185


========== Train Epoch 60 ==========
Loss: 0.009	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.2333    0.4118    0.2979        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.5243       185
   macro avg     0.4792    0.4859    0.4683       185
weighted avg     0.5362    0.5243    0.5162       185


========== Train Epoch 61 ==========
Loss: 0.011	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5189       185
   macro avg     0.4618    0.4659    0.4517       185
weighted avg     0.5126    0.5189    0.5020       185


========== Train Epoch 62 ==========
Loss: 0.010	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5135       185
   macro avg     0.4707    0.4482    0.4449       185
weighted avg     0.5181    0.5135    0.5002       185


========== Train Epoch 63 ==========
Loss: 0.009	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.1818    0.2105    0.1951        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5189       185
   macro avg     0.4744    0.4674    0.4580       185
weighted avg     0.5239    0.5189    0.5065       185


========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5189       185
   macro avg     0.4653    0.4688    0.4575       185
weighted avg     0.5227    0.5189    0.5102       185


Finished training!!!

Min Loss = 0.009 in epoch 59;
Max Accuracy = 56.22% in epoch 26;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
)

[0.23243243243243245, 0.3081081081081081, 0.3675675675675676, 0.34594594594594597, 0.24864864864864866, 0.31891891891891894, 0.43783783783783786, 0.2864864864864865, 0.4918918918918919, 0.5027027027027027, 0.4810810810810811, 0.2972972972972973, 0.4540540540540541, 0.5027027027027027, 0.4864864864864865, 0.4864864864864865, 0.4540540540540541, 0.5027027027027027, 0.5513513513513514, 0.4864864864864865, 0.5027027027027027, 0.4918918918918919, 0.5459459459459459, 0.5351351351351351, 0.4918918918918919, 0.5405405405405406, 0.5621621621621622, 0.4486486486486487, 0.4972972972972973, 0.4648648648648649, 0.41621621621621624, 0.4702702702702703, 0.3945945945945946, 0.24864864864864866, 0.21081081081081082, 0.43243243243243246, 0.43243243243243246, 0.4864864864864865, 0.5081081081081081, 0.4972972972972973, 0.44324324324324327, 0.5243243243243243, 0.4864864864864865, 0.5027027027027027, 0.518918918918919, 0.5405405405405406, 0.5027027027027027, 0.5513513513513514, 0.5297297297297298, 0.5297297297297298, 0.5135135135135135, 0.5243243243243243, 0.4864864864864865, 0.5081081081081081, 0.5081081081081081, 0.5027027027027027, 0.5081081081081081, 0.5135135135135135, 0.5297297297297298, 0.5243243243243243, 0.518918918918919, 0.5135135135135135, 0.518918918918919, 0.518918918918919]
