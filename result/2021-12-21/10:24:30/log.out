dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam resnet34
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.862	Accuracy: 29.19%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.2273    0.3226    0.2667        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.4444    0.3556    0.3951        45
         zxx     0.2353    0.5128    0.3226        39

    accuracy                         0.2919       185
   macro avg     0.3098    0.2404    0.2382       185
weighted avg     0.3146    0.2919    0.2701       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.625	Accuracy: 28.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1441    0.8421    0.2462        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.5625    0.2000    0.2951        45
         zxx     0.5517    0.4103    0.4706        39

    accuracy                         0.2811       185
   macro avg     0.3753    0.3130    0.2463       185
weighted avg     0.4432    0.2811    0.2623       185

micro f-score: 0.2810810810810811

========== Train Epoch 3 ==========
Loss: 1.472	Accuracy: 41.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3103    0.5806    0.4045        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6176    0.4667    0.5316        45
         zxx     0.4468    0.5385    0.4884        39

    accuracy                         0.4108       185
   macro avg     0.3780    0.3636    0.3556       185
weighted avg     0.4133    0.4108    0.3963       185

micro f-score: 0.4108108108108109

========== Train Epoch 4 ==========
Loss: 1.248	Accuracy: 40.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3429    0.3871    0.3636        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.8000    0.2667    0.4000        45
         zxx     0.3667    0.8462    0.5116        39

    accuracy                         0.4000       185
   macro avg     0.4577    0.3342    0.3068       185
weighted avg     0.4727    0.4000    0.3578       185

micro f-score: 0.4000000000000001

========== Train Epoch 5 ==========
Loss: 1.011	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2326    0.3226    0.2703        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.6667    0.6222    0.6437        45
         zxx     0.4444    0.9231    0.6000        39

    accuracy                         0.4378       185
   macro avg     0.3943    0.3309    0.3075       185
weighted avg     0.4187    0.4378    0.3822       185

micro f-score: 0.43783783783783786

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.716	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.2174    0.2941    0.2500        17
         mtx     0.2131    0.6842    0.3250        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6053    0.5897    0.5974        39

    accuracy                         0.4703       185
   macro avg     0.5399    0.4349    0.4309       185
weighted avg     0.6028    0.4703    0.4862       185

micro f-score: 0.4702702702702703

========== Train Epoch 7 ==========
Loss: 0.433	Accuracy: 45.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.1970    0.6842    0.3059        19
         nqx     0.3226    0.8333    0.4651        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.8333    0.5128    0.6349        39

    accuracy                         0.4541       185
   macro avg     0.5932    0.4516    0.3975       185
weighted avg     0.6473    0.4541    0.4446       185

micro f-score: 0.4540540540540541

========== Train Epoch 8 ==========
Loss: 0.239	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2791    0.6316    0.3871        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5312    0.7556    0.6239        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.5027       185
   macro avg     0.6315    0.4351    0.4348       185
weighted avg     0.6151    0.5027    0.4906       185

micro f-score: 0.5027027027027027

========== Train Epoch 9 ==========
Loss: 0.149	Accuracy: 40.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.1538    0.9412    0.2645        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6667    0.6222    0.6437        45
         zxx     0.7917    0.4872    0.6032        39

    accuracy                         0.4000       185
   macro avg     0.6113    0.3645    0.3193       185
weighted avg     0.6927    0.4000    0.3940       185

micro f-score: 0.4000000000000001

========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.119	Accuracy: 51.35%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.8000    0.2353    0.3636        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.3333    0.5833    0.4242        12
         qtx     0.4545    0.8889    0.6015        45
         zxx     0.7667    0.5897    0.6667        39

    accuracy                         0.5135       185
   macro avg     0.6248    0.4441    0.4436       185
weighted avg     0.6149    0.5135    0.4875       185

micro f-score: 0.5135135135135135

========== Train Epoch 11 ==========
Loss: 0.115	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.1905    0.6316    0.2927        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.4865       185
   macro avg     0.6029    0.4549    0.4364       185
weighted avg     0.6348    0.4865    0.4914       185

micro f-score: 0.4864864864864865

========== Train Epoch 12 ==========
Loss: 0.111	Accuracy: 38.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2419    0.9677    0.3871        31
         cwx     0.7500    0.1364    0.2308        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.7586    0.4889    0.5946        45
         zxx     0.9167    0.2821    0.4314        39

    accuracy                         0.3892       185
   macro avg     0.5586    0.3244    0.3205       185
weighted avg     0.6097    0.3892    0.3771       185

micro f-score: 0.3891891891891892

========== Train Epoch 13 ==========
Loss: 0.085	Accuracy: 52.97%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4000    0.4516    0.4242        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5297       185
   macro avg     0.5421    0.4533    0.4623       185
weighted avg     0.5486    0.5297    0.5069       185

micro f-score: 0.5297297297297298

========== Train Epoch 14 ==========
Loss: 0.058	Accuracy: 51.35%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3617    0.5484    0.4359        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.5574    0.7556    0.6415        45
         zxx     0.9091    0.5128    0.6557        39

    accuracy                         0.5135       185
   macro avg     0.5577    0.4697    0.4718       185
weighted avg     0.5904    0.5135    0.5112       185

micro f-score: 0.5135135135135135

========== Train Epoch 15 ==========
Loss: 0.051	Accuracy: 46.49%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3810    0.5161    0.4384        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.2545    0.7368    0.3784        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.5962    0.6889    0.6392        45
         zxx     0.9444    0.4359    0.5965        39

    accuracy                         0.4649       185
   macro avg     0.5966    0.4136    0.4001       185
weighted avg     0.6246    0.4649    0.4567       185

micro f-score: 0.4648648648648649

========== Train Epoch 16 ==========
Loss: 0.081	Accuracy: 46.49%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.2000    0.4211    0.2712        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.8125    0.2889    0.4262        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.4649       185
   macro avg     0.4683    0.4383    0.4224       185
weighted avg     0.5311    0.4649    0.4560       185

micro f-score: 0.4648648648648649

========== Train Epoch 17 ==========
Loss: 0.088	Accuracy: 34.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.1313    0.7647    0.2241        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.9000    0.2000    0.3273        45
         zxx     0.9333    0.3590    0.5185        39

    accuracy                         0.3405       185
   macro avg     0.5315    0.3803    0.3612       185
weighted avg     0.6393    0.3405    0.3776       185

micro f-score: 0.34054054054054056

========== Train Epoch 18 ==========
Loss: 0.054	Accuracy: 52.43%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.2903    0.3673        31
         cwx     0.3111    0.6364    0.4179        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.3226    0.8333    0.4651        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5243       185
   macro avg     0.5498    0.5119    0.4755       185
weighted avg     0.6053    0.5243    0.5218       185

micro f-score: 0.5243243243243243

========== Train Epoch 19 ==========
Loss: 0.047	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.2157    0.5789    0.3143        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.7857    0.5641    0.6567        39

    accuracy                         0.5027       185
   macro avg     0.4958    0.4477    0.4468       185
weighted avg     0.5572    0.5027    0.5100       185

micro f-score: 0.5027027027027027

========== Train Epoch 20 ==========
Loss: 0.043	Accuracy: 53.51%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5000    0.7727    0.6071        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.9333    0.3111    0.4667        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.5351       185
   macro avg     0.5785    0.5382    0.5099       185
weighted avg     0.6184    0.5351    0.5144       185

micro f-score: 0.5351351351351351

========== Train Epoch 21 ==========
Loss: 0.031	Accuracy: 56.76%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.3462    0.4737    0.4000        19
         nqx     0.2500    0.3333    0.2857        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.8929    0.6410    0.7463        39

    accuracy                         0.5676       185
   macro avg     0.5484    0.5242    0.5188       185
weighted avg     0.6251    0.5676    0.5807       185

micro f-score: 0.5675675675675675

========== Train Epoch 22 ==========
Loss: 0.039	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5459       185
   macro avg     0.5252    0.5128    0.4888       185
weighted avg     0.5752    0.5459    0.5286       185

micro f-score: 0.5459459459459459

========== Train Epoch 23 ==========
Loss: 0.031	Accuracy: 48.65%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4211    0.5161    0.4638        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.2667    0.4211    0.3265        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.4865       185
   macro avg     0.4809    0.4560    0.4398       185
weighted avg     0.5301    0.4865    0.4820       185

micro f-score: 0.4864864864864865

========== Train Epoch 24 ==========
Loss: 0.030	Accuracy: 58.38%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.4054    0.6818    0.5085        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5838       185
   macro avg     0.5492    0.5202    0.5197       185
weighted avg     0.6009    0.5838    0.5802       185

micro f-score: 0.5837837837837838

========== Train Epoch 25 ==========
Loss: 0.017	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.2973    0.6471    0.4074        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.9333    0.7179    0.8116        39

    accuracy                         0.5730       185
   macro avg     0.5501    0.5598    0.5200       185
weighted avg     0.6251    0.5730    0.5749       185

micro f-score: 0.572972972972973

========== Train Epoch 26 ==========
Loss: 0.019	Accuracy: 59.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5946       185
   macro avg     0.5625    0.5455    0.5277       185
weighted avg     0.5874    0.5946    0.5691       185

micro f-score: 0.5945945945945946

========== Train Epoch 27 ==========
Loss: 0.017	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.5838       185
   macro avg     0.5283    0.5464    0.5268       185
weighted avg     0.5961    0.5838    0.5802       185

micro f-score: 0.5837837837837838

========== Train Epoch 28 ==========
Loss: 0.022	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3559    0.6774    0.4667        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.5459       185
   macro avg     0.5348    0.4817    0.4824       185
weighted avg     0.5714    0.5459    0.5343       185

micro f-score: 0.5459459459459459

========== Train Epoch 29 ==========
Loss: 0.017	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5946       185
   macro avg     0.5607    0.5636    0.5334       185
weighted avg     0.6073    0.5946    0.5766       185

micro f-score: 0.5945945945945946

========== Train Epoch 30 ==========
Loss: 0.020	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.5000    0.9487    0.6549        39

    accuracy                         0.5784       185
   macro avg     0.5750    0.5264    0.5153       185
weighted avg     0.6057    0.5784    0.5496       185

micro f-score: 0.5783783783783784

========== Train Epoch 31 ==========
Loss: 0.020	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3846    0.4839    0.4286        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2500    0.4737    0.3273        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.8276    0.6154    0.7059        39

    accuracy                         0.5351       185
   macro avg     0.5342    0.5020    0.4923       185
weighted avg     0.5931    0.5351    0.5449       185

micro f-score: 0.5351351351351351

========== Train Epoch 32 ==========
Loss: 0.019	Accuracy: 55.68%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6491    0.8222    0.7255        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5568       185
   macro avg     0.5037    0.4798    0.4733       185
weighted avg     0.5312    0.5568    0.5240       185

micro f-score: 0.5567567567567567

========== Train Epoch 33 ==========
Loss: 0.016	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5568       185
   macro avg     0.4979    0.5198    0.4969       185
weighted avg     0.5584    0.5568    0.5484       185

micro f-score: 0.5567567567567567

========== Train Epoch 34 ==========
Loss: 0.013	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5459       185
   macro avg     0.4942    0.4919    0.4724       185
weighted avg     0.5410    0.5459    0.5214       185

micro f-score: 0.5459459459459459

========== Train Epoch 35 ==========
Loss: 0.012	Accuracy: 57.30%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5730       185
   macro avg     0.5302    0.5394    0.5195       185
weighted avg     0.5957    0.5730    0.5699       185

micro f-score: 0.572972972972973

========== Train Epoch 36 ==========
Loss: 0.014	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5946       185
   macro avg     0.5373    0.5460    0.5266       185
weighted avg     0.5940    0.5946    0.5828       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.014	Accuracy: 57.30%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.5730       185
   macro avg     0.5396    0.5360    0.5227       185
weighted avg     0.5855    0.5730    0.5623       185

micro f-score: 0.572972972972973

========== Train Epoch 38 ==========
Loss: 0.015	Accuracy: 57.84%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.5784       185
   macro avg     0.5244    0.5313    0.5246       185
weighted avg     0.5932    0.5784    0.5826       185

micro f-score: 0.5783783783783784

========== Train Epoch 39 ==========
Loss: 0.013	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5784       185
   macro avg     0.5297    0.5208    0.5131       185
weighted avg     0.5693    0.5784    0.5627       185

micro f-score: 0.5783783783783784

========== Train Epoch 40 ==========
Loss: 0.012	Accuracy: 56.76%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.2973    0.6471    0.4074        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5676       185
   macro avg     0.5447    0.5493    0.5105       185
weighted avg     0.6130    0.5676    0.5586       185

micro f-score: 0.5675675675675675

========== Train Epoch 41 ==========
Loss: 0.013	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5784       185
   macro avg     0.5711    0.5320    0.5223       185
weighted avg     0.5928    0.5784    0.5600       185

micro f-score: 0.5783783783783784

========== Train Epoch 42 ==========
Loss: 0.012	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.5303    0.8974    0.6667        39

    accuracy                         0.5568       185
   macro avg     0.5292    0.5189    0.4991       185
weighted avg     0.5797    0.5568    0.5425       185

micro f-score: 0.5567567567567567

========== Train Epoch 43 ==========
Loss: 0.011	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4038    0.6774    0.5060        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.7297    0.6923    0.7105        39

    accuracy                         0.5676       185
   macro avg     0.5279    0.5110    0.5027       185
weighted avg     0.5761    0.5676    0.5583       185

micro f-score: 0.5675675675675675

========== Train Epoch 44 ==========
Loss: 0.011	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5838       185
   macro avg     0.5297    0.5404    0.5249       185
weighted avg     0.5811    0.5838    0.5756       185

micro f-score: 0.5837837837837838

========== Train Epoch 45 ==========
Loss: 0.012	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5838       185
   macro avg     0.5431    0.5372    0.5258       185
weighted avg     0.5893    0.5838    0.5715       185

micro f-score: 0.5837837837837838

========== Train Epoch 46 ==========
Loss: 0.079	Accuracy: 23.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1575    0.9091    0.2685        22
         hdx     0.0625    0.0588    0.0606        17
         mtx     0.1000    0.0526    0.0690        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.7500    0.1333    0.2264        45
         zxx     0.6667    0.4103    0.5079        39

    accuracy                         0.2378       185
   macro avg     0.2481    0.2234    0.1618       185
weighted avg     0.3577    0.2378    0.2067       185

micro f-score: 0.23783783783783785

========== Train Epoch 47 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.558	Accuracy: 35.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.1053    0.4706    0.1720        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3438    0.9167    0.5000        12
         qtx     0.6458    0.6889    0.6667        45
         zxx     0.5217    0.3077    0.3871        39

    accuracy                         0.3514       185
   macro avg     0.3738    0.3581    0.2772       185
weighted avg     0.4423    0.3514    0.3205       185

micro f-score: 0.35135135135135137

========== Train Epoch 48 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.639	Accuracy: 30.81%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.2857    0.1290    0.1778        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.1442    0.7895    0.2439        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.8571    0.1333    0.2308        45
         zxx     0.5192    0.6923    0.5934        39

    accuracy                         0.3081       185
   macro avg     0.4580    0.2855    0.2382       185
weighted avg     0.5363    0.3081    0.2813       185

micro f-score: 0.3081081081081081

========== Train Epoch 49 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.197	Accuracy: 46.49%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3333    0.1935    0.2449        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.4362    0.9111    0.5899        45
         zxx     0.7407    0.5128    0.6061        39

    accuracy                         0.4649       185
   macro avg     0.4666    0.3992    0.3871       185
weighted avg     0.4887    0.4649    0.4298       185

micro f-score: 0.4648648648648649

========== Train Epoch 50 ==========
Loss: 0.081	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3824    0.4194    0.4000        31
         cwx     0.2766    0.5909    0.3768        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.1333    0.1053    0.1176        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.5909    0.6667    0.6265        39

    accuracy                         0.4649       185
   macro avg     0.4663    0.3946    0.3940       185
weighted avg     0.5306    0.4649    0.4703       185

micro f-score: 0.4648648648648649

========== Train Epoch 51 ==========
Loss: 0.037	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5902    0.9231    0.7200        39

    accuracy                         0.5243       185
   macro avg     0.4543    0.4612    0.4368       185
weighted avg     0.5187    0.5243    0.5002       185

micro f-score: 0.5243243243243243

========== Train Epoch 52 ==========
Loss: 0.030	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.1429    0.1053    0.1212        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.7105    0.6923    0.7013        39

    accuracy                         0.5189       185
   macro avg     0.4673    0.4922    0.4657       185
weighted avg     0.5293    0.5189    0.5159       185

micro f-score: 0.518918918918919

========== Train Epoch 53 ==========
Loss: 0.026	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7500    0.2903    0.4186        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.5362    0.9487    0.6852        39

    accuracy                         0.5568       185
   macro avg     0.5472    0.5270    0.5020       185
weighted avg     0.6101    0.5568    0.5426       185

micro f-score: 0.5567567567567567

========== Train Epoch 54 ==========
Loss: 0.023	Accuracy: 52.43%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5243       185
   macro avg     0.4692    0.4954    0.4661       185
weighted avg     0.5333    0.5243    0.5100       185

micro f-score: 0.5243243243243243

========== Train Epoch 55 ==========
Loss: 0.019	Accuracy: 54.05%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5882    0.7692    0.6667        39

    accuracy                         0.5405       185
   macro avg     0.4967    0.5063    0.4930       185
weighted avg     0.5580    0.5405    0.5394       185

micro f-score: 0.5405405405405406

========== Train Epoch 56 ==========
Loss: 0.018	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.5568       185
   macro avg     0.4981    0.5074    0.4841       185
weighted avg     0.5645    0.5568    0.5450       185

micro f-score: 0.5567567567567567

========== Train Epoch 57 ==========
Loss: 0.016	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5135       185
   macro avg     0.4384    0.4829    0.4437       185
weighted avg     0.5230    0.5135    0.5042       185

micro f-score: 0.5135135135135135

========== Train Epoch 58 ==========
Loss: 0.015	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.5441    0.9487    0.6916        39

    accuracy                         0.5838       185
   macro avg     0.5475    0.5337    0.5227       185
weighted avg     0.6006    0.5838    0.5687       185

micro f-score: 0.5837837837837838

========== Train Epoch 59 ==========
Loss: 0.015	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5514       185
   macro avg     0.5036    0.5065    0.4924       185
weighted avg     0.5679    0.5514    0.5433       185

micro f-score: 0.5513513513513514

========== Train Epoch 60 ==========
Loss: 0.016	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6923    0.8000    0.7423        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5730       185
   macro avg     0.4959    0.5112    0.4915       185
weighted avg     0.5395    0.5730    0.5467       185

micro f-score: 0.572972972972973

========== Train Epoch 61 ==========
Loss: 0.014	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.1333    0.1053    0.1176        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5459       185
   macro avg     0.4957    0.5077    0.4835       185
weighted avg     0.5586    0.5459    0.5319       185

micro f-score: 0.5459459459459459

========== Train Epoch 62 ==========
Loss: 0.018	Accuracy: 55.14%	Cost 53s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5514       185
   macro avg     0.4822    0.5155    0.4860       185
weighted avg     0.5529    0.5514    0.5392       185

micro f-score: 0.5513513513513514

========== Train Epoch 63 ==========
Loss: 0.014	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.2500    0.2941    0.2703        17
         mtx     0.1429    0.1053    0.1212        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.5072    0.8974    0.6481        39

    accuracy                         0.5243       185
   macro avg     0.5023    0.4787    0.4636       185
weighted avg     0.5722    0.5243    0.5175       185

micro f-score: 0.5243243243243243

========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 54.05%	Cost 38s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.1875    0.1579    0.1714        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6140    0.8974    0.7292        39

    accuracy                         0.5405       185
   macro avg     0.4821    0.5017    0.4768       185
weighted avg     0.5355    0.5405    0.5239       185

micro f-score: 0.5405405405405406

Finished training!!!

Min Loss = 0.011 in epoch 43;
Max Accuracy = 59.46% in epoch 25;
Total Cost 50 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.2918918918918919, 0.2810810810810811, 0.41081081081081083, 0.4, 0.43783783783783786, 0.4702702702702703, 0.4540540540540541, 0.5027027027027027, 0.4, 0.5135135135135135, 0.4864864864864865, 0.3891891891891892, 0.5297297297297298, 0.5135135135135135, 0.4648648648648649, 0.4648648648648649, 0.34054054054054056, 0.5243243243243243, 0.5027027027027027, 0.5351351351351351, 0.5675675675675675, 0.5459459459459459, 0.4864864864864865, 0.5837837837837838, 0.572972972972973, 0.5945945945945946, 0.5837837837837838, 0.5459459459459459, 0.5945945945945946, 0.5783783783783784, 0.5351351351351351, 0.5567567567567567, 0.5567567567567567, 0.5459459459459459, 0.572972972972973, 0.5945945945945946, 0.572972972972973, 0.5783783783783784, 0.5783783783783784, 0.5675675675675675, 0.5783783783783784, 0.5567567567567567, 0.5675675675675675, 0.5837837837837838, 0.5837837837837838, 0.23783783783783785, 0.35135135135135137, 0.3081081081081081, 0.4648648648648649, 0.4648648648648649, 0.5243243243243243, 0.518918918918919, 0.5567567567567567, 0.5243243243243243, 0.5405405405405406, 0.5567567567567567, 0.5135135135135135, 0.5837837837837838, 0.5513513513513514, 0.572972972972973, 0.5459459459459459, 0.5513513513513514, 0.5243243243243243, 0.5405405405405406]
