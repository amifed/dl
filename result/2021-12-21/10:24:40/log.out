dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.876	Accuracy: 30.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3143    0.3548    0.3333        31
         cwx     0.2273    0.2273    0.2273        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.3030    0.2222    0.2564        45
         zxx     0.2989    0.6667    0.4127        39

    accuracy                         0.3027       185
   macro avg     0.2348    0.2578    0.2328       185
weighted avg     0.2488    0.3027    0.2582       185

micro f-score: 0.3027027027027027

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.669	Accuracy: 34.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2308    0.2903    0.2571        31
         cwx     0.2500    0.5000    0.3333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.1333    0.1667    0.1481        12
         qtx     0.4138    0.5333    0.4660        45
         zxx     0.5769    0.3846    0.4615        39

    accuracy                         0.3459       185
   macro avg     0.3721    0.2904    0.2770       185
weighted avg     0.4020    0.3459    0.3310       185

micro f-score: 0.34594594594594597

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.543	Accuracy: 37.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2195    0.2903    0.2500        31
         cwx     0.2308    0.2727    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5250    0.4667    0.4941        45
         zxx     0.4079    0.7949    0.5391        39

    accuracy                         0.3730       185
   macro avg     0.3405    0.2757    0.2462       185
weighted avg     0.3806    0.3730    0.3250       185

micro f-score: 0.37297297297297294

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.394	Accuracy: 37.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2609    0.3871    0.3117        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.9333    0.3111    0.4667        45
         zxx     0.3366    0.8718    0.4857        39

    accuracy                         0.3730       185
   macro avg     0.4704    0.2912    0.2741       185
weighted avg     0.4902    0.3730    0.3340       185

micro f-score: 0.37297297297297294

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.230	Accuracy: 36.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3158    0.1935    0.2400        31
         cwx     0.1927    0.9545    0.3206        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.8333    0.3846    0.5263        39

    accuracy                         0.3622       185
   macro avg     0.4258    0.3158    0.2772       185
weighted avg     0.4718    0.3622    0.3460       185

micro f-score: 0.3621621621621622

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.044	Accuracy: 34.05%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     1.0000    0.2222    0.3636        45
         zxx     0.2806    1.0000    0.4382        39

    accuracy                         0.3405       185
   macro avg     0.3425    0.3161    0.2428       185
weighted avg     0.4019    0.3405    0.2545       185

micro f-score: 0.34054054054054056

========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.879	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3607    0.7097    0.4783        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6579    0.6410    0.6494        39

    accuracy                         0.5189       185
   macro avg     0.5097    0.4559    0.4088       185
weighted avg     0.5532    0.5189    0.4803       185

micro f-score: 0.518918918918919

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.660	Accuracy: 43.78%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.2222    0.7273    0.3404        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.6957    0.4103    0.5161        39

    accuracy                         0.4378       185
   macro avg     0.4805    0.3993    0.3770       185
weighted avg     0.5450    0.4378    0.4238       185

micro f-score: 0.43783783783783786

========== Train Epoch 9 ==========
Loss: 0.430	Accuracy: 44.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.4242    0.6364    0.5091        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2326    0.8333    0.3636        12
         qtx     0.9048    0.4222    0.5758        45
         zxx     0.4390    0.9231    0.5950        39

    accuracy                         0.4486       185
   macro avg     0.5001    0.4282    0.3383       185
weighted avg     0.5538    0.4486    0.3881       185

micro f-score: 0.4486486486486486

========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.281	Accuracy: 42.16%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.3120    1.0000    0.4756        39

    accuracy                         0.4216       185
   macro avg     0.4209    0.3407    0.3144       185
weighted avg     0.4196    0.4216    0.3538       185

micro f-score: 0.42162162162162165

========== Train Epoch 11 ==========
Loss: 0.188	Accuracy: 31.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2857    0.2581    0.2712        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1504    0.8947    0.2576        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.9286    0.2889    0.4407        45
         zxx     0.8235    0.3590    0.5000        39

    accuracy                         0.3189       185
   macro avg     0.5575    0.3297    0.3089       185
weighted avg     0.6281    0.3189    0.3385       185

micro f-score: 0.31891891891891894

========== Train Epoch 12 ==========
Loss: 0.126	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2381    0.5882    0.3390        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5459       185
   macro avg     0.5516    0.5278    0.5022       185
weighted avg     0.6135    0.5459    0.5485       185

micro f-score: 0.5459459459459459

========== Train Epoch 13 ==========
Loss: 0.098	Accuracy: 50.81%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3000    0.0968    0.1463        31
         cwx     0.3030    0.9091    0.4545        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.5081       185
   macro avg     0.4830    0.4697    0.4430       185
weighted avg     0.5485    0.5081    0.4975       185

micro f-score: 0.5081081081081081

========== Train Epoch 14 ==========
Loss: 0.068	Accuracy: 62.16%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.5625    0.4737    0.5143        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.6216       185
   macro avg     0.6220    0.5945    0.5990       185
weighted avg     0.6551    0.6216    0.6322       185

micro f-score: 0.6216216216216216

========== Train Epoch 15 ==========
Loss: 0.059	Accuracy: 60.54%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4500    0.4737    0.4615        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.6054       185
   macro avg     0.5704    0.5726    0.5610       185
weighted avg     0.6283    0.6054    0.6051       185

micro f-score: 0.6054054054054054

========== Train Epoch 16 ==========
Loss: 0.050	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5514       185
   macro avg     0.5082    0.5018    0.5013       185
weighted avg     0.5625    0.5514    0.5523       185

micro f-score: 0.5513513513513514

========== Train Epoch 17 ==========
Loss: 0.051	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3846    0.5263    0.4444        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.6290    0.8667    0.7290        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.5568       185
   macro avg     0.5349    0.5035    0.5025       185
weighted avg     0.5516    0.5568    0.5397       185

micro f-score: 0.5567567567567567

========== Train Epoch 18 ==========
Loss: 0.044	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.4118    0.6364    0.5000        22
         hdx     0.5625    0.5294    0.5455        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5838       185
   macro avg     0.5760    0.5539    0.5482       185
weighted avg     0.6188    0.5838    0.5809       185

micro f-score: 0.5837837837837838

========== Train Epoch 19 ==========
Loss: 0.044	Accuracy: 59.46%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.5161    0.8205    0.6337        39

    accuracy                         0.5946       185
   macro avg     0.6146    0.5821    0.5787       185
weighted avg     0.6500    0.5946    0.5981       185

micro f-score: 0.5945945945945946

========== Train Epoch 20 ==========
Loss: 0.040	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.4737    0.4737    0.4737        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.6897    0.5128    0.5882        39

    accuracy                         0.5568       185
   macro avg     0.5389    0.5245    0.5181       185
weighted avg     0.5696    0.5568    0.5498       185

micro f-score: 0.5567567567567567

========== Train Epoch 21 ==========
Loss: 0.069	Accuracy: 47.03%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.2090    0.7368    0.3256        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.4703       185
   macro avg     0.4276    0.4389    0.3942       185
weighted avg     0.4689    0.4703    0.4421       185

micro f-score: 0.4702702702702703

========== Train Epoch 22 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.056	Accuracy: 51.35%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.1818    0.2105    0.1951        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.6364    0.7778    0.7000        45
         zxx     0.5854    0.6154    0.6000        39

    accuracy                         0.5135       185
   macro avg     0.4887    0.4325    0.4441       185
weighted avg     0.5126    0.5135    0.5027       185

micro f-score: 0.5135135135135135

========== Train Epoch 23 ==========
Loss: 0.048	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4348    0.5263    0.4762        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5514       185
   macro avg     0.5505    0.5071    0.5040       185
weighted avg     0.5915    0.5514    0.5445       185

micro f-score: 0.5513513513513514

========== Train Epoch 24 ==========
Loss: 0.082	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.3913    0.4737    0.4286        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.5556    0.7692    0.6452        39

    accuracy                         0.5514       185
   macro avg     0.6041    0.5120    0.4861       185
weighted avg     0.6427    0.5514    0.5346       185

micro f-score: 0.5513513513513514

========== Train Epoch 25 ==========
Loss: 0.057	Accuracy: 50.81%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2093    0.4737    0.2903        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.5781    0.8222    0.6789        45
         zxx     0.9091    0.5128    0.6557        39

    accuracy                         0.5081       185
   macro avg     0.5940    0.4266    0.4285       185
weighted avg     0.6284    0.5081    0.4982       185

micro f-score: 0.5081081081081081

========== Train Epoch 26 ==========
Loss: 0.044	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.4211    0.8205    0.5565        39

    accuracy                         0.5297       185
   macro avg     0.6686    0.4561    0.4705       185
weighted avg     0.6308    0.5297    0.5043       185

micro f-score: 0.5297297297297298

========== Train Epoch 27 ==========
Loss: 0.053	Accuracy: 35.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2123    1.0000    0.3503        31
         cwx     0.2500    0.0455    0.0769        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     1.0000    0.3333    0.5000        45
         zxx     0.8667    0.3333    0.4815        39

    accuracy                         0.3514       185
   macro avg     0.7613    0.2927    0.2864       185
weighted avg     0.7507    0.3514    0.3391       185

micro f-score: 0.35135135135135137

========== Train Epoch 28 ==========
Loss: 0.059	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3818    0.6774    0.4884        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.5459       185
   macro avg     0.5698    0.4702    0.4743       185
weighted avg     0.5918    0.5459    0.5374       185

micro f-score: 0.5459459459459459

========== Train Epoch 29 ==========
Loss: 0.035	Accuracy: 59.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4524    0.8636    0.5938        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5946       185
   macro avg     0.5470    0.5623    0.5245       185
weighted avg     0.5986    0.5946    0.5751       185

micro f-score: 0.5945945945945946

========== Train Epoch 30 ==========
Loss: 0.032	Accuracy: 55.14%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.5672    0.8444    0.6786        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5514       185
   macro avg     0.5541    0.4846    0.4876       185
weighted avg     0.5573    0.5514    0.5199       185

micro f-score: 0.5513513513513514

========== Train Epoch 31 ==========
Loss: 0.028	Accuracy: 58.92%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5892       185
   macro avg     0.5512    0.5359    0.5195       185
weighted avg     0.5972    0.5892    0.5687       185

micro f-score: 0.5891891891891892

========== Train Epoch 32 ==========
Loss: 0.022	Accuracy: 62.16%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.4074    0.5789    0.4783        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.6216       185
   macro avg     0.5870    0.5707    0.5682       185
weighted avg     0.6421    0.6216    0.6216       185

micro f-score: 0.6216216216216216

========== Train Epoch 33 ==========
Loss: 0.017	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.6054       185
   macro avg     0.5762    0.5697    0.5693       185
weighted avg     0.6170    0.6054    0.6055       185

micro f-score: 0.6054054054054054

========== Train Epoch 34 ==========
Loss: 0.019	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.6522    0.6818    0.6667        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.6108       185
   macro avg     0.5699    0.5693    0.5643       185
weighted avg     0.6106    0.6108    0.6060       185

micro f-score: 0.6108108108108108

========== Train Epoch 35 ==========
Loss: 0.018	Accuracy: 59.46%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5946       185
   macro avg     0.5887    0.5493    0.5542       185
weighted avg     0.6236    0.5946    0.5932       185

micro f-score: 0.5945945945945946

========== Train Epoch 36 ==========
Loss: 0.015	Accuracy: 63.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.7778    0.6364    0.7000        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.6324       185
   macro avg     0.6017    0.5830    0.5899       185
weighted avg     0.6328    0.6324    0.6305       185

micro f-score: 0.6324324324324324

========== Train Epoch 37 ==========
Loss: 0.021	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.1935    0.3243        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.4062    0.8667    0.5532        45
         zxx     0.6667    0.6154    0.6400        39

    accuracy                         0.5135       185
   macro avg     0.6121    0.4548    0.4696       185
weighted avg     0.6229    0.5135    0.4923       185

micro f-score: 0.5135135135135135

========== Train Epoch 38 ==========
Loss: 0.046	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.2750    0.5789    0.3729        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.9310    0.6000    0.7297        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5405       185
   macro avg     0.5616    0.4754    0.4806       185
weighted avg     0.6154    0.5405    0.5431       185

micro f-score: 0.5405405405405406

========== Train Epoch 39 ==========
Loss: 0.025	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.6000       185
   macro avg     0.6107    0.5458    0.5527       185
weighted avg     0.6277    0.6000    0.5867       185

micro f-score: 0.6

========== Train Epoch 40 ==========
Loss: 0.020	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.8571    0.3529    0.5000        17
         mtx     0.3448    0.5263    0.4167        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.5946       185
   macro avg     0.6507    0.5383    0.5532       185
weighted avg     0.6616    0.5946    0.5910       185

micro f-score: 0.5945945945945946

========== Train Epoch 41 ==========
Loss: 0.022	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6162       185
   macro avg     0.5993    0.5537    0.5620       185
weighted avg     0.6255    0.6162    0.6085       185

micro f-score: 0.6162162162162163

========== Train Epoch 42 ==========
Loss: 0.019	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4474    0.5484    0.4928        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6000       185
   macro avg     0.5946    0.5569    0.5466       185
weighted avg     0.6337    0.6000    0.5928       185

micro f-score: 0.6

========== Train Epoch 43 ==========
Loss: 0.018	Accuracy: 62.70%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5217    0.6316    0.5714        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.6270       185
   macro avg     0.6109    0.5890    0.5908       185
weighted avg     0.6399    0.6270    0.6270       185

micro f-score: 0.6270270270270271

========== Train Epoch 44 ==========
Loss: 0.016	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.8182    0.4091    0.5455        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.5000    0.8444    0.6281        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5405       185
   macro avg     0.5797    0.4764    0.4914       185
weighted avg     0.5654    0.5405    0.5135       185

micro f-score: 0.5405405405405406

========== Train Epoch 45 ==========
Loss: 0.022	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4510    0.7419    0.5610        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6000       185
   macro avg     0.6141    0.5450    0.5436       185
weighted avg     0.6475    0.6000    0.5897       185

micro f-score: 0.6

========== Train Epoch 46 ==========
Loss: 0.020	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.5000    0.1364    0.2143        22
         hdx     1.0000    0.3529    0.5217        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.5789    0.7333    0.6471        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5514       185
   macro avg     0.5967    0.4730    0.4864       185
weighted avg     0.5733    0.5514    0.5241       185

micro f-score: 0.5513513513513514

========== Train Epoch 47 ==========
Loss: 0.017	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.6108       185
   macro avg     0.6061    0.5830    0.5703       185
weighted avg     0.6418    0.6108    0.6066       185

micro f-score: 0.6108108108108108

========== Train Epoch 48 ==========
Loss: 0.017	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.6800    0.7727    0.7234        22
         hdx     0.2667    0.4706    0.3404        17
         mtx     0.4444    0.6316    0.5217        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.5946       185
   macro avg     0.5896    0.5649    0.5604       185
weighted avg     0.6344    0.5946    0.6032       185

micro f-score: 0.5945945945945946

========== Train Epoch 49 ==========
Loss: 0.014	Accuracy: 60.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.9375    0.6818    0.7895        22
         hdx     1.0000    0.3529    0.5217        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.4625    0.9487    0.6218        39

    accuracy                         0.6054       185
   macro avg     0.6937    0.5490    0.5736       185
weighted avg     0.6633    0.6054    0.5896       185

micro f-score: 0.6054054054054054

========== Train Epoch 50 ==========
Loss: 0.015	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3800    0.6129    0.4691        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.6054       185
   macro avg     0.6030    0.5662    0.5758       185
weighted avg     0.6347    0.6054    0.6112       185

micro f-score: 0.6054054054054054

========== Train Epoch 51 ==========
Loss: 0.013	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.6296    0.7727    0.6939        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.6162       185
   macro avg     0.6088    0.5566    0.5541       185
weighted avg     0.6235    0.6162    0.5894       185

micro f-score: 0.6162162162162163

========== Train Epoch 52 ==========
Loss: 0.011	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4651    0.6452    0.5405        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.5838       185
   macro avg     0.5463    0.5448    0.5349       185
weighted avg     0.6079    0.5838    0.5855       185

micro f-score: 0.5837837837837838

========== Train Epoch 53 ==========
Loss: 0.014	Accuracy: 61.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3729    0.7097    0.4889        31
         cwx     1.0000    0.5000    0.6667        22
         hdx     0.8000    0.4706    0.5926        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.7500    0.6923    0.7200        39

    accuracy                         0.6108       185
   macro avg     0.6771    0.5646    0.5931       185
weighted avg     0.6868    0.6108    0.6245       185

micro f-score: 0.6108108108108108

========== Train Epoch 54 ==========
Loss: 0.011	Accuracy: 64.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.6800    0.7727    0.7234        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.6486       185
   macro avg     0.6098    0.6017    0.5981       185
weighted avg     0.6441    0.6486    0.6387       185

micro f-score: 0.6486486486486487

========== Train Epoch 55 ==========
Loss: 0.011	Accuracy: 64.32%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.7391    0.7727    0.7556        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.6432       185
   macro avg     0.6071    0.5984    0.5990       185
weighted avg     0.6396    0.6432    0.6368       185

micro f-score: 0.6432432432432432

========== Train Epoch 56 ==========
Loss: 0.012	Accuracy: 64.86%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.6800    0.7727    0.7234        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6486       185
   macro avg     0.6016    0.6068    0.6021       185
weighted avg     0.6452    0.6486    0.6454       185

micro f-score: 0.6486486486486487

========== Train Epoch 57 ==========
Loss: 0.015	Accuracy: 63.24%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.7368    0.6364    0.6829        22
         hdx     1.0000    0.2941    0.4545        17
         mtx     0.3514    0.6842    0.4643        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6324       185
   macro avg     0.6640    0.5963    0.5935       185
weighted avg     0.6861    0.6324    0.6347       185

micro f-score: 0.6324324324324324

========== Train Epoch 58 ==========
Loss: 0.014	Accuracy: 66.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.7368    0.6364    0.6829        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.4583    0.5789    0.5116        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7551    0.8222    0.7872        45
         zxx     0.6000    0.9231    0.7273        39

    accuracy                         0.6649       185
   macro avg     0.6828    0.6047    0.6162       185
weighted avg     0.6932    0.6649    0.6524       185

micro f-score: 0.6648648648648648

========== Train Epoch 59 ==========
Loss: 0.011	Accuracy: 64.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.7273    0.7273    0.7273        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.6486       185
   macro avg     0.6262    0.5963    0.6055       185
weighted avg     0.6421    0.6486    0.6399       185

micro f-score: 0.6486486486486487

========== Train Epoch 60 ==========
Loss: 0.013	Accuracy: 67.03%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.6667    0.8182    0.7347        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7551    0.8222    0.7872        45
         zxx     0.7500    0.7692    0.7595        39

    accuracy                         0.6703       185
   macro avg     0.6351    0.6258    0.6272       185
weighted avg     0.6621    0.6703    0.6637       185

micro f-score: 0.6702702702702703

========== Train Epoch 61 ==========
Loss: 0.012	Accuracy: 62.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.9000    0.2903    0.4390        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.5278    0.9744    0.6847        39

    accuracy                         0.6270       185
   macro avg     0.6621    0.5731    0.5807       185
weighted avg     0.6727    0.6270    0.6070       185

micro f-score: 0.6270270270270271

========== Train Epoch 62 ==========
Loss: 0.013	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3864    0.5484    0.4533        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.6000       185
   macro avg     0.5529    0.5379    0.5383       185
weighted avg     0.5919    0.6000    0.5898       185

micro f-score: 0.6

========== Train Epoch 63 ==========
Loss: 0.011	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4615    0.8182    0.5902        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5892       185
   macro avg     0.5679    0.5450    0.5393       185
weighted avg     0.6126    0.5892    0.5835       185

micro f-score: 0.5891891891891892

========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.5892       185
   macro avg     0.5592    0.5389    0.5440       185
weighted avg     0.5853    0.5892    0.5829       185

micro f-score: 0.5891891891891892

Finished training!!!

Min Loss = 0.011 in epoch 63;
Max Accuracy = 67.03% in epoch 59;
Total Cost 50 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.3027027027027027, 0.34594594594594597, 0.372972972972973, 0.372972972972973, 0.3621621621621622, 0.34054054054054056, 0.518918918918919, 0.43783783783783786, 0.4486486486486487, 0.42162162162162165, 0.31891891891891894, 0.5459459459459459, 0.5081081081081081, 0.6216216216216216, 0.6054054054054054, 0.5513513513513514, 0.5567567567567567, 0.5837837837837838, 0.5945945945945946, 0.5567567567567567, 0.4702702702702703, 0.5135135135135135, 0.5513513513513514, 0.5513513513513514, 0.5081081081081081, 0.5297297297297298, 0.35135135135135137, 0.5459459459459459, 0.5945945945945946, 0.5513513513513514, 0.5891891891891892, 0.6216216216216216, 0.6054054054054054, 0.6108108108108108, 0.5945945945945946, 0.6324324324324324, 0.5135135135135135, 0.5405405405405406, 0.6, 0.5945945945945946, 0.6162162162162163, 0.6, 0.6270270270270271, 0.5405405405405406, 0.6, 0.5513513513513514, 0.6108108108108108, 0.5945945945945946, 0.6054054054054054, 0.6054054054054054, 0.6162162162162163, 0.5837837837837838, 0.6108108108108108, 0.6486486486486487, 0.6432432432432432, 0.6486486486486487, 0.6324324324324324, 0.6648648648648648, 0.6486486486486487, 0.6702702702702703, 0.6270270270270271, 0.6, 0.5891891891891892, 0.5891891891891892]
