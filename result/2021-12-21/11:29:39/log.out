dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.855	Accuracy: 29.73%	Cost 40s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.4286    0.1364    0.2069        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.4318    0.4222    0.4270        45
         zxx     0.2441    0.7949    0.3735        39

    accuracy                         0.2973       185
   macro avg     0.2578    0.2099    0.1694       185
weighted avg     0.3042    0.2973    0.2250       185

micro f-score: 0.2972972972972973

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.662	Accuracy: 29.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.2222    0.2727    0.2449        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.2791    0.5333    0.3664        45
         zxx     0.3333    0.4359    0.3778        39

    accuracy                         0.2919       185
   macro avg     0.2192    0.2243    0.2021       185
weighted avg     0.2613    0.2919    0.2506       185

micro f-score: 0.2918918918918919

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.529	Accuracy: 40.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.4107    0.5111    0.4554        45
         zxx     0.4444    0.8205    0.5766        39

    accuracy                         0.4000       185
   macro avg     0.3535    0.3161    0.3066       185
weighted avg     0.3711    0.4000    0.3594       185

micro f-score: 0.4000000000000001

========== Train Epoch 4 ==========
Loss: 1.374	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2750    0.3548    0.3099        31
         cwx     0.2812    0.8182    0.4186        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.8095    0.4359    0.5667        39

    accuracy                         0.4162       185
   macro avg     0.5080    0.3683    0.3567       185
weighted avg     0.5118    0.4162    0.4086       185

micro f-score: 0.41621621621621624

========== Train Epoch 5 ==========
Loss: 1.237	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.3235    0.5000    0.3929        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3103    0.7500    0.4390        12
         qtx     0.8000    0.4444    0.5714        45
         zxx     0.4390    0.9231    0.5950        39

    accuracy                         0.4432       185
   macro avg     0.4512    0.4121    0.3461       185
weighted avg     0.5071    0.4432    0.3919       185

micro f-score: 0.44324324324324327

========== Train Epoch 6 ==========
Loss: 1.049	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3824    0.4194    0.4000        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2647    0.7500    0.3913        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.4432       185
   macro avg     0.4250    0.4074    0.3666       185
weighted avg     0.4571    0.4432    0.4179       185

micro f-score: 0.44324324324324327

========== Train Epoch 7 ==========
Loss: 0.887	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3571    0.4839    0.4110        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6429    0.6000    0.6207        45
         zxx     0.6486    0.6154    0.6316        39

    accuracy                         0.4811       185
   macro avg     0.4356    0.4452    0.4337       185
weighted avg     0.4817    0.4811    0.4766       185

micro f-score: 0.4810810810810811

========== Train Epoch 8 ==========
Loss: 0.715	Accuracy: 37.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3659    0.4839    0.4167        31
         cwx     0.2857    0.6364    0.3944        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.1930    0.9167    0.3188        12
         qtx     0.9000    0.4000    0.5538        45
         zxx     0.8182    0.2308    0.3600        39

    accuracy                         0.3730       185
   macro avg     0.4613    0.3961    0.3179       185
weighted avg     0.5677    0.3730    0.3667       185

micro f-score: 0.37297297297297294

========== Train Epoch 9 ==========
Loss: 0.522	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5784       185
   macro avg     0.5536    0.5357    0.5346       185
weighted avg     0.5976    0.5784    0.5749       185

micro f-score: 0.5783783783783784

========== Train Epoch 10 ==========
Loss: 0.369	Accuracy: 49.19%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.3714    0.5909    0.4561        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5070    0.8000    0.6207        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.4919       185
   macro avg     0.5162    0.4350    0.4449       185
weighted avg     0.5239    0.4919    0.4797       185

micro f-score: 0.4918918918918919

========== Train Epoch 11 ==========
Loss: 0.255	Accuracy: 42.16%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1684    0.8421    0.2807        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.4216       185
   macro avg     0.4456    0.3731    0.3384       185
weighted avg     0.4916    0.4216    0.4053       185

micro f-score: 0.42162162162162165

========== Train Epoch 12 ==========
Loss: 0.173	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5556    0.1613    0.2500        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.2128    0.8333    0.3390        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.5027       185
   macro avg     0.5102    0.4940    0.4485       185
weighted avg     0.5949    0.5027    0.5072       185

micro f-score: 0.5027027027027027

========== Train Epoch 13 ==========
Loss: 0.138	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3860    0.7097    0.5000        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.8889    0.6667    0.7619        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5730       185
   macro avg     0.5953    0.5083    0.5188       185
weighted avg     0.6039    0.5730    0.5593       185

micro f-score: 0.572972972972973

========== Train Epoch 14 ==========
Loss: 0.106	Accuracy: 41.08%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.8333    0.1613    0.2703        31
         cwx     0.3824    0.5909    0.4643        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1744    0.7895    0.2857        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     1.0000    0.1778    0.3019        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.4108       185
   macro avg     0.5775    0.4150    0.3738       185
weighted avg     0.6486    0.4108    0.3902       185

micro f-score: 0.4108108108108109

========== Train Epoch 15 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.078	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.2174    0.2632    0.2381        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.5500    0.7333    0.6286        45
         zxx     0.6923    0.6923    0.6923        39

    accuracy                         0.5459       185
   macro avg     0.5979    0.4739    0.4991       185
weighted avg     0.5803    0.5459    0.5390       185

micro f-score: 0.5459459459459459

========== Train Epoch 16 ==========
Loss: 0.066	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.8182    0.4091    0.5455        22
         hdx     0.2647    0.5294    0.3529        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     1.0000    0.5000    0.6667        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.5892       185
   macro avg     0.6446    0.5400    0.5546       185
weighted avg     0.6632    0.5892    0.5952       185

micro f-score: 0.5891891891891892

========== Train Epoch 17 ==========
Loss: 0.065	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5676       185
   macro avg     0.5281    0.5365    0.5311       185
weighted avg     0.5733    0.5676    0.5695       185

micro f-score: 0.5675675675675675

========== Train Epoch 18 ==========
Loss: 0.047	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3934    0.7742    0.5217        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2308    0.3158    0.2667        19
         nqx     0.9091    0.8333    0.8696        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6786    0.4872    0.5672        39

    accuracy                         0.5622       185
   macro avg     0.6193    0.5532    0.5647       185
weighted avg     0.6330    0.5622    0.5744       185

micro f-score: 0.5621621621621622

========== Train Epoch 19 ==========
Loss: 0.038	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3200    0.4211    0.3636        19
         nqx     0.3235    0.9167    0.4783        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.5838       185
   macro avg     0.5680    0.5790    0.5401       185
weighted avg     0.6456    0.5838    0.5889       185

micro f-score: 0.5837837837837838

========== Train Epoch 20 ==========
Loss: 0.032	Accuracy: 64.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.9000    0.7500    0.8182        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.6429    0.9231    0.7579        39

    accuracy                         0.6432       185
   macro avg     0.6230    0.5964    0.5990       185
weighted avg     0.6415    0.6432    0.6311       185

micro f-score: 0.6432432432432432

========== Train Epoch 21 ==========
Loss: 0.034	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5892       185
   macro avg     0.5652    0.5290    0.5381       185
weighted avg     0.5922    0.5892    0.5835       185

micro f-score: 0.5891891891891892

========== Train Epoch 22 ==========
Loss: 0.029	Accuracy: 63.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.6324       185
   macro avg     0.6089    0.5921    0.5881       185
weighted avg     0.6308    0.6324    0.6181       185

micro f-score: 0.6324324324324324

========== Train Epoch 23 ==========
Loss: 0.035	Accuracy: 60.54%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4412    0.6818    0.5357        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     1.0000    0.7500    0.8571        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.6667    0.8205    0.7356        39

    accuracy                         0.6054       185
   macro avg     0.6150    0.5813    0.5861       185
weighted avg     0.6354    0.6054    0.6077       185

micro f-score: 0.6054054054054054

========== Train Epoch 24 ==========
Loss: 0.043	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5946       185
   macro avg     0.6050    0.5626    0.5709       185
weighted avg     0.6249    0.5946    0.5981       185

micro f-score: 0.5945945945945946

========== Train Epoch 25 ==========
Loss: 0.043	Accuracy: 41.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.1188    1.0000    0.2124        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.7353    0.6410    0.6849        39

    accuracy                         0.4108       185
   macro avg     0.6479    0.4031    0.3581       185
weighted avg     0.7461    0.4108    0.4358       185

micro f-score: 0.4108108108108109

========== Train Epoch 26 ==========
Loss: 0.049	Accuracy: 48.65%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.2075    0.9167    0.3385        12
         qtx     0.5484    0.7556    0.6355        45
         zxx     0.8400    0.5385    0.6562        39

    accuracy                         0.4865       185
   macro avg     0.5386    0.4654    0.4298       185
weighted avg     0.5937    0.4865    0.4866       185

micro f-score: 0.4864864864864865

========== Train Epoch 27 ==========
Loss: 0.042	Accuracy: 57.30%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.3667    0.9167    0.5238        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.5730       185
   macro avg     0.5311    0.5603    0.5141       185
weighted avg     0.6150    0.5730    0.5656       185

micro f-score: 0.572972972972973

========== Train Epoch 28 ==========
Loss: 0.042	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7778    0.2258    0.3500        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.5373    0.9231    0.6792        39

    accuracy                         0.5676       185
   macro avg     0.5823    0.5101    0.5102       185
weighted avg     0.5937    0.5676    0.5400       185

micro f-score: 0.5675675675675675

========== Train Epoch 29 ==========
Loss: 0.037	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6000       185
   macro avg     0.5821    0.5822    0.5544       185
weighted avg     0.6201    0.6000    0.5867       185

micro f-score: 0.6

========== Train Epoch 30 ==========
Loss: 0.028	Accuracy: 62.16%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6216       185
   macro avg     0.5730    0.5892    0.5648       185
weighted avg     0.6202    0.6216    0.6100       185

micro f-score: 0.6216216216216216

========== Train Epoch 31 ==========
Loss: 0.022	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6108       185
   macro avg     0.6012    0.5889    0.5840       185
weighted avg     0.6313    0.6108    0.6059       185

micro f-score: 0.6108108108108108

========== Train Epoch 32 ==========
Loss: 0.024	Accuracy: 63.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5500    0.7097    0.6197        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7500    0.7692    0.7595        39

    accuracy                         0.6378       185
   macro avg     0.6026    0.6022    0.5971       185
weighted avg     0.6431    0.6378    0.6348       185

micro f-score: 0.6378378378378379

========== Train Epoch 33 ==========
Loss: 0.028	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.2424    0.4706    0.3200        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5892       185
   macro avg     0.5993    0.5613    0.5652       185
weighted avg     0.6407    0.5892    0.5991       185

micro f-score: 0.5891891891891892

========== Train Epoch 34 ==========
Loss: 0.020	Accuracy: 63.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6667    0.7273    0.6957        22
         hdx     0.2609    0.3529    0.3000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6324       185
   macro avg     0.5936    0.6006    0.5904       185
weighted avg     0.6333    0.6324    0.6275       185

micro f-score: 0.6324324324324324

========== Train Epoch 35 ==========
Loss: 0.023	Accuracy: 62.70%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.6270       185
   macro avg     0.5990    0.5879    0.5834       185
weighted avg     0.6401    0.6270    0.6225       185

micro f-score: 0.6270270270270271

========== Train Epoch 36 ==========
Loss: 0.017	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.2414    0.4118    0.3043        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6034    0.7778    0.6796        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.5838       185
   macro avg     0.6016    0.5336    0.5325       185
weighted avg     0.6147    0.5838    0.5702       185

micro f-score: 0.5837837837837838

========== Train Epoch 37 ==========
Loss: 0.031	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5556    0.6452    0.5970        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9231    0.5333    0.6761        45
         zxx     0.5143    0.9231    0.6606        39

    accuracy                         0.5730       185
   macro avg     0.5509    0.5212    0.5112       185
weighted avg     0.5974    0.5730    0.5536       185

micro f-score: 0.572972972972973

========== Train Epoch 38 ==========
Loss: 0.072	Accuracy: 40.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.1705    0.7895    0.2804        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     0.9231    0.3077    0.4615        39

    accuracy                         0.4000       185
   macro avg     0.5977    0.4101    0.3895       185
weighted avg     0.6630    0.4000    0.4276       185

micro f-score: 0.4000000000000001

========== Train Epoch 39 ==========
Loss: 0.164	Accuracy: 34.05%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1325    0.6471    0.2200        17
         mtx     0.1818    0.2105    0.1951        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     1.0000    0.2222    0.3636        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.3405       185
   macro avg     0.3658    0.3347    0.2798       185
weighted avg     0.4326    0.3405    0.3006       185

micro f-score: 0.34054054054054056

========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.294	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2317    0.8636    0.3654        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.6596    0.6889    0.6739        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.4378       185
   macro avg     0.4213    0.3474    0.2751       185
weighted avg     0.4218    0.4378    0.3615       185

micro f-score: 0.43783783783783786

========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.272	Accuracy: 43.78%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2162    0.4211    0.2857        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.9375    0.3333    0.4918        45
         zxx     0.4023    0.8974    0.5556        39

    accuracy                         0.4378       185
   macro avg     0.5591    0.4252    0.4090       185
weighted avg     0.6057    0.4378    0.4200       185

micro f-score: 0.43783783783783786

========== Train Epoch 42 ==========
Loss: 0.069	Accuracy: 52.97%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.7778    0.6364    0.7000        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.3158    0.3158    0.3158        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.4167    0.8974    0.5691        39

    accuracy                         0.5297       185
   macro avg     0.6035    0.4786    0.4796       185
weighted avg     0.5942    0.5297    0.4941       185

micro f-score: 0.5297297297297298

========== Train Epoch 43 ==========
Loss: 0.042	Accuracy: 61.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6108       185
   macro avg     0.5690    0.5826    0.5664       185
weighted avg     0.6075    0.6108    0.5999       185

micro f-score: 0.6108108108108108

========== Train Epoch 44 ==========
Loss: 0.034	Accuracy: 62.70%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.8667    0.5909    0.7027        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6270       185
   macro avg     0.6097    0.5907    0.5900       185
weighted avg     0.6379    0.6270    0.6217       185

micro f-score: 0.6270270270270271

========== Train Epoch 45 ==========
Loss: 0.030	Accuracy: 63.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6324       185
   macro avg     0.5870    0.5987    0.5838       185
weighted avg     0.6236    0.6324    0.6200       185

micro f-score: 0.6324324324324324

========== Train Epoch 46 ==========
Loss: 0.021	Accuracy: 62.70%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.8235    0.6364    0.7179        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.6270       185
   macro avg     0.6043    0.6017    0.5962       185
weighted avg     0.6280    0.6270    0.6220       185

micro f-score: 0.6270270270270271

========== Train Epoch 47 ==========
Loss: 0.021	Accuracy: 64.86%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.7826    0.8000    0.7912        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.6486       185
   macro avg     0.6454    0.5917    0.6074       185
weighted avg     0.6539    0.6486    0.6412       185

micro f-score: 0.6486486486486487

========== Train Epoch 48 ==========
Loss: 0.019	Accuracy: 65.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.5625    0.5294    0.5455        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7708    0.8222    0.7957        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6541       185
   macro avg     0.6188    0.6205    0.6179       185
weighted avg     0.6415    0.6541    0.6458       185

micro f-score: 0.654054054054054

========== Train Epoch 49 ==========
Loss: 0.018	Accuracy: 61.62%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.7778    0.6364    0.7000        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2273    0.2632    0.2439        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.6162       185
   macro avg     0.5906    0.5741    0.5801       185
weighted avg     0.6280    0.6162    0.6198       185

micro f-score: 0.6162162162162163

========== Train Epoch 50 ==========
Loss: 0.019	Accuracy: 63.78%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.7368    0.6364    0.6829        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6378       185
   macro avg     0.6095    0.5960    0.5916       185
weighted avg     0.6338    0.6378    0.6237       185

micro f-score: 0.6378378378378379

========== Train Epoch 51 ==========
Loss: 0.018	Accuracy: 62.70%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6270       185
   macro avg     0.6038    0.5805    0.5879       185
weighted avg     0.6187    0.6270    0.6186       185

micro f-score: 0.6270270270270271

========== Train Epoch 52 ==========
Loss: 0.017	Accuracy: 64.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6486       185
   macro avg     0.6041    0.6227    0.6066       185
weighted avg     0.6353    0.6486    0.6369       185

micro f-score: 0.6486486486486487

========== Train Epoch 53 ==========
Loss: 0.016	Accuracy: 64.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8718    0.7556    0.8095        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6486       185
   macro avg     0.6064    0.6141    0.5982       185
weighted avg     0.6528    0.6486    0.6396       185

micro f-score: 0.6486486486486487

========== Train Epoch 54 ==========
Loss: 0.013	Accuracy: 64.86%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6486       185
   macro avg     0.6089    0.6159    0.6057       185
weighted avg     0.6389    0.6486    0.6378       185

micro f-score: 0.6486486486486487

========== Train Epoch 55 ==========
Loss: 0.014	Accuracy: 64.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.9143    0.7111    0.8000        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6432       185
   macro avg     0.5987    0.6143    0.5971       185
weighted avg     0.6456    0.6432    0.6351       185

micro f-score: 0.6432432432432432

========== Train Epoch 56 ==========
Loss: 0.011	Accuracy: 62.70%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6270       185
   macro avg     0.6187    0.5778    0.5859       185
weighted avg     0.6233    0.6270    0.6135       185

micro f-score: 0.6270270270270271

========== Train Epoch 57 ==========
Loss: 0.013	Accuracy: 63.24%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.7857    0.9167    0.8462        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6324       185
   macro avg     0.6107    0.6041    0.5977       185
weighted avg     0.6354    0.6324    0.6226       185

micro f-score: 0.6324324324324324

========== Train Epoch 58 ==========
Loss: 0.013	Accuracy: 64.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7059    0.8000    0.7500        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6432       185
   macro avg     0.6095    0.5984    0.5904       185
weighted avg     0.6274    0.6432    0.6229       185

micro f-score: 0.6432432432432432

========== Train Epoch 59 ==========
Loss: 0.016	Accuracy: 64.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.6486       185
   macro avg     0.6012    0.6265    0.6039       185
weighted avg     0.6538    0.6486    0.6415       185

micro f-score: 0.6486486486486487

========== Train Epoch 60 ==========
Loss: 0.015	Accuracy: 64.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6432       185
   macro avg     0.6268    0.6057    0.6078       185
weighted avg     0.6388    0.6432    0.6318       185

micro f-score: 0.6432432432432432

========== Train Epoch 61 ==========
Loss: 0.013	Accuracy: 64.86%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.6486       185
   macro avg     0.6193    0.6154    0.6136       185
weighted avg     0.6357    0.6486    0.6384       185

micro f-score: 0.6486486486486487

========== Train Epoch 62 ==========
Loss: 0.015	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.3000    0.3158    0.3077        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6108       185
   macro avg     0.6101    0.5549    0.5620       185
weighted avg     0.6284    0.6108    0.5971       185

micro f-score: 0.6108108108108108

========== Train Epoch 63 ==========
Loss: 0.013	Accuracy: 62.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6270       185
   macro avg     0.6029    0.5916    0.5939       185
weighted avg     0.6191    0.6270    0.6194       185

micro f-score: 0.6270270270270271

========== Train Epoch 64 ==========
Loss: 0.013	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6162       185
   macro avg     0.6015    0.5656    0.5715       185
weighted avg     0.6083    0.6162    0.5994       185

micro f-score: 0.6162162162162163

Finished training!!!

Min Loss = 0.011 in epoch 55;
Max Accuracy = 65.41% in epoch 47;
Total Cost 50 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.2972972972972973, 0.2918918918918919, 0.4, 0.41621621621621624, 0.44324324324324327, 0.44324324324324327, 0.4810810810810811, 0.372972972972973, 0.5783783783783784, 0.4918918918918919, 0.42162162162162165, 0.5027027027027027, 0.572972972972973, 0.41081081081081083, 0.5459459459459459, 0.5891891891891892, 0.5675675675675675, 0.5621621621621622, 0.5837837837837838, 0.6432432432432432, 0.5891891891891892, 0.6324324324324324, 0.6054054054054054, 0.5945945945945946, 0.41081081081081083, 0.4864864864864865, 0.572972972972973, 0.5675675675675675, 0.6, 0.6216216216216216, 0.6108108108108108, 0.6378378378378379, 0.5891891891891892, 0.6324324324324324, 0.6270270270270271, 0.5837837837837838, 0.572972972972973, 0.4, 0.34054054054054056, 0.43783783783783786, 0.43783783783783786, 0.5297297297297298, 0.6108108108108108, 0.6270270270270271, 0.6324324324324324, 0.6270270270270271, 0.6486486486486487, 0.654054054054054, 0.6162162162162163, 0.6378378378378379, 0.6270270270270271, 0.6486486486486487, 0.6486486486486487, 0.6486486486486487, 0.6432432432432432, 0.6270270270270271, 0.6324324324324324, 0.6432432432432432, 0.6486486486486487, 0.6432432432432432, 0.6486486486486487, 0.6108108108108108, 0.6270270270270271, 0.6162162162162163]
