dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam resnet34
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.826	Accuracy: 29.19%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2609    0.2727    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3818    0.4667    0.4200        45
         zxx     0.2547    0.6923    0.3724        39

    accuracy                         0.2919       185
   macro avg     0.1282    0.2045    0.1513       185
weighted avg     0.1776    0.2919    0.2124       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.624	Accuracy: 31.35%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5909    0.2889    0.3881        45
         zxx     0.2556    0.8718    0.3953        39

    accuracy                         0.3135       185
   macro avg     0.3162    0.2451    0.2199       185
weighted avg     0.3632    0.3135    0.2627       185

micro f-score: 0.31351351351351353

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.410	Accuracy: 38.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.2778    0.3226    0.2985        31
         cwx     0.4286    0.1364    0.2069        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.7188    0.5111    0.5974        45
         zxx     0.3269    0.8718    0.4755        39

    accuracy                         0.3892       185
   macro avg     0.3574    0.2834    0.2584       185
weighted avg     0.4034    0.3892    0.3380       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.233	Accuracy: 40.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3226    0.6452    0.4301        31
         cwx     0.2222    0.3636    0.2759        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.9444    0.3778    0.5397        45
         zxx     0.4462    0.7436    0.5577        39

    accuracy                         0.4054       185
   macro avg     0.4193    0.3162    0.2796       185
weighted avg     0.4691    0.4054    0.3637       185

micro f-score: 0.40540540540540543

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.046	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2979    0.9032    0.4480        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6304    0.6444    0.6374        45
         zxx     1.0000    0.2308    0.3750        39

    accuracy                         0.4162       185
   macro avg     0.4095    0.3546    0.3193       185
weighted avg     0.5024    0.4162    0.3777       185

micro f-score: 0.41621621621621624

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.793	Accuracy: 35.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.2432    0.2903    0.2647        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2083    0.8333    0.3333        12
         qtx     0.6875    0.2444    0.3607        45
         zxx     0.4559    0.7949    0.5794        39

    accuracy                         0.3568       185
   macro avg     0.3326    0.3425    0.2684       185
weighted avg     0.3994    0.3568    0.3149       185

micro f-score: 0.3567567567567568

========== Train Epoch 7 ==========
Loss: 0.545	Accuracy: 45.95%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4043    0.6129    0.4872        31
         cwx     0.2632    0.4545    0.3333        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.3056    0.9167    0.4583        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.8750    0.1795    0.2979        39

    accuracy                         0.4595       185
   macro avg     0.5507    0.4619    0.4069       185
weighted avg     0.5988    0.4595    0.4381       185

micro f-score: 0.4594594594594595

========== Train Epoch 8 ==========
Loss: 0.362	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.2258    0.3111        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.4000    0.8889    0.5517        45
         zxx     0.6667    0.4103    0.5079        39

    accuracy                         0.4378       185
   macro avg     0.5980    0.3642    0.3660       185
weighted avg     0.5659    0.4378    0.4055       185

micro f-score: 0.43783783783783786

========== Train Epoch 9 ==========
Loss: 0.230	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.1795    0.7368    0.2887        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     1.0000    0.2222    0.3636        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.4324       185
   macro avg     0.6530    0.4503    0.4060       185
weighted avg     0.7037    0.4324    0.4306       185

micro f-score: 0.43243243243243246

========== Train Epoch 10 ==========
Loss: 0.163	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5882    0.6452    0.6154        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2414    0.3684    0.2917        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5000    0.6923    0.5806        39

    accuracy                         0.5351       185
   macro avg     0.5251    0.4548    0.4626       185
weighted avg     0.5614    0.5351    0.5293       185

micro f-score: 0.5351351351351351

========== Train Epoch 11 ==========
Loss: 0.111	Accuracy: 45.41%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.3864    0.7727    0.5152        22
         hdx     0.2105    0.7059    0.3243        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.4541       185
   macro avg     0.5803    0.4338    0.3895       185
weighted avg     0.6208    0.4541    0.4362       185

micro f-score: 0.4540540540540541

========== Train Epoch 12 ==========
Loss: 0.080	Accuracy: 44.86%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.2759    0.7273    0.4000        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     1.0000    0.3111    0.4746        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.4486       185
   macro avg     0.5116    0.4153    0.3843       185
weighted avg     0.5742    0.4486    0.4213       185

micro f-score: 0.4486486486486486

========== Train Epoch 13 ==========
Loss: 0.083	Accuracy: 34.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2736    0.9355    0.4234        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2941    0.8333    0.4348        12
         qtx     0.8571    0.2667    0.4068        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.3405       185
   macro avg     0.3363    0.3821    0.2783       185
weighted avg     0.3757    0.3405    0.2699       185

micro f-score: 0.34054054054054056

========== Train Epoch 14 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.078	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4878    0.6452    0.5556        31
         cwx     0.3953    0.7727    0.5231        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.1905    0.2105    0.2000        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.6250    0.6667    0.6452        45
         zxx     0.7857    0.2821    0.4151        39

    accuracy                         0.4919       185
   macro avg     0.4978    0.4543    0.4409       185
weighted avg     0.5444    0.4919    0.4799       185

micro f-score: 0.4918918918918919

========== Train Epoch 15 ==========
Loss: 0.066	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4000    0.7097    0.5116        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.2000    0.4737    0.2812        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.9412    0.3556    0.5161        45
         zxx     0.8000    0.6154    0.6957        39

    accuracy                         0.4649       185
   macro avg     0.5416    0.4545    0.4411       185
weighted avg     0.6130    0.4649    0.4733       185

micro f-score: 0.4648648648648649

========== Train Epoch 16 ==========
Loss: 0.067	Accuracy: 41.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3333    0.9333    0.4912        45
         zxx     0.9091    0.2564    0.4000        39

    accuracy                         0.4108       185
   macro avg     0.4589    0.3261    0.3233       185
weighted avg     0.5235    0.4108    0.3710       185

micro f-score: 0.4108108108108109

========== Train Epoch 17 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.098	Accuracy: 32.97%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.2090    0.6364    0.3146        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.1746    0.9167    0.2933        12
         qtx     0.8667    0.2889    0.4333        45
         zxx     0.7037    0.4872    0.5758        39

    accuracy                         0.3297       185
   macro avg     0.3613    0.3541    0.2649       185
weighted avg     0.4787    0.3297    0.3176       185

micro f-score: 0.32972972972972975

========== Train Epoch 18 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.075	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.9524    0.4444    0.6061        45
         zxx     0.3793    0.8462    0.5238        39

    accuracy                         0.4595       185
   macro avg     0.5253    0.3945    0.3729       185
weighted avg     0.5633    0.4595    0.4306       185

micro f-score: 0.4594594594594595

========== Train Epoch 19 ==========
Loss: 0.097	Accuracy: 38.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1562    0.5882    0.2469        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.4776    0.7111    0.5714        45
         zxx     0.7778    0.3590    0.4912        39

    accuracy                         0.3838       185
   macro avg     0.4106    0.3308    0.3060       185
weighted avg     0.4409    0.3838    0.3603       185

micro f-score: 0.3837837837837838

========== Train Epoch 20 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.071	Accuracy: 50.81%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3377    0.8387    0.4815        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.5081       185
   macro avg     0.5323    0.4773    0.4727       185
weighted avg     0.6013    0.5081    0.5140       185

micro f-score: 0.5081081081081081

========== Train Epoch 21 ==========
Loss: 0.051	Accuracy: 61.08%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     1.0000    0.5833    0.7368        12
         qtx     0.6207    0.8000    0.6990        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6108       185
   macro avg     0.6876    0.5364    0.5391       185
weighted avg     0.6577    0.6108    0.5807       185

micro f-score: 0.6108108108108108

========== Train Epoch 22 ==========
Loss: 0.055	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7273    0.2581    0.3810        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2188    0.3684    0.2745        19
         nqx     0.2778    0.8333    0.4167        12
         qtx     0.5769    0.6667    0.6186        45
         zxx     0.6667    0.6667    0.6667        39

    accuracy                         0.4703       185
   macro avg     0.5464    0.4475    0.3953       185
weighted avg     0.5950    0.4703    0.4500       185

micro f-score: 0.4702702702702703

========== Train Epoch 23 ==========
Loss: 0.047	Accuracy: 55.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5641    0.7097    0.6286        31
         cwx     0.4186    0.8182    0.5538        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2963    0.4211    0.3478        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.8947    0.4359    0.5862        39

    accuracy                         0.5568       185
   macro avg     0.5636    0.5398    0.5231       185
weighted avg     0.6294    0.5568    0.5611       185

micro f-score: 0.5567567567567567

========== Train Epoch 24 ==========
Loss: 0.039	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2424    0.4211    0.3077        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.5405       185
   macro avg     0.5451    0.4863    0.4949       185
weighted avg     0.5836    0.5405    0.5413       185

micro f-score: 0.5405405405405406

========== Train Epoch 25 ==========
Loss: 0.027	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.2308    0.5294    0.3214        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.5161    0.8205    0.6337        39

    accuracy                         0.5135       185
   macro avg     0.5276    0.4900    0.4503       185
weighted avg     0.5882    0.5135    0.4976       185

micro f-score: 0.5135135135135135

========== Train Epoch 26 ==========
Loss: 0.034	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2708    0.6842    0.3881        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6364    0.7778    0.7000        45
         zxx     0.9500    0.4872    0.6441        39

    accuracy                         0.5351       185
   macro avg     0.5447    0.5018    0.4827       185
weighted avg     0.6253    0.5351    0.5371       185

micro f-score: 0.5351351351351351

========== Train Epoch 27 ==========
Loss: 0.049	Accuracy: 42.70%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.4103    0.7273    0.5246        22
         hdx     0.1667    0.3529    0.2264        17
         mtx     0.2222    0.5263    0.3125        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     1.0000    0.1282    0.2273        39

    accuracy                         0.4270       185
   macro avg     0.5991    0.4317    0.4084       185
weighted avg     0.6603    0.4270    0.4318       185

micro f-score: 0.427027027027027

========== Train Epoch 28 ==========
Loss: 0.065	Accuracy: 48.65%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2000    0.3158    0.2449        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5507    0.8444    0.6667        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.4865       185
   macro avg     0.4679    0.3740    0.3521       185
weighted avg     0.5288    0.4865    0.4406       185

micro f-score: 0.4864864864864865

========== Train Epoch 29 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.044	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4773    0.6774    0.5600        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.1765    0.4737    0.2571        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.9444    0.3778    0.5397        45
         zxx     0.9000    0.4615    0.6102        39

    accuracy                         0.4703       185
   macro avg     0.5345    0.4762    0.4617       185
weighted avg     0.6363    0.4703    0.4969       185

micro f-score: 0.4702702702702703

========== Train Epoch 30 ==========
Loss: 0.049	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2105    1.0000    0.3478        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.5208    0.6410    0.5747        39

    accuracy                         0.4595       185
   macro avg     0.3895    0.4386    0.3598       185
weighted avg     0.4800    0.4595    0.4324       185

micro f-score: 0.4594594594594595

========== Train Epoch 31 ==========
Loss: 0.059	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4048    0.5484    0.4658        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2353    0.4211    0.3019        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.5217    0.6154    0.5647        39

    accuracy                         0.4811       185
   macro avg     0.5410    0.4073    0.3938       185
weighted avg     0.5613    0.4811    0.4563       185

micro f-score: 0.4810810810810811

========== Train Epoch 32 ==========
Loss: 0.068	Accuracy: 46.49%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.2250    0.8182    0.3529        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.8519    0.5111    0.6389        45
         zxx     0.8400    0.5385    0.6562        39

    accuracy                         0.4649       185
   macro avg     0.5065    0.4107    0.3972       185
weighted avg     0.5745    0.4649    0.4680       185

micro f-score: 0.4648648648648649

========== Train Epoch 33 ==========
Loss: 0.088	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2921    0.8387    0.4333        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.9500    0.4872    0.6441        39

    accuracy                         0.4811       185
   macro avg     0.4688    0.4039    0.3980       185
weighted avg     0.5930    0.4811    0.4865       185

micro f-score: 0.4810810810810811

========== Train Epoch 34 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.059	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2000    0.4737    0.2812        19
         nqx     0.2903    0.7500    0.4186        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6897    0.5128    0.5882        39

    accuracy                         0.4973       185
   macro avg     0.5236    0.4903    0.4708       185
weighted avg     0.5945    0.4973    0.5196       185

micro f-score: 0.4972972972972973

========== Train Epoch 35 ==========
Loss: 0.053	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3750    0.4839    0.4225        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5362    0.8222    0.6491        45
         zxx     0.7391    0.4359    0.5484        39

    accuracy                         0.4973       185
   macro avg     0.5176    0.4528    0.4418       185
weighted avg     0.5414    0.4973    0.4763       185

micro f-score: 0.4972972972972973

========== Train Epoch 36 ==========
Loss: 0.028	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.2353    0.4706    0.3137        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5000    0.9231    0.6486        39

    accuracy                         0.5189       185
   macro avg     0.5471    0.4678    0.4566       185
weighted avg     0.6039    0.5189    0.5027       185

micro f-score: 0.518918918918919

========== Train Epoch 37 ==========
Loss: 0.024	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.3333    0.9167    0.4889        12
         qtx     1.0000    0.5333    0.6957        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5459       185
   macro avg     0.5287    0.5551    0.5108       185
weighted avg     0.6137    0.5459    0.5524       185

micro f-score: 0.5459459459459459

========== Train Epoch 38 ==========
Loss: 0.025	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.5065    0.8667    0.6393        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.5676       185
   macro avg     0.5328    0.5109    0.4963       185
weighted avg     0.5666    0.5676    0.5411       185

micro f-score: 0.5675675675675675

========== Train Epoch 39 ==========
Loss: 0.026	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.1717    0.8947    0.2881        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.9545    0.4667    0.6269        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.4378       185
   macro avg     0.5756    0.3832    0.3493       185
weighted avg     0.6780    0.4378    0.4321       185

micro f-score: 0.43783783783783786

========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.061	Accuracy: 39.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.1111    0.1053    0.1081        19
         nqx     0.1569    0.6667    0.2540        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4844    0.7949    0.6019        39

    accuracy                         0.3946       185
   macro avg     0.3389    0.3506    0.2919       185
weighted avg     0.4127    0.3946    0.3582       185

micro f-score: 0.3945945945945946

========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.083	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.1754    0.5882    0.2703        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.9565    0.4889    0.6471        45
         zxx     0.5490    0.7179    0.6222        39

    accuracy                         0.4703       185
   macro avg     0.5580    0.4253    0.4256       185
weighted avg     0.6007    0.4703    0.4803       185

micro f-score: 0.4702702702702703

========== Train Epoch 42 ==========
Loss: 0.103	Accuracy: 52.43%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.2727    0.7500    0.4000        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.6944    0.6410    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.4927    0.4861    0.4616       185
weighted avg     0.5552    0.5243    0.5215       185

micro f-score: 0.5243243243243243

========== Train Epoch 43 ==========
Loss: 0.053	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.1964    0.6471    0.3014        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.6512    0.7179    0.6829        39

    accuracy                         0.4757       185
   macro avg     0.4096    0.4121    0.3713       185
weighted avg     0.4831    0.4757    0.4471       185

micro f-score: 0.4756756756756757

========== Train Epoch 44 ==========
Loss: 0.058	Accuracy: 43.24%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.2500    0.3636    0.2963        22
         hdx     0.2619    0.6471    0.3729        17
         mtx     0.1000    0.0526    0.0690        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.6316    0.6154    0.6234        39

    accuracy                         0.4324       185
   macro avg     0.3375    0.3699    0.3377       185
weighted avg     0.4333    0.4324    0.4211       185

micro f-score: 0.43243243243243246

========== Train Epoch 45 ==========
Loss: 0.046	Accuracy: 51.35%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4000    0.5161    0.4507        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.1875    0.3158    0.2353        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5135       185
   macro avg     0.5006    0.4860    0.4772       185
weighted avg     0.5723    0.5135    0.5278       185

micro f-score: 0.5135135135135135

========== Train Epoch 46 ==========
Loss: 0.043	Accuracy: 49.73%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6000    0.0968    0.1667        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.3214    0.7500    0.4500        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5161    0.8205    0.6337        39

    accuracy                         0.4973       185
   macro avg     0.4759    0.4772    0.4273       185
weighted avg     0.5281    0.4973    0.4644       185

micro f-score: 0.4972972972972973

========== Train Epoch 47 ==========
Loss: 0.042	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.5351       185
   macro avg     0.5321    0.5127    0.4975       185
weighted avg     0.5792    0.5351    0.5252       185

micro f-score: 0.5351351351351351

========== Train Epoch 48 ==========
Loss: 0.028	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.3158    0.3158    0.3158        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.5730       185
   macro avg     0.5338    0.5299    0.5255       185
weighted avg     0.6003    0.5730    0.5802       185

micro f-score: 0.572972972972973

========== Train Epoch 49 ==========
Loss: 0.020	Accuracy: 60.54%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6054       185
   macro avg     0.5565    0.5647    0.5448       185
weighted avg     0.5984    0.6054    0.5897       185

micro f-score: 0.6054054054054054

========== Train Epoch 50 ==========
Loss: 0.018	Accuracy: 62.70%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.5882    0.5882    0.5882        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6270       185
   macro avg     0.5917    0.6025    0.5858       185
weighted avg     0.6367    0.6270    0.6193       185

micro f-score: 0.6270270270270271

========== Train Epoch 51 ==========
Loss: 0.014	Accuracy: 61.08%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6108       185
   macro avg     0.5589    0.5541    0.5538       185
weighted avg     0.5957    0.6108    0.6009       185

micro f-score: 0.6108108108108108

========== Train Epoch 52 ==========
Loss: 0.016	Accuracy: 62.16%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.6216       185
   macro avg     0.5897    0.5833    0.5745       185
weighted avg     0.6356    0.6216    0.6148       185

micro f-score: 0.6216216216216216

========== Train Epoch 53 ==========
Loss: 0.014	Accuracy: 62.70%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.9143    0.7111    0.8000        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.6270       185
   macro avg     0.5900    0.6020    0.5880       185
weighted avg     0.6496    0.6270    0.6308       185

micro f-score: 0.6270270270270271

========== Train Epoch 54 ==========
Loss: 0.013	Accuracy: 62.70%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8919    0.7333    0.8049        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.6270       185
   macro avg     0.5961    0.5987    0.5916       185
weighted avg     0.6425    0.6270    0.6290       185

micro f-score: 0.6270270270270271

========== Train Epoch 55 ==========
Loss: 0.014	Accuracy: 64.32%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8750    0.7778    0.8235        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6432       185
   macro avg     0.5994    0.6087    0.5956       185
weighted avg     0.6518    0.6432    0.6399       185

micro f-score: 0.6432432432432432

========== Train Epoch 56 ==========
Loss: 0.014	Accuracy: 64.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.5882    0.5882    0.5882        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8684    0.7333    0.7952        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6432       185
   macro avg     0.6100    0.6094    0.6014       185
weighted avg     0.6527    0.6432    0.6389       185

micro f-score: 0.6432432432432432

========== Train Epoch 57 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.9677    0.6667    0.7895        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6108       185
   macro avg     0.5870    0.5957    0.5751       185
weighted avg     0.6347    0.6108    0.6037       185

micro f-score: 0.6108108108108108

========== Train Epoch 58 ==========
Loss: 0.012	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3617    0.5484    0.4359        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5622       185
   macro avg     0.5462    0.5271    0.5073       185
weighted avg     0.5911    0.5622    0.5522       185

micro f-score: 0.5621621621621622

========== Train Epoch 59 ==========
Loss: 0.014	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.4839    0.6818    0.5660        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.9667    0.6444    0.7733        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5568       185
   macro avg     0.5081    0.5054    0.4864       185
weighted avg     0.5762    0.5568    0.5432       185

micro f-score: 0.5567567567567567

========== Train Epoch 60 ==========
Loss: 0.013	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.5000    0.7273    0.5926        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.9630    0.5778    0.7222        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5676       185
   macro avg     0.5314    0.5332    0.5169       185
weighted avg     0.5971    0.5676    0.5616       185

micro f-score: 0.5675675675675675

========== Train Epoch 61 ==========
Loss: 0.014	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4054    0.4839    0.4412        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5892       185
   macro avg     0.5421    0.5301    0.5303       185
weighted avg     0.5963    0.5892    0.5881       185

micro f-score: 0.5891891891891892

========== Train Epoch 62 ==========
Loss: 0.012	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.5625    0.5294    0.5455        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5730       185
   macro avg     0.5458    0.5526    0.5415       185
weighted avg     0.5970    0.5730    0.5754       185

micro f-score: 0.572972972972973

========== Train Epoch 63 ==========
Loss: 0.012	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5946       185
   macro avg     0.5605    0.5789    0.5545       185
weighted avg     0.6120    0.5946    0.5877       185

micro f-score: 0.5945945945945946

========== Train Epoch 64 ==========
Loss: 0.008	Accuracy: 58.92%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8500    0.7556    0.8000        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5892       185
   macro avg     0.5284    0.5393    0.5258       185
weighted avg     0.5838    0.5892    0.5779       185

micro f-score: 0.5891891891891892

Finished training!!!

Min Loss = 0.008 in epoch 63;
Max Accuracy = 64.32% in epoch 54;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.2918918918918919, 0.31351351351351353, 0.3891891891891892, 0.40540540540540543, 0.41621621621621624, 0.3567567567567568, 0.4594594594594595, 0.43783783783783786, 0.43243243243243246, 0.5351351351351351, 0.4540540540540541, 0.4486486486486487, 0.34054054054054056, 0.4918918918918919, 0.4648648648648649, 0.41081081081081083, 0.32972972972972975, 0.4594594594594595, 0.3837837837837838, 0.5081081081081081, 0.6108108108108108, 0.4702702702702703, 0.5567567567567567, 0.5405405405405406, 0.5135135135135135, 0.5351351351351351, 0.42702702702702705, 0.4864864864864865, 0.4702702702702703, 0.4594594594594595, 0.4810810810810811, 0.4648648648648649, 0.4810810810810811, 0.4972972972972973, 0.4972972972972973, 0.518918918918919, 0.5459459459459459, 0.5675675675675675, 0.43783783783783786, 0.3945945945945946, 0.4702702702702703, 0.5243243243243243, 0.4756756756756757, 0.43243243243243246, 0.5135135135135135, 0.4972972972972973, 0.5351351351351351, 0.572972972972973, 0.6054054054054054, 0.6270270270270271, 0.6108108108108108, 0.6216216216216216, 0.6270270270270271, 0.6270270270270271, 0.6432432432432432, 0.6432432432432432, 0.6108108108108108, 0.5621621621621622, 0.5567567567567567, 0.5675675675675675, 0.5891891891891892, 0.572972972972973, 0.5945945945945946, 0.5891891891891892]
