dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.870	Accuracy: 31.35%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.1538    0.1290    0.1404        31
         cwx     0.2609    0.2727    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4400    0.4889    0.4632        45
         zxx     0.3059    0.6667    0.4194        39

    accuracy                         0.3135       185
   macro avg     0.1658    0.2225    0.1842       185
weighted avg     0.2283    0.3135    0.2563       185

micro f-score: 0.31351351351351353

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.656	Accuracy: 35.14%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.1957    0.4091    0.2647        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.4750    0.4222    0.4471        45
         zxx     0.3846    0.7692    0.5128        39

    accuracy                         0.3514       185
   macro avg     0.3337    0.2749    0.2473       185
weighted avg     0.3619    0.3514    0.3069       185

micro f-score: 0.35135135135135137

========== Train Epoch 3 ==========
Loss: 1.501	Accuracy: 38.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.2545    0.4516    0.3256        31
         cwx     0.2000    0.0909    0.1250        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.5000    0.5111    0.5055        45
         zxx     0.4615    0.6154    0.5275        39

    accuracy                         0.3892       185
   macro avg     0.4241    0.3254    0.3202       185
weighted avg     0.4268    0.3892    0.3676       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
Loss: 1.361	Accuracy: 38.38%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3438    0.3548    0.3492        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.2273    0.2941    0.2564        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.4706    0.5333    0.5000        45
         zxx     0.4583    0.5641    0.5057        39

    accuracy                         0.3838       185
   macro avg     0.3452    0.3218    0.3223       185
weighted avg     0.3732    0.3838    0.3713       185

micro f-score: 0.3837837837837838

========== Train Epoch 5 ==========
Loss: 1.210	Accuracy: 39.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.2812    0.4091    0.3333        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.2143    0.2500    0.2308        12
         qtx     0.4096    0.7556    0.5312        45
         zxx     0.8571    0.3077    0.4528        39

    accuracy                         0.3946       185
   macro avg     0.4505    0.3536    0.3359       185
weighted avg     0.5156    0.3946    0.3699       185

micro f-score: 0.3945945945945946

========== Train Epoch 6 ==========
Loss: 1.031	Accuracy: 38.38%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4054    0.4839    0.4412        31
         cwx     0.2500    0.1364    0.1765        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.1628    0.3684    0.2258        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.7647    0.2889    0.4194        45
         zxx     0.4792    0.5897    0.5287        39

    accuracy                         0.3838       185
   macro avg     0.3958    0.3718    0.3566       185
weighted avg     0.4564    0.3838    0.3847       185

micro f-score: 0.3837837837837838

========== Train Epoch 7 ==========
Loss: 0.822	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3409    0.9677    0.5042        31
         cwx     0.3548    0.5000    0.4151        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.7619    0.3556    0.4848        45
         zxx     0.7692    0.5128    0.6154        39

    accuracy                         0.4486       185
   macro avg     0.4155    0.3964    0.3647       185
weighted avg     0.4979    0.4486    0.4212       185

micro f-score: 0.4486486486486486

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.615	Accuracy: 42.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2000    0.3529    0.2553        17
         mtx     0.2414    0.3684    0.2917        19
         nqx     0.2381    0.4167    0.3030        12
         qtx     0.5312    0.7556    0.6239        45
         zxx     0.7391    0.4359    0.5484        39

    accuracy                         0.4270       185
   macro avg     0.4881    0.3921    0.3682       185
weighted avg     0.5667    0.4270    0.4150       185

micro f-score: 0.427027027027027

========== Train Epoch 9 ==========
Loss: 0.404	Accuracy: 41.62%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.2000    0.2941    0.2381        17
         mtx     0.2553    0.6316    0.3636        19
         nqx     0.2500    0.6667    0.3636        12
         qtx     1.0000    0.2667    0.4211        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.4162       185
   macro avg     0.4902    0.4489    0.3966       185
weighted avg     0.6046    0.4162    0.4242       185

micro f-score: 0.41621621621621624

========== Train Epoch 10 ==========
Loss: 0.319	Accuracy: 40.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3385    0.7097    0.4583        31
         cwx     0.2973    0.5000    0.3729        22
         hdx     0.1842    0.4118    0.2545        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.7273    0.3556    0.4776        45
         zxx     0.8095    0.4359    0.5667        39

    accuracy                         0.4054       185
   macro avg     0.4795    0.3597    0.3315       185
weighted avg     0.5593    0.4054    0.3997       185

micro f-score: 0.40540540540540543

========== Train Epoch 11 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.246	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.8000    0.1290    0.2222        31
         cwx     0.3043    0.9545    0.4615        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.6512    0.7179    0.6829        39

    accuracy                         0.5081       185
   macro avg     0.5490    0.4930    0.4473       185
weighted avg     0.6234    0.5081    0.4903       185

micro f-score: 0.5081081081081081

========== Train Epoch 12 ==========
Loss: 0.145	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.2581    0.6667    0.3721        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.5189       185
   macro avg     0.4818    0.4970    0.4713       185
weighted avg     0.5518    0.5189    0.5236       185

micro f-score: 0.518918918918919

========== Train Epoch 13 ==========
Loss: 0.117	Accuracy: 50.27%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.3529    0.5455    0.4286        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.4923    0.8205    0.6154        39

    accuracy                         0.5027       185
   macro avg     0.5041    0.4425    0.4200       185
weighted avg     0.5370    0.5027    0.4619       185

micro f-score: 0.5027027027027027

========== Train Epoch 14 ==========
Loss: 0.098	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3833    0.7419    0.5055        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.8462    0.5641    0.6769        39

    accuracy                         0.5676       185
   macro avg     0.5756    0.5385    0.5385       185
weighted avg     0.6208    0.5676    0.5737       185

micro f-score: 0.5675675675675675

========== Train Epoch 15 ==========
Loss: 0.076	Accuracy: 54.05%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.3704    0.5263    0.4348        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5405       185
   macro avg     0.5199    0.4923    0.4821       185
weighted avg     0.5466    0.5405    0.5254       185

micro f-score: 0.5405405405405406

========== Train Epoch 16 ==========
Loss: 0.074	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     1.0000    0.2632    0.4167        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.4648    0.8462    0.6000        39

    accuracy                         0.5622       185
   macro avg     0.6313    0.5227    0.5222       185
weighted avg     0.6294    0.5622    0.5478       185

micro f-score: 0.5621621621621622

========== Train Epoch 17 ==========
Loss: 0.057	Accuracy: 56.22%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3500    0.7368    0.4746        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5172    0.7692    0.6186        39

    accuracy                         0.5622       185
   macro avg     0.5905    0.5260    0.5248       185
weighted avg     0.5973    0.5622    0.5531       185

micro f-score: 0.5621621621621622

========== Train Epoch 18 ==========
Loss: 0.060	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.3636    0.7273    0.4848        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     1.0000    0.5000    0.6667        12
         qtx     0.6154    0.7111    0.6598        45
         zxx     0.6923    0.6923    0.6923        39

    accuracy                         0.5459       185
   macro avg     0.6047    0.4919    0.4976       185
weighted avg     0.5893    0.5459    0.5330       185

micro f-score: 0.5459459459459459

========== Train Epoch 19 ==========
Loss: 0.044	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2766    0.8387    0.4160        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.4757       185
   macro avg     0.5234    0.3912    0.3991       185
weighted avg     0.5707    0.4757    0.4712       185

micro f-score: 0.4756756756756757

========== Train Epoch 20 ==========
Loss: 0.037	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.5645    0.7778    0.6542        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5838       185
   macro avg     0.5764    0.5268    0.5363       185
weighted avg     0.5836    0.5838    0.5664       185

micro f-score: 0.5837837837837838

========== Train Epoch 21 ==========
Loss: 0.030	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4419    0.6129    0.5135        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5892       185
   macro avg     0.5701    0.5465    0.5432       185
weighted avg     0.6008    0.5892    0.5843       185

micro f-score: 0.5891891891891892

========== Train Epoch 22 ==========
Loss: 0.035	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5730       185
   macro avg     0.5423    0.5287    0.5308       185
weighted avg     0.5719    0.5730    0.5680       185

micro f-score: 0.572972972972973

========== Train Epoch 23 ==========
Loss: 0.033	Accuracy: 53.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3404    0.5161    0.4103        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.3333    0.4211    0.3721        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.5351       185
   macro avg     0.5617    0.5224    0.5327       185
weighted avg     0.5765    0.5351    0.5451       185

micro f-score: 0.5351351351351351

========== Train Epoch 24 ==========
Loss: 0.029	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3600    0.4737    0.4091        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.5676       185
   macro avg     0.5407    0.5179    0.5226       185
weighted avg     0.5744    0.5676    0.5661       185

micro f-score: 0.5675675675675675

========== Train Epoch 25 ==========
Loss: 0.035	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4545    0.6452    0.5333        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.5892       185
   macro avg     0.5668    0.5439    0.5349       185
weighted avg     0.6060    0.5892    0.5806       185

micro f-score: 0.5891891891891892

========== Train Epoch 26 ==========
Loss: 0.025	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4737    0.4737    0.4737        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.5686    0.7436    0.6444        39

    accuracy                         0.5784       185
   macro avg     0.5764    0.5521    0.5561       185
weighted avg     0.5788    0.5784    0.5694       185

micro f-score: 0.5783783783783784

========== Train Epoch 27 ==========
Loss: 0.021	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3529    0.5806    0.4390        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.5514       185
   macro avg     0.5589    0.5173    0.5001       185
weighted avg     0.6038    0.5514    0.5482       185

micro f-score: 0.5513513513513514

========== Train Epoch 28 ==========
Loss: 0.024	Accuracy: 57.84%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3617    0.5484    0.4359        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5784       185
   macro avg     0.5831    0.5492    0.5596       185
weighted avg     0.6052    0.5784    0.5856       185

micro f-score: 0.5783783783783784

========== Train Epoch 29 ==========
Loss: 0.026	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.2500    0.5294    0.3396        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.5351       185
   macro avg     0.5254    0.5093    0.4991       185
weighted avg     0.5716    0.5351    0.5402       185

micro f-score: 0.5351351351351351

========== Train Epoch 30 ==========
Loss: 0.021	Accuracy: 56.76%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3784    0.4516    0.4118        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.5676       185
   macro avg     0.5347    0.5313    0.5252       185
weighted avg     0.5656    0.5676    0.5614       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.018	Accuracy: 57.30%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.6154    0.4211    0.5000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5730       185
   macro avg     0.5607    0.5423    0.5381       185
weighted avg     0.5814    0.5730    0.5641       185

micro f-score: 0.572972972972973

========== Train Epoch 32 ==========
Loss: 0.018	Accuracy: 55.68%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.3684    0.4516    0.4058        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6182    0.7556    0.6800        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5568       185
   macro avg     0.5454    0.5046    0.5114       185
weighted avg     0.5552    0.5568    0.5447       185

micro f-score: 0.5567567567567567

========== Train Epoch 33 ==========
Loss: 0.021	Accuracy: 61.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.6162       185
   macro avg     0.5956    0.5981    0.5848       185
weighted avg     0.6381    0.6162    0.6166       185

micro f-score: 0.6162162162162163

========== Train Epoch 34 ==========
Loss: 0.019	Accuracy: 57.30%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4318    0.6129    0.5067        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5730       185
   macro avg     0.5284    0.5253    0.5117       185
weighted avg     0.5798    0.5730    0.5646       185

micro f-score: 0.572972972972973

========== Train Epoch 35 ==========
Loss: 0.023	Accuracy: 50.27%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2200    0.9167    0.3548        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5027       185
   macro avg     0.5402    0.4873    0.4275       185
weighted avg     0.5971    0.5027    0.4851       185

micro f-score: 0.5027027027027027

========== Train Epoch 36 ==========
Loss: 0.021	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3273    0.5806    0.4186        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5952    0.6410    0.6173        39

    accuracy                         0.5405       185
   macro avg     0.5617    0.5038    0.5128       185
weighted avg     0.5797    0.5405    0.5425       185

micro f-score: 0.5405405405405406

========== Train Epoch 37 ==========
Loss: 0.017	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5514       185
   macro avg     0.5422    0.5123    0.5205       185
weighted avg     0.5539    0.5514    0.5475       185

micro f-score: 0.5513513513513514

========== Train Epoch 38 ==========
Loss: 0.021	Accuracy: 56.76%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3585    0.6129    0.4524        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5676       185
   macro avg     0.5622    0.5124    0.5264       185
weighted avg     0.5932    0.5676    0.5704       185

micro f-score: 0.5675675675675675

========== Train Epoch 39 ==========
Loss: 0.022	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2424    0.4706    0.3200        17
         mtx     0.2683    0.5789    0.3667        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6304    0.7436    0.6824        39

    accuracy                         0.4919       185
   macro avg     0.5448    0.4580    0.4517       185
weighted avg     0.5716    0.4919    0.4956       185

micro f-score: 0.4918918918918919

========== Train Epoch 40 ==========
Loss: 0.023	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.7742    0.4660        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.3571    0.5263    0.4255        19
         nqx     0.4783    0.9167    0.6286        12
         qtx     0.9231    0.5333    0.6761        45
         zxx     0.8571    0.6154    0.7164        39

    accuracy                         0.5297       185
   macro avg     0.5999    0.5152    0.4736       185
weighted avg     0.6707    0.5297    0.5234       185

micro f-score: 0.5297297297297298

========== Train Epoch 41 ==========
Loss: 0.031	Accuracy: 49.73%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4615    0.1935    0.2727        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.2286    0.4211    0.2963        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.4973       185
   macro avg     0.5056    0.4801    0.4454       185
weighted avg     0.5456    0.4973    0.4823       185

micro f-score: 0.4972972972972973

========== Train Epoch 42 ==========
Loss: 0.108	Accuracy: 29.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3488    0.4839    0.4054        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.1325    0.6471    0.2200        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2564    0.8333    0.3922        12
         qtx     0.6667    0.0889    0.1569        45
         zxx     1.0000    0.3077    0.4706        39

    accuracy                         0.2919       185
   macro avg     0.6292    0.3513    0.2617       185
weighted avg     0.6819    0.2919    0.2716       185

micro f-score: 0.2918918918918919

========== Train Epoch 43 ==========
Loss: 0.334	Accuracy: 29.73%	Cost 47s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     1.0000    0.1556    0.2692        45
         zxx     0.2453    1.0000    0.3939        39

    accuracy                         0.2973       185
   macro avg     0.6600    0.2570    0.1951       185
weighted avg     0.6814    0.2973    0.2073       185

micro f-score: 0.2972972972972973

========== Train Epoch 44 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.216	Accuracy: 40.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2222    0.8182    0.3495        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3810    0.4211    0.4000        19
         nqx     0.3043    0.5833    0.4000        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     1.0000    0.3846    0.5556        39

    accuracy                         0.4000       185
   macro avg     0.5004    0.4031    0.3416       185
weighted avg     0.5328    0.4000    0.3757       185

micro f-score: 0.4000000000000001

========== Train Epoch 45 ==========
Loss: 0.131	Accuracy: 54.59%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3590    0.4516    0.4000        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.2750    0.6471    0.3860        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.5459       185
   macro avg     0.6374    0.5170    0.5089       185
weighted avg     0.6405    0.5459    0.5437       185

micro f-score: 0.5459459459459459

========== Train Epoch 46 ==========
Loss: 0.065	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.2558    0.5789    0.3548        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.5351       185
   macro avg     0.5645    0.5175    0.5152       185
weighted avg     0.5780    0.5351    0.5374       185

micro f-score: 0.5351351351351351

========== Train Epoch 47 ==========
Loss: 0.035	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4103    0.5161    0.4571        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7576    0.6410    0.6944        39

    accuracy                         0.5459       185
   macro avg     0.5337    0.4824    0.4828       185
weighted avg     0.5688    0.5459    0.5437       185

micro f-score: 0.5459459459459459

========== Train Epoch 48 ==========
Loss: 0.024	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3542    0.5484    0.4304        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.8400    0.4667    0.6000        45
         zxx     0.6000    0.6923    0.6429        39

    accuracy                         0.5459       185
   macro avg     0.5634    0.5529    0.5400       185
weighted avg     0.5864    0.5459    0.5444       185

micro f-score: 0.5459459459459459

========== Train Epoch 49 ==========
Loss: 0.022	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5892       185
   macro avg     0.5644    0.5695    0.5574       185
weighted avg     0.6093    0.5892    0.5867       185

micro f-score: 0.5891891891891892

========== Train Epoch 50 ==========
Loss: 0.019	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3415    0.4516    0.3889        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.5730       185
   macro avg     0.5296    0.5417    0.5249       185
weighted avg     0.5676    0.5730    0.5617       185

micro f-score: 0.572972972972973

========== Train Epoch 51 ==========
Loss: 0.019	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3846    0.4839    0.4286        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5676       185
   macro avg     0.5560    0.5130    0.5145       185
weighted avg     0.5880    0.5676    0.5571       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 0.018	Accuracy: 63.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7255    0.8222    0.7708        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.6324       185
   macro avg     0.5960    0.5957    0.5829       185
weighted avg     0.6209    0.6324    0.6132       185

micro f-score: 0.6324324324324324

========== Train Epoch 53 ==========
Loss: 0.017	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.6000       185
   macro avg     0.5761    0.5734    0.5651       185
weighted avg     0.5869    0.6000    0.5861       185

micro f-score: 0.6

========== Train Epoch 54 ==========
Loss: 0.016	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3158    0.3158    0.3158        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5622       185
   macro avg     0.5362    0.5295    0.5292       185
weighted avg     0.5664    0.5622    0.5598       185

micro f-score: 0.5621621621621622

========== Train Epoch 55 ==========
Loss: 0.018	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8276    0.5333    0.6486        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.5838       185
   macro avg     0.5661    0.5796    0.5642       185
weighted avg     0.6073    0.5838    0.5849       185

micro f-score: 0.5837837837837838

========== Train Epoch 56 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.6108       185
   macro avg     0.5825    0.6038    0.5873       185
weighted avg     0.6087    0.6108    0.6055       185

micro f-score: 0.6108108108108108

========== Train Epoch 57 ==========
Loss: 0.018	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3611    0.4194    0.3881        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5676       185
   macro avg     0.5288    0.5549    0.5295       185
weighted avg     0.5644    0.5676    0.5582       185

micro f-score: 0.5675675675675675

========== Train Epoch 58 ==========
Loss: 0.016	Accuracy: 61.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6108       185
   macro avg     0.5921    0.5934    0.5842       185
weighted avg     0.6057    0.6108    0.5994       185

micro f-score: 0.6108108108108108

========== Train Epoch 59 ==========
Loss: 0.014	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3810    0.5161    0.4384        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7297    0.6923    0.7105        39

    accuracy                         0.6054       185
   macro avg     0.5913    0.5958    0.5772       185
weighted avg     0.6230    0.6054    0.6031       185

micro f-score: 0.6054054054054054

========== Train Epoch 60 ==========
Loss: 0.013	Accuracy: 57.30%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.7273    0.6154    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5423    0.5584    0.5412       185
weighted avg     0.5778    0.5730    0.5688       185

micro f-score: 0.572972972972973

========== Train Epoch 61 ==========
Loss: 0.016	Accuracy: 60.54%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.6054       185
   macro avg     0.5697    0.5808    0.5730       185
weighted avg     0.5985    0.6054    0.6004       185

micro f-score: 0.6054054054054054

========== Train Epoch 62 ==========
Loss: 0.018	Accuracy: 62.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7059    0.8000    0.7500        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6216       185
   macro avg     0.5894    0.5833    0.5803       185
weighted avg     0.6123    0.6216    0.6127       185

micro f-score: 0.6216216216216216

========== Train Epoch 63 ==========
Loss: 0.013	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3500    0.4516    0.3944        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.7742    0.6154    0.6857        39

    accuracy                         0.5622       185
   macro avg     0.5442    0.5477    0.5323       185
weighted avg     0.5868    0.5622    0.5652       185

micro f-score: 0.5621621621621622

========== Train Epoch 64 ==========
Loss: 0.016	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3462    0.5806    0.4337        31
         cwx     0.6522    0.6818    0.6667        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.5784       185
   macro avg     0.5745    0.5606    0.5500       185
weighted avg     0.5963    0.5784    0.5720       185

micro f-score: 0.5783783783783784

Finished training!!!

Min Loss = 0.012 in epoch 55;
Max Accuracy = 63.24% in epoch 51;
Total Cost 49 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.31351351351351353, 0.35135135135135137, 0.3891891891891892, 0.3837837837837838, 0.3945945945945946, 0.3837837837837838, 0.4486486486486487, 0.42702702702702705, 0.41621621621621624, 0.40540540540540543, 0.5081081081081081, 0.518918918918919, 0.5027027027027027, 0.5675675675675675, 0.5405405405405406, 0.5621621621621622, 0.5621621621621622, 0.5459459459459459, 0.4756756756756757, 0.5837837837837838, 0.5891891891891892, 0.572972972972973, 0.5351351351351351, 0.5675675675675675, 0.5891891891891892, 0.5783783783783784, 0.5513513513513514, 0.5783783783783784, 0.5351351351351351, 0.5675675675675675, 0.572972972972973, 0.5567567567567567, 0.6162162162162163, 0.572972972972973, 0.5027027027027027, 0.5405405405405406, 0.5513513513513514, 0.5675675675675675, 0.4918918918918919, 0.5297297297297298, 0.4972972972972973, 0.2918918918918919, 0.2972972972972973, 0.4, 0.5459459459459459, 0.5351351351351351, 0.5459459459459459, 0.5459459459459459, 0.5891891891891892, 0.572972972972973, 0.5675675675675675, 0.6324324324324324, 0.6, 0.5621621621621622, 0.5837837837837838, 0.6108108108108108, 0.5675675675675675, 0.6108108108108108, 0.6054054054054054, 0.572972972972973, 0.6054054054054054, 0.6216216216216216, 0.5621621621621622, 0.5783783783783784]
