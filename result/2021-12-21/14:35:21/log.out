dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: cbam resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.845	Accuracy: 31.89%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2500    0.0455    0.0769        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.3766    0.6444    0.4754        45
         zxx     0.2604    0.6410    0.3704        39

    accuracy                         0.3189       185
   macro avg     0.1981    0.2378    0.1890       185
weighted avg     0.2087    0.3189    0.2288       185

micro f-score: 0.31891891891891894

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.633	Accuracy: 36.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.2800    0.6774    0.3962        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.3519    0.4872    0.4086        39

    accuracy                         0.3676       185
   macro avg     0.2374    0.2902    0.2491       185
weighted avg     0.2923    0.3676    0.3130       185

micro f-score: 0.3675675675675676

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.474	Accuracy: 38.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.2500    0.1364    0.1765        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.8182    0.4000    0.5373        45
         zxx     0.3217    0.9487    0.4805        39

    accuracy                         0.3838       185
   macro avg     0.3837    0.3007    0.2849       185
weighted avg     0.4392    0.3838    0.3435       185

micro f-score: 0.3837837837837838

========== Train Epoch 4 ==========
Loss: 1.321	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3125    0.3226    0.3175        31
         cwx     0.2623    0.7273    0.3855        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2692    0.3684    0.3111        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.9474    0.4000    0.5625        45
         zxx     0.8182    0.4615    0.5902        39

    accuracy                         0.4324       185
   macro avg     0.5207    0.4426    0.4237       185
weighted avg     0.5993    0.4324    0.4535       185

micro f-score: 0.43243243243243246

========== Train Epoch 5 ==========
Loss: 1.145	Accuracy: 48.65%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3913    0.5806    0.4675        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.4865       185
   macro avg     0.3312    0.4112    0.3498       185
weighted avg     0.3933    0.4865    0.4199       185

micro f-score: 0.4864864864864865

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.995	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4130    0.6129    0.4935        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.4821    0.6000    0.5347        45
         zxx     0.3934    0.6154    0.4800        39

    accuracy                         0.4324       185
   macro avg     0.4365    0.3463    0.3407       185
weighted avg     0.4406    0.4324    0.3950       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 0.753	Accuracy: 51.89%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.4516    0.9333    0.6087        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5189       185
   macro avg     0.5210    0.3975    0.3910       185
weighted avg     0.5259    0.5189    0.4613       185

micro f-score: 0.518918918918919

========== Train Epoch 8 ==========
Loss: 0.534	Accuracy: 54.59%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.1765    0.1765    0.1765        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.6222    0.6222    0.6222        45
         zxx     0.7647    0.6667    0.7123        39

    accuracy                         0.5459       185
   macro avg     0.5071    0.5295    0.4974       185
weighted avg     0.5695    0.5459    0.5467       185

micro f-score: 0.5459459459459459

========== Train Epoch 9 ==========
Loss: 0.361	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.1935    0.2791        31
         cwx     0.3065    0.8636    0.4524        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.1724    0.2632    0.2083        19
         nqx     0.3704    0.8333    0.5128        12
         qtx     1.0000    0.3778    0.5484        45
         zxx     0.9130    0.5385    0.6774        39

    accuracy                         0.4486       185
   macro avg     0.5137    0.4806    0.4273       185
weighted avg     0.6283    0.4486    0.4601       185

micro f-score: 0.4486486486486486

========== Train Epoch 10 ==========
Loss: 0.219	Accuracy: 51.35%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2326    0.5882    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3333    0.8333    0.4762        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.5135       185
   macro avg     0.4159    0.4902    0.4084       185
weighted avg     0.4681    0.5135    0.4615       185

micro f-score: 0.5135135135135135

========== Train Epoch 11 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.152	Accuracy: 37.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.2676    0.8636    0.4086        22
         hdx     0.1579    0.1765    0.1667        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2703    0.8333    0.4082        12
         qtx     0.8889    0.1778    0.2963        45
         zxx     0.7826    0.4615    0.5806        39

    accuracy                         0.3730       185
   macro avg     0.4501    0.4155    0.3390       185
weighted avg     0.5547    0.3730    0.3604       185

micro f-score: 0.37297297297297294

========== Train Epoch 12 ==========
Loss: 0.087	Accuracy: 50.81%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.5000    0.7273    0.5926        22
         hdx     0.1875    0.3529    0.2449        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.6957    0.3556    0.4706        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.5081       185
   macro avg     0.5269    0.4719    0.4648       185
weighted avg     0.5524    0.5081    0.4995       185

micro f-score: 0.5081081081081081

========== Train Epoch 13 ==========
Loss: 0.065	Accuracy: 55.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.2903    0.3673        31
         cwx     0.3902    0.7273    0.5079        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2222    0.4211    0.2909        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.9032    0.7179    0.8000        39

    accuracy                         0.5568       185
   macro avg     0.5562    0.5322    0.5230       185
weighted avg     0.6206    0.5568    0.5689       185

micro f-score: 0.5567567567567567

========== Train Epoch 14 ==========
Loss: 0.057	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7000    0.7778    0.7368        45
         zxx     0.8182    0.6923    0.7500        39

    accuracy                         0.6054       185
   macro avg     0.5597    0.5630    0.5435       185
weighted avg     0.6077    0.6054    0.5932       185

micro f-score: 0.6054054054054054

========== Train Epoch 15 ==========
Loss: 0.044	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4043    0.6129    0.4872        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5892       185
   macro avg     0.5713    0.5623    0.5537       185
weighted avg     0.6108    0.5892    0.5848       185

micro f-score: 0.5891891891891892

========== Train Epoch 16 ==========
Loss: 0.033	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6140    0.8974    0.7292        39

    accuracy                         0.6054       185
   macro avg     0.5670    0.5795    0.5620       185
weighted avg     0.6105    0.6054    0.5940       185

micro f-score: 0.6054054054054054

========== Train Epoch 17 ==========
Loss: 0.038	Accuracy: 54.59%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4043    0.6129    0.4872        31
         cwx     0.4615    0.8182    0.5902        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.9375    0.3333    0.4918        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.5459       185
   macro avg     0.5405    0.5393    0.5045       185
weighted avg     0.6051    0.5459    0.5278       185

micro f-score: 0.5459459459459459

========== Train Epoch 18 ==========
Loss: 0.038	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4634    0.6129    0.5278        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.5833    0.7778    0.6667        45
         zxx     0.7879    0.6667    0.7222        39

    accuracy                         0.5784       185
   macro avg     0.5774    0.5282    0.5335       185
weighted avg     0.5965    0.5784    0.5700       185

micro f-score: 0.5783783783783784

========== Train Epoch 19 ==========
Loss: 0.031	Accuracy: 57.30%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.6129    0.5507        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.2500    0.4706    0.3265        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5730       185
   macro avg     0.5532    0.5077    0.5093       185
weighted avg     0.6063    0.5730    0.5711       185

micro f-score: 0.572972972972973

========== Train Epoch 20 ==========
Loss: 0.038	Accuracy: 45.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4615    0.1935    0.2727        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2564    0.8333    0.3922        12
         qtx     0.4302    0.8222    0.5649        45
         zxx     0.7568    0.7179    0.7368        39

    accuracy                         0.4541       185
   macro avg     0.4507    0.3872    0.3172       185
weighted avg     0.5027    0.4541    0.3926       185

micro f-score: 0.4540540540540541

========== Train Epoch 21 ==========
Loss: 0.093	Accuracy: 40.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3651    0.7419    0.4894        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2500    0.6471    0.3607        17
         mtx     0.1538    0.2105    0.1778        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     1.0000    0.2889    0.4483        45
         zxx     0.8667    0.3333    0.4815        39

    accuracy                         0.4054       185
   macro avg     0.5054    0.4105    0.3865       185
weighted avg     0.6135    0.4054    0.4141       185

micro f-score: 0.40540540540540543

========== Train Epoch 22 ==========
Loss: 0.070	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.2245    0.6471    0.3333        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.4474    0.7556    0.5620        45
         zxx     0.8462    0.5641    0.6769        39

    accuracy                         0.4649       185
   macro avg     0.4954    0.4301    0.4103       185
weighted avg     0.4792    0.4649    0.4331       185

micro f-score: 0.4648648648648649

========== Train Epoch 23 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.053	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.2727    0.5294    0.3600        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.5568       185
   macro avg     0.4899    0.4897    0.4704       185
weighted avg     0.5416    0.5568    0.5335       185

micro f-score: 0.5567567567567567

========== Train Epoch 24 ==========
Loss: 0.038	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4423    0.7419    0.5542        31
         cwx     0.3947    0.6818    0.5000        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     1.0000    0.5897    0.7419        39

    accuracy                         0.5514       185
   macro avg     0.5474    0.5391    0.4875       185
weighted avg     0.6473    0.5514    0.5494       185

micro f-score: 0.5513513513513514

========== Train Epoch 25 ==========
Loss: 0.034	Accuracy: 44.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.3396    0.8182    0.4800        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.2340    0.9167    0.3729        12
         qtx     0.8462    0.2444    0.3793        45
         zxx     0.8485    0.7179    0.7778        39

    accuracy                         0.4486       185
   macro avg     0.4770    0.4754    0.3991       185
weighted avg     0.5836    0.4486    0.4401       185

micro f-score: 0.4486486486486486

========== Train Epoch 26 ==========
Loss: 0.027	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2414    0.3684    0.2917        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.8611    0.7949    0.8267        39

    accuracy                         0.6108       185
   macro avg     0.5836    0.5996    0.5779       185
weighted avg     0.6556    0.6108    0.6203       185

micro f-score: 0.6108108108108108

========== Train Epoch 27 ==========
Loss: 0.020	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5294    0.8182    0.6429        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.6270       185
   macro avg     0.5526    0.5873    0.5562       185
weighted avg     0.6209    0.6270    0.6114       185

micro f-score: 0.6270270270270271

========== Train Epoch 28 ==========
Loss: 0.025	Accuracy: 56.22%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.4487    0.8974    0.5983        39

    accuracy                         0.5622       185
   macro avg     0.6097    0.5115    0.5255       185
weighted avg     0.6278    0.5622    0.5569       185

micro f-score: 0.5621621621621622

========== Train Epoch 29 ==========
Loss: 0.020	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6054       185
   macro avg     0.5572    0.5699    0.5591       185
weighted avg     0.6160    0.6054    0.6068       185

micro f-score: 0.6054054054054054

========== Train Epoch 30 ==========
Loss: 0.019	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6270       185
   macro avg     0.5648    0.5858    0.5659       185
weighted avg     0.6266    0.6270    0.6191       185

micro f-score: 0.6270270270270271

========== Train Epoch 31 ==========
Loss: 0.022	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.5211    0.9487    0.6727        39

    accuracy                         0.5838       185
   macro avg     0.5788    0.5384    0.5376       185
weighted avg     0.5956    0.5838    0.5642       185

micro f-score: 0.5837837837837838

========== Train Epoch 32 ==========
Loss: 0.022	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6216       185
   macro avg     0.5964    0.5763    0.5661       185
weighted avg     0.6155    0.6216    0.6035       185

micro f-score: 0.6216216216216216

========== Train Epoch 33 ==========
Loss: 0.015	Accuracy: 57.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.8889    0.3636    0.5161        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.5538    0.8000    0.6545        45
         zxx     0.5556    0.8974    0.6863        39

    accuracy                         0.5730       185
   macro avg     0.6148    0.5026    0.5119       185
weighted avg     0.6011    0.5730    0.5432       185

micro f-score: 0.572972972972973

========== Train Epoch 34 ==========
Loss: 0.015	Accuracy: 56.22%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.1935    0.7059    0.3038        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.5622       185
   macro avg     0.6451    0.5354    0.5384       185
weighted avg     0.6996    0.5622    0.5891       185

micro f-score: 0.5621621621621622

========== Train Epoch 35 ==========
Loss: 0.019	Accuracy: 42.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     1.0000    0.1290    0.2286        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2000    0.3158    0.2449        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.3750    0.8667    0.5235        45
         zxx     0.5833    0.5385    0.5600        39

    accuracy                         0.4216       185
   macro avg     0.6512    0.3417    0.3436       185
weighted avg     0.6228    0.4216    0.3778       185

micro f-score: 0.42162162162162165

========== Train Epoch 36 ==========
Loss: 0.024	Accuracy: 54.05%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.3958    0.8636    0.5429        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.9545    0.4667    0.6269        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5405       185
   macro avg     0.5262    0.5251    0.4907       185
weighted avg     0.5925    0.5405    0.5276       185

micro f-score: 0.5405405405405406

========== Train Epoch 37 ==========
Loss: 0.025	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3824    0.8387    0.5253        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5676       185
   macro avg     0.5534    0.5091    0.4876       185
weighted avg     0.6101    0.5676    0.5484       185

micro f-score: 0.5675675675675675

========== Train Epoch 38 ==========
Loss: 0.031	Accuracy: 43.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4286    0.1935    0.2667        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.1852    0.5882    0.2817        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.7419    0.5111    0.6053        45
         zxx     0.4384    0.8205    0.5714        39

    accuracy                         0.4324       185
   macro avg     0.4706    0.3820    0.3609       185
weighted avg     0.5041    0.4324    0.4096       185

micro f-score: 0.43243243243243246

========== Train Epoch 39 ==========
Loss: 0.036	Accuracy: 37.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2632    0.6818    0.3797        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.1228    0.3684    0.1842        19
         nqx     0.3200    0.6667    0.4324        12
         qtx     0.9000    0.4000    0.5538        45
         zxx     0.9048    0.4872    0.6333        39

    accuracy                         0.3784       185
   macro avg     0.4658    0.3972    0.3528       185
weighted avg     0.5432    0.3784    0.3866       185

micro f-score: 0.37837837837837834

========== Train Epoch 40 ==========
Loss: 0.077	Accuracy: 41.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.3188    0.9778    0.4809        45
         zxx     0.7826    0.4615    0.5806        39

    accuracy                         0.4108       185
   macro avg     0.6013    0.3235    0.3282       185
weighted avg     0.5335    0.4108    0.3531       185

micro f-score: 0.4108108108108109

========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.097	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.2791    0.5455    0.3692        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.4737    0.2466        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.8889    0.5333    0.6667        45
         zxx     0.4800    0.6154    0.5393        39

    accuracy                         0.4108       185
   macro avg     0.4449    0.3711    0.3506       185
weighted avg     0.5034    0.4108    0.4028       185

micro f-score: 0.4108108108108109

========== Train Epoch 42 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.112	Accuracy: 43.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3377    0.8387    0.4815        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.3478    0.6154    0.4444        39

    accuracy                         0.4378       185
   macro avg     0.5827    0.3438    0.3260       185
weighted avg     0.5617    0.4378    0.3972       185

micro f-score: 0.43783783783783786

========== Train Epoch 43 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.081	Accuracy: 38.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.2955    0.5909    0.3939        22
         hdx     0.1667    0.2353    0.1951        17
         mtx     0.1515    0.2632    0.1923        19
         nqx     0.2703    0.8333    0.4082        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.8571    0.4615    0.6000        39

    accuracy                         0.3892       185
   macro avg     0.4828    0.4190    0.3722       185
weighted avg     0.6061    0.3892    0.4126       185

micro f-score: 0.3891891891891892

========== Train Epoch 44 ==========
Loss: 0.048	Accuracy: 46.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4255    0.6452    0.5128        31
         cwx     0.3143    0.5000    0.3860        22
         hdx     0.2414    0.4118    0.3043        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3929    0.9167    0.5500        12
         qtx     0.8846    0.5111    0.6479        45
         zxx     1.0000    0.3077    0.4706        39

    accuracy                         0.4649       185
   macro avg     0.5012    0.4854    0.4314       185
weighted avg     0.6080    0.4649    0.4675       185

micro f-score: 0.4648648648648649

========== Train Epoch 45 ==========
Loss: 0.038	Accuracy: 52.97%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.3333    0.8636    0.4810        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5297       185
   macro avg     0.5338    0.4904    0.4749       185
weighted avg     0.5971    0.5297    0.5284       185

micro f-score: 0.5297297297297298

========== Train Epoch 46 ==========
Loss: 0.026	Accuracy: 59.46%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.5217    0.9231    0.6667        39

    accuracy                         0.5946       185
   macro avg     0.5818    0.5579    0.5389       185
weighted avg     0.6008    0.5946    0.5689       185

micro f-score: 0.5945945945945946

========== Train Epoch 47 ==========
Loss: 0.016	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4146    0.7727    0.5397        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6000       185
   macro avg     0.5478    0.5676    0.5323       185
weighted avg     0.6068    0.6000    0.5845       185

micro f-score: 0.6

========== Train Epoch 48 ==========
Loss: 0.016	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.5838       185
   macro avg     0.5066    0.5509    0.5183       185
weighted avg     0.5584    0.5838    0.5574       185

micro f-score: 0.5837837837837838

========== Train Epoch 49 ==========
Loss: 0.016	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.6216       185
   macro avg     0.5880    0.5911    0.5687       185
weighted avg     0.6244    0.6216    0.6069       185

micro f-score: 0.6216216216216216

========== Train Epoch 50 ==========
Loss: 0.020	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6000       185
   macro avg     0.5191    0.5545    0.5301       185
weighted avg     0.5641    0.6000    0.5732       185

micro f-score: 0.6

========== Train Epoch 51 ==========
Loss: 0.014	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.2759    0.4706    0.3478        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6875    0.9167    0.7857        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6054       185
   macro avg     0.5800    0.5811    0.5626       185
weighted avg     0.6200    0.6054    0.5972       185

micro f-score: 0.6054054054054054

========== Train Epoch 52 ==========
Loss: 0.013	Accuracy: 60.00%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.6000       185
   macro avg     0.5843    0.5664    0.5411       185
weighted avg     0.6044    0.6000    0.5734       185

micro f-score: 0.6

========== Train Epoch 53 ==========
Loss: 0.014	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5625    0.9231    0.6990        39

    accuracy                         0.6270       185
   macro avg     0.6127    0.5972    0.5791       185
weighted avg     0.6360    0.6270    0.6083       185

micro f-score: 0.6270270270270271

========== Train Epoch 54 ==========
Loss: 0.011	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.7333    0.9167    0.8148        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6270       185
   macro avg     0.5786    0.6032    0.5775       185
weighted avg     0.6193    0.6270    0.6107       185

micro f-score: 0.6270270270270271

========== Train Epoch 55 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6108       185
   macro avg     0.5821    0.5901    0.5693       185
weighted avg     0.6210    0.6108    0.6008       185

micro f-score: 0.6108108108108108

========== Train Epoch 56 ==========
Loss: 0.011	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.5902    0.9231    0.7200        39

    accuracy                         0.5838       185
   macro avg     0.5371    0.5283    0.5150       185
weighted avg     0.5711    0.5838    0.5595       185

micro f-score: 0.5837837837837838

========== Train Epoch 57 ==========
Loss: 0.013	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5838       185
   macro avg     0.5260    0.5410    0.5166       185
weighted avg     0.5666    0.5838    0.5587       185

micro f-score: 0.5837837837837838

========== Train Epoch 58 ==========
Loss: 0.012	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6324       185
   macro avg     0.5709    0.6017    0.5741       185
weighted avg     0.6282    0.6324    0.6214       185

micro f-score: 0.6324324324324324

========== Train Epoch 59 ==========
Loss: 0.011	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6108       185
   macro avg     0.5821    0.5932    0.5663       185
weighted avg     0.6317    0.6108    0.6019       185

micro f-score: 0.6108108108108108

========== Train Epoch 60 ==========
Loss: 0.012	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.6324       185
   macro avg     0.6058    0.6054    0.5892       185
weighted avg     0.6381    0.6324    0.6194       185

micro f-score: 0.6324324324324324

========== Train Epoch 61 ==========
Loss: 0.011	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.6140    0.8974    0.7292        39

    accuracy                         0.6270       185
   macro avg     0.5913    0.5901    0.5691       185
weighted avg     0.6168    0.6270    0.6027       185

micro f-score: 0.6270270270270271

========== Train Epoch 62 ==========
Loss: 0.013	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.5714    0.9231    0.7059        39

    accuracy                         0.6108       185
   macro avg     0.5928    0.5858    0.5714       185
weighted avg     0.6264    0.6108    0.5986       185

micro f-score: 0.6108108108108108

========== Train Epoch 63 ==========
Loss: 0.009	Accuracy: 66.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8182    0.8000    0.8090        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6649       185
   macro avg     0.6164    0.6329    0.6154       185
weighted avg     0.6616    0.6649    0.6567       185

micro f-score: 0.6648648648648648

========== Train Epoch 64 ==========
Loss: 0.013	Accuracy: 56.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.1915    0.5294    0.2812        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.6875    0.9167    0.7857        12
         qtx     0.9655    0.6222    0.7568        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5676       185
   macro avg     0.5661    0.5487    0.5278       185
weighted avg     0.6377    0.5676    0.5747       185

micro f-score: 0.5675675675675675

Finished training!!!

Min Loss = 0.009 in epoch 62;
Max Accuracy = 66.49% in epoch 62;
Total Cost 33 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.31891891891891894, 0.3675675675675676, 0.3837837837837838, 0.43243243243243246, 0.4864864864864865, 0.43243243243243246, 0.518918918918919, 0.5459459459459459, 0.4486486486486487, 0.5135135135135135, 0.372972972972973, 0.5081081081081081, 0.5567567567567567, 0.6054054054054054, 0.5891891891891892, 0.6054054054054054, 0.5459459459459459, 0.5783783783783784, 0.572972972972973, 0.4540540540540541, 0.40540540540540543, 0.4648648648648649, 0.5567567567567567, 0.5513513513513514, 0.4486486486486487, 0.6108108108108108, 0.6270270270270271, 0.5621621621621622, 0.6054054054054054, 0.6270270270270271, 0.5837837837837838, 0.6216216216216216, 0.572972972972973, 0.5621621621621622, 0.42162162162162165, 0.5405405405405406, 0.5675675675675675, 0.43243243243243246, 0.3783783783783784, 0.41081081081081083, 0.41081081081081083, 0.43783783783783786, 0.3891891891891892, 0.4648648648648649, 0.5297297297297298, 0.5945945945945946, 0.6, 0.5837837837837838, 0.6216216216216216, 0.6, 0.6054054054054054, 0.6, 0.6270270270270271, 0.6270270270270271, 0.6108108108108108, 0.5837837837837838, 0.5837837837837838, 0.6324324324324324, 0.6108108108108108, 0.6324324324324324, 0.6270270270270271, 0.6108108108108108, 0.6648648648648648, 0.5675675675675675]
