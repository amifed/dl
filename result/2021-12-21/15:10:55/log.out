dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: cbam resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.815	Accuracy: 29.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.4242    0.3111    0.3590        45
         zxx     0.2558    0.8462    0.3929        39

    accuracy                         0.2973       185
   macro avg     0.1948    0.2227    0.1741       185
weighted avg     0.2204    0.2973    0.2184       185

micro f-score: 0.2972972972972973

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.576	Accuracy: 35.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2857    0.1290    0.1778        31
         cwx     0.1961    0.4545    0.2740        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4286    0.6000    0.5000        45
         zxx     0.4464    0.6410    0.5263        39

    accuracy                         0.3568       185
   macro avg     0.1938    0.2607    0.2112       185
weighted avg     0.2696    0.3568    0.2949       185

micro f-score: 0.3567567567567568

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.441	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.3333    0.2857        12
         qtx     0.5435    0.5556    0.5495        45
         zxx     0.4110    0.7692    0.5357        39

    accuracy                         0.4486       185
   macro avg     0.3455    0.3645    0.3408       185
weighted avg     0.4034    0.4486    0.4099       185

micro f-score: 0.4486486486486486

========== Train Epoch 4 ==========
Loss: 1.317	Accuracy: 27.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3333    0.0323    0.0588        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5000    0.1333    0.2105        45
         zxx     0.2484    1.0000    0.3980        39

    accuracy                         0.2703       185
   macro avg     0.1985    0.2141    0.1410       185
weighted avg     0.2498    0.2703    0.1657       185

micro f-score: 0.2702702702702703

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.137	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3333    0.3548    0.3438        31
         cwx     0.2676    0.8636    0.4086        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.9091    0.2564    0.4000        39

    accuracy                         0.4108       185
   macro avg     0.5402    0.3885    0.3710       185
weighted avg     0.5630    0.4108    0.4080       185

micro f-score: 0.4108108108108109

========== Train Epoch 6 ==========
Loss: 0.957	Accuracy: 47.03%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.3333    0.6364    0.4375        22
         hdx     0.2083    0.2941    0.2439        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.3333    0.6667    0.4444        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.6897    0.5128    0.5882        39

    accuracy                         0.4703       185
   macro avg     0.4488    0.4572    0.4289       185
weighted avg     0.5376    0.4703    0.4825       185

micro f-score: 0.4702702702702703

========== Train Epoch 7 ==========
Loss: 0.778	Accuracy: 45.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3684    0.4516    0.4058        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.4022    0.9487    0.5649        39

    accuracy                         0.4595       185
   macro avg     0.5486    0.3713    0.3262       185
weighted avg     0.5614    0.4595    0.3951       185

micro f-score: 0.4594594594594595

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.605	Accuracy: 30.27%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.0833    0.0588    0.0690        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.9000    0.2000    0.3273        45
         zxx     0.2600    1.0000    0.4127        39

    accuracy                         0.3027       185
   macro avg     0.4705    0.2480    0.2190       185
weighted avg     0.4779    0.3027    0.2322       185

micro f-score: 0.3027027027027027

========== Train Epoch 9 ==========
Loss: 0.474	Accuracy: 35.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.3333    0.7273    0.4571        22
         hdx     0.1857    0.7647    0.2989        17
         mtx     0.2308    0.3158    0.2667        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     1.0000    0.2667    0.4211        45
         zxx     0.6000    0.3846    0.4688        39

    accuracy                         0.3514       185
   macro avg     0.4428    0.3651    0.2977       185
weighted avg     0.5758    0.3514    0.3392       185

micro f-score: 0.35135135135135137

========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.300	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.1846    0.7059    0.2927        17
         mtx     0.1714    0.3158    0.2222        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.9000    0.2000    0.3273        45
         zxx     1.0000    0.4359    0.6071        39

    accuracy                         0.4162       185
   macro avg     0.5664    0.4645    0.4389       185
weighted avg     0.6700    0.4162    0.4449       185

micro f-score: 0.41621621621621624

========== Train Epoch 11 ==========
Loss: 0.190	Accuracy: 44.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.3000    0.7500    0.4286        12
         qtx     0.3960    0.8889    0.5479        45
         zxx     0.7500    0.5385    0.6269        39

    accuracy                         0.4432       185
   macro avg     0.4844    0.3950    0.3515       185
weighted avg     0.5126    0.4432    0.3888       185

micro f-score: 0.44324324324324327

========== Train Epoch 12 ==========
Loss: 0.146	Accuracy: 30.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.1548    0.7647    0.2574        17
         mtx     0.2162    0.4211    0.2857        19
         nqx     0.2963    0.6667    0.4103        12
         qtx     0.8182    0.2000    0.3214        45
         zxx     0.8571    0.1538    0.2609        39

    accuracy                         0.3081       185
   macro avg     0.5299    0.3883    0.3247       185
weighted avg     0.6303    0.3081    0.3151       185

micro f-score: 0.3081081081081081

========== Train Epoch 13 ==========
Loss: 0.106	Accuracy: 50.27%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.3016    0.8636    0.4471        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     0.8824    0.3333    0.4839        45
         zxx     0.9500    0.4872    0.6441        39

    accuracy                         0.5027       185
   macro avg     0.5725    0.5375    0.4961       185
weighted avg     0.6601    0.5027    0.5137       185

micro f-score: 0.5027027027027027

========== Train Epoch 14 ==========
Loss: 0.082	Accuracy: 49.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.3571    0.8974    0.5109        39

    accuracy                         0.4973       185
   macro avg     0.6737    0.4017    0.4134       185
weighted avg     0.6269    0.4973    0.4622       185

micro f-score: 0.4972972972972973

========== Train Epoch 15 ==========
Loss: 0.052	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5440    0.5336    0.5257       185
weighted avg     0.5764    0.5622    0.5566       185

micro f-score: 0.5621621621621622

========== Train Epoch 16 ==========
Loss: 0.042	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.3600    0.7500    0.4865        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.6108       185
   macro avg     0.5826    0.5984    0.5739       185
weighted avg     0.6399    0.6108    0.6143       185

micro f-score: 0.6108108108108108

========== Train Epoch 17 ==========
Loss: 0.046	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.4337    0.9231    0.5902        39

    accuracy                         0.5730       185
   macro avg     0.5846    0.5229    0.5165       185
weighted avg     0.6038    0.5730    0.5491       185

micro f-score: 0.572972972972973

========== Train Epoch 18 ==========
Loss: 0.037	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5946       185
   macro avg     0.5799    0.5709    0.5566       185
weighted avg     0.6068    0.5946    0.5816       185

micro f-score: 0.5945945945945946

========== Train Epoch 19 ==========
Loss: 0.049	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.2449    0.7059    0.3636        17
         mtx     0.2000    0.4211    0.2712        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.8000    0.4103    0.5424        39

    accuracy                         0.4649       185
   macro avg     0.5818    0.4905    0.4737       185
weighted avg     0.6420    0.4649    0.4902       185

micro f-score: 0.4648648648648649

========== Train Epoch 20 ==========
Loss: 0.043	Accuracy: 48.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3019    0.5161    0.3810        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4865       185
   macro avg     0.5641    0.4284    0.4194       185
weighted avg     0.5870    0.4865    0.4611       185

micro f-score: 0.4864864864864865

========== Train Epoch 21 ==========
Loss: 0.034	Accuracy: 36.22%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7333    0.3548    0.4783        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.1287    0.6842    0.2167        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.9286    0.2889    0.4407        45
         zxx     1.0000    0.2051    0.3404        39

    accuracy                         0.3622       185
   macro avg     0.6496    0.3969    0.4073       185
weighted avg     0.7312    0.3622    0.4106       185

micro f-score: 0.3621621621621622

========== Train Epoch 22 ==========
Loss: 0.059	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2923    0.6129    0.3958        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.9286    0.2889    0.4407        45
         zxx     0.4000    0.8718    0.5484        39

    accuracy                         0.4324       185
   macro avg     0.5265    0.3825    0.3718       185
weighted avg     0.5479    0.4324    0.3941       185

micro f-score: 0.43243243243243246

========== Train Epoch 23 ==========
Loss: 0.045	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4286    0.7742    0.5517        31
         cwx     0.5000    0.8182    0.6207        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.8276    0.6154    0.7059        39

    accuracy                         0.5946       185
   macro avg     0.6028    0.5527    0.5470       185
weighted avg     0.6280    0.5946    0.5843       185

micro f-score: 0.5945945945945946

========== Train Epoch 24 ==========
Loss: 0.035	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.2857    0.7059    0.4068        17
         mtx     0.3478    0.4211    0.3810        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.5405       185
   macro avg     0.5567    0.5353    0.5216       185
weighted avg     0.6019    0.5405    0.5486       185

micro f-score: 0.5405405405405406

========== Train Epoch 25 ==========
Loss: 0.028	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.2162    0.4211    0.2857        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.9688    0.6889    0.8052        45
         zxx     0.7812    0.6410    0.7042        39

    accuracy                         0.5838       185
   macro avg     0.5986    0.5575    0.5567       185
weighted avg     0.6758    0.5838    0.6099       185

micro f-score: 0.5837837837837838

========== Train Epoch 26 ==========
Loss: 0.021	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.4400    0.6471    0.5238        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7647    0.6667    0.7123        39

    accuracy                         0.6108       185
   macro avg     0.5551    0.5883    0.5618       185
weighted avg     0.6078    0.6108    0.6022       185

micro f-score: 0.6108108108108108

========== Train Epoch 27 ==========
Loss: 0.023	Accuracy: 56.22%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5622       185
   macro avg     0.5312    0.5231    0.5219       185
weighted avg     0.5763    0.5622    0.5636       185

micro f-score: 0.5621621621621622

========== Train Epoch 28 ==========
Loss: 0.023	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5838       185
   macro avg     0.5500    0.5397    0.5392       185
weighted avg     0.5919    0.5838    0.5811       185

micro f-score: 0.5837837837837838

========== Train Epoch 29 ==========
Loss: 0.022	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3043    0.8235    0.4444        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.6842    0.6667    0.6753        39

    accuracy                         0.5946       185
   macro avg     0.6050    0.5866    0.5732       185
weighted avg     0.6549    0.5946    0.6070       185

micro f-score: 0.5945945945945946

========== Train Epoch 30 ==========
Loss: 0.052	Accuracy: 36.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2273    0.2632    0.2439        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     1.0000    0.1333    0.2353        45
         zxx     0.3091    0.8718    0.4564        39

    accuracy                         0.3676       185
   macro avg     0.3829    0.3455    0.2970       185
weighted avg     0.4487    0.3676    0.2986       185

micro f-score: 0.3675675675675676

========== Train Epoch 31 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.142	Accuracy: 29.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2941    0.1613    0.2083        31
         cwx     0.1709    0.9091    0.2878        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.2353    0.3333    0.2759        12
         qtx     0.8824    0.3333    0.4839        45
         zxx     1.0000    0.2051    0.3404        39

    accuracy                         0.2973       185
   macro avg     0.4225    0.3000    0.2598       185
weighted avg     0.5488    0.2973    0.2993       185

micro f-score: 0.2972972972972973

========== Train Epoch 32 ==========
Loss: 0.077	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.1932    0.8947    0.3178        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     1.0000    0.3077    0.4706        39

    accuracy                         0.4649       185
   macro avg     0.6147    0.4701    0.4690       185
weighted avg     0.6893    0.4649    0.5001       185

micro f-score: 0.4648648648648649

========== Train Epoch 33 ==========
Loss: 0.054	Accuracy: 47.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3590    0.4516    0.4000        31
         cwx     0.3043    0.6364    0.4118        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3462    0.4737    0.4000        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     1.0000    0.3333    0.5000        39

    accuracy                         0.4703       185
   macro avg     0.5020    0.4685    0.4384       185
weighted avg     0.5831    0.4703    0.4741       185

micro f-score: 0.4702702702702703

========== Train Epoch 34 ==========
Loss: 0.057	Accuracy: 49.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5556    0.1613    0.2500        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5769    0.6667    0.6186        45
         zxx     0.4217    0.8974    0.5738        39

    accuracy                         0.4973       185
   macro avg     0.5903    0.4410    0.4230       185
weighted avg     0.5810    0.4973    0.4519       185

micro f-score: 0.4972972972972973

========== Train Epoch 35 ==========
Loss: 0.044	Accuracy: 30.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1467    0.9167    0.2529        12
         qtx     1.0000    0.2000    0.3333        45
         zxx     0.3474    0.8462    0.4925        39

    accuracy                         0.3081       185
   macro avg     0.4634    0.3007    0.1910       185
weighted avg     0.5706    0.3081    0.2404       185

micro f-score: 0.3081081081081081

========== Train Epoch 36 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.043	Accuracy: 54.59%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3667    0.9167    0.5238        12
         qtx     0.6296    0.7556    0.6869        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5459       185
   macro avg     0.4832    0.5036    0.4387       185
weighted avg     0.5232    0.5459    0.4979       185

micro f-score: 0.5459459459459459

========== Train Epoch 37 ==========
Loss: 0.045	Accuracy: 52.43%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3243    0.3871    0.3529        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5243       185
   macro avg     0.4836    0.4555    0.4518       185
weighted avg     0.5158    0.5243    0.5047       185

micro f-score: 0.5243243243243243

========== Train Epoch 38 ==========
Loss: 0.042	Accuracy: 52.97%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3684    0.4516    0.4058        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.4211    0.8205    0.5565        39

    accuracy                         0.5297       185
   macro avg     0.5947    0.4609    0.4725       185
weighted avg     0.6102    0.5297    0.5210       185

micro f-score: 0.5297297297297298

========== Train Epoch 39 ==========
Loss: 0.031	Accuracy: 42.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8750    0.2258    0.3590        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.1304    0.6316    0.2162        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.8125    0.3333    0.4727        39

    accuracy                         0.4270       185
   macro avg     0.6008    0.4094    0.4230       185
weighted avg     0.6856    0.4270    0.4732       185

micro f-score: 0.427027027027027

========== Train Epoch 40 ==========
Loss: 0.024	Accuracy: 59.46%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.4932    0.9231    0.6429        39

    accuracy                         0.5946       185
   macro avg     0.5900    0.5420    0.5276       185
weighted avg     0.6100    0.5946    0.5671       185

micro f-score: 0.5945945945945946

========== Train Epoch 41 ==========
Loss: 0.019	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5405    0.6452    0.5882        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6667    0.6667    0.6667        39

    accuracy                         0.6054       185
   macro avg     0.5684    0.5691    0.5653       185
weighted avg     0.6103    0.6054    0.6050       185

micro f-score: 0.6054054054054054

========== Train Epoch 42 ==========
Loss: 0.020	Accuracy: 61.08%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.6108       185
   macro avg     0.5834    0.5835    0.5796       185
weighted avg     0.6173    0.6108    0.6105       185

micro f-score: 0.6108108108108108

========== Train Epoch 43 ==========
Loss: 0.013	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.6054       185
   macro avg     0.6071    0.5715    0.5656       185
weighted avg     0.6240    0.6054    0.5917       185

micro f-score: 0.6054054054054054

========== Train Epoch 44 ==========
Loss: 0.014	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5892       185
   macro avg     0.5810    0.5565    0.5237       185
weighted avg     0.6210    0.5892    0.5653       185

micro f-score: 0.5891891891891892

========== Train Epoch 45 ==========
Loss: 0.016	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.6216       185
   macro avg     0.5869    0.5887    0.5709       185
weighted avg     0.6211    0.6216    0.6096       185

micro f-score: 0.6216216216216216

========== Train Epoch 46 ==========
Loss: 0.014	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.5000    0.5882    0.5405        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6270       185
   macro avg     0.5845    0.6063    0.5866       185
weighted avg     0.6248    0.6270    0.6187       185

micro f-score: 0.6270270270270271

========== Train Epoch 47 ==========
Loss: 0.013	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.2400    0.7059    0.3582        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.5730       185
   macro avg     0.5787    0.5489    0.5292       185
weighted avg     0.6470    0.5730    0.5804       185

micro f-score: 0.572972972972973

========== Train Epoch 48 ==========
Loss: 0.015	Accuracy: 60.00%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4000    0.4516    0.4242        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6000       185
   macro avg     0.5876    0.5578    0.5519       185
weighted avg     0.6031    0.6000    0.5847       185

micro f-score: 0.6

========== Train Epoch 49 ==========
Loss: 0.012	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5946       185
   macro avg     0.5443    0.5644    0.5386       185
weighted avg     0.5870    0.5946    0.5779       185

micro f-score: 0.5945945945945946

========== Train Epoch 50 ==========
Loss: 0.011	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3077    0.7059    0.4286        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.6108       185
   macro avg     0.6113    0.6088    0.5809       185
weighted avg     0.6617    0.6108    0.6148       185

micro f-score: 0.6108108108108108

========== Train Epoch 51 ==========
Loss: 0.012	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.5455    0.8182    0.6545        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.6162       185
   macro avg     0.5834    0.5826    0.5693       185
weighted avg     0.6140    0.6162    0.6051       185

micro f-score: 0.6162162162162163

========== Train Epoch 52 ==========
Loss: 0.010	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.6108       185
   macro avg     0.5869    0.5860    0.5698       185
weighted avg     0.6167    0.6108    0.6030       185

micro f-score: 0.6108108108108108

========== Train Epoch 53 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.6108       185
   macro avg     0.5643    0.5774    0.5645       185
weighted avg     0.6187    0.6108    0.6094       185

micro f-score: 0.6108108108108108

========== Train Epoch 54 ==========
Loss: 0.013	Accuracy: 60.00%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6000       185
   macro avg     0.5581    0.5643    0.5501       185
weighted avg     0.5946    0.6000    0.5864       185

micro f-score: 0.6

========== Train Epoch 55 ==========
Loss: 0.014	Accuracy: 60.00%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.6000       185
   macro avg     0.5773    0.5663    0.5529       185
weighted avg     0.6111    0.6000    0.5875       185

micro f-score: 0.6

========== Train Epoch 56 ==========
Loss: 0.010	Accuracy: 61.62%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.6162       185
   macro avg     0.6393    0.5795    0.5783       185
weighted avg     0.6346    0.6162    0.6028       185

micro f-score: 0.6162162162162163

========== Train Epoch 57 ==========
Loss: 0.011	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4000    0.7059    0.5106        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5946       185
   macro avg     0.5699    0.5872    0.5634       185
weighted avg     0.6100    0.5946    0.5904       185

micro f-score: 0.5945945945945946

========== Train Epoch 58 ==========
Loss: 0.012	Accuracy: 60.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3429    0.7059    0.4615        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.9355    0.6444    0.7632        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.6000       185
   macro avg     0.5912    0.5816    0.5641       185
weighted avg     0.6458    0.6000    0.6036       185

micro f-score: 0.6

========== Train Epoch 59 ==========
Loss: 0.012	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.4737    0.9231    0.6261        39

    accuracy                         0.5946       185
   macro avg     0.6056    0.5546    0.5447       185
weighted avg     0.6297    0.5946    0.5776       185

micro f-score: 0.5945945945945946

========== Train Epoch 60 ==========
Loss: 0.010	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.5625    0.8182    0.6667        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6667    0.8205    0.7356        39

    accuracy                         0.6216       185
   macro avg     0.5868    0.5946    0.5626       185
weighted avg     0.6202    0.6216    0.5999       185

micro f-score: 0.6216216216216216

========== Train Epoch 61 ==========
Loss: 0.012	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6270       185
   macro avg     0.6072    0.6049    0.5796       185
weighted avg     0.6468    0.6270    0.6150       185

micro f-score: 0.6270270270270271

========== Train Epoch 62 ==========
Loss: 0.010	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.2857    0.7059    0.4068        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.9394    0.6889    0.7949        45
         zxx     0.7812    0.6410    0.7042        39

    accuracy                         0.5946       185
   macro avg     0.5819    0.5808    0.5609       185
weighted avg     0.6564    0.5946    0.6086       185

micro f-score: 0.5945945945945946

========== Train Epoch 63 ==========
Loss: 0.010	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.9143    0.7111    0.8000        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6216       185
   macro avg     0.5764    0.5853    0.5734       185
weighted avg     0.6265    0.6216    0.6158       185

micro f-score: 0.6216216216216216

========== Train Epoch 64 ==========
Loss: 0.009	Accuracy: 62.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.6216       185
   macro avg     0.6010    0.5851    0.5799       185
weighted avg     0.6250    0.6216    0.6132       185

micro f-score: 0.6216216216216216

Finished training!!!

Min Loss = 0.009 in epoch 63;
Max Accuracy = 62.70% in epoch 45;
Total Cost 32 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=64, out_features=4, bias=True)
            (2): ReLU()
            (3): Linear(in_features=4, out_features=64, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=128, out_features=8, bias=True)
            (2): ReLU()
            (3): Linear(in_features=8, out_features=128, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=256, out_features=16, bias=True)
            (2): ReLU()
            (3): Linear(in_features=16, out_features=256, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (cbam): CBAM(
        (ChannelGate): ChannelGate(
          (mlp): Sequential(
            (0): Flatten()
            (1): Linear(in_features=512, out_features=32, bias=True)
            (2): ReLU()
            (3): Linear(in_features=32, out_features=512, bias=True)
          )
        )
        (SpatialGate): SpatialGate(
          (compress): ChannelPool()
          (spatial): BasicConv(
            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.2972972972972973, 0.3567567567567568, 0.4486486486486487, 0.2702702702702703, 0.41081081081081083, 0.4702702702702703, 0.4594594594594595, 0.3027027027027027, 0.35135135135135137, 0.41621621621621624, 0.44324324324324327, 0.3081081081081081, 0.5027027027027027, 0.4972972972972973, 0.5621621621621622, 0.6108108108108108, 0.572972972972973, 0.5945945945945946, 0.4648648648648649, 0.4864864864864865, 0.3621621621621622, 0.43243243243243246, 0.5945945945945946, 0.5405405405405406, 0.5837837837837838, 0.6108108108108108, 0.5621621621621622, 0.5837837837837838, 0.5945945945945946, 0.3675675675675676, 0.2972972972972973, 0.4648648648648649, 0.4702702702702703, 0.4972972972972973, 0.3081081081081081, 0.5459459459459459, 0.5243243243243243, 0.5297297297297298, 0.42702702702702705, 0.5945945945945946, 0.6054054054054054, 0.6108108108108108, 0.6054054054054054, 0.5891891891891892, 0.6216216216216216, 0.6270270270270271, 0.572972972972973, 0.6, 0.5945945945945946, 0.6108108108108108, 0.6162162162162163, 0.6108108108108108, 0.6108108108108108, 0.6, 0.6, 0.6162162162162163, 0.5945945945945946, 0.6, 0.5945945945945946, 0.6216216216216216, 0.6270270270270271, 0.5945945945945946, 0.6216216216216216, 0.6216216216216216]
