dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.842	Accuracy: 24.32%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2056    0.7097    0.3188        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0800    0.1176    0.0952        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4545    0.3333    0.3846        45
         zxx     0.4000    0.0513    0.0909        39

    accuracy                         0.2432       185
   macro avg     0.2200    0.1991    0.1628       185
weighted avg     0.2843    0.2432    0.2046       185

micro f-score: 0.24324324324324326

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.625	Accuracy: 37.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.1667    0.2727    0.2069        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.4242    0.3111    0.3590        45
         zxx     0.4915    0.7436    0.5918        39

    accuracy                         0.3730       185
   macro avg     0.3400    0.3142    0.3021       185
weighted avg     0.3687    0.3730    0.3491       185

micro f-score: 0.37297297297297294

========== Train Epoch 3 ==========
Loss: 1.512	Accuracy: 38.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3115    0.6129    0.4130        31
         cwx     0.2353    0.1818    0.2051        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4177    0.7333    0.5323        45
         zxx     0.6250    0.3846    0.4762        39

    accuracy                         0.3892       185
   macro avg     0.3699    0.2851    0.2544       185
weighted avg     0.3784    0.3892    0.3334       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
Loss: 1.303	Accuracy: 39.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3679    0.8667    0.5166        45
         zxx     0.6429    0.4615    0.5373        39

    accuracy                         0.3946       185
   macro avg     0.3453    0.3007    0.2799       185
weighted avg     0.4067    0.3946    0.3427       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.173	Accuracy: 42.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2500    0.0323    0.0571        31
         cwx     0.3429    0.5455    0.4211        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.7500    0.4615        12
         qtx     0.6154    0.3556    0.4507        45
         zxx     0.4302    0.9487    0.5920        39

    accuracy                         0.4216       185
   macro avg     0.4722    0.3994    0.3219       185
weighted avg     0.4708    0.4216    0.3507       185

micro f-score: 0.42162162162162165

========== Train Epoch 6 ==========
Loss: 1.081	Accuracy: 43.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.2903    0.3673        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5946    0.4889    0.5366        45
         zxx     0.3762    0.9744    0.5429        39

    accuracy                         0.4378       185
   macro avg     0.3581    0.3399    0.3089       185
weighted avg     0.4232    0.4378    0.3831       185

micro f-score: 0.43783783783783786

========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.867	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.2656    0.7727    0.3953        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2553    0.6316    0.3636        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.8571    0.1333    0.2308        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.4162       185
   macro avg     0.4925    0.4311    0.3616       185
weighted avg     0.5766    0.4162    0.3720       185

micro f-score: 0.41621621621621624

========== Train Epoch 8 ==========
Loss: 0.619	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.4865    0.8182    0.6102        22
         hdx     0.5500    0.6471    0.5946        17
         mtx     0.3333    0.4737    0.3913        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5514       185
   macro avg     0.5572    0.5670    0.5127       185
weighted avg     0.6067    0.5514    0.5274       185

micro f-score: 0.5513513513513514

========== Train Epoch 9 ==========
Loss: 0.456	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.6182    0.7556    0.6800        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5514       185
   macro avg     0.5963    0.5058    0.4639       185
weighted avg     0.5978    0.5514    0.5046       185

micro f-score: 0.5513513513513514

========== Train Epoch 10 ==========
Loss: 0.256	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.3913    0.4737    0.4286        19
         nqx     0.2750    0.9167    0.4231        12
         qtx     0.9200    0.5111    0.6571        45
         zxx     0.5000    0.9744    0.6609        39

    accuracy                         0.5189       185
   macro avg     0.4919    0.5159    0.4449       185
weighted avg     0.5332    0.5189    0.4739       185

micro f-score: 0.518918918918919

========== Train Epoch 11 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.167	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.2203    0.7647    0.3421        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.6140    0.7778    0.6863        45
         zxx     1.0000    0.3846    0.5556        39

    accuracy                         0.5081       185
   macro avg     0.5906    0.4799    0.4649       185
weighted avg     0.6368    0.5081    0.5065       185

micro f-score: 0.5081081081081081

========== Train Epoch 12 ==========
Loss: 0.109	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.4634    0.9744    0.6281        39

    accuracy                         0.5838       185
   macro avg     0.6204    0.5548    0.5451       185
weighted avg     0.6450    0.5838    0.5665       185

micro f-score: 0.5837837837837838

========== Train Epoch 13 ==========
Loss: 0.094	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3692    0.7742    0.5000        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.3333    0.6471    0.4400        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.9615    0.6410    0.7692        39

    accuracy                         0.5784       185
   macro avg     0.6640    0.5717    0.5525       185
weighted avg     0.7274    0.5784    0.5907       185

micro f-score: 0.5783783783783784

========== Train Epoch 14 ==========
Loss: 0.097	Accuracy: 49.19%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.8065    0.4717        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.9375    0.3846    0.5455        39

    accuracy                         0.4919       185
   macro avg     0.5927    0.4808    0.4653       185
weighted avg     0.6555    0.4919    0.5004       185

micro f-score: 0.4918918918918919

========== Train Epoch 15 ==========
Loss: 0.082	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5116    0.7097    0.5946        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.4545    0.5263    0.4878        19
         nqx     0.3056    0.9167    0.4583        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.9032    0.7179    0.8000        39

    accuracy                         0.6162       185
   macro avg     0.6352    0.6092    0.5807       185
weighted avg     0.7123    0.6162    0.6330       185

micro f-score: 0.6162162162162163

========== Train Epoch 16 ==========
Loss: 0.059	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3673    0.5806    0.4500        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.2500    0.6316    0.3582        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.9545    0.4667    0.6269        45
         zxx     0.8333    0.7692    0.8000        39

    accuracy                         0.5459       185
   macro avg     0.6353    0.5054    0.5157       185
weighted avg     0.6805    0.5459    0.5658       185

micro f-score: 0.5459459459459459

========== Train Epoch 17 ==========
Loss: 0.067	Accuracy: 67.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5227    0.7419    0.6133        31
         cwx     0.8571    0.5455    0.6667        22
         hdx     0.7778    0.4118    0.5385        17
         mtx     0.5789    0.5789    0.5789        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.6000    0.9231    0.7273        39

    accuracy                         0.6757       185
   macro avg     0.7313    0.6502    0.6639       185
weighted avg     0.7346    0.6757    0.6750       185

micro f-score: 0.6756756756756757

========== Train Epoch 18 ==========
Loss: 0.050	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.3600    0.7500    0.4865        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.5946       185
   macro avg     0.5695    0.5718    0.5409       185
weighted avg     0.6521    0.5946    0.5958       185

micro f-score: 0.5945945945945946

========== Train Epoch 19 ==========
Loss: 0.050	Accuracy: 67.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5526    0.6774    0.6087        31
         cwx     0.5806    0.8182    0.6792        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.8889    0.6667    0.7619        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.6757       185
   macro avg     0.6544    0.6223    0.6219       185
weighted avg     0.6689    0.6757    0.6601       185

micro f-score: 0.6756756756756757

========== Train Epoch 20 ==========
Loss: 0.039	Accuracy: 65.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.5667    0.7727    0.6538        22
         hdx     0.7778    0.4118    0.5385        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.6595       185
   macro avg     0.6372    0.6249    0.6141       185
weighted avg     0.6657    0.6595    0.6504       185

micro f-score: 0.6594594594594595

========== Train Epoch 21 ==========
Loss: 0.043	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4773    0.6774    0.5600        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.2667    0.7059    0.3871        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.9310    0.6923    0.7941        39

    accuracy                         0.5946       185
   macro avg     0.6294    0.5954    0.5696       185
weighted avg     0.6966    0.5946    0.6079       185

micro f-score: 0.5945945945945946

========== Train Epoch 22 ==========
Loss: 0.038	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7778    0.2258    0.3500        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.6167    0.8222    0.7048        45
         zxx     0.5000    0.9744    0.6609        39

    accuracy                         0.5946       185
   macro avg     0.6709    0.5188    0.5349       185
weighted avg     0.6451    0.5946    0.5589       185

micro f-score: 0.5945945945945946

========== Train Epoch 23 ==========
Loss: 0.026	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3784    0.9032    0.5333        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.5556    0.5882    0.5714        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.9355    0.6444    0.7632        45
         zxx     0.9000    0.6923    0.7826        39

    accuracy                         0.6216       185
   macro avg     0.6409    0.5901    0.5782       185
weighted avg     0.7002    0.6216    0.6212       185

micro f-score: 0.6216216216216216

========== Train Epoch 24 ==========
Loss: 0.025	Accuracy: 65.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8000    0.5161    0.6275        31
         cwx     0.7083    0.7727    0.7391        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.6207    0.9231    0.7423        39

    accuracy                         0.6595       185
   macro avg     0.6272    0.6176    0.6106       185
weighted avg     0.6787    0.6595    0.6541       185

micro f-score: 0.6594594594594595

========== Train Epoch 25 ==========
Loss: 0.030	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3857    0.8710    0.5347        31
         cwx     0.9000    0.4091    0.5625        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.9615    0.6410    0.7692        39

    accuracy                         0.6000       185
   macro avg     0.6635    0.5736    0.5714       185
weighted avg     0.7080    0.6000    0.6070       185

micro f-score: 0.6

========== Train Epoch 26 ==========
Loss: 0.025	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.4595    0.7727    0.5763        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2857    0.3158    0.3000        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.9677    0.6667    0.7895        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.6054       185
   macro avg     0.5786    0.5526    0.5460       185
weighted avg     0.6466    0.6054    0.6032       185

micro f-score: 0.6054054054054054

========== Train Epoch 27 ==========
Loss: 0.032	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.4318    0.9744    0.5984        39

    accuracy                         0.5730       185
   macro avg     0.6495    0.5523    0.5425       185
weighted avg     0.6790    0.5730    0.5534       185

micro f-score: 0.572972972972973

========== Train Epoch 28 ==========
Loss: 0.026	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.2895    0.6471    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.9091    0.7692    0.8333        39

    accuracy                         0.6270       185
   macro avg     0.6153    0.6054    0.5915       185
weighted avg     0.6711    0.6270    0.6352       185

micro f-score: 0.6270270270270271

========== Train Epoch 29 ==========
Loss: 0.024	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4058    0.9032    0.5600        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.8095    0.8718    0.8395        39

    accuracy                         0.6270       185
   macro avg     0.7032    0.5685    0.5618       185
weighted avg     0.7208    0.6270    0.6068       185

micro f-score: 0.6270270270270271

========== Train Epoch 30 ==========
Loss: 0.033	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6162       185
   macro avg     0.6201    0.5718    0.5732       185
weighted avg     0.6610    0.6162    0.6197       185

micro f-score: 0.6162162162162163

========== Train Epoch 31 ==========
Loss: 0.030	Accuracy: 47.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.4651    0.9091    0.6154        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.9231    0.2667    0.4138        45
         zxx     0.3824    1.0000    0.5532        39

    accuracy                         0.4757       185
   macro avg     0.5182    0.4825    0.4188       185
weighted avg     0.5191    0.4757    0.3983       185

micro f-score: 0.4756756756756757

========== Train Epoch 32 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.033	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.6000       185
   macro avg     0.6345    0.5926    0.5566       185
weighted avg     0.6722    0.6000    0.5863       185

micro f-score: 0.6

========== Train Epoch 33 ==========
Loss: 0.033	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5405    0.6452    0.5882        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6667    0.7556    0.7083        45
         zxx     0.7949    0.7949    0.7949        39

    accuracy                         0.6324       185
   macro avg     0.6229    0.5897    0.5862       185
weighted avg     0.6514    0.6324    0.6277       185

micro f-score: 0.6324324324324324

========== Train Epoch 34 ==========
Loss: 0.025	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.6604    0.7778    0.7143        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6378       185
   macro avg     0.6005    0.5933    0.5740       185
weighted avg     0.6206    0.6378    0.6117       185

micro f-score: 0.6378378378378379

========== Train Epoch 35 ==========
Loss: 0.025	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2553    0.6316    0.3636        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     1.0000    0.5333    0.6957        45
         zxx     0.7778    0.8974    0.8333        39

    accuracy                         0.6000       185
   macro avg     0.6284    0.5700    0.5720       185
weighted avg     0.6938    0.6000    0.6173       185

micro f-score: 0.6

========== Train Epoch 36 ==========
Loss: 0.024	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.4815    0.8667    0.6190        45
         zxx     0.6545    0.9231    0.7660        39

    accuracy                         0.5946       185
   macro avg     0.6893    0.5305    0.5336       185
weighted avg     0.6758    0.5946    0.5557       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.023	Accuracy: 65.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.8235    0.6364    0.7179        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.4762    0.5263    0.5000        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.6541       185
   macro avg     0.6287    0.6446    0.6267       185
weighted avg     0.6678    0.6541    0.6536       185

micro f-score: 0.654054054054054

========== Train Epoch 38 ==========
Loss: 0.022	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3824    0.8387    0.5253        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.6108       185
   macro avg     0.6371    0.5643    0.5525       185
weighted avg     0.6665    0.6108    0.5985       185

micro f-score: 0.6108108108108108

========== Train Epoch 39 ==========
Loss: 0.022	Accuracy: 50.27%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.2048    0.8947    0.3333        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     1.0000    0.5333    0.6957        45
         zxx     0.6429    0.9231    0.7579        39

    accuracy                         0.5027       185
   macro avg     0.5913    0.4418    0.4123       185
weighted avg     0.6879    0.5027    0.4936       185

micro f-score: 0.5027027027027027

========== Train Epoch 40 ==========
Loss: 0.016	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6667    0.7273    0.6957        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.8421    0.8205    0.8312        39

    accuracy                         0.6486       185
   macro avg     0.6205    0.6368    0.5951       185
weighted avg     0.6780    0.6486    0.6413       185

micro f-score: 0.6486486486486487

========== Train Epoch 41 ==========
Loss: 0.016	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.1774    1.0000    0.3014        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.9524    0.4444    0.6061        45
         zxx     0.9524    0.5128    0.6667        39

    accuracy                         0.4054       185
   macro avg     0.7646    0.4008    0.3911       185
weighted avg     0.8212    0.4054    0.4233       185

micro f-score: 0.40540540540540543

========== Train Epoch 42 ==========
Loss: 0.021	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.4412    0.6818    0.5357        22
         hdx     0.5000    0.5882    0.5405        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.9333    0.6222    0.7467        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6216       185
   macro avg     0.6128    0.5871    0.5593       185
weighted avg     0.6624    0.6216    0.6069       185

micro f-score: 0.6216216216216216

========== Train Epoch 43 ==========
Loss: 0.021	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.6216       185
   macro avg     0.6037    0.6015    0.5947       185
weighted avg     0.6320    0.6216    0.6202       185

micro f-score: 0.6216216216216216

========== Train Epoch 44 ==========
Loss: 0.022	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4583    0.7097    0.5570        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.7442    0.8205    0.7805        39

    accuracy                         0.5946       185
   macro avg     0.5580    0.5605    0.5447       185
weighted avg     0.6192    0.5946    0.5911       185

micro f-score: 0.5945945945945946

========== Train Epoch 45 ==========
Loss: 0.018	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5892       185
   macro avg     0.5535    0.5708    0.5298       185
weighted avg     0.6077    0.5892    0.5704       185

micro f-score: 0.5891891891891892

========== Train Epoch 46 ==========
Loss: 0.022	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.3659    0.6818    0.4762        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.3333    0.5789    0.4231        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.7059    0.9231    0.8000        39

    accuracy                         0.5676       185
   macro avg     0.5731    0.5297    0.5170       185
weighted avg     0.6271    0.5676    0.5625       185

micro f-score: 0.5675675675675675

========== Train Epoch 47 ==========
Loss: 0.017	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.8333    0.2941    0.4348        17
         mtx     0.3913    0.4737    0.4286        19
         nqx     0.2941    0.8333    0.4348        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.6108       185
   macro avg     0.6561    0.5835    0.5645       185
weighted avg     0.7002    0.6108    0.6146       185

micro f-score: 0.6108108108108108

========== Train Epoch 48 ==========
Loss: 0.015	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4237    0.8065    0.5556        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.9286    0.6667    0.7761        39

    accuracy                         0.6054       185
   macro avg     0.6125    0.5763    0.5655       185
weighted avg     0.6645    0.6054    0.6052       185

micro f-score: 0.6054054054054054

========== Train Epoch 49 ==========
Loss: 0.013	Accuracy: 67.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4902    0.8065    0.6098        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.8000    0.4706    0.5926        17
         mtx     0.5625    0.4737    0.5143        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.9310    0.6000    0.7297        45
         zxx     0.7447    0.8974    0.8140        39

    accuracy                         0.6757       185
   macro avg     0.6911    0.6491    0.6504       185
weighted avg     0.7179    0.6757    0.6748       185

micro f-score: 0.6756756756756757

========== Train Epoch 50 ==========
Loss: 0.013	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.4146    0.7727    0.5397        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.8250    0.8462    0.8354        39

    accuracy                         0.6324       185
   macro avg     0.5977    0.6044    0.5727       185
weighted avg     0.6664    0.6324    0.6282       185

micro f-score: 0.6324324324324324

========== Train Epoch 51 ==========
Loss: 0.011	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.4103    0.7273    0.5246        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.7778    0.8974    0.8333        39

    accuracy                         0.6324       185
   macro avg     0.6121    0.5971    0.5756       185
weighted avg     0.6655    0.6324    0.6255       185

micro f-score: 0.6324324324324324

========== Train Epoch 52 ==========
Loss: 0.010	Accuracy: 68.11%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.4400    0.6471    0.5238        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7660    0.9231    0.8372        39

    accuracy                         0.6811       185
   macro avg     0.6731    0.6618    0.6372       185
weighted avg     0.7061    0.6811    0.6716       185

micro f-score: 0.6810810810810811

========== Train Epoch 53 ==========
Loss: 0.014	Accuracy: 67.03%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7660    0.8000    0.7826        45
         zxx     0.7955    0.8974    0.8434        39

    accuracy                         0.6703       185
   macro avg     0.6416    0.6123    0.6052       185
weighted avg     0.6721    0.6703    0.6554       185

micro f-score: 0.6702702702702703

========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 68.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.5517    0.7273    0.6275        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7826    0.8000    0.7912        45
         zxx     0.7500    0.9231    0.8276        39

    accuracy                         0.6865       185
   macro avg     0.6563    0.6453    0.6364       185
weighted avg     0.6890    0.6865    0.6757       185

micro f-score: 0.6864864864864865

========== Train Epoch 55 ==========
Loss: 0.015	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.3235    0.6471    0.4314        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.9615    0.5556    0.7042        45
         zxx     0.7778    0.8974    0.8333        39

    accuracy                         0.6324       185
   macro avg     0.6220    0.6253    0.5946       185
weighted avg     0.6951    0.6324    0.6358       185

micro f-score: 0.6324324324324324

========== Train Epoch 56 ==========
Loss: 0.014	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.6774    0.6364        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.7273    0.4706    0.5714        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.8000    0.6667    0.7273        12
         qtx     0.6545    0.8000    0.7200        45
         zxx     0.8621    0.6410    0.7353        39

    accuracy                         0.6432       185
   macro avg     0.6501    0.6086    0.6203       185
weighted avg     0.6621    0.6432    0.6437       185

micro f-score: 0.6432432432432432

========== Train Epoch 57 ==========
Loss: 0.015	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5405    0.6452    0.5882        31
         cwx     0.7895    0.6818    0.7317        22
         hdx     0.4583    0.6471    0.5366        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6432       185
   macro avg     0.6326    0.6224    0.5956       185
weighted avg     0.6733    0.6432    0.6303       185

micro f-score: 0.6432432432432432

========== Train Epoch 58 ==========
Loss: 0.039	Accuracy: 28.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.7500    0.1364    0.2308        22
         hdx     0.2093    0.5294    0.3000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1385    0.7500    0.2338        12
         qtx     0.4286    0.6667    0.5217        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.2865       185
   macro avg     0.3609    0.3067    0.2011       185
weighted avg     0.3892    0.2865    0.2174       185

micro f-score: 0.2864864864864865

========== Train Epoch 59 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.894	Accuracy: 17.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2537    0.5484    0.3469        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1628    0.4118    0.2333        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0833    0.5000    0.1429        12
         qtx     0.0000    0.0000    0.0000        45
         zxx     1.0000    0.0513    0.0976        39

    accuracy                         0.1730       185
   macro avg     0.2143    0.2159    0.1172       185
weighted avg     0.2737    0.1730    0.1094       185

micro f-score: 0.17297297297297298

========== Train Epoch 60 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.134	Accuracy: 42.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.1833    0.5789    0.2785        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.5179    0.6444    0.5743        45
         zxx     1.0000    0.2821    0.4400        39

    accuracy                         0.4216       185
   macro avg     0.5080    0.3846    0.3759       185
weighted avg     0.5604    0.4216    0.4228       185

micro f-score: 0.42162162162162165

========== Train Epoch 61 ==========
Loss: 0.478	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1714    0.5000    0.2553        12
         qtx     0.3871    0.8000    0.5217        45
         zxx     0.7647    0.3333    0.4643        39

    accuracy                         0.4108       185
   macro avg     0.4200    0.3661    0.3449       185
weighted avg     0.4718    0.4108    0.3866       185

micro f-score: 0.4108108108108109

========== Train Epoch 62 ==========
Loss: 0.199	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4186    0.5806    0.4865        31
         cwx     0.4333    0.5909    0.5000        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.9375    0.3333    0.4918        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5189       185
   macro avg     0.5362    0.4941    0.4832       185
weighted avg     0.5840    0.5189    0.5047       185

micro f-score: 0.518918918918919

========== Train Epoch 63 ==========
Loss: 0.091	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4444    0.6452    0.5263        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.5892       185
   macro avg     0.5551    0.5298    0.5231       185
weighted avg     0.5963    0.5892    0.5715       185

micro f-score: 0.5891891891891892

========== Train Epoch 64 ==========
Loss: 0.045	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.2903    0.4737    0.3600        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.9091    0.4444    0.5970        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.5730       185
   macro avg     0.5759    0.5491    0.5271       185
weighted avg     0.6312    0.5730    0.5655       185

micro f-score: 0.572972972972973

Finished training!!!

Min Loss = 0.010 in epoch 51;
Max Accuracy = 68.65% in epoch 53;
Total Cost 31 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP()
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.24324324324324326, 0.372972972972973, 0.3891891891891892, 0.3945945945945946, 0.42162162162162165, 0.43783783783783786, 0.41621621621621624, 0.5513513513513514, 0.5513513513513514, 0.518918918918919, 0.5081081081081081, 0.5837837837837838, 0.5783783783783784, 0.4918918918918919, 0.6162162162162163, 0.5459459459459459, 0.6756756756756757, 0.5945945945945946, 0.6756756756756757, 0.6594594594594595, 0.5945945945945946, 0.5945945945945946, 0.6216216216216216, 0.6594594594594595, 0.6, 0.6054054054054054, 0.572972972972973, 0.6270270270270271, 0.6270270270270271, 0.6162162162162163, 0.4756756756756757, 0.6, 0.6324324324324324, 0.6378378378378379, 0.6, 0.5945945945945946, 0.654054054054054, 0.6108108108108108, 0.5027027027027027, 0.6486486486486487, 0.40540540540540543, 0.6216216216216216, 0.6216216216216216, 0.5945945945945946, 0.5891891891891892, 0.5675675675675675, 0.6108108108108108, 0.6054054054054054, 0.6756756756756757, 0.6324324324324324, 0.6324324324324324, 0.6810810810810811, 0.6702702702702703, 0.6864864864864865, 0.6324324324324324, 0.6432432432432432, 0.6432432432432432, 0.2864864864864865, 0.17297297297297298, 0.42162162162162165, 0.41081081081081083, 0.518918918918919, 0.5891891891891892, 0.572972972972973]
