dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.869	Accuracy: 18.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2500    0.0645    0.1026        31
         cwx     0.1818    0.1818    0.1818        22
         hdx     0.1182    0.7647    0.2047        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.3438    0.2444    0.2857        45
         zxx     1.0000    0.0256    0.0500        39

    accuracy                         0.1838       185
   macro avg     0.3563    0.2187    0.1683       185
weighted avg     0.4077    0.1838    0.1606       185

micro f-score: 0.1837837837837838

========== Train Epoch 2 ==========
Loss: 1.637	Accuracy: 40.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4603    0.6444    0.5370        45
         zxx     0.3913    0.9231    0.5496        39

    accuracy                         0.4054       185
   macro avg     0.4534    0.3081    0.2701       185
weighted avg     0.4925    0.4054    0.3243       185

micro f-score: 0.40540540540540543

========== Train Epoch 3 ==========
Loss: 1.486	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.4545    0.6667    0.5405        45
         zxx     0.3837    0.8462    0.5280        39

    accuracy                         0.4108       185
   macro avg     0.2707    0.3349    0.2800       185
weighted avg     0.2895    0.4108    0.3215       185

micro f-score: 0.4108108108108109

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.348	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2989    0.8387    0.4407        31
         cwx     0.5000    0.1364    0.2143        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7500    0.4000    0.5217        45
         zxx     0.5000    0.5897    0.5412        39

    accuracy                         0.4162       185
   macro avg     0.3453    0.3640    0.3099       185
weighted avg     0.4213    0.4162    0.3696       185

micro f-score: 0.41621621621621624

========== Train Epoch 5 ==========
Loss: 1.181	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.1613    0.2500        31
         cwx     0.2128    0.9091    0.3448        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6047    0.5778    0.5909        45
         zxx     1.0000    0.3077    0.4706        39

    accuracy                         0.4000       185
   macro avg     0.5025    0.3946    0.3678       185
weighted avg     0.5666    0.4000    0.3953       185

micro f-score: 0.4000000000000001

========== Train Epoch 6 ==========
Loss: 0.986	Accuracy: 28.11%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.5000    0.2273    0.3125        22
         hdx     0.1452    0.5294    0.2278        17
         mtx     0.1304    0.4737    0.2045        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.8000    0.1778    0.2909        45
         zxx     0.8000    0.3077    0.4444        39

    accuracy                         0.2811       185
   macro avg     0.4709    0.3085    0.2951       185
weighted avg     0.5652    0.2811    0.3109       185

micro f-score: 0.2810810810810811

========== Train Epoch 7 ==========
Loss: 0.804	Accuracy: 48.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.1714    0.3529    0.2308        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.5588    0.8444    0.6726        45
         zxx     0.5294    0.9231    0.6729        39

    accuracy                         0.4865       185
   macro avg     0.6153    0.3649    0.3320       185
weighted avg     0.6010    0.4865    0.4186       185

micro f-score: 0.4864864864864865

========== Train Epoch 8 ==========
Loss: 0.600	Accuracy: 38.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.2118    0.8182    0.3364        22
         hdx     0.2500    0.4706    0.3265        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     1.0000    0.3846    0.5556        39

    accuracy                         0.3838       185
   macro avg     0.6069    0.3691    0.3484       185
weighted avg     0.6152    0.3838    0.3841       185

micro f-score: 0.3837837837837838

========== Train Epoch 9 ==========
Loss: 0.421	Accuracy: 54.05%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3250    0.4194    0.3662        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.5405       185
   macro avg     0.5726    0.4926    0.4641       185
weighted avg     0.6028    0.5405    0.5191       185

micro f-score: 0.5405405405405406

========== Train Epoch 10 ==========
Loss: 0.227	Accuracy: 53.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3830    0.5806    0.4615        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.2667    0.7059    0.3871        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.9286    0.6667    0.7761        39

    accuracy                         0.5351       185
   macro avg     0.5787    0.4855    0.4693       185
weighted avg     0.6390    0.5351    0.5348       185

micro f-score: 0.5351351351351351

========== Train Epoch 11 ==========
Loss: 0.148	Accuracy: 55.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.3404    0.7273    0.4638        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.3000    0.3158    0.3077        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     1.0000    0.5778    0.7324        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.5514       185
   macro avg     0.5726    0.5199    0.4975       185
weighted avg     0.6299    0.5514    0.5364       185

micro f-score: 0.5513513513513514

========== Train Epoch 12 ==========
Loss: 0.119	Accuracy: 49.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     1.0000    0.4222    0.5938        45
         zxx     0.4000    0.9744    0.5672        39

    accuracy                         0.4919       185
   macro avg     0.6153    0.4410    0.4312       185
weighted avg     0.6370    0.4919    0.4652       185

micro f-score: 0.4918918918918919

========== Train Epoch 13 ==========
Loss: 0.108	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6162       185
   macro avg     0.5584    0.5713    0.5508       185
weighted avg     0.6005    0.6162    0.5960       185

micro f-score: 0.6162162162162163

========== Train Epoch 14 ==========
Loss: 0.071	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4054    0.6818    0.5085        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.7143    0.8974    0.7955        39

    accuracy                         0.5946       185
   macro avg     0.5606    0.5713    0.5457       185
weighted avg     0.6344    0.5946    0.5922       185

micro f-score: 0.5945945945945946

========== Train Epoch 15 ==========
Loss: 0.049	Accuracy: 55.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3333    0.6471    0.4400        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5385    0.8974    0.6731        39

    accuracy                         0.5514       185
   macro avg     0.5376    0.5160    0.4802       185
weighted avg     0.5940    0.5514    0.5209       185

micro f-score: 0.5513513513513514

========== Train Epoch 16 ==========
Loss: 0.058	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4255    0.6452    0.5128        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.8667    0.6667    0.7536        39

    accuracy                         0.5892       185
   macro avg     0.5843    0.5615    0.5408       185
weighted avg     0.6388    0.5892    0.5889       185

micro f-score: 0.5891891891891892

========== Train Epoch 17 ==========
Loss: 0.048	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9355    0.6444    0.7632        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6162       185
   macro avg     0.5907    0.5842    0.5793       185
weighted avg     0.6421    0.6162    0.6182       185

micro f-score: 0.6162162162162163

========== Train Epoch 18 ==========
Loss: 0.041	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5128    0.6452    0.5714        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.8667    0.6667    0.7536        39

    accuracy                         0.6216       185
   macro avg     0.5916    0.5938    0.5749       185
weighted avg     0.6423    0.6216    0.6192       185

micro f-score: 0.6216216216216216

========== Train Epoch 19 ==========
Loss: 0.036	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4576    0.8710    0.6000        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.8519    0.5897    0.6970        39

    accuracy                         0.6108       185
   macro avg     0.6444    0.5775    0.5866       185
weighted avg     0.6918    0.6108    0.6250       185

micro f-score: 0.6108108108108108

========== Train Epoch 20 ==========
Loss: 0.040	Accuracy: 57.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.4000    0.6364    0.4912        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.5784       185
   macro avg     0.5554    0.5473    0.5130       185
weighted avg     0.6197    0.5784    0.5603       185

micro f-score: 0.5783783783783784

========== Train Epoch 21 ==========
Loss: 0.029	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.2927    0.7059    0.4138        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6216       185
   macro avg     0.6369    0.5898    0.5696       185
weighted avg     0.6808    0.6216    0.6165       185

micro f-score: 0.6216216216216216

========== Train Epoch 22 ==========
Loss: 0.033	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4561    0.8387    0.5909        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.6162       185
   macro avg     0.6175    0.5848    0.5815       185
weighted avg     0.6864    0.6162    0.6281       185

micro f-score: 0.6162162162162163

========== Train Epoch 23 ==========
Loss: 0.028	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8333    0.3226    0.4651        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3226    0.5882    0.4167        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.6054       185
   macro avg     0.6162    0.5745    0.5439       185
weighted avg     0.6747    0.6054    0.5907       185

micro f-score: 0.6054054054054054

========== Train Epoch 24 ==========
Loss: 0.036	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7333    0.3548    0.4783        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.5000    0.4737    0.4865        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6364    0.7778    0.7000        45
         zxx     0.7292    0.8974    0.8046        39

    accuracy                         0.6324       185
   macro avg     0.6165    0.5986    0.5828       185
weighted avg     0.6418    0.6324    0.6152       185

micro f-score: 0.6324324324324324

========== Train Epoch 25 ==========
Loss: 0.030	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.6452    0.4938        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.6207    0.8000    0.6990        45
         zxx     0.8621    0.6410    0.7353        39

    accuracy                         0.5838       185
   macro avg     0.5893    0.5404    0.5370       185
weighted avg     0.6119    0.5838    0.5717       185

micro f-score: 0.5837837837837838

========== Train Epoch 26 ==========
Loss: 0.039	Accuracy: 64.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.7500    0.9231    0.8276        39

    accuracy                         0.6486       185
   macro avg     0.6141    0.6073    0.6000       185
weighted avg     0.6412    0.6486    0.6370       185

micro f-score: 0.6486486486486487

========== Train Epoch 27 ==========
Loss: 0.037	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.5758    0.9744    0.7238        39

    accuracy                         0.6162       185
   macro avg     0.5992    0.5596    0.5595       185
weighted avg     0.6238    0.6162    0.5990       185

micro f-score: 0.6162162162162163

========== Train Epoch 28 ==========
Loss: 0.024	Accuracy: 65.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6541       185
   macro avg     0.6207    0.6168    0.6068       185
weighted avg     0.6449    0.6541    0.6405       185

micro f-score: 0.654054054054054

========== Train Epoch 29 ==========
Loss: 0.021	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.2432    0.5294    0.3333        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.8421    0.8205    0.8312        39

    accuracy                         0.6000       185
   macro avg     0.5926    0.5467    0.5547       185
weighted avg     0.6591    0.6000    0.6180       185

micro f-score: 0.6

========== Train Epoch 30 ==========
Loss: 0.018	Accuracy: 64.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6486       185
   macro avg     0.6198    0.5976    0.6017       185
weighted avg     0.6486    0.6486    0.6433       185

micro f-score: 0.6486486486486487

========== Train Epoch 31 ==========
Loss: 0.018	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.2727    0.5294    0.3600        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5606    0.9487    0.7048        39

    accuracy                         0.5676       185
   macro avg     0.5842    0.5383    0.5055       185
weighted avg     0.6320    0.5676    0.5410       185

micro f-score: 0.5675675675675675

========== Train Epoch 32 ==========
Loss: 0.018	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.2895    0.6471    0.4000        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.7660    0.9231    0.8372        39

    accuracy                         0.6324       185
   macro avg     0.6283    0.6051    0.5881       185
weighted avg     0.6910    0.6324    0.6345       185

micro f-score: 0.6324324324324324

========== Train Epoch 33 ==========
Loss: 0.022	Accuracy: 65.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.4595    0.7727    0.5763        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7200    0.8000    0.7579        45
         zxx     0.7400    0.9487    0.8315        39

    accuracy                         0.6541       185
   macro avg     0.6371    0.6069    0.5874       185
weighted avg     0.6686    0.6541    0.6293       185

micro f-score: 0.654054054054054

========== Train Epoch 34 ==========
Loss: 0.020	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.6216       185
   macro avg     0.5699    0.5735    0.5689       185
weighted avg     0.6232    0.6216    0.6198       185

micro f-score: 0.6216216216216216

========== Train Epoch 35 ==========
Loss: 0.018	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5135    0.9744    0.6726        39

    accuracy                         0.6162       185
   macro avg     0.6357    0.5709    0.5647       185
weighted avg     0.6466    0.6162    0.5908       185

micro f-score: 0.6162162162162163

========== Train Epoch 36 ==========
Loss: 0.022	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.1923    0.8333    0.3125        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.8049    0.8462    0.8250        39

    accuracy                         0.5459       185
   macro avg     0.5742    0.5127    0.4823       185
weighted avg     0.6514    0.5459    0.5577       185

micro f-score: 0.5459459459459459

========== Train Epoch 37 ==========
Loss: 0.028	Accuracy: 34.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5385    0.2258    0.3182        31
         cwx     0.1538    0.8182    0.2590        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     1.0000    0.2889    0.4483        45
         zxx     0.9474    0.4615    0.6207        39

    accuracy                         0.3459       185
   macro avg     0.4819    0.3200    0.3140       185
weighted avg     0.6232    0.3459    0.3777       185

micro f-score: 0.34594594594594597

========== Train Epoch 38 ==========
Loss: 0.137	Accuracy: 29.19%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2222    0.8387    0.3514        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.1395    0.3158    0.1935        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.8462    0.2444    0.3793        45
         zxx     0.8571    0.1538    0.2609        39

    accuracy                         0.2919       185
   macro avg     0.5807    0.2778    0.2566       185
weighted avg     0.5948    0.2919    0.2687       185

micro f-score: 0.2918918918918919

========== Train Epoch 39 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.592	Accuracy: 29.73%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.1034    0.1579    0.1250        19
         nqx     0.1250    0.6667    0.2105        12
         qtx     0.4590    0.6222    0.5283        45
         zxx     0.8182    0.2308    0.3600        39

    accuracy                         0.2973       185
   macro avg     0.3793    0.2870    0.2419       185
weighted avg     0.4561    0.2973    0.2852       185

micro f-score: 0.2972972972972973

========== Train Epoch 40 ==========
Loss: 0.548	Accuracy: 44.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.1765    0.1765    0.1765        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3824    0.8667    0.5306        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.4432       185
   macro avg     0.5257    0.3117    0.2804       185
weighted avg     0.5476    0.4432    0.3749       185

micro f-score: 0.44324324324324327

========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.240	Accuracy: 39.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2561    0.6774    0.3717        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2308    0.7500    0.3529        12
         qtx     0.9231    0.2667    0.4138        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.3946       185
   macro avg     0.4955    0.4001    0.3543       185
weighted avg     0.5966    0.3946    0.3938       185

micro f-score: 0.3945945945945946

========== Train Epoch 42 ==========
Loss: 0.116	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4865    0.5806    0.5294        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6162       185
   macro avg     0.5726    0.5597    0.5592       185
weighted avg     0.6064    0.6162    0.6058       185

micro f-score: 0.6162162162162163

========== Train Epoch 43 ==========
Loss: 0.078	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.8056    0.7436    0.7733        39

    accuracy                         0.5838       185
   macro avg     0.5250    0.5473    0.5239       185
weighted avg     0.5978    0.5838    0.5829       185

micro f-score: 0.5837837837837838

========== Train Epoch 44 ==========
Loss: 0.049	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6432       185
   macro avg     0.6093    0.5901    0.5901       185
weighted avg     0.6309    0.6432    0.6288       185

micro f-score: 0.6432432432432432

========== Train Epoch 45 ==========
Loss: 0.029	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.4146    0.7727    0.5397        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5838       185
   macro avg     0.5430    0.5243    0.5071       185
weighted avg     0.5994    0.5838    0.5693       185

micro f-score: 0.5837837837837838

========== Train Epoch 46 ==========
Loss: 0.020	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6270       185
   macro avg     0.5869    0.5808    0.5722       185
weighted avg     0.6244    0.6270    0.6162       185

micro f-score: 0.6270270270270271

========== Train Epoch 47 ==========
Loss: 0.020	Accuracy: 57.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.2500    0.4118    0.3111        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5730       185
   macro avg     0.5502    0.5149    0.5091       185
weighted avg     0.6114    0.5730    0.5668       185

micro f-score: 0.572972972972973

========== Train Epoch 48 ==========
Loss: 0.022	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6108       185
   macro avg     0.5569    0.5616    0.5476       185
weighted avg     0.6108    0.6108    0.6009       185

micro f-score: 0.6108108108108108

========== Train Epoch 49 ==========
Loss: 0.021	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.3448    0.5882    0.4348        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6054       185
   macro avg     0.5563    0.5579    0.5433       185
weighted avg     0.6148    0.6054    0.5971       185

micro f-score: 0.6054054054054054

========== Train Epoch 50 ==========
Loss: 0.018	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5838       185
   macro avg     0.5312    0.5158    0.5089       185
weighted avg     0.5829    0.5838    0.5693       185

micro f-score: 0.5837837837837838

========== Train Epoch 51 ==========
Loss: 0.014	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.8205    0.8205    0.8205        39

    accuracy                         0.6000       185
   macro avg     0.5545    0.5514    0.5448       185
weighted avg     0.6130    0.6000    0.6007       185

micro f-score: 0.6

========== Train Epoch 52 ==========
Loss: 0.013	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6108       185
   macro avg     0.5588    0.5681    0.5500       185
weighted avg     0.6105    0.6108    0.5987       185

micro f-score: 0.6108108108108108

========== Train Epoch 53 ==========
Loss: 0.015	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6108       185
   macro avg     0.5562    0.5523    0.5453       185
weighted avg     0.6238    0.6108    0.6099       185

micro f-score: 0.6108108108108108

========== Train Epoch 54 ==========
Loss: 0.016	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.3226    0.5882    0.4167        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.6054       185
   macro avg     0.5517    0.5578    0.5428       185
weighted avg     0.6146    0.6054    0.6001       185

micro f-score: 0.6054054054054054

========== Train Epoch 55 ==========
Loss: 0.018	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.5606    0.9487    0.7048        39

    accuracy                         0.6162       185
   macro avg     0.5909    0.5708    0.5588       185
weighted avg     0.6311    0.6162    0.5993       185

micro f-score: 0.6162162162162163

========== Train Epoch 56 ==========
Loss: 0.014	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6216       185
   macro avg     0.5856    0.5801    0.5664       185
weighted avg     0.6310    0.6216    0.6109       185

micro f-score: 0.6216216216216216

========== Train Epoch 57 ==========
Loss: 0.014	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.2941    0.5882    0.3922        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.7292    0.8974    0.8046        39

    accuracy                         0.6162       185
   macro avg     0.5766    0.5676    0.5573       185
weighted avg     0.6454    0.6162    0.6171       185

micro f-score: 0.6162162162162163

========== Train Epoch 58 ==========
Loss: 0.017	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.8000    0.8000    0.8000        45
         zxx     0.6207    0.9231    0.7423        39

    accuracy                         0.6270       185
   macro avg     0.5747    0.5504    0.5478       185
weighted avg     0.6241    0.6270    0.6093       185

micro f-score: 0.6270270270270271

========== Train Epoch 59 ==========
Loss: 0.017	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6216       185
   macro avg     0.5622    0.5631    0.5547       185
weighted avg     0.6176    0.6216    0.6123       185

micro f-score: 0.6216216216216216

========== Train Epoch 60 ==========
Loss: 0.014	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.6102    0.9231    0.7347        39

    accuracy                         0.6270       185
   macro avg     0.6042    0.5866    0.5726       185
weighted avg     0.6572    0.6270    0.6193       185

micro f-score: 0.6270270270270271

========== Train Epoch 61 ==========
Loss: 0.014	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.6216       185
   macro avg     0.5677    0.5705    0.5626       185
weighted avg     0.6190    0.6216    0.6150       185

micro f-score: 0.6216216216216216

========== Train Epoch 62 ==========
Loss: 0.012	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6324       185
   macro avg     0.5842    0.5892    0.5803       185
weighted avg     0.6369    0.6324    0.6276       185

micro f-score: 0.6324324324324324

========== Train Epoch 63 ==========
Loss: 0.015	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.6429    0.9231    0.7579        39

    accuracy                         0.6324       185
   macro avg     0.5887    0.5831    0.5741       185
weighted avg     0.6392    0.6324    0.6229       185

micro f-score: 0.6324324324324324

========== Train Epoch 64 ==========
Loss: 0.014	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6108       185
   macro avg     0.5492    0.5612    0.5449       185
weighted avg     0.6062    0.6108    0.5995       185

micro f-score: 0.6108108108108108

Finished training!!!

Min Loss = 0.012 in epoch 61;
Max Accuracy = 65.41% in epoch 27;
Total Cost 31 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP()
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.1837837837837838, 0.40540540540540543, 0.41081081081081083, 0.41621621621621624, 0.4, 0.2810810810810811, 0.4864864864864865, 0.3837837837837838, 0.5405405405405406, 0.5351351351351351, 0.5513513513513514, 0.4918918918918919, 0.6162162162162163, 0.5945945945945946, 0.5513513513513514, 0.5891891891891892, 0.6162162162162163, 0.6216216216216216, 0.6108108108108108, 0.5783783783783784, 0.6216216216216216, 0.6162162162162163, 0.6054054054054054, 0.6324324324324324, 0.5837837837837838, 0.6486486486486487, 0.6162162162162163, 0.654054054054054, 0.6, 0.6486486486486487, 0.5675675675675675, 0.6324324324324324, 0.654054054054054, 0.6216216216216216, 0.6162162162162163, 0.5459459459459459, 0.34594594594594597, 0.2918918918918919, 0.2972972972972973, 0.44324324324324327, 0.3945945945945946, 0.6162162162162163, 0.5837837837837838, 0.6432432432432432, 0.5837837837837838, 0.6270270270270271, 0.572972972972973, 0.6108108108108108, 0.6054054054054054, 0.5837837837837838, 0.6, 0.6108108108108108, 0.6108108108108108, 0.6054054054054054, 0.6162162162162163, 0.6216216216216216, 0.6162162162162163, 0.6270270270270271, 0.6216216216216216, 0.6270270270270271, 0.6216216216216216, 0.6324324324324324, 0.6324324324324324, 0.6108108108108108]
