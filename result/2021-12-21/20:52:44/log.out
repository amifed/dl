dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.859	Accuracy: 32.43%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.1940    0.5909    0.2921        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5769    0.3333    0.4225        45
         zxx     0.3562    0.6667    0.4643        39

    accuracy                         0.3243       185
   macro avg     0.2621    0.2841    0.2300       185
weighted avg     0.3255    0.3243    0.2748       185

micro f-score: 0.32432432432432434

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.624	Accuracy: 33.51%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4746    0.6222    0.5385        45
         zxx     0.2698    0.8718    0.4121        39

    accuracy                         0.3351       185
   macro avg     0.1063    0.2134    0.1358       185
weighted avg     0.1723    0.3351    0.2179       185

micro f-score: 0.33513513513513515

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.488	Accuracy: 36.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.2353    0.1818    0.2051        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6818    0.3333    0.4478        45
         zxx     0.3367    0.8462    0.4818        39

    accuracy                         0.3676       185
   macro avg     0.3080    0.2892    0.2706       185
weighted avg     0.3814    0.3676    0.3337       185

micro f-score: 0.3675675675675676

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.315	Accuracy: 43.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4038    0.6774    0.5060        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.4020    0.9111    0.5578        45
         zxx     1.0000    0.1282    0.2273        39

    accuracy                         0.4324       185
   macro avg     0.5115    0.3544    0.3325       185
weighted avg     0.5344    0.4324    0.3621       185

micro f-score: 0.43243243243243246

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.178	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3400    0.5484    0.4198        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.1930    0.9167    0.3188        12
         qtx     0.8571    0.4000    0.5455        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.4054       185
   macro avg     0.3023    0.3765    0.2864       185
weighted avg     0.4156    0.4054    0.3673       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.933	Accuracy: 42.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.9167    0.2444    0.3860        45
         zxx     0.3182    0.8974    0.4698        39

    accuracy                         0.4216       185
   macro avg     0.6391    0.3839    0.3921       185
weighted avg     0.6484    0.4216    0.4060       185

micro f-score: 0.42162162162162165

========== Train Epoch 7 ==========
Loss: 0.779	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.2258    0.3111        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2600    0.6842    0.3768        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.8333    0.4444    0.5797        45
         zxx     0.4375    0.8974    0.5882        39

    accuracy                         0.4432       185
   macro avg     0.4865    0.3786    0.3295       185
weighted avg     0.5588    0.4432    0.3996       185

micro f-score: 0.44324324324324327

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.551	Accuracy: 36.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.1882    0.8421    0.3077        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     1.0000    0.1778    0.3019        45
         zxx     0.4545    0.8974    0.6034        39

    accuracy                         0.3676       185
   macro avg     0.6684    0.3470    0.2874       185
weighted avg     0.7323    0.3676    0.3112       185

micro f-score: 0.3675675675675676

========== Train Epoch 9 ==========
Loss: 0.329	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4783    0.9167    0.6286        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6162       185
   macro avg     0.6742    0.5575    0.5261       185
weighted avg     0.6666    0.6162    0.5796       185

micro f-score: 0.6162162162162163

========== Train Epoch 10 ==========
Loss: 0.217	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.4444    0.8889    0.5926        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5135       185
   macro avg     0.5682    0.4024    0.3916       185
weighted avg     0.5924    0.5135    0.4512       185

micro f-score: 0.5135135135135135

========== Train Epoch 11 ==========
Loss: 0.136	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     1.0000    0.3636    0.5333        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.4800    0.8000    0.6000        45
         zxx     0.7667    0.5897    0.6667        39

    accuracy                         0.5459       185
   macro avg     0.6564    0.5090    0.4963       185
weighted avg     0.6509    0.5459    0.5284       185

micro f-score: 0.5459459459459459

========== Train Epoch 12 ==========
Loss: 0.091	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.2778    0.5882    0.3774        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.8649    0.8205    0.8421        39

    accuracy                         0.6108       185
   macro avg     0.5843    0.5827    0.5620       185
weighted avg     0.6449    0.6108    0.6097       185

micro f-score: 0.6108108108108108

========== Train Epoch 13 ==========
Loss: 0.087	Accuracy: 49.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6364    0.2258    0.3333        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.1719    0.6471    0.2716        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.9167    0.4889    0.6377        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.4973       185
   macro avg     0.5680    0.4704    0.4686       185
weighted avg     0.6416    0.4973    0.5195       185

micro f-score: 0.4972972972972973

========== Train Epoch 14 ==========
Loss: 0.068	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6216       185
   macro avg     0.5977    0.5839    0.5687       185
weighted avg     0.6525    0.6216    0.6174       185

micro f-score: 0.6216216216216216

========== Train Epoch 15 ==========
Loss: 0.064	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.6452    0.5634        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6250    0.7778    0.6931        45
         zxx     0.8125    0.6667    0.7324        39

    accuracy                         0.5892       185
   macro avg     0.5570    0.5304    0.5363       185
weighted avg     0.5957    0.5892    0.5843       185

micro f-score: 0.5891891891891892

========== Train Epoch 16 ==========
Loss: 0.057	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4222    0.6129    0.5000        31
         cwx     0.5455    0.8182    0.6545        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.8000    0.7179    0.7568        39

    accuracy                         0.5892       185
   macro avg     0.5656    0.5443    0.5398       185
weighted avg     0.6108    0.5892    0.5868       185

micro f-score: 0.5891891891891892

========== Train Epoch 17 ==========
Loss: 0.057	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4348    0.6452    0.5195        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.5568       185
   macro avg     0.5494    0.5298    0.5220       185
weighted avg     0.6127    0.5568    0.5675       185

micro f-score: 0.5567567567567567

========== Train Epoch 18 ==========
Loss: 0.043	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.1961    0.5882    0.2941        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.5459       185
   macro avg     0.5748    0.5301    0.5092       185
weighted avg     0.6596    0.5459    0.5606       185

micro f-score: 0.5459459459459459

========== Train Epoch 19 ==========
Loss: 0.057	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2821    0.6471    0.3929        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6000       185
   macro avg     0.5990    0.5732    0.5416       185
weighted avg     0.6538    0.6000    0.5944       185

micro f-score: 0.6

========== Train Epoch 20 ==========
Loss: 0.057	Accuracy: 50.81%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.3611    1.0000    0.5306        39

    accuracy                         0.5081       185
   macro avg     0.6221    0.4511    0.4689       185
weighted avg     0.6231    0.5081    0.4912       185

micro f-score: 0.5081081081081081

========== Train Epoch 21 ==========
Loss: 0.055	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.5362    0.9487    0.6852        39

    accuracy                         0.5784       185
   macro avg     0.5718    0.5529    0.5267       185
weighted avg     0.6189    0.5784    0.5550       185

micro f-score: 0.5783783783783784

========== Train Epoch 22 ==========
Loss: 0.054	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3824    0.4194    0.4000        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.5352    0.8444    0.6552        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.5405       185
   macro avg     0.5358    0.4856    0.4684       185
weighted avg     0.5651    0.5405    0.5162       185

micro f-score: 0.5405405405405406

========== Train Epoch 23 ==========
Loss: 0.048	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.1613    0.2778        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.5522    0.9487    0.6981        39

    accuracy                         0.5730       185
   macro avg     0.6380    0.5402    0.5059       185
weighted avg     0.6669    0.5730    0.5353       185

micro f-score: 0.572972972972973

========== Train Epoch 24 ==========
Loss: 0.052	Accuracy: 47.03%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2569    0.9032    0.4000        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.5625    0.5294    0.5455        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.9000    0.4615    0.6102        39

    accuracy                         0.4703       185
   macro avg     0.6844    0.4147    0.4149       185
weighted avg     0.7254    0.4703    0.4700       185

micro f-score: 0.4702702702702703

========== Train Epoch 25 ==========
Loss: 0.050	Accuracy: 48.65%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3684    0.6774    0.4773        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2619    0.9167    0.4074        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.4865       185
   macro avg     0.4069    0.4498    0.3775       185
weighted avg     0.4864    0.4865    0.4519       185

micro f-score: 0.4864864864864865

========== Train Epoch 26 ==========
Loss: 0.050	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.2750    0.6471    0.3860        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5351       185
   macro avg     0.5228    0.5007    0.4760       185
weighted avg     0.5901    0.5351    0.5282       185

micro f-score: 0.5351351351351351

========== Train Epoch 27 ==========
Loss: 0.102	Accuracy: 49.19%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.2464    0.7727    0.3736        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.8621    0.6410    0.7353        39

    accuracy                         0.4919       185
   macro avg     0.5838    0.4535    0.4362       185
weighted avg     0.6305    0.4919    0.4996       185

micro f-score: 0.4918918918918919

========== Train Epoch 28 ==========
Loss: 0.080	Accuracy: 50.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.4324    0.7273    0.5424        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.3103    0.7500    0.4390        12
         qtx     0.5469    0.7778    0.6422        45
         zxx     0.9231    0.3077    0.4615        39

    accuracy                         0.5081       185
   macro avg     0.5579    0.5039    0.4709       185
weighted avg     0.5963    0.5081    0.4928       185

micro f-score: 0.5081081081081081

========== Train Epoch 29 ==========
Loss: 0.059	Accuracy: 54.59%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3684    0.4516    0.4058        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4000    1.0000    0.5714        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.8387    0.6667    0.7429        39

    accuracy                         0.5459       185
   macro avg     0.5093    0.5546    0.4958       185
weighted avg     0.5991    0.5459    0.5445       185

micro f-score: 0.5459459459459459

========== Train Epoch 30 ==========
Loss: 0.050	Accuracy: 48.11%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3385    0.7097    0.4583        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.9048    0.4222    0.5758        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.4811       185
   macro avg     0.6286    0.4098    0.3964       185
weighted avg     0.6324    0.4811    0.4488       185

micro f-score: 0.4810810810810811

========== Train Epoch 31 ==========
Loss: 0.039	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.5070    0.9231    0.6545        39

    accuracy                         0.5568       185
   macro avg     0.5417    0.4846    0.4716       185
weighted avg     0.5930    0.5568    0.5329       185

micro f-score: 0.5567567567567567

========== Train Epoch 32 ==========
Loss: 0.033	Accuracy: 55.68%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3768    0.8387    0.5200        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.5568       185
   macro avg     0.5767    0.5046    0.4981       185
weighted avg     0.6104    0.5568    0.5434       185

micro f-score: 0.5567567567567567

========== Train Epoch 33 ==========
Loss: 0.021	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     1.0000    0.5778    0.7324        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.5892       185
   macro avg     0.5742    0.5568    0.5419       185
weighted avg     0.6457    0.5892    0.5895       185

micro f-score: 0.5891891891891892

========== Train Epoch 34 ==========
Loss: 0.031	Accuracy: 54.05%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.4598    0.8889    0.6061        45
         zxx     0.6512    0.7179    0.6829        39

    accuracy                         0.5405       185
   macro avg     0.5965    0.4646    0.4867       185
weighted avg     0.5794    0.5405    0.5162       185

micro f-score: 0.5405405405405406

========== Train Epoch 35 ==========
Loss: 0.020	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.5892       185
   macro avg     0.5300    0.5496    0.5247       185
weighted avg     0.6104    0.5892    0.5858       185

micro f-score: 0.5891891891891892

========== Train Epoch 36 ==========
Loss: 0.019	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.2963    0.6667    0.4103        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.8056    0.7436    0.7733        39

    accuracy                         0.5946       185
   macro avg     0.5529    0.5704    0.5450       185
weighted avg     0.6300    0.5946    0.6007       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.020	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5714    0.7273    0.6400        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6216       185
   macro avg     0.5814    0.5947    0.5620       185
weighted avg     0.6270    0.6216    0.6047       185

micro f-score: 0.6216216216216216

========== Train Epoch 38 ==========
Loss: 0.021	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.7949    0.7949    0.7949        39

    accuracy                         0.6000       185
   macro avg     0.5573    0.5546    0.5497       185
weighted avg     0.5980    0.6000    0.5943       185

micro f-score: 0.6

========== Train Epoch 39 ==========
Loss: 0.017	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.4750    0.9744    0.6387        39

    accuracy                         0.5784       185
   macro avg     0.5590    0.5334    0.5122       185
weighted avg     0.6108    0.5784    0.5557       185

micro f-score: 0.5783783783783784

========== Train Epoch 40 ==========
Loss: 0.017	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3962    0.6774    0.5000        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.8621    0.6410    0.7353        39

    accuracy                         0.5946       185
   macro avg     0.6072    0.5853    0.5706       185
weighted avg     0.6619    0.5946    0.6028       185

micro f-score: 0.5945945945945946

========== Train Epoch 41 ==========
Loss: 0.013	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6270       185
   macro avg     0.6119    0.6122    0.5845       185
weighted avg     0.6620    0.6270    0.6260       185

micro f-score: 0.6270270270270271

========== Train Epoch 42 ==========
Loss: 0.036	Accuracy: 36.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1392    0.9167    0.2418        12
         qtx     0.4839    0.6667    0.5607        45
         zxx     1.0000    0.1795    0.3043        39

    accuracy                         0.3622       185
   macro avg     0.4666    0.3696    0.2969       185
weighted avg     0.5370    0.3622    0.3379       185

micro f-score: 0.3621621621621622

========== Train Epoch 43 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.047	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3922    0.6452    0.4878        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5459       185
   macro avg     0.4455    0.4416    0.4247       185
weighted avg     0.5261    0.5459    0.5193       185

micro f-score: 0.5459459459459459

========== Train Epoch 44 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.041	Accuracy: 38.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.2903    0.5806    0.3871        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.1860    0.4211    0.2581        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     1.0000    0.1111    0.2000        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.3838       185
   macro avg     0.5503    0.3567    0.3316       185
weighted avg     0.6062    0.3838    0.3562       185

micro f-score: 0.3837837837837838

========== Train Epoch 45 ==========
Loss: 0.054	Accuracy: 46.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.2034    0.6316    0.3077        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.7917    0.4872    0.6032        39

    accuracy                         0.4649       185
   macro avg     0.4983    0.4560    0.4481       185
weighted avg     0.5740    0.4649    0.4903       185

micro f-score: 0.4648648648648649

========== Train Epoch 46 ==========
Loss: 0.092	Accuracy: 42.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2407    0.8387    0.3741        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.9048    0.4222    0.5758        45
         zxx     0.6875    0.5641    0.6197        39

    accuracy                         0.4270       185
   macro avg     0.5960    0.3581    0.3713       185
weighted avg     0.6117    0.4270    0.4301       185

micro f-score: 0.427027027027027

========== Train Epoch 47 ==========
Loss: 0.213	Accuracy: 33.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3125    0.6452    0.4211        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.2500    0.5882    0.3509        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4000    0.6222    0.4870        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.3351       185
   macro avg     0.2625    0.2941    0.2235       185
weighted avg     0.2706    0.3351    0.2540       185

micro f-score: 0.33513513513513515

========== Train Epoch 48 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.362	Accuracy: 38.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2609    0.8182    0.3956        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.0714    0.0526    0.0606        19
         nqx     0.2174    0.8333    0.3448        12
         qtx     0.8077    0.4667    0.5915        45
         zxx     0.7308    0.4872    0.5846        39

    accuracy                         0.3838       185
   macro avg     0.3697    0.3965    0.3097       185
weighted avg     0.4489    0.3838    0.3603       185

micro f-score: 0.3837837837837838

========== Train Epoch 49 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.282	Accuracy: 40.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3673    0.8000    0.5035        45
         zxx     0.4762    0.7692    0.5882        39

    accuracy                         0.4054       185
   macro avg     0.2995    0.2850    0.2314       185
weighted avg     0.3525    0.4054    0.3092       185

micro f-score: 0.40540540540540543

========== Train Epoch 50 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.177	Accuracy: 29.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.1739    0.2353    0.2000        17
         mtx     0.1562    0.7895    0.2609        19
         nqx     0.2500    0.5833    0.3500        12
         qtx     1.0000    0.2889    0.4483        45
         zxx     0.7500    0.3077    0.4364        39

    accuracy                         0.2973       185
   macro avg     0.5293    0.3390    0.2797       185
weighted avg     0.6618    0.2973    0.3032       185

micro f-score: 0.2972972972972973

========== Train Epoch 51 ==========
Loss: 0.125	Accuracy: 49.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3378    0.8065    0.4762        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.0909    0.0526    0.0667        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.8636    0.4222    0.5672        45
         zxx     0.7742    0.6154    0.6857        39

    accuracy                         0.4973       185
   macro avg     0.5264    0.4515    0.4484       185
weighted avg     0.5821    0.4973    0.4948       185

micro f-score: 0.4972972972972973

========== Train Epoch 52 ==========
Loss: 0.052	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5135    0.9744    0.6726        39

    accuracy                         0.5459       185
   macro avg     0.5251    0.5170    0.4732       185
weighted avg     0.5808    0.5459    0.5082       185

micro f-score: 0.5459459459459459

========== Train Epoch 53 ==========
Loss: 0.035	Accuracy: 52.97%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3590    0.4516    0.4000        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.8065    0.6410    0.7143        39

    accuracy                         0.5297       185
   macro avg     0.4844    0.4935    0.4823       185
weighted avg     0.5406    0.5297    0.5295       185

micro f-score: 0.5297297297297298

========== Train Epoch 54 ==========
Loss: 0.024	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.5161    0.4507        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5676       185
   macro avg     0.5475    0.5316    0.5342       185
weighted avg     0.5898    0.5676    0.5710       185

micro f-score: 0.5675675675675675

========== Train Epoch 55 ==========
Loss: 0.025	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.6207    0.9231    0.7423        39

    accuracy                         0.5514       185
   macro avg     0.5002    0.5175    0.4977       185
weighted avg     0.5513    0.5514    0.5372       185

micro f-score: 0.5513513513513514

========== Train Epoch 56 ==========
Loss: 0.022	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4737    0.2903    0.3600        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.5459       185
   macro avg     0.4748    0.5007    0.4751       185
weighted avg     0.5345    0.5459    0.5279       185

micro f-score: 0.5459459459459459

========== Train Epoch 57 ==========
Loss: 0.018	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.5730       185
   macro avg     0.5188    0.5314    0.5181       185
weighted avg     0.5872    0.5730    0.5729       185

micro f-score: 0.572972972972973

========== Train Epoch 58 ==========
Loss: 0.017	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.7955    0.8974    0.8434        39

    accuracy                         0.6162       185
   macro avg     0.5544    0.5678    0.5581       185
weighted avg     0.6132    0.6162    0.6116       185

micro f-score: 0.6162162162162163

========== Train Epoch 59 ==========
Loss: 0.019	Accuracy: 57.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.8250    0.8462    0.8354        39

    accuracy                         0.5784       185
   macro avg     0.5254    0.5456    0.5283       185
weighted avg     0.5961    0.5784    0.5816       185

micro f-score: 0.5783783783783784

========== Train Epoch 60 ==========
Loss: 0.015	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5333    0.7273    0.6154        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.7059    0.9231    0.8000        39

    accuracy                         0.5892       185
   macro avg     0.5205    0.5371    0.5177       185
weighted avg     0.5741    0.5892    0.5709       185

micro f-score: 0.5891891891891892

========== Train Epoch 61 ==========
Loss: 0.011	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7143    0.8974    0.7955        39

    accuracy                         0.5838       185
   macro avg     0.5181    0.5312    0.5189       185
weighted avg     0.5649    0.5838    0.5689       185

micro f-score: 0.5837837837837838

========== Train Epoch 62 ==========
Loss: 0.016	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.7727    0.8718    0.8193        39

    accuracy                         0.5676       185
   macro avg     0.5039    0.5216    0.5077       185
weighted avg     0.5633    0.5676    0.5611       185

micro f-score: 0.5675675675675675

========== Train Epoch 63 ==========
Loss: 0.010	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.5622       185
   macro avg     0.4989    0.5245    0.4961       185
weighted avg     0.5583    0.5622    0.5448       185

micro f-score: 0.5621621621621622

========== Train Epoch 64 ==========
Loss: 0.013	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.5714    0.7273    0.6400        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6032    0.9744    0.7451        39

    accuracy                         0.6000       185
   macro avg     0.5592    0.5450    0.5330       185
weighted avg     0.5853    0.6000    0.5720       185

micro f-score: 0.6

Finished training!!!

Min Loss = 0.010 in epoch 62;
Max Accuracy = 62.70% in epoch 40;
Total Cost 31 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP()
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.32432432432432434, 0.33513513513513515, 0.3675675675675676, 0.43243243243243246, 0.40540540540540543, 0.42162162162162165, 0.44324324324324327, 0.3675675675675676, 0.6162162162162163, 0.5135135135135135, 0.5459459459459459, 0.6108108108108108, 0.4972972972972973, 0.6216216216216216, 0.5891891891891892, 0.5891891891891892, 0.5567567567567567, 0.5459459459459459, 0.6, 0.5081081081081081, 0.5783783783783784, 0.5405405405405406, 0.572972972972973, 0.4702702702702703, 0.4864864864864865, 0.5351351351351351, 0.4918918918918919, 0.5081081081081081, 0.5459459459459459, 0.4810810810810811, 0.5567567567567567, 0.5567567567567567, 0.5891891891891892, 0.5405405405405406, 0.5891891891891892, 0.5945945945945946, 0.6216216216216216, 0.6, 0.5783783783783784, 0.5945945945945946, 0.6270270270270271, 0.3621621621621622, 0.5459459459459459, 0.3837837837837838, 0.4648648648648649, 0.42702702702702705, 0.33513513513513515, 0.3837837837837838, 0.40540540540540543, 0.2972972972972973, 0.4972972972972973, 0.5459459459459459, 0.5297297297297298, 0.5675675675675675, 0.5513513513513514, 0.5459459459459459, 0.572972972972973, 0.6162162162162163, 0.5783783783783784, 0.5891891891891892, 0.5837837837837838, 0.5675675675675675, 0.5621621621621622, 0.6]
