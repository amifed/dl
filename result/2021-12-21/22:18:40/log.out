dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 18
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.839	Accuracy: 22.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1299    0.4545    0.2020        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2571    0.7500    0.3830        12
         qtx     0.6667    0.0444    0.0833        45
         zxx     0.3214    0.4615    0.3789        39

    accuracy                         0.2216       185
   macro avg     0.2250    0.2612    0.1708       185
weighted avg     0.2804    0.2216    0.1626       185

micro f-score: 0.22162162162162163

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.590	Accuracy: 35.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3043    0.6774    0.4200        31
         cwx     0.2917    0.3182    0.3043        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.1731    0.7500    0.2812        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.6923    0.2308    0.3462        39

    accuracy                         0.3514       185
   macro avg     0.3834    0.3557    0.2963       185
weighted avg     0.4933    0.3514    0.3433       185

micro f-score: 0.35135135135135137

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.385	Accuracy: 43.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2727    0.8710    0.4154        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.6452    0.5128    0.5714        39

    accuracy                         0.4324       185
   macro avg     0.5194    0.3449    0.3230       185
weighted avg     0.5495    0.4324    0.3990       185

micro f-score: 0.43243243243243246

========== Train Epoch 4 ==========
Loss: 1.182	Accuracy: 28.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3333    0.1613    0.2174        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6364    0.1556    0.2500        45
         zxx     0.2583    1.0000    0.4105        39

    accuracy                         0.2865       185
   macro avg     0.3387    0.2021    0.1488       185
weighted avg     0.3987    0.2865    0.2020       185

micro f-score: 0.2864864864864865

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.846	Accuracy: 37.84%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3333    0.5161    0.4051        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8182    0.2000    0.3214        45
         zxx     0.3241    0.8974    0.4762        39

    accuracy                         0.3784       185
   macro avg     0.5203    0.3371    0.2897       185
weighted avg     0.5358    0.3784    0.3101       185

micro f-score: 0.37837837837837834

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.535	Accuracy: 45.95%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.3333    0.6818    0.4478        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.4833    0.7436    0.5859        39

    accuracy                         0.4595       185
   macro avg     0.3853    0.3865    0.3581       185
weighted avg     0.4382    0.4595    0.4262       185

micro f-score: 0.4594594594594595

========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.287	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2680    0.8387    0.4062        31
         cwx     0.3659    0.6818    0.4762        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7308    0.4222    0.5352        45
         zxx     1.0000    0.1538    0.2667        39

    accuracy                         0.4054       185
   macro avg     0.5229    0.3962    0.3560       185
weighted avg     0.5813    0.4054    0.3712       185

micro f-score: 0.40540540540540543

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.160	Accuracy: 45.41%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.5769    0.6667    0.6186        45
         zxx     0.3878    0.9744    0.5547        39

    accuracy                         0.4541       185
   macro avg     0.4323    0.3400    0.2960       185
weighted avg     0.4722    0.4541    0.3726       185

micro f-score: 0.4540540540540541

========== Train Epoch 9 ==========
Loss: 0.106	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2703    0.5263    0.3571        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5968    0.8222    0.6916        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.5622       185
   macro avg     0.5634    0.4816    0.4871       185
weighted avg     0.5963    0.5622    0.5478       185

micro f-score: 0.5621621621621622

========== Train Epoch 10 ==========
Loss: 0.068	Accuracy: 48.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2857    0.7097    0.4074        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.8571    0.5333    0.6575        45
         zxx     0.5102    0.6410    0.5682        39

    accuracy                         0.4811       185
   macro avg     0.5652    0.4263    0.4426       185
weighted avg     0.5817    0.4811    0.4806       185

micro f-score: 0.4810810810810811

========== Train Epoch 11 ==========
Loss: 0.088	Accuracy: 52.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3673    0.5806    0.4500        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.5297       185
   macro avg     0.5803    0.4965    0.4740       185
weighted avg     0.5948    0.5297    0.5067       185

micro f-score: 0.5297297297297298

========== Train Epoch 12 ==========
Loss: 0.052	Accuracy: 51.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.2619    0.5789    0.3607        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.5385    0.8974    0.6731        39

    accuracy                         0.5135       185
   macro avg     0.4406    0.4658    0.4210       185
weighted avg     0.4578    0.5135    0.4589       185

micro f-score: 0.5135135135135135

========== Train Epoch 13 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.048	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5250    0.6774    0.5915        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.9167    0.4889    0.6377        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5405       185
   macro avg     0.5095    0.5255    0.4986       185
weighted avg     0.5976    0.5405    0.5475       185

micro f-score: 0.5405405405405406

========== Train Epoch 14 ==========
Loss: 0.051	Accuracy: 58.92%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5892       185
   macro avg     0.5332    0.5444    0.5366       185
weighted avg     0.5905    0.5892    0.5883       185

micro f-score: 0.5891891891891892

========== Train Epoch 15 ==========
Loss: 0.053	Accuracy: 57.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.5303    0.8974    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5177    0.5336    0.5023       185
weighted avg     0.5691    0.5730    0.5464       185

micro f-score: 0.572972972972973

========== Train Epoch 16 ==========
Loss: 0.041	Accuracy: 60.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7692    0.3226    0.4545        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.6800    0.7556    0.7158        45
         zxx     0.5139    0.9487    0.6667        39

    accuracy                         0.6000       185
   macro avg     0.6194    0.5414    0.5463       185
weighted avg     0.6231    0.6000    0.5744       185

micro f-score: 0.6

========== Train Epoch 17 ==========
Loss: 0.030	Accuracy: 52.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4222    0.6129    0.5000        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.4872    0.8444    0.6179        45
         zxx     0.8000    0.5128    0.6250        39

    accuracy                         0.5243       185
   macro avg     0.5071    0.4378    0.4339       185
weighted avg     0.5310    0.5243    0.4907       185

micro f-score: 0.5243243243243243

========== Train Epoch 18 ==========
Loss: 0.026	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3710    0.7419    0.4946        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.7931    0.5897    0.6765        39

    accuracy                         0.5622       185
   macro avg     0.5439    0.5255    0.5189       185
weighted avg     0.6080    0.5622    0.5656       185

micro f-score: 0.5621621621621622

========== Train Epoch 19 ==========
Loss: 0.050	Accuracy: 48.65%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.1622    0.7059    0.2637        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.4865       185
   macro avg     0.6441    0.5079    0.4959       185
weighted avg     0.6990    0.4865    0.5178       185

micro f-score: 0.4864864864864865

========== Train Epoch 20 ==========
Loss: 0.025	Accuracy: 53.51%	Cost 35s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.3750    0.6818    0.4839        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.5351       185
   macro avg     0.5473    0.5096    0.4472       185
weighted avg     0.6202    0.5351    0.4923       185

micro f-score: 0.5351351351351351

========== Train Epoch 21 ==========
Loss: 0.016	Accuracy: 58.92%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.5892       185
   macro avg     0.5778    0.5614    0.5437       185
weighted avg     0.6136    0.5892    0.5784       185

micro f-score: 0.5891891891891892

========== Train Epoch 22 ==========
Loss: 0.025	Accuracy: 58.38%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.5873    0.8222    0.6852        45
         zxx     0.8065    0.6410    0.7143        39

    accuracy                         0.5838       185
   macro avg     0.5614    0.5234    0.5295       185
weighted avg     0.5847    0.5838    0.5709       185

micro f-score: 0.5837837837837838

========== Train Epoch 23 ==========
Loss: 0.025	Accuracy: 61.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.4375    0.6364    0.5185        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6108       185
   macro avg     0.6128    0.5331    0.5233       185
weighted avg     0.6162    0.6108    0.5776       185

micro f-score: 0.6108108108108108

========== Train Epoch 24 ==========
Loss: 0.024	Accuracy: 54.59%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.1897    0.6471    0.2933        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8846    0.5111    0.6479        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.5459       185
   macro avg     0.6106    0.5265    0.5246       185
weighted avg     0.6702    0.5459    0.5696       185

micro f-score: 0.5459459459459459

========== Train Epoch 25 ==========
Loss: 0.024	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.4146    0.7727    0.5397        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.8667    0.6667    0.7536        39

    accuracy                         0.5730       185
   macro avg     0.5447    0.5431    0.5107       185
weighted avg     0.5948    0.5730    0.5595       185

micro f-score: 0.572972972972973

========== Train Epoch 26 ==========
Loss: 0.022	Accuracy: 62.16%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.9355    0.6444    0.7632        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6216       185
   macro avg     0.5872    0.6077    0.5799       185
weighted avg     0.6440    0.6216    0.6170       185

micro f-score: 0.6216216216216216

========== Train Epoch 27 ==========
Loss: 0.018	Accuracy: 59.46%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5606    0.9487    0.7048        39

    accuracy                         0.5946       185
   macro avg     0.5849    0.5690    0.5555       185
weighted avg     0.6176    0.5946    0.5825       185

micro f-score: 0.5945945945945946

========== Train Epoch 28 ==========
Loss: 0.020	Accuracy: 60.00%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.5000    0.6818    0.5769        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6000       185
   macro avg     0.5239    0.5489    0.5244       185
weighted avg     0.5718    0.6000    0.5761       185

micro f-score: 0.6

========== Train Epoch 29 ==========
Loss: 0.021	Accuracy: 55.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4400    0.9167    0.5946        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5568       185
   macro avg     0.5032    0.5244    0.4744       185
weighted avg     0.5419    0.5568    0.5197       185

micro f-score: 0.5567567567567567

========== Train Epoch 30 ==========
Loss: 0.015	Accuracy: 58.38%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4865    0.5806    0.5294        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.2286    0.4706    0.3077        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.7812    0.6410    0.7042        39

    accuracy                         0.5838       185
   macro avg     0.5957    0.5541    0.5531       185
weighted avg     0.6257    0.5838    0.5883       185

micro f-score: 0.5837837837837838

========== Train Epoch 31 ==========
Loss: 0.020	Accuracy: 57.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.3800    0.8636    0.5278        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8889    0.5333    0.6667        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.5730       185
   macro avg     0.5414    0.5473    0.5191       185
weighted avg     0.6037    0.5730    0.5622       185

micro f-score: 0.572972972972973

========== Train Epoch 32 ==========
Loss: 0.014	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.2963    0.7273    0.4211        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.5405       185
   macro avg     0.5313    0.4844    0.4784       185
weighted avg     0.5781    0.5405    0.5340       185

micro f-score: 0.5405405405405406

========== Train Epoch 33 ==========
Loss: 0.014	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5556    0.8974    0.6863        39

    accuracy                         0.5622       185
   macro avg     0.5388    0.5293    0.5134       185
weighted avg     0.5857    0.5622    0.5525       185

micro f-score: 0.5621621621621622

========== Train Epoch 34 ==========
Loss: 0.014	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.4471    0.9744    0.6129        39

    accuracy                         0.5405       185
   macro avg     0.5485    0.5077    0.4643       185
weighted avg     0.5882    0.5405    0.4980       185

micro f-score: 0.5405405405405406

========== Train Epoch 35 ==========
Loss: 0.016	Accuracy: 62.70%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4545    0.6452    0.5333        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6270       185
   macro avg     0.6024    0.5864    0.5716       185
weighted avg     0.6363    0.6270    0.6136       185

micro f-score: 0.6270270270270271

========== Train Epoch 36 ==========
Loss: 0.015	Accuracy: 59.46%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8182    0.2903    0.4286        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2500    0.3158    0.2791        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.6863    0.7778    0.7292        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5946       185
   macro avg     0.5741    0.5522    0.5418       185
weighted avg     0.6165    0.5946    0.5808       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.017	Accuracy: 57.84%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4348    0.6452    0.5195        31
         cwx     0.4595    0.7727    0.5763        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.9200    0.5897    0.7188        39

    accuracy                         0.5784       185
   macro avg     0.5078    0.5599    0.5171       185
weighted avg     0.5798    0.5784    0.5611       185

micro f-score: 0.5783783783783784

========== Train Epoch 38 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.051	Accuracy: 33.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2500    0.0645    0.1026        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.8182    0.2000    0.3214        45
         zxx     0.2901    0.9744    0.4471        39

    accuracy                         0.3351       185
   macro avg     0.4331    0.2664    0.2282       185
weighted avg     0.4708    0.3351    0.2702       185

micro f-score: 0.33513513513513515

========== Train Epoch 39 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.429	Accuracy: 22.70%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0841    0.4737    0.1429        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4203    0.6444    0.5088        45
         zxx     1.0000    0.0256    0.0500        39

    accuracy                         0.2270       185
   macro avg     0.3986    0.1791    0.1277       185
weighted avg     0.4885    0.2270    0.1769       185

micro f-score: 0.22702702702702704

========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.832	Accuracy: 34.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2941    0.4545    0.3571        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2963    0.6667    0.4103        12
         qtx     0.8333    0.2222    0.3509        45
         zxx     0.3153    0.8974    0.4667        39

    accuracy                         0.3459       185
   macro avg     0.3913    0.3276    0.2407       185
weighted avg     0.4261    0.3459    0.2631       185

micro f-score: 0.34594594594594597

========== Train Epoch 41 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.357	Accuracy: 25.95%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2160    0.8710    0.3462        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.1724    0.2941    0.2174        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.7143    0.1111    0.1923        45
         zxx     0.8889    0.2051    0.3333        39

    accuracy                         0.2595       185
   macro avg     0.4750    0.2365    0.1985       185
weighted avg     0.5537    0.2595    0.2235       185

micro f-score: 0.2594594594594595

========== Train Epoch 42 ==========
Loss: 0.154	Accuracy: 45.95%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.7500    0.4286        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.7097    0.5641    0.6286        39

    accuracy                         0.4595       185
   macro avg     0.3873    0.4348    0.3951       185
weighted avg     0.4630    0.4595    0.4520       185

micro f-score: 0.4594594594594595

========== Train Epoch 43 ==========
Loss: 0.077	Accuracy: 49.19%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2000    0.2353    0.2162        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.5577    0.6444    0.5979        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.4919       185
   macro avg     0.4487    0.4172    0.4187       185
weighted avg     0.4759    0.4919    0.4704       185

micro f-score: 0.4918918918918919

========== Train Epoch 44 ==========
Loss: 0.042	Accuracy: 51.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3958    0.6129    0.4810        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.1667    0.1765    0.1714        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5189       185
   macro avg     0.4650    0.4674    0.4515       185
weighted avg     0.5164    0.5189    0.5019       185

micro f-score: 0.518918918918919

========== Train Epoch 45 ==========
Loss: 0.028	Accuracy: 51.89%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.3824    0.5909    0.4643        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5189       185
   macro avg     0.4315    0.4759    0.4382       185
weighted avg     0.5203    0.5189    0.5061       185

micro f-score: 0.518918918918919

========== Train Epoch 46 ==========
Loss: 0.027	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.1765    0.1765    0.1765        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.4865    0.9231    0.6372        39

    accuracy                         0.5027       185
   macro avg     0.4573    0.4357    0.4264       185
weighted avg     0.5105    0.5027    0.4804       185

micro f-score: 0.5027027027027027

========== Train Epoch 47 ==========
Loss: 0.022	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.2143    0.3529    0.2667        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5568       185
   macro avg     0.5212    0.5090    0.5015       185
weighted avg     0.5830    0.5568    0.5543       185

micro f-score: 0.5567567567567567

========== Train Epoch 48 ==========
Loss: 0.019	Accuracy: 54.05%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5405       185
   macro avg     0.4771    0.4881    0.4697       185
weighted avg     0.5315    0.5405    0.5207       185

micro f-score: 0.5405405405405406

========== Train Epoch 49 ==========
Loss: 0.021	Accuracy: 55.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.5926    0.7111    0.6465        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5568       185
   macro avg     0.4944    0.4948    0.4831       185
weighted avg     0.5235    0.5568    0.5277       185

micro f-score: 0.5567567567567567

========== Train Epoch 50 ==========
Loss: 0.011	Accuracy: 54.59%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.2105    0.2353    0.2222        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.5714    0.9231    0.7059        39

    accuracy                         0.5459       185
   macro avg     0.4424    0.4874    0.4550       185
weighted avg     0.5110    0.5459    0.5152       185

micro f-score: 0.5459459459459459

========== Train Epoch 51 ==========
Loss: 0.016	Accuracy: 49.19%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.1379    0.2353    0.1739        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.4919       185
   macro avg     0.4191    0.4353    0.4146       185
weighted avg     0.4939    0.4919    0.4757       185

micro f-score: 0.4918918918918919

========== Train Epoch 52 ==========
Loss: 0.015	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5730       185
   macro avg     0.4437    0.5076    0.4697       185
weighted avg     0.5055    0.5730    0.5341       185

micro f-score: 0.572972972972973

========== Train Epoch 53 ==========
Loss: 0.017	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5622       185
   macro avg     0.4504    0.5191    0.4714       185
weighted avg     0.5279    0.5622    0.5353       185

micro f-score: 0.5621621621621622

========== Train Epoch 54 ==========
Loss: 0.017	Accuracy: 57.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6296    0.7556    0.6869        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.5784       185
   macro avg     0.4782    0.5167    0.4828       185
weighted avg     0.5305    0.5784    0.5439       185

micro f-score: 0.5783783783783784

========== Train Epoch 55 ==========
Loss: 0.014	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.2000    0.2353    0.2162        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5873    0.9487    0.7255        39

    accuracy                         0.5622       185
   macro avg     0.4638    0.5055    0.4727       185
weighted avg     0.5327    0.5622    0.5319       185

micro f-score: 0.5621621621621622

========== Train Epoch 56 ==========
Loss: 0.014	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.5968    0.9487    0.7327        39

    accuracy                         0.5622       185
   macro avg     0.4674    0.5103    0.4739       185
weighted avg     0.5399    0.5622    0.5317       185

micro f-score: 0.5621621621621622

========== Train Epoch 57 ==========
Loss: 0.012	Accuracy: 57.84%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.1429    0.1176    0.1290        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6000    0.9231    0.7273        39

    accuracy                         0.5784       185
   macro avg     0.4577    0.5143    0.4758       185
weighted avg     0.5325    0.5784    0.5436       185

micro f-score: 0.5783783783783784

========== Train Epoch 58 ==========
Loss: 0.013	Accuracy: 55.14%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5514       185
   macro avg     0.4351    0.4892    0.4525       185
weighted avg     0.5074    0.5514    0.5191       185

micro f-score: 0.5513513513513514

========== Train Epoch 59 ==========
Loss: 0.014	Accuracy: 54.59%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.5459       185
   macro avg     0.5027    0.4970    0.4612       185
weighted avg     0.5771    0.5459    0.5241       185

micro f-score: 0.5459459459459459

========== Train Epoch 60 ==========
Loss: 0.013	Accuracy: 58.38%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.5838       185
   macro avg     0.5015    0.5216    0.4941       185
weighted avg     0.5770    0.5838    0.5632       185

micro f-score: 0.5837837837837838

========== Train Epoch 61 ==========
Loss: 0.014	Accuracy: 56.76%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5676       185
   macro avg     0.4507    0.5034    0.4694       185
weighted avg     0.5076    0.5676    0.5299       185

micro f-score: 0.5675675675675675

========== Train Epoch 62 ==========
Loss: 0.011	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.5622       185
   macro avg     0.4561    0.4934    0.4580       185
weighted avg     0.5391    0.5622    0.5315       185

micro f-score: 0.5621621621621622

========== Train Epoch 63 ==========
Loss: 0.012	Accuracy: 55.14%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2500    0.2941    0.2703        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5514       185
   macro avg     0.4437    0.5175    0.4665       185
weighted avg     0.5252    0.5514    0.5290       185

micro f-score: 0.5513513513513514

========== Train Epoch 64 ==========
Loss: 0.011	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6667    0.8205    0.7356        39

    accuracy                         0.5622       185
   macro avg     0.4513    0.5224    0.4753       185
weighted avg     0.5242    0.5622    0.5344       185

micro f-score: 0.5621621621621622

Finished training!!!

Min Loss = 0.011 in epoch 49;
Max Accuracy = 62.70% in epoch 34;
Total Cost 36 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP()
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.22162162162162163, 0.35135135135135137, 0.43243243243243246, 0.2864864864864865, 0.3783783783783784, 0.4594594594594595, 0.40540540540540543, 0.4540540540540541, 0.5621621621621622, 0.4810810810810811, 0.5297297297297298, 0.5135135135135135, 0.5405405405405406, 0.5891891891891892, 0.572972972972973, 0.6, 0.5243243243243243, 0.5621621621621622, 0.4864864864864865, 0.5351351351351351, 0.5891891891891892, 0.5837837837837838, 0.6108108108108108, 0.5459459459459459, 0.572972972972973, 0.6216216216216216, 0.5945945945945946, 0.6, 0.5567567567567567, 0.5837837837837838, 0.572972972972973, 0.5405405405405406, 0.5621621621621622, 0.5405405405405406, 0.6270270270270271, 0.5945945945945946, 0.5783783783783784, 0.33513513513513515, 0.22702702702702704, 0.34594594594594597, 0.2594594594594595, 0.4594594594594595, 0.4918918918918919, 0.518918918918919, 0.518918918918919, 0.5027027027027027, 0.5567567567567567, 0.5405405405405406, 0.5567567567567567, 0.5459459459459459, 0.4918918918918919, 0.572972972972973, 0.5621621621621622, 0.5783783783783784, 0.5621621621621622, 0.5621621621621622, 0.5783783783783784, 0.5513513513513514, 0.5459459459459459, 0.5837837837837838, 0.5675675675675675, 0.5621621621621622, 0.5513513513513514, 0.5621621621621622]
