dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: True

parallel segmentent dataset : /home/djy/dataset/ycrcb_hsv_dataset2
msg: spp resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 18
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.822	Accuracy: 29.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1875    0.4091    0.2571        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2051    0.6667    0.3137        12
         qtx     0.3443    0.4667    0.3962        45
         zxx     0.4595    0.4359    0.4474        39

    accuracy                         0.2973       185
   macro avg     0.1709    0.2826    0.2021       185
weighted avg     0.2162    0.2973    0.2416       185

micro f-score: 0.2972972972972973

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.627	Accuracy: 36.76%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1667    0.0323    0.0541        31
         cwx     0.1972    0.6364    0.3011        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.7500    0.4286        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.5833    0.5385    0.5600        39

    accuracy                         0.3676       185
   macro avg     0.2583    0.3526    0.2684       185
weighted avg     0.3303    0.3676    0.3208       185

micro f-score: 0.3675675675675676

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.464	Accuracy: 40.54%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.3077    0.5455    0.3934        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.4528    0.6154    0.5217        39

    accuracy                         0.4054       185
   macro avg     0.3268    0.3426    0.3206       185
weighted avg     0.3920    0.4054    0.3844       185

micro f-score: 0.40540540540540543

========== Train Epoch 4 ==========
Loss: 1.232	Accuracy: 41.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3824    0.4194    0.4000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2258    0.3684    0.2800        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4384    0.7111    0.5424        45
         zxx     0.5333    0.6154    0.5714        39

    accuracy                         0.4108       185
   macro avg     0.2257    0.3020    0.2563       185
weighted avg     0.3063    0.4108    0.3482       185

micro f-score: 0.4108108108108109

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.965	Accuracy: 34.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.2657    0.9744    0.4176        39

    accuracy                         0.3405       185
   macro avg     0.3007    0.2306    0.1700       185
weighted avg     0.3433    0.3405    0.2441       185

micro f-score: 0.34054054054054056

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.648	Accuracy: 38.92%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.1250    0.8333    0.2174        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.3892       185
   macro avg     0.3787    0.3870    0.3297       185
weighted avg     0.4674    0.3892    0.3948       185

micro f-score: 0.3891891891891892

========== Train Epoch 7 ==========
Loss: 0.358	Accuracy: 50.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8889    0.2581    0.4000        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2581    0.4211    0.3200        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.4458    0.9487    0.6066        39

    accuracy                         0.5081       185
   macro avg     0.6024    0.4491    0.4471       185
weighted avg     0.6483    0.5081    0.4939       185

micro f-score: 0.5081081081081081

========== Train Epoch 8 ==========
Loss: 0.188	Accuracy: 40.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.1750    0.4118    0.2456        17
         mtx     0.1500    0.3158    0.2034        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.4848    0.8205    0.6095        39

    accuracy                         0.4000       185
   macro avg     0.4702    0.3562    0.3326       185
weighted avg     0.5184    0.4000    0.3779       185

micro f-score: 0.4000000000000001

========== Train Epoch 9 ==========
Loss: 0.121	Accuracy: 37.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.3200    0.3636    0.3404        22
         hdx     0.2143    0.3529    0.2667        17
         mtx     0.1728    0.7368    0.2800        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.9231    0.2667    0.4138        45
         zxx     0.7812    0.6410    0.7042        39

    accuracy                         0.3730       185
   macro avg     0.5350    0.3703    0.3413       185
weighted avg     0.6197    0.3730    0.3799       185

micro f-score: 0.37297297297297294

========== Train Epoch 10 ==========
Loss: 0.110	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.3256    0.6364    0.4308        22
         hdx     0.1754    0.5882    0.2703        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6923    0.2000    0.3103        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.4054       185
   macro avg     0.4176    0.4337    0.3811       185
weighted avg     0.4856    0.4054    0.3939       185

micro f-score: 0.40540540540540543

========== Train Epoch 11 ==========
Loss: 0.076	Accuracy: 51.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4000    0.5806    0.4737        31
         cwx     0.3667    0.5000    0.4231        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.7586    0.5641    0.6471        39

    accuracy                         0.5135       185
   macro avg     0.4238    0.4532    0.4322       185
weighted avg     0.4874    0.5135    0.4928       185

micro f-score: 0.5135135135135135

========== Train Epoch 12 ==========
Loss: 0.077	Accuracy: 44.86%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.6667    0.2727    0.3871        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.1724    0.2632    0.2083        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.4706    0.8889    0.6154        45
         zxx     0.9286    0.3333    0.4906        39

    accuracy                         0.4486       185
   macro avg     0.4934    0.4085    0.3932       185
weighted avg     0.5546    0.4486    0.4311       185

micro f-score: 0.4486486486486486

========== Train Epoch 13 ==========
Loss: 0.063	Accuracy: 44.32%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.2069    0.3529    0.2609        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.7391    0.3778    0.5000        45
         zxx     0.4390    0.9231    0.5950        39

    accuracy                         0.4432       185
   macro avg     0.4624    0.3923    0.3865       185
weighted avg     0.5116    0.4432    0.4266       185

micro f-score: 0.44324324324324327

========== Train Epoch 14 ==========
Loss: 0.059	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.4872    0.8444    0.6179        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5405       185
   macro avg     0.5583    0.4549    0.4436       185
weighted avg     0.5672    0.5405    0.4996       185

micro f-score: 0.5405405405405406

========== Train Epoch 15 ==========
Loss: 0.054	Accuracy: 50.81%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.4691    0.8444    0.6032        45
         zxx     0.8000    0.6154    0.6957        39

    accuracy                         0.5081       185
   macro avg     0.4832    0.4476    0.4417       185
weighted avg     0.5171    0.5081    0.4855       185

micro f-score: 0.5081081081081081

========== Train Epoch 16 ==========
Loss: 0.040	Accuracy: 54.59%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3966    0.7419    0.5169        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     0.8000    0.7179    0.7568        39

    accuracy                         0.5459       185
   macro avg     0.5048    0.5010    0.4704       185
weighted avg     0.5678    0.5459    0.5318       185

micro f-score: 0.5459459459459459

========== Train Epoch 17 ==========
Loss: 0.031	Accuracy: 52.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3158    0.3158    0.3158        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.5818    0.7111    0.6400        45
         zxx     0.5139    0.9487    0.6667        39

    accuracy                         0.5297       185
   macro avg     0.5973    0.4674    0.4416       185
weighted avg     0.5818    0.5297    0.4782       185

micro f-score: 0.5297297297297298

========== Train Epoch 18 ==========
Loss: 0.044	Accuracy: 51.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2683    0.6471    0.3793        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8750    0.3111    0.4590        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.5135       185
   macro avg     0.5212    0.5309    0.4856       185
weighted avg     0.5893    0.5135    0.5044       185

micro f-score: 0.5135135135135135

========== Train Epoch 19 ==========
Loss: 0.029	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5676       185
   macro avg     0.5104    0.5089    0.4925       185
weighted avg     0.5505    0.5676    0.5451       185

micro f-score: 0.5675675675675675

========== Train Epoch 20 ==========
Loss: 0.022	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5622       185
   macro avg     0.5540    0.5294    0.5187       185
weighted avg     0.6050    0.5622    0.5566       185

micro f-score: 0.5621621621621622

========== Train Epoch 21 ==========
Loss: 0.028	Accuracy: 57.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5730       185
   macro avg     0.5262    0.5397    0.5150       185
weighted avg     0.5699    0.5730    0.5561       185

micro f-score: 0.572972972972973

========== Train Epoch 22 ==========
Loss: 0.020	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4737    0.4737    0.4737        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5622       185
   macro avg     0.5306    0.5149    0.5086       185
weighted avg     0.5619    0.5622    0.5464       185

micro f-score: 0.5621621621621622

========== Train Epoch 23 ==========
Loss: 0.023	Accuracy: 52.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3286    0.7419    0.4554        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.8065    0.6410    0.7143        39

    accuracy                         0.5297       185
   macro avg     0.5312    0.4905    0.4640       185
weighted avg     0.5986    0.5297    0.5231       185

micro f-score: 0.5297297297297298

========== Train Epoch 24 ==========
Loss: 0.023	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2286    0.4706    0.3077        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5676       185
   macro avg     0.5674    0.5411    0.5270       185
weighted avg     0.5997    0.5676    0.5616       185

micro f-score: 0.5675675675675675

========== Train Epoch 25 ==========
Loss: 0.019	Accuracy: 52.43%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.2083    0.5882    0.3077        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.5243       185
   macro avg     0.5406    0.5315    0.5000       185
weighted avg     0.6095    0.5243    0.5259       185

micro f-score: 0.5243243243243243

========== Train Epoch 26 ==========
Loss: 0.017	Accuracy: 54.05%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7500    0.2903    0.4186        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.2051    0.4706    0.2857        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5405       185
   macro avg     0.5450    0.5139    0.4989       185
weighted avg     0.5997    0.5405    0.5413       185

micro f-score: 0.5405405405405406

========== Train Epoch 27 ==========
Loss: 0.018	Accuracy: 54.59%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4314    0.7097    0.5366        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.5459       185
   macro avg     0.4997    0.4947    0.4747       185
weighted avg     0.5441    0.5459    0.5278       185

micro f-score: 0.5459459459459459

========== Train Epoch 28 ==========
Loss: 0.017	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5676       185
   macro avg     0.5314    0.5107    0.5076       185
weighted avg     0.5961    0.5676    0.5678       185

micro f-score: 0.5675675675675675

========== Train Epoch 29 ==========
Loss: 0.019	Accuracy: 54.05%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.5405       185
   macro avg     0.4853    0.4676    0.4589       185
weighted avg     0.5304    0.5405    0.5155       185

micro f-score: 0.5405405405405406

========== Train Epoch 30 ==========
Loss: 0.012	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.2759    0.4706    0.3478        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.8214    0.5111    0.6301        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.5676       185
   macro avg     0.5601    0.5506    0.5320       185
weighted avg     0.6021    0.5676    0.5585       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.013	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.5614    0.7111    0.6275        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5525    0.5025    0.5004       185
weighted avg     0.5665    0.5622    0.5352       185

micro f-score: 0.5621621621621622

========== Train Epoch 32 ==========
Loss: 0.014	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.5962    0.6889    0.6392        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5405       185
   macro avg     0.4883    0.4732    0.4673       185
weighted avg     0.5070    0.5405    0.5125       185

micro f-score: 0.5405405405405406

========== Train Epoch 33 ==========
Loss: 0.012	Accuracy: 57.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5217    0.9231    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5561    0.5294    0.5264       185
weighted avg     0.5921    0.5730    0.5612       185

micro f-score: 0.572972972972973

========== Train Epoch 34 ==========
Loss: 0.014	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5568       185
   macro avg     0.5234    0.5075    0.4984       185
weighted avg     0.5580    0.5568    0.5431       185

micro f-score: 0.5567567567567567

========== Train Epoch 35 ==========
Loss: 0.016	Accuracy: 55.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.6200    0.6889    0.6526        45
         zxx     0.5769    0.7692    0.6593        39

    accuracy                         0.5568       185
   macro avg     0.5236    0.4968    0.4922       185
weighted avg     0.5358    0.5568    0.5328       185

micro f-score: 0.5567567567567567

========== Train Epoch 36 ==========
Loss: 0.016	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.2667    0.4706    0.3404        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.5405       185
   macro avg     0.5195    0.4854    0.4740       185
weighted avg     0.5558    0.5405    0.5189       185

micro f-score: 0.5405405405405406

========== Train Epoch 37 ==========
Loss: 0.014	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4359    0.5484    0.4857        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5568       185
   macro avg     0.4838    0.5180    0.4950       185
weighted avg     0.5307    0.5568    0.5363       185

micro f-score: 0.5567567567567567

========== Train Epoch 38 ==========
Loss: 0.011	Accuracy: 58.38%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.4444    0.4211    0.4324        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5838       185
   macro avg     0.5385    0.5502    0.5287       185
weighted avg     0.5891    0.5838    0.5709       185

micro f-score: 0.5837837837837838

========== Train Epoch 39 ==========
Loss: 0.015	Accuracy: 55.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.7576    0.6410    0.6944        39

    accuracy                         0.5568       185
   macro avg     0.5073    0.5292    0.5078       185
weighted avg     0.5609    0.5568    0.5511       185

micro f-score: 0.5567567567567567

========== Train Epoch 40 ==========
Loss: 0.014	Accuracy: 23.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.0833    1.0000    0.1538        12
         qtx     0.9231    0.2667    0.4138        45
         zxx     0.9333    0.3590    0.5185        39

    accuracy                         0.2324       185
   macro avg     0.5390    0.2695    0.2174       185
weighted avg     0.6276    0.2324    0.2655       185

micro f-score: 0.23243243243243245

========== Train Epoch 41 ==========
Loss: 0.016	Accuracy: 48.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4795    0.8974    0.6250        39

    accuracy                         0.4811       185
   macro avg     0.4605    0.4204    0.3802       185
weighted avg     0.5000    0.4811    0.4349       185

micro f-score: 0.4810810810810811

========== Train Epoch 42 ==========
Loss: 0.015	Accuracy: 55.14%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.3214    0.4737    0.3830        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5514       185
   macro avg     0.5065    0.5003    0.4938       185
weighted avg     0.5612    0.5514    0.5446       185

micro f-score: 0.5513513513513514

========== Train Epoch 43 ==========
Loss: 0.014	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.4688    0.6818    0.5556        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6458    0.6889    0.6667        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5730       185
   macro avg     0.5506    0.5206    0.4987       185
weighted avg     0.5739    0.5730    0.5478       185

micro f-score: 0.572972972972973

========== Train Epoch 44 ==========
Loss: 0.013	Accuracy: 54.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.1429    0.1176    0.1290        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5459       185
   macro avg     0.4829    0.4928    0.4796       185
weighted avg     0.5323    0.5459    0.5299       185

micro f-score: 0.5459459459459459

========== Train Epoch 45 ==========
Loss: 0.020	Accuracy: 20.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.1875    0.0968    0.1277        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.1282    0.5882    0.2105        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1351    0.8333    0.2326        12
         qtx     0.8750    0.1556    0.2642        45
         zxx     1.0000    0.0769    0.1429        39

    accuracy                         0.2000       185
   macro avg     0.4751    0.2761    0.1836       185
weighted avg     0.5945    0.2000    0.1868       185

micro f-score: 0.20000000000000004

========== Train Epoch 46 ==========
Loss: 0.561	Accuracy: 20.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2000    0.2258    0.2121        31
         cwx     0.1961    0.4545    0.2740        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1167    0.5833    0.1944        12
         qtx     0.2692    0.1556    0.1972        45
         zxx     0.6667    0.1538    0.2500        39

    accuracy                         0.2000       185
   macro avg     0.2069    0.2247    0.1611       185
weighted avg     0.2704    0.2000    0.1814       185

micro f-score: 0.20000000000000004

========== Train Epoch 47 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.149	Accuracy: 29.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2214    0.9355    0.3580        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5556    0.1111    0.1852        45
         zxx     0.4545    0.5128    0.4819        39

    accuracy                         0.2973       185
   macro avg     0.3188    0.2293    0.1589       185
weighted avg     0.3870    0.2973    0.2170       185

micro f-score: 0.2972972972972973

========== Train Epoch 48 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.457	Accuracy: 36.76%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.2857    0.9333    0.4375        45
         zxx     1.0000    0.4359    0.6071        39

    accuracy                         0.3676       185
   macro avg     0.5009    0.2684    0.2569       185
weighted avg     0.5502    0.3676    0.3105       185

micro f-score: 0.3675675675675676

========== Train Epoch 49 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.188	Accuracy: 30.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.1538    0.7059    0.2526        17
         mtx     0.1212    0.2105    0.1538        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6000    0.1333    0.2182        45
         zxx     0.5172    0.7692    0.6186        39

    accuracy                         0.3081       185
   macro avg     0.4846    0.2867    0.2266       185
weighted avg     0.5681    0.3081    0.2719       185

micro f-score: 0.3081081081081081

========== Train Epoch 50 ==========
Loss: 0.117	Accuracy: 48.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4222    0.6129    0.5000        31
         cwx     0.3548    0.5000    0.4151        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.1429    0.1053    0.1212        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.6364    0.7179    0.6747        39

    accuracy                         0.4811       185
   macro avg     0.4307    0.4001    0.3843       185
weighted avg     0.4814    0.4811    0.4591       185

micro f-score: 0.4810810810810811

========== Train Epoch 51 ==========
Loss: 0.069	Accuracy: 43.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.3333    0.5000    0.4000        22
         hdx     0.1579    0.5294    0.2432        17
         mtx     0.1333    0.1053    0.1176        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.8824    0.3333    0.4839        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.4324       185
   macro avg     0.4890    0.4042    0.3996       185
weighted avg     0.5887    0.4324    0.4570       185

micro f-score: 0.43243243243243246

========== Train Epoch 52 ==========
Loss: 0.042	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.1333    0.1176    0.1250        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3158    0.5000    0.3871        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5027       185
   macro avg     0.4343    0.4486    0.4328       185
weighted avg     0.5121    0.5027    0.4990       185

micro f-score: 0.5027027027027027

========== Train Epoch 53 ==========
Loss: 0.028	Accuracy: 50.81%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.1905    0.2353    0.2105        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.5081       185
   macro avg     0.4681    0.4415    0.4409       185
weighted avg     0.5269    0.5081    0.5016       185

micro f-score: 0.5081081081081081

========== Train Epoch 54 ==========
Loss: 0.023	Accuracy: 49.73%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.4973       185
   macro avg     0.4283    0.4305    0.4207       185
weighted avg     0.4942    0.4973    0.4853       185

micro f-score: 0.4972972972972973

========== Train Epoch 55 ==========
Loss: 0.027	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.3333    0.4091    0.3673        22
         hdx     0.2273    0.2941    0.2564        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6136    0.6000    0.6067        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.4757       185
   macro avg     0.4202    0.4133    0.4123       185
weighted avg     0.4752    0.4757    0.4715       185

micro f-score: 0.4756756756756757

========== Train Epoch 56 ==========
Loss: 0.018	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.3333    0.5000    0.4000        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6765    0.5111    0.5823        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.4811       185
   macro avg     0.4185    0.4207    0.4126       185
weighted avg     0.4807    0.4811    0.4734       185

micro f-score: 0.4810810810810811

========== Train Epoch 57 ==========
Loss: 0.017	Accuracy: 49.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.7241    0.4667    0.5676        45
         zxx     0.5439    0.7949    0.6458        39

    accuracy                         0.4973       185
   macro avg     0.4477    0.4530    0.4389       185
weighted avg     0.5053    0.4973    0.4868       185

micro f-score: 0.4972972972972973

========== Train Epoch 58 ==========
Loss: 0.016	Accuracy: 48.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6364    0.4667    0.5385        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.4865       185
   macro avg     0.4302    0.4395    0.4261       185
weighted avg     0.4863    0.4865    0.4771       185

micro f-score: 0.4864864864864865

========== Train Epoch 59 ==========
Loss: 0.018	Accuracy: 47.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6286    0.4889    0.5500        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.4757       185
   macro avg     0.4123    0.4185    0.4074       185
weighted avg     0.4662    0.4757    0.4610       185

micro f-score: 0.4756756756756757

========== Train Epoch 60 ==========
Loss: 0.015	Accuracy: 49.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.4973       185
   macro avg     0.4311    0.4354    0.4270       185
weighted avg     0.4817    0.4973    0.4827       185

micro f-score: 0.4972972972972973

========== Train Epoch 61 ==========
Loss: 0.017	Accuracy: 51.35%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6667    0.5778    0.6190        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5135       185
   macro avg     0.4557    0.4536    0.4465       185
weighted avg     0.5134    0.5135    0.5036       185

micro f-score: 0.5135135135135135

========== Train Epoch 62 ==========
Loss: 0.013	Accuracy: 47.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.6562    0.4667    0.5455        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.4757       185
   macro avg     0.4167    0.4199    0.4036       185
weighted avg     0.4797    0.4757    0.4591       185

micro f-score: 0.4756756756756757

========== Train Epoch 63 ==========
Loss: 0.016	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.4919       185
   macro avg     0.4315    0.4332    0.4242       185
weighted avg     0.4849    0.4919    0.4788       185

micro f-score: 0.4918918918918919

========== Train Epoch 64 ==========
Loss: 0.017	Accuracy: 49.73%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.8500    0.3778    0.5231        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.4973       185
   macro avg     0.4746    0.4800    0.4489       185
weighted avg     0.5415    0.4973    0.4824       185

micro f-score: 0.4972972972972973

Finished training!!!

Min Loss = 0.011 in epoch 37;
Max Accuracy = 58.38% in epoch 37;
Total Cost 37 minutes

ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (spppool): SPP()
  (convspp): Conv2d(256, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bnspp): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (reluspp): ReLU(inplace=True)
  (conv1_): Conv2d(3, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1_): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu_): ReLU(inplace=True)
  (maxpool_): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4_): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool_): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc_): Linear(in_features=512, out_features=7, bias=True)
  (__fc__): Linear(in_features=1024, out_features=7, bias=True)
)

[0.2972972972972973, 0.3675675675675676, 0.40540540540540543, 0.41081081081081083, 0.34054054054054056, 0.3891891891891892, 0.5081081081081081, 0.4, 0.372972972972973, 0.40540540540540543, 0.5135135135135135, 0.4486486486486487, 0.44324324324324327, 0.5405405405405406, 0.5081081081081081, 0.5459459459459459, 0.5297297297297298, 0.5135135135135135, 0.5675675675675675, 0.5621621621621622, 0.572972972972973, 0.5621621621621622, 0.5297297297297298, 0.5675675675675675, 0.5243243243243243, 0.5405405405405406, 0.5459459459459459, 0.5675675675675675, 0.5405405405405406, 0.5675675675675675, 0.5621621621621622, 0.5405405405405406, 0.572972972972973, 0.5567567567567567, 0.5567567567567567, 0.5405405405405406, 0.5567567567567567, 0.5837837837837838, 0.5567567567567567, 0.23243243243243245, 0.4810810810810811, 0.5513513513513514, 0.572972972972973, 0.5459459459459459, 0.2, 0.2, 0.2972972972972973, 0.3675675675675676, 0.3081081081081081, 0.4810810810810811, 0.43243243243243246, 0.5027027027027027, 0.5081081081081081, 0.4972972972972973, 0.4756756756756757, 0.4810810810810811, 0.4972972972972973, 0.4864864864864865, 0.4756756756756757, 0.4972972972972973, 0.5135135135135135, 0.4756756756756757, 0.4918918918918919, 0.4972972972972973]
