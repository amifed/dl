dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet18 cbam spp
using model: ResNet, resnet18
using device cuda:0
batch_size = 10
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.833	Accuracy: 31.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.2000    0.5000    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2143    0.2500    0.2308        12
         qtx     0.3457    0.6222    0.4444        45
         zxx     0.4444    0.2051    0.2807        39

    accuracy                         0.3135       185
   macro avg     0.2393    0.2622    0.2250       185
weighted avg     0.2943    0.3135    0.2721       185

micro f-score: 0.31351351351351353

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.663	Accuracy: 35.14%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2326    0.4545    0.3077        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5667    0.3778    0.4533        45
         zxx     0.3438    0.8462    0.4889        39

    accuracy                         0.3514       185
   macro avg     0.2549    0.2949    0.2373       185
weighted avg     0.2922    0.3514    0.2800       185

micro f-score: 0.35135135135135137

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.530	Accuracy: 40.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.1522    0.3182    0.2059        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.3333    0.5000    0.4000        12
         qtx     0.5588    0.4222    0.4810        45
         zxx     0.5000    0.7692    0.6061        39

    accuracy                         0.4000       185
   macro avg     0.3594    0.3540    0.3306       185
weighted avg     0.4068    0.4000    0.3794       185

micro f-score: 0.4000000000000001

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.485	Accuracy: 39.46%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6000    0.0968    0.1667        31
         cwx     0.3043    0.3182    0.3111        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.2500    0.8333    0.3846        12
         qtx     0.4194    0.5778    0.4860        45
         zxx     0.5227    0.5897    0.5542        39

    accuracy                         0.3946       185
   macro avg     0.3995    0.3761    0.3191       185
weighted avg     0.4349    0.3946    0.3579       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.336	Accuracy: 40.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.2391    0.5000    0.3235        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.2667    0.3333    0.2963        12
         qtx     0.4462    0.6444    0.5273        45
         zxx     0.8095    0.4359    0.5667        39

    accuracy                         0.4000       185
   macro avg     0.3938    0.3534    0.3467       185
weighted avg     0.4511    0.4000    0.3953       185

micro f-score: 0.4000000000000001

========== Train Epoch 6 ==========
Loss: 1.250	Accuracy: 48.11%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.1875    0.7500    0.3000        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.7297    0.6923    0.7105        39

    accuracy                         0.4811       185
   macro avg     0.5018    0.4444    0.4113       185
weighted avg     0.5611    0.4811    0.4822       185

micro f-score: 0.4810810810810811

========== Train Epoch 7 ==========
Loss: 1.147	Accuracy: 51.35%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.3103    0.8182    0.4500        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8400    0.4667    0.6000        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.5135       185
   macro avg     0.4975    0.4873    0.4640       185
weighted avg     0.5831    0.5135    0.5173       185

micro f-score: 0.5135135135135135

========== Train Epoch 8 ==========
Loss: 1.050	Accuracy: 51.89%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.3148    0.7727    0.4474        22
         hdx     0.2222    0.2353    0.2286        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.5189       185
   macro avg     0.4622    0.4798    0.4482       185
weighted avg     0.5562    0.5189    0.5110       185

micro f-score: 0.518918918918919

========== Train Epoch 9 ==========
Loss: 0.983	Accuracy: 51.35%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.2115    0.5789    0.3099        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.8400    0.4667    0.6000        45
         zxx     0.8182    0.6923    0.7500        39

    accuracy                         0.5135       185
   macro avg     0.5722    0.4774    0.4879       185
weighted avg     0.6240    0.5135    0.5373       185

micro f-score: 0.5135135135135135

========== Train Epoch 10 ==========
Loss: 0.782	Accuracy: 57.84%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.3692    0.7742    0.5000        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.9310    0.6000    0.7297        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.5784       185
   macro avg     0.5790    0.5203    0.4961       185
weighted avg     0.6266    0.5784    0.5561       185

micro f-score: 0.5783783783783784

========== Train Epoch 11 ==========
Loss: 0.656	Accuracy: 50.81%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.2895    0.9167    0.4400        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5081       185
   macro avg     0.4011    0.4962    0.4095       185
weighted avg     0.4694    0.5081    0.4596       185

micro f-score: 0.5081081081081081

========== Train Epoch 12 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.528	Accuracy: 50.27%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.4103    0.7273    0.5246        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.1356    0.4211    0.2051        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.5027       185
   macro avg     0.6264    0.4411    0.4414       185
weighted avg     0.6838    0.5027    0.5258       185

micro f-score: 0.5027027027027027

========== Train Epoch 13 ==========
Loss: 0.401	Accuracy: 57.30%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3056    0.6471    0.4151        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.3333    0.8333    0.4762        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5730       185
   macro avg     0.5680    0.5652    0.5217       185
weighted avg     0.6417    0.5730    0.5730       185

micro f-score: 0.572972972972973

========== Train Epoch 14 ==========
Loss: 0.301	Accuracy: 60.54%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5946    0.7097    0.6471        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.2273    0.5882    0.3279        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.6054       185
   macro avg     0.6298    0.5826    0.5825       185
weighted avg     0.6916    0.6054    0.6251       185

micro f-score: 0.6054054054054054

========== Train Epoch 15 ==========
Loss: 0.223	Accuracy: 62.16%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.3103    0.4737    0.3750        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.7727    0.8718    0.8193        39

    accuracy                         0.6216       185
   macro avg     0.6146    0.5941    0.5934       185
weighted avg     0.6724    0.6216    0.6325       185

micro f-score: 0.6216216216216216

========== Train Epoch 16 ==========
Loss: 0.187	Accuracy: 59.46%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.8000    0.1290    0.2222        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.8571    0.3529    0.5000        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.2973    0.9167    0.4490        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5625    0.9231    0.6990        39

    accuracy                         0.5946       185
   macro avg     0.6527    0.5801    0.5355       185
weighted avg     0.6908    0.5946    0.5701       185

micro f-score: 0.5945945945945946

========== Train Epoch 17 ==========
Loss: 0.137	Accuracy: 64.86%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.4651    0.6452    0.5405        31
         cwx     0.9091    0.4545    0.6061        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8684    0.7333    0.7952        45
         zxx     0.8649    0.8205    0.8421        39

    accuracy                         0.6486       185
   macro avg     0.6594    0.6101    0.6193       185
weighted avg     0.7019    0.6486    0.6612       185

micro f-score: 0.6486486486486487

========== Train Epoch 18 ==========
Loss: 0.104	Accuracy: 55.68%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     0.4545    0.9091    0.6061        22
         hdx     0.3429    0.7059    0.4615        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.9259    0.5556    0.6944        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.5568       185
   macro avg     0.5986    0.5181    0.4714       185
weighted avg     0.6315    0.5568    0.5270       185

micro f-score: 0.5567567567567567

========== Train Epoch 19 ==========
Loss: 0.110	Accuracy: 61.08%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4262    0.8387    0.5652        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.8333    0.2941    0.4348        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.9583    0.5111    0.6667        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6108       185
   macro avg     0.6233    0.5797    0.5571       185
weighted avg     0.6581    0.6108    0.5892       185

micro f-score: 0.6108108108108108

========== Train Epoch 20 ==========
Loss: 0.086	Accuracy: 63.24%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4884    0.6774    0.5676        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.5625    0.9231    0.6990        39

    accuracy                         0.6324       185
   macro avg     0.6600    0.5967    0.5994       185
weighted avg     0.6805    0.6324    0.6237       185

micro f-score: 0.6324324324324324

========== Train Epoch 21 ==========
Loss: 0.100	Accuracy: 58.92%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     1.0000    0.3182    0.4828        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3226    0.8333    0.4651        12
         qtx     0.9375    0.6667    0.7792        45
         zxx     0.5278    0.9744    0.6847        39

    accuracy                         0.5892       185
   macro avg     0.6087    0.5381    0.5081       185
weighted avg     0.6666    0.5892    0.5717       185

micro f-score: 0.5891891891891892

========== Train Epoch 22 ==========
Loss: 0.092	Accuracy: 62.16%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     1.0000    0.2941    0.4545        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.6216       185
   macro avg     0.6551    0.5751    0.5757       185
weighted avg     0.6447    0.6216    0.6053       185

micro f-score: 0.6216216216216216

========== Train Epoch 23 ==========
Loss: 0.118	Accuracy: 52.43%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.9167    0.5000    0.6471        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.3962    0.9333    0.5563        45
         zxx     0.8750    0.5385    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.6363    0.4749    0.4845       185
weighted avg     0.6308    0.5243    0.5004       185

micro f-score: 0.5243243243243243

========== Train Epoch 24 ==========
Loss: 0.096	Accuracy: 59.46%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.4286    0.8182    0.5625        22
         hdx     0.3158    0.7059    0.4364        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.8571    0.5333    0.6575        45
         zxx     0.8293    0.8718    0.8500        39

    accuracy                         0.5946       185
   macro avg     0.5875    0.5621    0.5287       185
weighted avg     0.6613    0.5946    0.5883       185

micro f-score: 0.5945945945945946

========== Train Epoch 25 ==========
Loss: 0.087	Accuracy: 55.14%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.2647    0.5294    0.3529        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.5000    0.9231    0.6486        39

    accuracy                         0.5514       185
   macro avg     0.6298    0.5175    0.5258       185
weighted avg     0.6410    0.5514    0.5486       185

micro f-score: 0.5513513513513514

========== Train Epoch 26 ==========
Loss: 0.081	Accuracy: 51.89%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.2625    0.9545    0.4118        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.5189       185
   macro avg     0.5999    0.4792    0.4650       185
weighted avg     0.6709    0.5189    0.5310       185

micro f-score: 0.518918918918919

========== Train Epoch 27 ==========
Loss: 0.097	Accuracy: 47.57%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.2151    0.9091    0.3478        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     1.0000    0.3556    0.5246        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.4757       185
   macro avg     0.6103    0.4731    0.4515       185
weighted avg     0.6922    0.4757    0.4916       185

micro f-score: 0.4756756756756757

========== Train Epoch 28 ==========
Loss: 0.114	Accuracy: 57.84%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.5784       185
   macro avg     0.5479    0.5733    0.5373       185
weighted avg     0.6084    0.5784    0.5716       185

micro f-score: 0.5783783783783784

========== Train Epoch 29 ==========
Loss: 0.080	Accuracy: 60.54%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.9000    0.2903    0.4390        31
         cwx     0.6522    0.6818    0.6667        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.3200    0.6667    0.4324        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6054       185
   macro avg     0.5771    0.5548    0.5254       185
weighted avg     0.6408    0.6054    0.5836       185

micro f-score: 0.6054054054054054

========== Train Epoch 30 ==========
Loss: 0.076	Accuracy: 69.73%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.7200    0.9231    0.8090        39

    accuracy                         0.6973       185
   macro avg     0.6617    0.6579    0.6543       185
weighted avg     0.6933    0.6973    0.6902       185

micro f-score: 0.6972972972972973

========== Train Epoch 31 ==========
Loss: 0.062	Accuracy: 56.22%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2075    0.9167    0.3385        12
         qtx     1.0000    0.6222    0.7671        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5622       185
   macro avg     0.6214    0.5280    0.4902       185
weighted avg     0.6893    0.5622    0.5641       185

micro f-score: 0.5621621621621622

========== Train Epoch 32 ==========
Loss: 0.038	Accuracy: 64.86%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8095    0.8718    0.8395        39

    accuracy                         0.6486       185
   macro avg     0.6048    0.6182    0.6007       185
weighted avg     0.6763    0.6486    0.6545       185

micro f-score: 0.6486486486486487

========== Train Epoch 33 ==========
Loss: 0.037	Accuracy: 66.49%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.7308    0.6129    0.6667        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.6649       185
   macro avg     0.6444    0.6253    0.6198       185
weighted avg     0.6757    0.6649    0.6559       185

micro f-score: 0.6648648648648648

========== Train Epoch 34 ==========
Loss: 0.032	Accuracy: 58.92%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5263    0.6452    0.5797        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.2321    0.7647    0.3562        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.9565    0.4889    0.6471        45
         zxx     0.8649    0.8205    0.8421        39

    accuracy                         0.5892       185
   macro avg     0.6495    0.5767    0.5592       185
weighted avg     0.7142    0.5892    0.6030       185

micro f-score: 0.5891891891891892

========== Train Epoch 35 ==========
Loss: 0.050	Accuracy: 59.46%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4000    0.8387    0.5417        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.5946       185
   macro avg     0.6491    0.5643    0.5771       185
weighted avg     0.6761    0.5946    0.6054       185

micro f-score: 0.5945945945945946

========== Train Epoch 36 ==========
Loss: 0.044	Accuracy: 50.81%	Cost 52s
              precision    recall  f1-score   support

         bzx     1.0000    0.1290    0.2286        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2308    0.5294    0.3214        17
         mtx     0.2500    0.6842    0.3662        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.7879    0.6667    0.7222        39

    accuracy                         0.5081       185
   macro avg     0.6167    0.4939    0.4763       185
weighted avg     0.6928    0.5081    0.5204       185

micro f-score: 0.5081081081081081

========== Train Epoch 37 ==========
Loss: 0.055	Accuracy: 57.30%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.9333    0.6364    0.7568        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.5000    0.8222    0.6218        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.5730       185
   macro avg     0.6126    0.5297    0.5430       185
weighted avg     0.6115    0.5730    0.5612       185

micro f-score: 0.572972972972973

========== Train Epoch 38 ==========
Loss: 0.083	Accuracy: 57.30%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.4568    0.9487    0.6167        39

    accuracy                         0.5730       185
   macro avg     0.6225    0.5062    0.5009       185
weighted avg     0.6051    0.5730    0.5300       185

micro f-score: 0.572972972972973

========== Train Epoch 39 ==========
Loss: 0.060	Accuracy: 58.38%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.4200    0.6774    0.5185        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.8333    0.2941    0.4348        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5838       185
   macro avg     0.5409    0.5341    0.4992       185
weighted avg     0.5882    0.5838    0.5531       185

micro f-score: 0.5837837837837838

========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.096	Accuracy: 56.76%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.8571    0.2727    0.4138        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.3023    0.6842    0.4194        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5676       185
   macro avg     0.5797    0.5221    0.5098       185
weighted avg     0.6127    0.5676    0.5579       185

micro f-score: 0.5675675675675675

========== Train Epoch 41 ==========
Loss: 0.102	Accuracy: 59.46%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.7778    0.4118    0.5385        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.3333    0.7500    0.4615        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.5147    0.8974    0.6542        39

    accuracy                         0.5946       185
   macro avg     0.6404    0.5698    0.5506       185
weighted avg     0.6797    0.5946    0.5848       185

micro f-score: 0.5945945945945946

========== Train Epoch 42 ==========
Loss: 0.087	Accuracy: 41.62%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     1.0000    0.2727    0.4286        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.1402    0.7895    0.2381        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.8636    0.4222    0.5672        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.4162       185
   macro avg     0.7118    0.3776    0.3770       185
weighted avg     0.7454    0.4162    0.4445       185

micro f-score: 0.41621621621621624

========== Train Epoch 43 ==========
Loss: 0.120	Accuracy: 41.62%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2000    0.9545    0.3307        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2941    0.4167    0.3448        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.8571    0.6154    0.7164        39

    accuracy                         0.4162       185
   macro avg     0.4497    0.3948    0.3508       185
weighted avg     0.5245    0.4162    0.4065       185

micro f-score: 0.41621621621621624

========== Train Epoch 44 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.057	Accuracy: 60.54%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.3333    0.7368    0.4590        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6054       185
   macro avg     0.5905    0.5648    0.5543       185
weighted avg     0.6460    0.6054    0.6067       185

micro f-score: 0.6054054054054054

========== Train Epoch 45 ==========
Loss: 0.058	Accuracy: 62.70%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.3200    0.4211    0.3636        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.8500    0.8718    0.8608        39

    accuracy                         0.6270       185
   macro avg     0.5815    0.5794    0.5768       185
weighted avg     0.6563    0.6270    0.6374       185

micro f-score: 0.6270270270270271

========== Train Epoch 46 ==========
Loss: 0.028	Accuracy: 64.32%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.7368    0.4516    0.5600        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6432       185
   macro avg     0.5986    0.6060    0.5892       185
weighted avg     0.6585    0.6432    0.6408       185

micro f-score: 0.6432432432432432

========== Train Epoch 47 ==========
Loss: 0.039	Accuracy: 63.24%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6324       185
   macro avg     0.5784    0.6040    0.5806       185
weighted avg     0.6378    0.6324    0.6279       185

micro f-score: 0.6324324324324324

========== Train Epoch 48 ==========
Loss: 0.021	Accuracy: 63.78%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.5714    0.7273    0.6400        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.9143    0.7111    0.8000        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6378       185
   macro avg     0.6016    0.6158    0.5938       185
weighted avg     0.6581    0.6378    0.6321       185

micro f-score: 0.6378378378378379

========== Train Epoch 49 ==========
Loss: 0.023	Accuracy: 65.95%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.7778    0.6364    0.7000        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6595       185
   macro avg     0.6339    0.6300    0.6234       185
weighted avg     0.6574    0.6595    0.6501       185

micro f-score: 0.6594594594594595

========== Train Epoch 50 ==========
Loss: 0.038	Accuracy: 63.24%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.5455    0.8182    0.6545        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.9355    0.6444    0.7632        45
         zxx     0.5373    0.9231    0.6792        39

    accuracy                         0.6324       185
   macro avg     0.6574    0.6052    0.5935       185
weighted avg     0.6847    0.6324    0.6191       185

micro f-score: 0.6324324324324324

========== Train Epoch 51 ==========
Loss: 0.030	Accuracy: 63.24%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.7647    0.5909    0.6667        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.6324       185
   macro avg     0.6068    0.5979    0.5809       185
weighted avg     0.6451    0.6324    0.6192       185

micro f-score: 0.6324324324324324

========== Train Epoch 52 ==========
Loss: 0.026	Accuracy: 65.95%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.7368    0.6364    0.6829        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.9189    0.7556    0.8293        45
         zxx     0.7857    0.8462    0.8148        39

    accuracy                         0.6595       185
   macro avg     0.6170    0.6268    0.6075       185
weighted avg     0.6905    0.6595    0.6645       185

micro f-score: 0.6594594594594595

========== Train Epoch 53 ==========
Loss: 0.032	Accuracy: 65.41%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6541       185
   macro avg     0.6425    0.6148    0.6027       185
weighted avg     0.6756    0.6541    0.6441       185

micro f-score: 0.654054054054054

========== Train Epoch 54 ==========
Loss: 0.075	Accuracy: 48.65%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.3846    0.6818    0.4918        22
         hdx     0.2286    0.4706    0.3077        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.9630    0.5778    0.7222        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.4865       185
   macro avg     0.4468    0.4405    0.3821       185
weighted avg     0.5430    0.4865    0.4421       185

micro f-score: 0.4864864864864865

========== Train Epoch 55 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.051	Accuracy: 60.54%	Cost 50s
              precision    recall  f1-score   support

         bzx     1.0000    0.2258    0.3684        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6054       185
   macro avg     0.6249    0.5902    0.5517       185
weighted avg     0.6811    0.6054    0.5914       185

micro f-score: 0.6054054054054054

========== Train Epoch 56 ==========
Loss: 0.030	Accuracy: 61.62%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.3214    0.4737    0.3830        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6162       185
   macro avg     0.6011    0.5708    0.5774       185
weighted avg     0.6382    0.6162    0.6195       185

micro f-score: 0.6162162162162163

========== Train Epoch 57 ==========
Loss: 0.034	Accuracy: 55.14%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.3860    0.7097    0.5000        31
         cwx     0.7647    0.5909    0.6667        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.2903    0.4737    0.3600        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.9412    0.3556    0.5161        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5514       185
   macro avg     0.6759    0.5148    0.5264       185
weighted avg     0.6787    0.5514    0.5492       185

micro f-score: 0.5513513513513514

========== Train Epoch 58 ==========
Loss: 0.043	Accuracy: 60.54%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.3333    0.5263    0.4082        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6054       185
   macro avg     0.6190    0.5593    0.5551       185
weighted avg     0.6495    0.6054    0.5986       185

micro f-score: 0.6054054054054054

========== Train Epoch 59 ==========
Loss: 0.035	Accuracy: 60.00%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4103    0.7273    0.5246        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.9643    0.6000    0.7397        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6000       185
   macro avg     0.6031    0.5567    0.5600       185
weighted avg     0.6541    0.6000    0.6075       185

micro f-score: 0.6

========== Train Epoch 60 ==========
Loss: 0.048	Accuracy: 58.38%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.4500    0.8182    0.5806        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5838       185
   macro avg     0.5962    0.5663    0.5013       185
weighted avg     0.6259    0.5838    0.5347       185

micro f-score: 0.5837837837837838

========== Train Epoch 61 ==========
Loss: 0.054	Accuracy: 60.00%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.6000       185
   macro avg     0.5576    0.5628    0.5528       185
weighted avg     0.6067    0.6000    0.5937       185

micro f-score: 0.6

========== Train Epoch 62 ==========
Loss: 0.041	Accuracy: 64.32%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.8235    0.6364    0.7179        22
         hdx     0.6364    0.4118    0.5000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.6432       185
   macro avg     0.6356    0.6172    0.6003       185
weighted avg     0.6653    0.6432    0.6312       185

micro f-score: 0.6432432432432432

========== Train Epoch 63 ==========
Loss: 0.044	Accuracy: 57.84%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.3623    0.8065    0.5000        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5784       185
   macro avg     0.5067    0.5135    0.4775       185
weighted avg     0.5765    0.5784    0.5477       185

micro f-score: 0.5783783783783784

========== Train Epoch 64 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.043	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.8000    0.8205    0.8101        39

    accuracy                         0.6270       185
   macro avg     0.5830    0.5956    0.5789       185
weighted avg     0.6352    0.6270    0.6241       185

micro f-score: 0.6270270270270271

Finished training!!!

Min Loss = 0.021 in epoch 47;
Max Accuracy = 69.73% in epoch 29;
Total Cost 53 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPP: 1-4                               [-1, 256, 160, 160]       --
|    └─MaxPool2d: 2-1                    [-1, 64, 160, 160]        --
|    └─MaxPool2d: 2-2                    [-1, 64, 160, 160]        --
|    └─MaxPool2d: 2-3                    [-1, 64, 160, 160]        --
├─Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
├─BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
├─ReLU: 1-7                              [-1, 64, 80, 80]          --
├─Sequential: 1-8                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-4                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-5                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-9                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-6                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         2,284
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-10                       [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-8                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         8,564
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-9                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-11                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-10                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         33,412
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-11                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
├─Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 12,072,927
Trainable params: 12,072,927
Non-trainable params: 0
Total mult-adds (G): 8.86
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 83.59
Params size (MB): 46.05
Estimated Total Size (MB): 130.82
==========================================================================================
[0.31351351351351353, 0.35135135135135137, 0.4, 0.3945945945945946, 0.4, 0.4810810810810811, 0.5135135135135135, 0.518918918918919, 0.5135135135135135, 0.5783783783783784, 0.5081081081081081, 0.5027027027027027, 0.572972972972973, 0.6054054054054054, 0.6216216216216216, 0.5945945945945946, 0.6486486486486487, 0.5567567567567567, 0.6108108108108108, 0.6324324324324324, 0.5891891891891892, 0.6216216216216216, 0.5243243243243243, 0.5945945945945946, 0.5513513513513514, 0.518918918918919, 0.4756756756756757, 0.5783783783783784, 0.6054054054054054, 0.6972972972972973, 0.5621621621621622, 0.6486486486486487, 0.6648648648648648, 0.5891891891891892, 0.5945945945945946, 0.5081081081081081, 0.572972972972973, 0.572972972972973, 0.5837837837837838, 0.5675675675675675, 0.5945945945945946, 0.41621621621621624, 0.41621621621621624, 0.6054054054054054, 0.6270270270270271, 0.6432432432432432, 0.6324324324324324, 0.6378378378378379, 0.6594594594594595, 0.6324324324324324, 0.6324324324324324, 0.6594594594594595, 0.654054054054054, 0.4864864864864865, 0.6054054054054054, 0.6162162162162163, 0.5513513513513514, 0.6054054054054054, 0.6, 0.5837837837837838, 0.6, 0.6432432432432432, 0.5783783783783784, 0.6270270270270271]
