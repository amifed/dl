dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet34 spp
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.890	Accuracy: 24.86%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2727    0.2727    0.2727        22
         hdx     0.1316    0.2941    0.1818        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2683    0.2444    0.2558        45
         zxx     0.2927    0.6154    0.3967        39

    accuracy                         0.2486       185
   macro avg     0.1379    0.2038    0.1582       185
weighted avg     0.1715    0.2486    0.1950       185

micro f-score: 0.24864864864864866

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.705	Accuracy: 25.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1905    0.1818    0.1860        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1446    0.6316    0.2353        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.7500    0.0667    0.1224        45
         zxx     0.3867    0.7436    0.5088        39

    accuracy                         0.2595       185
   macro avg     0.2102    0.2320    0.1504       185
weighted avg     0.3014    0.2595    0.1833       185

micro f-score: 0.2594594594594595

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.588	Accuracy: 34.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.1910    0.7727    0.3063        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.8750    0.3111    0.4590        45
         zxx     0.4444    0.7179    0.5490        39

    accuracy                         0.3459       185
   macro avg     0.3265    0.2950    0.2434       185
weighted avg     0.4180    0.3459    0.3049       185

micro f-score: 0.34594594594594597

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.395	Accuracy: 42.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3151    0.7419    0.4423        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.3226    0.5882    0.4167        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.5714    0.6222    0.5957        45
         zxx     0.9167    0.2821    0.4314        39

    accuracy                         0.4270       185
   macro avg     0.4533    0.3829    0.3571       185
weighted avg     0.5107    0.4270    0.4016       185

micro f-score: 0.427027027027027

========== Train Epoch 5 ==========
Loss: 1.279	Accuracy: 45.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3556    0.5161    0.4211        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.5476    0.5111    0.5287        45
         zxx     0.5303    0.8974    0.6667        39

    accuracy                         0.4595       185
   macro avg     0.4634    0.3686    0.3554       185
weighted avg     0.4759    0.4595    0.4190       185

micro f-score: 0.4594594594594595

========== Train Epoch 6 ==========
Loss: 1.063	Accuracy: 42.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.1786    0.8333    0.2941        12
         qtx     0.6304    0.6444    0.6374        45
         zxx     0.8000    0.4103    0.5424        39

    accuracy                         0.4216       185
   macro avg     0.4549    0.4073    0.3655       185
weighted avg     0.5203    0.4216    0.4268       185

micro f-score: 0.42162162162162165

========== Train Epoch 7 ==========
Loss: 0.916	Accuracy: 41.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3929    0.5789    0.4681        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.8889    0.3556    0.5079        45
         zxx     0.3274    0.9487    0.4868        39

    accuracy                         0.4162       185
   macro avg     0.4715    0.3897    0.3487       185
weighted avg     0.4871    0.4162    0.3611       185

micro f-score: 0.41621621621621624

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.776	Accuracy: 28.11%	Cost 31s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1207    0.7368    0.2074        19
         nqx     0.2759    0.6667    0.3902        12
         qtx     0.7692    0.2222    0.3448        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.2811       185
   macro avg     0.4880    0.3093    0.2371       185
weighted avg     0.6025    0.2811    0.2713       185

micro f-score: 0.2810810810810811

========== Train Epoch 9 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.575	Accuracy: 45.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.2317    0.8636    0.3654        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.2500    0.6667    0.3636        12
         qtx     0.8846    0.5111    0.6479        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.4595       185
   macro avg     0.4938    0.4352    0.3729       185
weighted avg     0.6059    0.4595    0.4483       185

micro f-score: 0.4594594594594595

========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.454	Accuracy: 29.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2500    0.0645    0.1026        31
         cwx     0.1707    0.9545    0.2897        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6364    0.4667    0.5385        45
         zxx     1.0000    0.1282    0.2273        39

    accuracy                         0.2919       185
   macro avg     0.3868    0.2699    0.2204       185
weighted avg     0.4922    0.2919    0.2684       185

micro f-score: 0.2918918918918919

========== Train Epoch 11 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.438	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.2647    0.4737    0.3396        19
         nqx     0.1930    0.9167    0.3188        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.4649       185
   macro avg     0.4488    0.4803    0.4138       185
weighted avg     0.5582    0.4649    0.4744       185

micro f-score: 0.4648648648648649

========== Train Epoch 12 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.325	Accuracy: 48.11%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.2045    0.4737    0.2857        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.4811       185
   macro avg     0.5204    0.4283    0.4168       185
weighted avg     0.5590    0.4811    0.4616       185

micro f-score: 0.4810810810810811

========== Train Epoch 13 ==========
Loss: 0.181	Accuracy: 47.03%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     1.0000    0.2353    0.3810        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.1639    0.8333    0.2740        12
         qtx     0.9048    0.4222    0.5758        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.4703       185
   macro avg     0.6092    0.4545    0.4286       185
weighted avg     0.6652    0.4703    0.4846       185

micro f-score: 0.4702702702702703

========== Train Epoch 14 ==========
Loss: 0.152	Accuracy: 57.84%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.8438    0.6923    0.7606        39

    accuracy                         0.5784       185
   macro avg     0.5173    0.5483    0.5237       185
weighted avg     0.5819    0.5784    0.5744       185

micro f-score: 0.5783783783783784

========== Train Epoch 15 ==========
Loss: 0.135	Accuracy: 47.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8947    0.3778    0.5312        45
         zxx     0.3482    1.0000    0.5166        39

    accuracy                         0.4757       185
   macro avg     0.5210    0.4370    0.4261       185
weighted avg     0.5645    0.4757    0.4460       185

micro f-score: 0.4756756756756757

========== Train Epoch 16 ==========
Loss: 0.074	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3659    0.9677    0.5310        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.8889    0.4103    0.5614        39

    accuracy                         0.5459       185
   macro avg     0.5720    0.5015    0.4915       185
weighted avg     0.6155    0.5459    0.5297       185

micro f-score: 0.5459459459459459

========== Train Epoch 17 ==========
Loss: 0.082	Accuracy: 54.05%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8889    0.5333    0.6667        45
         zxx     0.4800    0.9231    0.6316        39

    accuracy                         0.5405       185
   macro avg     0.5163    0.4909    0.4775       185
weighted avg     0.5767    0.5405    0.5248       185

micro f-score: 0.5405405405405406

========== Train Epoch 18 ==========
Loss: 0.084	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2449    0.6316    0.3529        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.5514       185
   macro avg     0.5764    0.5216    0.5280       185
weighted avg     0.6224    0.5514    0.5700       185

micro f-score: 0.5513513513513514

========== Train Epoch 19 ==========
Loss: 0.059	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.3542    0.7727    0.4857        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.8529    0.7436    0.7945        39

    accuracy                         0.5946       185
   macro avg     0.5826    0.5488    0.5464       185
weighted avg     0.6242    0.5946    0.5943       185

micro f-score: 0.5945945945945946

========== Train Epoch 20 ==========
Loss: 0.040	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2973    0.9167    0.4490        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.5784       185
   macro avg     0.5371    0.5433    0.4959       185
weighted avg     0.6234    0.5784    0.5686       185

micro f-score: 0.5783783783783784

========== Train Epoch 21 ==========
Loss: 0.034	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.3548    0.5000    0.4151        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6324       185
   macro avg     0.5759    0.5877    0.5649       185
weighted avg     0.6285    0.6324    0.6182       185

micro f-score: 0.6324324324324324

========== Train Epoch 22 ==========
Loss: 0.026	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6108       185
   macro avg     0.5648    0.5669    0.5563       185
weighted avg     0.6093    0.6108    0.6007       185

micro f-score: 0.6108108108108108

========== Train Epoch 23 ==========
Loss: 0.023	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6054       185
   macro avg     0.5545    0.5700    0.5479       185
weighted avg     0.6113    0.6054    0.5985       185

micro f-score: 0.6054054054054054

========== Train Epoch 24 ==========
Loss: 0.032	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6324       185
   macro avg     0.6020    0.6033    0.5853       185
weighted avg     0.6500    0.6324    0.6283       185

micro f-score: 0.6324324324324324

========== Train Epoch 25 ==========
Loss: 0.026	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.7292    0.8974    0.8046        39

    accuracy                         0.6108       185
   macro avg     0.5575    0.5634    0.5551       185
weighted avg     0.5977    0.6108    0.5987       185

micro f-score: 0.6108108108108108

========== Train Epoch 26 ==========
Loss: 0.031	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7037    0.6129    0.6552        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6432       185
   macro avg     0.5901    0.5959    0.5788       185
weighted avg     0.6549    0.6432    0.6392       185

micro f-score: 0.6432432432432432

========== Train Epoch 27 ==========
Loss: 0.020	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.6108       185
   macro avg     0.5790    0.5659    0.5549       185
weighted avg     0.6182    0.6108    0.5984       185

micro f-score: 0.6108108108108108

========== Train Epoch 28 ==========
Loss: 0.015	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6607    0.9487    0.7789        39

    accuracy                         0.6270       185
   macro avg     0.5879    0.5823    0.5763       185
weighted avg     0.6208    0.6270    0.6141       185

micro f-score: 0.6270270270270271

========== Train Epoch 29 ==========
Loss: 0.017	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.6324       185
   macro avg     0.5848    0.5968    0.5865       185
weighted avg     0.6341    0.6324    0.6296       185

micro f-score: 0.6324324324324324

========== Train Epoch 30 ==========
Loss: 0.014	Accuracy: 64.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6486       185
   macro avg     0.6101    0.6215    0.6139       185
weighted avg     0.6529    0.6486    0.6487       185

micro f-score: 0.6486486486486487

========== Train Epoch 31 ==========
Loss: 0.017	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5122    0.6774    0.5833        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6324       185
   macro avg     0.5918    0.5837    0.5819       185
weighted avg     0.6270    0.6324    0.6235       185

micro f-score: 0.6324324324324324

========== Train Epoch 32 ==========
Loss: 0.013	Accuracy: 66.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8537    0.7778    0.8140        45
         zxx     0.7500    0.9231    0.8276        39

    accuracy                         0.6649       185
   macro avg     0.6133    0.6198    0.6106       185
weighted avg     0.6688    0.6649    0.6612       185

micro f-score: 0.6648648648648648

========== Train Epoch 33 ==========
Loss: 0.017	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.7500    0.9231    0.8276        39

    accuracy                         0.6432       185
   macro avg     0.5930    0.6056    0.5918       185
weighted avg     0.6400    0.6432    0.6358       185

micro f-score: 0.6432432432432432

========== Train Epoch 34 ==========
Loss: 0.016	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.3333    0.6818    0.4478        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.5838       185
   macro avg     0.5511    0.5509    0.5240       185
weighted avg     0.6110    0.5838    0.5712       185

micro f-score: 0.5837837837837838

========== Train Epoch 35 ==========
Loss: 0.018	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.6667    0.9231    0.7742        39

    accuracy                         0.6108       185
   macro avg     0.5727    0.5679    0.5556       185
weighted avg     0.6067    0.6108    0.5955       185

micro f-score: 0.6108108108108108

========== Train Epoch 36 ==========
Loss: 0.024	Accuracy: 57.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4167    0.6452    0.5063        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.5730       185
   macro avg     0.5076    0.5397    0.4894       185
weighted avg     0.5924    0.5730    0.5476       185

micro f-score: 0.572972972972973

========== Train Epoch 37 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.028	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5676       185
   macro avg     0.5800    0.5018    0.5158       185
weighted avg     0.6012    0.5676    0.5612       185

micro f-score: 0.5675675675675675

========== Train Epoch 38 ==========
Loss: 0.033	Accuracy: 50.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4615    0.1935    0.2727        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2340    0.5789    0.3333        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5081       185
   macro avg     0.5488    0.4706    0.4696       185
weighted avg     0.5696    0.5081    0.5039       185

micro f-score: 0.5081081081081081

========== Train Epoch 39 ==========
Loss: 0.269	Accuracy: 37.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.2051    0.6667    0.3137        12
         qtx     0.3750    0.8000    0.5106        45
         zxx     0.6452    0.5128    0.5714        39

    accuracy                         0.3730       185
   macro avg     0.2652    0.3146    0.2421       185
weighted avg     0.3313    0.3730    0.3029       185

micro f-score: 0.37297297297297294

========== Train Epoch 40 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.962	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1618    0.9167    0.2750        12
         qtx     1.0000    0.4444    0.6154        45
         zxx     0.6279    0.6923    0.6585        39

    accuracy                         0.4108       185
   macro avg     0.5111    0.4141    0.3561       185
weighted avg     0.6384    0.4108    0.4187       185

micro f-score: 0.4108108108108109

========== Train Epoch 41 ==========
Loss: 0.580	Accuracy: 45.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3571    0.3226    0.3390        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1558    1.0000    0.2697        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.8214    0.5897    0.6866        39

    accuracy                         0.4541       185
   macro avg     0.4960    0.4431    0.3994       185
weighted avg     0.5804    0.4541    0.4743       185

micro f-score: 0.4540540540540541

========== Train Epoch 42 ==========
Loss: 0.256	Accuracy: 51.35%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.8182    0.4091    0.5455        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2174    0.2632    0.2381        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.4872    0.9744    0.6496        39

    accuracy                         0.5135       185
   macro avg     0.5385    0.4889    0.4617       185
weighted avg     0.5845    0.5135    0.4903       185

micro f-score: 0.5135135135135135

========== Train Epoch 43 ==========
Loss: 0.114	Accuracy: 49.73%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.3529    0.5455    0.4286        22
         hdx     0.2500    0.2941    0.2703        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.4667    0.7778    0.5833        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.4973       185
   macro avg     0.5255    0.4361    0.4250       185
weighted avg     0.5474    0.4973    0.4618       185

micro f-score: 0.4972972972972973

========== Train Epoch 44 ==========
Loss: 0.080	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.8387    0.5417        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6087    0.6222    0.6154        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.5459       185
   macro avg     0.5274    0.5007    0.4915       185
weighted avg     0.5710    0.5459    0.5338       185

micro f-score: 0.5459459459459459

========== Train Epoch 45 ==========
Loss: 0.045	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.9333    0.6222    0.7467        45
         zxx     0.6066    0.9487    0.7400        39

    accuracy                         0.6270       185
   macro avg     0.5855    0.5875    0.5710       185
weighted avg     0.6409    0.6270    0.6151       185

micro f-score: 0.6270270270270271

========== Train Epoch 46 ==========
Loss: 0.031	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4773    0.6774    0.5600        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6216       185
   macro avg     0.5766    0.5860    0.5728       185
weighted avg     0.6260    0.6216    0.6145       185

micro f-score: 0.6216216216216216

========== Train Epoch 47 ==========
Loss: 0.021	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5838       185
   macro avg     0.5553    0.5592    0.5414       185
weighted avg     0.6020    0.5838    0.5747       185

micro f-score: 0.5837837837837838

========== Train Epoch 48 ==========
Loss: 0.019	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6162       185
   macro avg     0.5572    0.5853    0.5618       185
weighted avg     0.6150    0.6162    0.6050       185

micro f-score: 0.6162162162162163

========== Train Epoch 49 ==========
Loss: 0.023	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.6981    0.9487    0.8043        39

    accuracy                         0.6324       185
   macro avg     0.5850    0.5978    0.5787       185
weighted avg     0.6444    0.6324    0.6258       185

micro f-score: 0.6324324324324324

========== Train Epoch 50 ==========
Loss: 0.010	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.6162       185
   macro avg     0.5702    0.5897    0.5681       185
weighted avg     0.6220    0.6162    0.6072       185

micro f-score: 0.6162162162162163

========== Train Epoch 51 ==========
Loss: 0.014	Accuracy: 65.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.9333    0.6222    0.7467        45
         zxx     0.6667    0.9744    0.7917        39

    accuracy                         0.6541       185
   macro avg     0.6053    0.6219    0.6006       185
weighted avg     0.6607    0.6541    0.6412       185

micro f-score: 0.654054054054054

========== Train Epoch 52 ==========
Loss: 0.015	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.6774    0.6364        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.9000    0.6000    0.7200        45
         zxx     0.7255    0.9487    0.8222        39

    accuracy                         0.6432       185
   macro avg     0.5839    0.6094    0.5815       185
weighted avg     0.6518    0.6432    0.6322       185

micro f-score: 0.6432432432432432

========== Train Epoch 53 ==========
Loss: 0.017	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6607    0.9487    0.7789        39

    accuracy                         0.6270       185
   macro avg     0.5665    0.5814    0.5614       185
weighted avg     0.6219    0.6270    0.6129       185

micro f-score: 0.6270270270270271

========== Train Epoch 54 ==========
Loss: 0.013	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6054       185
   macro avg     0.5521    0.5714    0.5485       185
weighted avg     0.6025    0.6054    0.5915       185

micro f-score: 0.6054054054054054

========== Train Epoch 55 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.6379    0.9487    0.7629        39

    accuracy                         0.6108       185
   macro avg     0.5699    0.5865    0.5594       185
weighted avg     0.6306    0.6108    0.5998       185

micro f-score: 0.6108108108108108

========== Train Epoch 56 ==========
Loss: 0.016	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.9310    0.6000    0.7297        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6216       185
   macro avg     0.5759    0.5967    0.5686       185
weighted avg     0.6481    0.6216    0.6181       185

micro f-score: 0.6216216216216216

========== Train Epoch 57 ==========
Loss: 0.014	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6216       185
   macro avg     0.5685    0.5901    0.5686       185
weighted avg     0.6255    0.6216    0.6136       185

micro f-score: 0.6216216216216216

========== Train Epoch 58 ==========
Loss: 0.013	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6108       185
   macro avg     0.5594    0.5761    0.5554       185
weighted avg     0.6135    0.6108    0.6014       185

micro f-score: 0.6108108108108108

========== Train Epoch 59 ==========
Loss: 0.014	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.6129    0.5507        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6054       185
   macro avg     0.5493    0.5647    0.5485       185
weighted avg     0.5974    0.6054    0.5935       185

micro f-score: 0.6054054054054054

========== Train Epoch 60 ==========
Loss: 0.017	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6545    0.9231    0.7660        39

    accuracy                         0.6324       185
   macro avg     0.5905    0.5922    0.5822       185
weighted avg     0.6283    0.6324    0.6209       185

micro f-score: 0.6324324324324324

========== Train Epoch 61 ==========
Loss: 0.013	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5968    0.9487    0.7327        39

    accuracy                         0.6162       185
   macro avg     0.5805    0.5807    0.5664       185
weighted avg     0.6298    0.6162    0.6059       185

micro f-score: 0.6162162162162163

========== Train Epoch 62 ==========
Loss: 0.015	Accuracy: 61.08%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6108       185
   macro avg     0.5632    0.5741    0.5556       185
weighted avg     0.6211    0.6108    0.6027       185

micro f-score: 0.6108108108108108

========== Train Epoch 63 ==========
Loss: 0.012	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.6162       185
   macro avg     0.5673    0.5802    0.5622       185
weighted avg     0.6192    0.6162    0.6055       185

micro f-score: 0.6162162162162163

========== Train Epoch 64 ==========
Loss: 0.012	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6108       185
   macro avg     0.5477    0.5750    0.5509       185
weighted avg     0.6135    0.6108    0.6020       185

micro f-score: 0.6108108108108108

Finished training!!!

Min Loss = 0.010 in epoch 49;
Max Accuracy = 66.49% in epoch 31;
Total Cost 32 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
ReLU: 1-3                              [-1, 64, 160, 160]        --
SPP: 1-4                               [-1, 256, 160, 160]       --
Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
ReLU: 1-7                              [-1, 64, 80, 80]          --
Sequential: 1-8                        [-1, 64, 80, 80]          --
|    BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    ReLU: 3-6                    [-1, 64, 80, 80]          --
|    BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-7                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-8             [-1, 64, 80, 80]          128
|    |    ReLU: 3-9                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-10                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-11            [-1, 64, 80, 80]          128
|    |    ReLU: 3-12                   [-1, 64, 80, 80]          --
|    BasicBlock: 2-3                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-13                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-14            [-1, 64, 80, 80]          128
|    |    ReLU: 3-15                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-16                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-17            [-1, 64, 80, 80]          128
|    |    ReLU: 3-18                   [-1, 64, 80, 80]          --
Sequential: 1-9                        [-1, 128, 40, 40]         --
|    BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-19                 [-1, 128, 40, 40]         73,728
|    |    BatchNorm2d: 3-20            [-1, 128, 40, 40]         256
|    |    ReLU: 3-21                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-22                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    Sequential: 3-24             [-1, 128, 40, 40]         8,448
|    |    ReLU: 3-25                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-5                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    ReLU: 3-28                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-29                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-30            [-1, 128, 40, 40]         256
|    |    ReLU: 3-31                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-6                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-32                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-33            [-1, 128, 40, 40]         256
|    |    ReLU: 3-34                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-35                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-36            [-1, 128, 40, 40]         256
|    |    ReLU: 3-37                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-38                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-39            [-1, 128, 40, 40]         256
|    |    ReLU: 3-40                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-41                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-42            [-1, 128, 40, 40]         256
|    |    ReLU: 3-43                   [-1, 128, 40, 40]         --
Sequential: 1-10                       [-1, 256, 20, 20]         --
|    BasicBlock: 2-8                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-44                 [-1, 256, 20, 20]         294,912
|    |    BatchNorm2d: 3-45            [-1, 256, 20, 20]         512
|    |    ReLU: 3-46                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-47                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-48            [-1, 256, 20, 20]         512
|    |    Sequential: 3-49             [-1, 256, 20, 20]         33,280
|    |    ReLU: 3-50                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-9                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-51                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    ReLU: 3-56                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-10                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-57                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-58            [-1, 256, 20, 20]         512
|    |    ReLU: 3-59                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-60                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-61            [-1, 256, 20, 20]         512
|    |    ReLU: 3-62                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-63                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-64            [-1, 256, 20, 20]         512
|    |    ReLU: 3-65                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    ReLU: 3-68                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    ReLU: 3-71                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-72                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-73            [-1, 256, 20, 20]         512
|    |    ReLU: 3-74                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-75                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-76            [-1, 256, 20, 20]         512
|    |    ReLU: 3-77                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-78                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-79            [-1, 256, 20, 20]         512
|    |    ReLU: 3-80                   [-1, 256, 20, 20]         --
Sequential: 1-11                       [-1, 512, 10, 10]         --
|    BasicBlock: 2-14                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-81                 [-1, 512, 10, 10]         1,179,648
|    |    BatchNorm2d: 3-82            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-83                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-84                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-85            [-1, 512, 10, 10]         1,024
|    |    Sequential: 3-86             [-1, 512, 10, 10]         132,096
|    |    ReLU: 3-87                   [-1, 512, 10, 10]         --
|    BasicBlock: 2-15                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-88                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-89            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-90                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-91                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-92            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-93                   [-1, 512, 10, 10]         --
|    BasicBlock: 2-16                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-94                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-99                   [-1, 512, 10, 10]         --
AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 22,091,207
Trainable params: 22,091,207
Non-trainable params: 0
Total mult-adds (G): 12.66
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 122.66
Params size (MB): 84.27
Estimated Total Size (MB): 208.10
==========================================================================================
[0.24864864864864866, 0.2594594594594595, 0.34594594594594597, 0.42702702702702705, 0.4594594594594595, 0.42162162162162165, 0.41621621621621624, 0.2810810810810811, 0.4594594594594595, 0.2918918918918919, 0.4648648648648649, 0.4810810810810811, 0.4702702702702703, 0.5783783783783784, 0.4756756756756757, 0.5459459459459459, 0.5405405405405406, 0.5513513513513514, 0.5945945945945946, 0.5783783783783784, 0.6324324324324324, 0.6108108108108108, 0.6054054054054054, 0.6324324324324324, 0.6108108108108108, 0.6432432432432432, 0.6108108108108108, 0.6270270270270271, 0.6324324324324324, 0.6486486486486487, 0.6324324324324324, 0.6648648648648648, 0.6432432432432432, 0.5837837837837838, 0.6108108108108108, 0.572972972972973, 0.5675675675675675, 0.5081081081081081, 0.372972972972973, 0.41081081081081083, 0.4540540540540541, 0.5135135135135135, 0.4972972972972973, 0.5459459459459459, 0.6270270270270271, 0.6216216216216216, 0.5837837837837838, 0.6162162162162163, 0.6324324324324324, 0.6162162162162163, 0.654054054054054, 0.6432432432432432, 0.6270270270270271, 0.6054054054054054, 0.6108108108108108, 0.6216216216216216, 0.6216216216216216, 0.6108108108108108, 0.6054054054054054, 0.6324324324324324, 0.6162162162162163, 0.6108108108108108, 0.6162162162162163, 0.6108108108108108]
