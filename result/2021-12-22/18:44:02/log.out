dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: resnet34 spp
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.918	Accuracy: 23.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1667    0.0455    0.0714        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2059    0.3684    0.2642        19
         nqx     0.1639    0.8333    0.2740        12
         qtx     0.5000    0.0667    0.1176        45
         zxx     0.3026    0.5897    0.4000        39

    accuracy                         0.2378       185
   macro avg     0.1913    0.2719    0.1610       185
weighted avg     0.2370    0.2378    0.1663       185

micro f-score: 0.23783783783783785

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.721	Accuracy: 25.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2239    0.9677    0.3636        31
         cwx     0.1304    0.1364    0.1333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     1.0000    0.0444    0.0851        45
         zxx     0.5294    0.2308    0.3214        39

    accuracy                         0.2595       185
   macro avg     0.3326    0.2447    0.1835       185
weighted avg     0.4367    0.2595    0.1900       185

micro f-score: 0.2594594594594595

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.629	Accuracy: 33.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2294    0.8065    0.3571        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4902    0.5556    0.5208        45
         zxx     0.7778    0.1795    0.2917        39

    accuracy                         0.3351       185
   macro avg     0.3949    0.2581    0.2200       185
weighted avg     0.4182    0.3351    0.2837       185

micro f-score: 0.33513513513513515

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.458	Accuracy: 18.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.2500    0.0323    0.0571        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1224    0.3529    0.1818        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.1038    0.9167    0.1864        12
         qtx     1.0000    0.0444    0.0851        45
         zxx     0.6190    0.3333    0.4333        39

    accuracy                         0.1838       185
   macro avg     0.3469    0.2475    0.1478       185
weighted avg     0.4679    0.1838    0.1598       185

micro f-score: 0.1837837837837838

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.320	Accuracy: 41.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3250    0.8387    0.4685        31
         cwx     0.3182    0.3182    0.3182        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.7500    0.3333    0.4615        45
         zxx     0.5750    0.5897    0.5823        39

    accuracy                         0.4162       185
   macro avg     0.3566    0.3467    0.3210       185
weighted avg     0.4456    0.4162    0.3904       185

micro f-score: 0.41621621621621624

========== Train Epoch 6 ==========
Loss: 1.089	Accuracy: 33.51%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4286    0.5806    0.4932        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.1071    0.4737    0.1748        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.7778    0.1556    0.2593        45
         zxx     0.7619    0.4103    0.5333        39

    accuracy                         0.3351       185
   macro avg     0.5529    0.3243    0.3242       185
weighted avg     0.5830    0.3351    0.3555       185

micro f-score: 0.33513513513513515

========== Train Epoch 7 ==========
Loss: 0.942	Accuracy: 38.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4038    0.6774    0.5060        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2115    0.9167    0.3437        12
         qtx     1.0000    0.1333    0.2353        45
         zxx     0.4203    0.7436    0.5370        39

    accuracy                         0.3838       185
   macro avg     0.3860    0.3790    0.2725       185
weighted avg     0.4925    0.3838    0.3115       185

micro f-score: 0.3837837837837838

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.769	Accuracy: 45.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3529    0.7742    0.4848        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.2000    0.2105    0.2051        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     0.6296    0.4359    0.5152        39

    accuracy                         0.4541       185
   macro avg     0.4553    0.4293    0.4081       185
weighted avg     0.5214    0.4541    0.4486       185

micro f-score: 0.4540540540540541

========== Train Epoch 9 ==========
Loss: 0.503	Accuracy: 41.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.3036    0.7727    0.4359        22
         hdx     0.8333    0.2941    0.4348        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.8889    0.1778    0.2963        45
         zxx     0.4070    0.8974    0.5600        39

    accuracy                         0.4108       185
   macro avg     0.4583    0.4151    0.3401       185
weighted avg     0.5035    0.4108    0.3401       185

micro f-score: 0.4108108108108109

========== Train Epoch 10 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.537	Accuracy: 45.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.1642    0.9167    0.2785        12
         qtx     0.6452    0.4444    0.5263        45
         zxx     0.7647    0.6667    0.7123        39

    accuracy                         0.4541       185
   macro avg     0.5677    0.4483    0.4040       185
weighted avg     0.6061    0.4541    0.4653       185

micro f-score: 0.4540540540540541

========== Train Epoch 11 ==========
Loss: 0.414	Accuracy: 32.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3750    0.4839    0.4225        31
         cwx     0.2088    0.8636    0.3363        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.1923    0.2632    0.2222        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.8000    0.0889    0.1600        45
         zxx     0.8889    0.2051    0.3333        39

    accuracy                         0.3243       185
   macro avg     0.5307    0.3687    0.3336       185
weighted avg     0.5840    0.3243    0.3057       185

micro f-score: 0.32432432432432434

========== Train Epoch 12 ==========
Loss: 0.293	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3214    0.7500    0.4500        12
         qtx     0.5469    0.7778    0.6422        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.5459       185
   macro avg     0.5861    0.4754    0.4350       185
weighted avg     0.5946    0.5459    0.5058       185

micro f-score: 0.5459459459459459

========== Train Epoch 13 ==========
Loss: 0.205	Accuracy: 55.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3448    0.8333    0.4878        12
         qtx     0.6034    0.7778    0.6796        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.5568       185
   macro avg     0.5196    0.4976    0.4590       185
weighted avg     0.5554    0.5568    0.5197       185

micro f-score: 0.5567567567567567

========== Train Epoch 14 ==========
Loss: 0.144	Accuracy: 48.11%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.2881    0.7727    0.4198        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.2381    0.5263    0.3279        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.9200    0.5897    0.7188        39

    accuracy                         0.4811       185
   macro avg     0.6195    0.4639    0.4417       185
weighted avg     0.6552    0.4811    0.4875       185

micro f-score: 0.4810810810810811

========== Train Epoch 15 ==========
Loss: 0.132	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5135    0.6129    0.5588        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6162       185
   macro avg     0.5532    0.5496    0.5371       185
weighted avg     0.5887    0.6162    0.5921       185

micro f-score: 0.6162162162162163

========== Train Epoch 16 ==========
Loss: 0.115	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.5152    0.7727    0.6182        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2692    0.3684    0.3111        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.9130    0.5385    0.6774        39

    accuracy                         0.5676       185
   macro avg     0.5634    0.5784    0.5417       185
weighted avg     0.6325    0.5676    0.5741       185

micro f-score: 0.5675675675675675

========== Train Epoch 17 ==========
Loss: 0.079	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.5588    0.9744    0.7103        39

    accuracy                         0.5676       185
   macro avg     0.5785    0.5239    0.5295       185
weighted avg     0.5837    0.5676    0.5515       185

micro f-score: 0.5675675675675675

========== Train Epoch 18 ==========
Loss: 0.065	Accuracy: 61.08%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.3333    0.5263    0.4082        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.6545    0.9231    0.7660        39

    accuracy                         0.6108       185
   macro avg     0.6040    0.5848    0.5646       185
weighted avg     0.6678    0.6108    0.6110       185

micro f-score: 0.6108108108108108

========== Train Epoch 19 ==========
Loss: 0.049	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.6429    0.5294    0.5806        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.5806    0.9231    0.7129        39

    accuracy                         0.5838       185
   macro avg     0.5490    0.5382    0.5331       185
weighted avg     0.5931    0.5838    0.5739       185

micro f-score: 0.5837837837837838

========== Train Epoch 20 ==========
Loss: 0.054	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.1667    0.2632    0.2041        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5351       185
   macro avg     0.5243    0.4587    0.4610       185
weighted avg     0.5645    0.5351    0.5223       185

micro f-score: 0.5351351351351351

========== Train Epoch 21 ==========
Loss: 0.078	Accuracy: 56.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.0909    0.0526    0.0667        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5676       185
   macro avg     0.5410    0.5208    0.5151       185
weighted avg     0.5853    0.5676    0.5596       185

micro f-score: 0.5675675675675675

========== Train Epoch 22 ==========
Loss: 0.072	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3793    0.6471    0.4783        17
         mtx     0.3103    0.4737    0.3750        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.6108       185
   macro avg     0.5873    0.5829    0.5710       185
weighted avg     0.6544    0.6108    0.6208       185

micro f-score: 0.6108108108108108

========== Train Epoch 23 ==========
Loss: 0.050	Accuracy: 56.22%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.3488    0.6818    0.4615        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6379    0.9487    0.7629        39

    accuracy                         0.5622       185
   macro avg     0.5276    0.4946    0.4750       185
weighted avg     0.5952    0.5622    0.5394       185

micro f-score: 0.5621621621621622

========== Train Epoch 24 ==========
Loss: 0.084	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.2326    0.8333    0.3636        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.5672    0.9744    0.7170        39

    accuracy                         0.5297       185
   macro avg     0.5700    0.5160    0.4588       185
weighted avg     0.6266    0.5297    0.5029       185

micro f-score: 0.5297297297297298

========== Train Epoch 25 ==========
Loss: 0.113	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.2031    0.7647    0.3210        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2812    0.7500    0.4091        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.4649       185
   macro avg     0.5692    0.4576    0.3883       185
weighted avg     0.6460    0.4649    0.4496       185

micro f-score: 0.4648648648648649

========== Train Epoch 26 ==========
Loss: 0.085	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     1.0000    0.4545    0.6250        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2692    0.7368    0.3944        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5429    0.9744    0.6972        39

    accuracy                         0.5514       185
   macro avg     0.4643    0.4493    0.4091       185
weighted avg     0.5653    0.5514    0.5113       185

micro f-score: 0.5513513513513514

========== Train Epoch 27 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.053	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.8125    0.5909    0.6842        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.4935    0.9744    0.6552        39

    accuracy                         0.5838       185
   macro avg     0.6038    0.5417    0.5481       185
weighted avg     0.6286    0.5838    0.5750       185

micro f-score: 0.5837837837837838

========== Train Epoch 28 ==========
Loss: 0.049	Accuracy: 50.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.8889    0.3636    0.5161        22
         hdx     1.0000    0.1765    0.3000        17
         mtx     0.1622    0.6316    0.2581        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.8000    0.7179    0.7568        39

    accuracy                         0.5081       185
   macro avg     0.6607    0.4499    0.4714       185
weighted avg     0.6967    0.5081    0.5416       185

micro f-score: 0.5081081081081081

========== Train Epoch 29 ==========
Loss: 0.052	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4510    0.7419    0.5610        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.6000    0.5294    0.5625        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.5965    0.7556    0.6667        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.5892       185
   macro avg     0.5949    0.5529    0.5158       185
weighted avg     0.6066    0.5892    0.5515       185

micro f-score: 0.5891891891891892

========== Train Epoch 30 ==========
Loss: 0.062	Accuracy: 52.97%	Cost 31s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.4103    0.7273    0.5246        22
         hdx     0.7500    0.5294    0.6207        17
         mtx     0.2857    0.5263    0.3704        19
         nqx     0.2692    0.5833    0.3684        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5297       185
   macro avg     0.6093    0.5324    0.4855       185
weighted avg     0.6869    0.5297    0.5179       185

micro f-score: 0.5297297297297298

========== Train Epoch 31 ==========
Loss: 0.067	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4483    0.8387    0.5843        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.7000    0.4118    0.5185        17
         mtx     0.2692    0.3684    0.3111        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.8500    0.4359    0.5763        39

    accuracy                         0.5514       185
   macro avg     0.5968    0.5436    0.5195       185
weighted avg     0.6434    0.5514    0.5505       185

micro f-score: 0.5513513513513514

========== Train Epoch 32 ==========
Loss: 0.053	Accuracy: 49.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2623    0.7273    0.3855        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.6000    0.4737    0.5294        19
         nqx     0.3226    0.8333    0.4651        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.8214    0.5897    0.6866        39

    accuracy                         0.4973       185
   macro avg     0.4812    0.4933    0.4243       185
weighted avg     0.5174    0.4973    0.4646       185

micro f-score: 0.4972972972972973

========== Train Epoch 33 ==========
Loss: 0.035	Accuracy: 56.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.5676       185
   macro avg     0.5601    0.5166    0.5217       185
weighted avg     0.5863    0.5676    0.5680       185

micro f-score: 0.5675675675675675

========== Train Epoch 34 ==========
Loss: 0.076	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3158    0.5000    0.3871        12
         qtx     0.4205    0.8222    0.5564        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.4919       185
   macro avg     0.5708    0.4113    0.3828       185
weighted avg     0.5775    0.4919    0.4320       185

micro f-score: 0.4918918918918919

========== Train Epoch 35 ==========
Loss: 0.144	Accuracy: 35.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.2571    0.5294    0.3462        17
         mtx     0.1505    0.7368    0.2500        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     1.0000    0.2667    0.4211        45
         zxx     1.0000    0.3590    0.5283        39

    accuracy                         0.3514       185
   macro avg     0.5588    0.4010    0.3761       185
weighted avg     0.6607    0.3514    0.3799       185

micro f-score: 0.35135135135135137

========== Train Epoch 36 ==========
Loss: 0.242	Accuracy: 34.05%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.6000    0.2727    0.3750        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.1458    0.3684    0.2090        19
         nqx     0.1250    0.7500    0.2143        12
         qtx     0.9091    0.2222    0.3571        45
         zxx     0.7647    0.6667    0.7123        39

    accuracy                         0.3405       185
   macro avg     0.5064    0.3564    0.3172       185
weighted avg     0.6065    0.3405    0.3617       185

micro f-score: 0.34054054054054056

========== Train Epoch 37 ==========
Loss: 0.386	Accuracy: 50.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3958    0.6129    0.4810        31
         cwx     0.3824    0.5909    0.4643        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.9474    0.4000    0.5625        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.5081       185
   macro avg     0.4787    0.4575    0.4100       185
weighted avg     0.5455    0.5081    0.4656       185

micro f-score: 0.5081081081081081

========== Train Epoch 38 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.250	Accuracy: 50.81%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.5000    0.1818    0.2667        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2727    0.4737    0.3462        19
         nqx     0.2667    0.6667    0.3810        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.5081       185
   macro avg     0.4805    0.4824    0.4508       185
weighted avg     0.5509    0.5081    0.5076       185

micro f-score: 0.5081081081081081

========== Train Epoch 39 ==========
Loss: 0.153	Accuracy: 51.35%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.3846    0.6818    0.4918        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.3235    0.5789    0.4151        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.6154    0.7111    0.6598        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.5135       185
   macro avg     0.5419    0.4893    0.4657       185
weighted avg     0.5901    0.5135    0.5038       185

micro f-score: 0.5135135135135135

========== Train Epoch 40 ==========
Loss: 0.095	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.5351       185
   macro avg     0.5303    0.4752    0.4812       185
weighted avg     0.5678    0.5351    0.5259       185

micro f-score: 0.5351351351351351

========== Train Epoch 41 ==========
Loss: 0.062	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.6275    0.7111    0.6667        45
         zxx     0.7241    0.5385    0.6176        39

    accuracy                         0.5459       185
   macro avg     0.5220    0.5287    0.4995       185
weighted avg     0.5627    0.5459    0.5361       185

micro f-score: 0.5459459459459459

========== Train Epoch 42 ==========
Loss: 0.056	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.5946       185
   macro avg     0.5388    0.5296    0.5309       185
weighted avg     0.5860    0.5946    0.5873       185

micro f-score: 0.5945945945945946

========== Train Epoch 43 ==========
Loss: 0.039	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.2857    0.4211    0.3404        19
         nqx     0.2963    0.6667    0.4103        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5351       185
   macro avg     0.5085    0.5120    0.4870       185
weighted avg     0.5846    0.5351    0.5394       185

micro f-score: 0.5351351351351351

========== Train Epoch 44 ==========
Loss: 0.029	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5676       185
   macro avg     0.5160    0.5260    0.5088       185
weighted avg     0.5738    0.5676    0.5591       185

micro f-score: 0.5675675675675675

========== Train Epoch 45 ==========
Loss: 0.018	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.6108       185
   macro avg     0.5735    0.5667    0.5612       185
weighted avg     0.6073    0.6108    0.6001       185

micro f-score: 0.6108108108108108

========== Train Epoch 46 ==========
Loss: 0.015	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6108       185
   macro avg     0.5708    0.5682    0.5611       185
weighted avg     0.6118    0.6108    0.6042       185

micro f-score: 0.6108108108108108

========== Train Epoch 47 ==========
Loss: 0.014	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5892       185
   macro avg     0.5504    0.5450    0.5380       185
weighted avg     0.5877    0.5892    0.5800       185

micro f-score: 0.5891891891891892

========== Train Epoch 48 ==========
Loss: 0.013	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5946       185
   macro avg     0.5542    0.5635    0.5490       185
weighted avg     0.5885    0.5946    0.5832       185

micro f-score: 0.5945945945945946

========== Train Epoch 49 ==========
Loss: 0.016	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5946       185
   macro avg     0.5375    0.5462    0.5350       185
weighted avg     0.5803    0.5946    0.5814       185

micro f-score: 0.5945945945945946

========== Train Epoch 50 ==========
Loss: 0.016	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.7727    0.8718    0.8193        39

    accuracy                         0.6162       185
   macro avg     0.5616    0.5751    0.5623       185
weighted avg     0.6164    0.6162    0.6111       185

micro f-score: 0.6162162162162163

========== Train Epoch 51 ==========
Loss: 0.015	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6054       185
   macro avg     0.5551    0.5597    0.5527       185
weighted avg     0.5948    0.6054    0.5962       185

micro f-score: 0.6054054054054054

========== Train Epoch 52 ==========
Loss: 0.016	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6000       185
   macro avg     0.5450    0.5620    0.5450       185
weighted avg     0.5934    0.6000    0.5907       185

micro f-score: 0.6

========== Train Epoch 53 ==========
Loss: 0.015	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.5946       185
   macro avg     0.5368    0.5576    0.5437       185
weighted avg     0.5950    0.5946    0.5918       185

micro f-score: 0.5945945945945946

========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.6216       185
   macro avg     0.5713    0.5745    0.5685       185
weighted avg     0.6160    0.6216    0.6152       185

micro f-score: 0.6216216216216216

========== Train Epoch 55 ==========
Loss: 0.012	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.6162       185
   macro avg     0.5597    0.5684    0.5625       185
weighted avg     0.6092    0.6162    0.6109       185

micro f-score: 0.6162162162162163

========== Train Epoch 56 ==========
Loss: 0.015	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8333    0.7778    0.8046        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6162       185
   macro avg     0.5534    0.5616    0.5540       185
weighted avg     0.6104    0.6162    0.6092       185

micro f-score: 0.6162162162162163

========== Train Epoch 57 ==========
Loss: 0.012	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6162       185
   macro avg     0.5546    0.5687    0.5583       185
weighted avg     0.6148    0.6162    0.6119       185

micro f-score: 0.6162162162162163

========== Train Epoch 58 ==========
Loss: 0.015	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.6270       185
   macro avg     0.5886    0.5742    0.5763       185
weighted avg     0.6218    0.6270    0.6181       185

micro f-score: 0.6270270270270271

========== Train Epoch 59 ==========
Loss: 0.014	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6324       185
   macro avg     0.5793    0.5840    0.5782       185
weighted avg     0.6270    0.6324    0.6259       185

micro f-score: 0.6324324324324324

========== Train Epoch 60 ==========
Loss: 0.011	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6108       185
   macro avg     0.5506    0.5603    0.5486       185
weighted avg     0.6013    0.6108    0.5996       185

micro f-score: 0.6108108108108108

========== Train Epoch 61 ==========
Loss: 0.014	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6324       185
   macro avg     0.5784    0.5884    0.5797       185
weighted avg     0.6224    0.6324    0.6238       185

micro f-score: 0.6324324324324324

========== Train Epoch 62 ==========
Loss: 0.011	Accuracy: 61.62%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6162       185
   macro avg     0.5597    0.5649    0.5575       185
weighted avg     0.6126    0.6162    0.6090       185

micro f-score: 0.6162162162162163

========== Train Epoch 63 ==========
Loss: 0.012	Accuracy: 63.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6378       185
   macro avg     0.5871    0.5898    0.5841       185
weighted avg     0.6303    0.6378    0.6305       185

micro f-score: 0.6378378378378379

========== Train Epoch 64 ==========
Loss: 0.012	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6162       185
   macro avg     0.5719    0.5678    0.5651       185
weighted avg     0.6153    0.6162    0.6098       185

micro f-score: 0.6162162162162163

Finished training!!!

Min Loss = 0.011 in epoch 61;
Max Accuracy = 63.78% in epoch 62;
Total Cost 33 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
ReLU: 1-3                              [-1, 64, 160, 160]        --
SPP: 1-4                               [-1, 256, 160, 160]       --
Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
ReLU: 1-7                              [-1, 64, 80, 80]          --
Sequential: 1-8                        [-1, 64, 80, 80]          --
|    BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    ReLU: 3-6                    [-1, 64, 80, 80]          --
|    BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-7                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-8             [-1, 64, 80, 80]          128
|    |    ReLU: 3-9                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-10                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-11            [-1, 64, 80, 80]          128
|    |    ReLU: 3-12                   [-1, 64, 80, 80]          --
|    BasicBlock: 2-3                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-13                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-14            [-1, 64, 80, 80]          128
|    |    ReLU: 3-15                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-16                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-17            [-1, 64, 80, 80]          128
|    |    ReLU: 3-18                   [-1, 64, 80, 80]          --
Sequential: 1-9                        [-1, 128, 40, 40]         --
|    BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-19                 [-1, 128, 40, 40]         73,728
|    |    BatchNorm2d: 3-20            [-1, 128, 40, 40]         256
|    |    ReLU: 3-21                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-22                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    Sequential: 3-24             [-1, 128, 40, 40]         8,448
|    |    ReLU: 3-25                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-5                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    ReLU: 3-28                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-29                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-30            [-1, 128, 40, 40]         256
|    |    ReLU: 3-31                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-6                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-32                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-33            [-1, 128, 40, 40]         256
|    |    ReLU: 3-34                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-35                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-36            [-1, 128, 40, 40]         256
|    |    ReLU: 3-37                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-38                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-39            [-1, 128, 40, 40]         256
|    |    ReLU: 3-40                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-41                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-42            [-1, 128, 40, 40]         256
|    |    ReLU: 3-43                   [-1, 128, 40, 40]         --
Sequential: 1-10                       [-1, 256, 20, 20]         --
|    BasicBlock: 2-8                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-44                 [-1, 256, 20, 20]         294,912
|    |    BatchNorm2d: 3-45            [-1, 256, 20, 20]         512
|    |    ReLU: 3-46                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-47                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-48            [-1, 256, 20, 20]         512
|    |    Sequential: 3-49             [-1, 256, 20, 20]         33,280
|    |    ReLU: 3-50                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-9                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-51                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    ReLU: 3-56                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-10                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-57                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-58            [-1, 256, 20, 20]         512
|    |    ReLU: 3-59                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-60                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-61            [-1, 256, 20, 20]         512
|    |    ReLU: 3-62                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-63                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-64            [-1, 256, 20, 20]         512
|    |    ReLU: 3-65                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    ReLU: 3-68                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    ReLU: 3-71                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-72                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-73            [-1, 256, 20, 20]         512
|    |    ReLU: 3-74                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-75                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-76            [-1, 256, 20, 20]         512
|    |    ReLU: 3-77                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-78                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-79            [-1, 256, 20, 20]         512
|    |    ReLU: 3-80                   [-1, 256, 20, 20]         --
Sequential: 1-11                       [-1, 512, 10, 10]         --
|    BasicBlock: 2-14                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-81                 [-1, 512, 10, 10]         1,179,648
|    |    BatchNorm2d: 3-82            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-83                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-84                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-85            [-1, 512, 10, 10]         1,024
|    |    Sequential: 3-86             [-1, 512, 10, 10]         132,096
|    |    ReLU: 3-87                   [-1, 512, 10, 10]         --
|    BasicBlock: 2-15                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-88                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-89            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-90                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-91                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-92            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-93                   [-1, 512, 10, 10]         --
|    BasicBlock: 2-16                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-94                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-99                   [-1, 512, 10, 10]         --
AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 22,091,207
Trainable params: 22,091,207
Non-trainable params: 0
Total mult-adds (G): 12.66
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 122.66
Params size (MB): 84.27
Estimated Total Size (MB): 208.10
==========================================================================================
[0.23783783783783785, 0.2594594594594595, 0.33513513513513515, 0.1837837837837838, 0.41621621621621624, 0.33513513513513515, 0.3837837837837838, 0.4540540540540541, 0.41081081081081083, 0.4540540540540541, 0.32432432432432434, 0.5459459459459459, 0.5567567567567567, 0.4810810810810811, 0.6162162162162163, 0.5675675675675675, 0.5675675675675675, 0.6108108108108108, 0.5837837837837838, 0.5351351351351351, 0.5675675675675675, 0.6108108108108108, 0.5621621621621622, 0.5297297297297298, 0.4648648648648649, 0.5513513513513514, 0.5837837837837838, 0.5081081081081081, 0.5891891891891892, 0.5297297297297298, 0.5513513513513514, 0.4972972972972973, 0.5675675675675675, 0.4918918918918919, 0.35135135135135137, 0.34054054054054056, 0.5081081081081081, 0.5081081081081081, 0.5135135135135135, 0.5351351351351351, 0.5459459459459459, 0.5945945945945946, 0.5351351351351351, 0.5675675675675675, 0.6108108108108108, 0.6108108108108108, 0.5891891891891892, 0.5945945945945946, 0.5945945945945946, 0.6162162162162163, 0.6054054054054054, 0.6, 0.5945945945945946, 0.6216216216216216, 0.6162162162162163, 0.6162162162162163, 0.6162162162162163, 0.6270270270270271, 0.6324324324324324, 0.6108108108108108, 0.6324324324324324, 0.6162162162162163, 0.6378378378378379, 0.6162162162162163]
