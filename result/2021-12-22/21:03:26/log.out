dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ResNet34_SPP_CBAM
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.865	Accuracy: 27.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.5000    0.1364    0.2143        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.2727    0.2000    0.2308        45
         zxx     0.2424    0.8205    0.3743        39

    accuracy                         0.2703       185
   macro avg     0.3268    0.2148    0.1795       185
weighted avg     0.3622    0.2703    0.2070       185

micro f-score: 0.2702702702702703

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.679	Accuracy: 38.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.2500    0.0455    0.0769        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2273    0.4167    0.2941        12
         qtx     0.4630    0.5556    0.5051        45
         zxx     0.3626    0.8462    0.5077        39

    accuracy                         0.3838       185
   macro avg     0.3463    0.3043    0.2577       185
weighted avg     0.3782    0.3838    0.3167       185

micro f-score: 0.3837837837837838

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.523	Accuracy: 41.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.2000    0.0909    0.1250        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.3393    0.9744    0.5033        39

    accuracy                         0.4108       185
   macro avg     0.4676    0.3142    0.3042       185
weighted avg     0.4591    0.4108    0.3630       185

micro f-score: 0.4108108108108109

========== Train Epoch 4 ==========
Loss: 1.343	Accuracy: 36.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.5714    0.1818    0.2759        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.6250    0.2222    0.3279        45
         zxx     0.2847    1.0000    0.4432        39

    accuracy                         0.3676       185
   macro avg     0.5755    0.2910    0.2780       185
weighted avg     0.5630    0.3676    0.3180       185

micro f-score: 0.3675675675675676

========== Train Epoch 5 ==========
Loss: 1.203	Accuracy: 45.41%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3333    0.1935    0.2449        31
         cwx     0.2903    0.8182    0.4286        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.6250    0.6410    0.6329        39

    accuracy                         0.4541       185
   macro avg     0.4426    0.4152    0.3984       185
weighted avg     0.4828    0.4541    0.4432       185

micro f-score: 0.4540540540540541

========== Train Epoch 6 ==========
Loss: 1.035	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.3261    1.0000    0.4918        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.4162       185
   macro avg     0.3661    0.2876    0.2342       185
weighted avg     0.3860    0.4162    0.3049       185

micro f-score: 0.41621621621621624

========== Train Epoch 7 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.846	Accuracy: 48.65%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.3061    0.6818    0.4225        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.4865       185
   macro avg     0.3916    0.3936    0.3562       185
weighted avg     0.4550    0.4865    0.4368       185

micro f-score: 0.4864864864864865

========== Train Epoch 8 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.709	Accuracy: 43.78%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4098    0.8065    0.5435        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.1622    0.3529    0.2222        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.3143    0.9167    0.4681        12
         qtx     0.7143    0.4444    0.5479        45
         zxx     1.0000    0.1538    0.2667        39

    accuracy                         0.4378       185
   macro avg     0.5787    0.4726    0.4186       185
weighted avg     0.6488    0.4378    0.4290       185

micro f-score: 0.43783783783783786

========== Train Epoch 9 ==========
Loss: 0.583	Accuracy: 42.70%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.3846    0.4839    0.4286        31
         cwx     0.3529    0.5455    0.4286        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.1429    0.2105    0.1702        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.5077    0.7333    0.6000        45
         zxx     1.0000    0.2564    0.4082        39

    accuracy                         0.4270       185
   macro avg     0.4942    0.3640    0.3588       185
weighted avg     0.5403    0.4270    0.4121       185

micro f-score: 0.427027027027027

========== Train Epoch 10 ==========
Loss: 0.405	Accuracy: 51.89%	Cost 31s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.7000    0.3182    0.4375        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3333    0.4737    0.3913        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.4800    0.9231    0.6316        39

    accuracy                         0.5189       185
   macro avg     0.5880    0.4643    0.4429       185
weighted avg     0.6232    0.5189    0.4764       185

micro f-score: 0.518918918918919

========== Train Epoch 11 ==========
Loss: 0.236	Accuracy: 57.30%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.3684    0.6364    0.4667        22
         hdx     0.3158    0.7059    0.4364        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.5730       185
   macro avg     0.6086    0.5494    0.5259       185
weighted avg     0.6576    0.5730    0.5679       185

micro f-score: 0.572972972972973

========== Train Epoch 12 ==========
Loss: 0.200	Accuracy: 52.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7000    0.2258    0.3415        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2432    0.4737    0.3214        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.5217    0.8000    0.6316        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5243       185
   macro avg     0.5247    0.4756    0.4339       185
weighted avg     0.5616    0.5243    0.4800       185

micro f-score: 0.5243243243243243

========== Train Epoch 13 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.191	Accuracy: 53.51%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.8889    0.3636    0.5161        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2558    0.5789    0.3548        19
         nqx     0.2353    0.6667    0.3478        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5351       185
   macro avg     0.6054    0.5079    0.4875       185
weighted avg     0.6671    0.5351    0.5462       185

micro f-score: 0.5351351351351351

========== Train Epoch 14 ==========
Loss: 0.144	Accuracy: 49.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2667    0.4706    0.3404        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2292    0.9167    0.3667        12
         qtx     0.9167    0.4889    0.6377        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.4973       185
   macro avg     0.5301    0.5040    0.4316       185
weighted avg     0.6240    0.4973    0.4911       185

micro f-score: 0.4972972972972973

========== Train Epoch 15 ==========
Loss: 0.103	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.3421    0.7647    0.4727        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.5892       185
   macro avg     0.5712    0.5717    0.5418       185
weighted avg     0.6292    0.5892    0.5821       185

micro f-score: 0.5891891891891892

========== Train Epoch 16 ==========
Loss: 0.094	Accuracy: 60.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.4231    0.9167    0.5789        12
         qtx     0.9231    0.5333    0.6761        45
         zxx     0.5556    0.8974    0.6863        39

    accuracy                         0.6000       185
   macro avg     0.6217    0.5852    0.5539       185
weighted avg     0.6597    0.6000    0.5866       185

micro f-score: 0.6

========== Train Epoch 17 ==========
Loss: 0.091	Accuracy: 64.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.8000    0.4706    0.5926        17
         mtx     0.6667    0.7368    0.7000        19
         nqx     0.3056    0.9167    0.4583        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.6432       185
   macro avg     0.6643    0.6406    0.6127       185
weighted avg     0.7028    0.6432    0.6474       185

micro f-score: 0.6432432432432432

========== Train Epoch 18 ==========
Loss: 0.100	Accuracy: 58.38%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.4348    0.5263    0.4762        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8276    0.5333    0.6486        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5838       185
   macro avg     0.5907    0.5739    0.5549       185
weighted avg     0.6302    0.5838    0.5828       185

micro f-score: 0.5837837837837838

========== Train Epoch 19 ==========
Loss: 0.077	Accuracy: 56.22%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4865    0.5806    0.5294        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.6250    0.5263    0.5714        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8077    0.4667    0.5915        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5622       185
   macro avg     0.6060    0.5408    0.5332       185
weighted avg     0.6256    0.5622    0.5511       185

micro f-score: 0.5621621621621622

========== Train Epoch 20 ==========
Loss: 0.057	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.2619    0.6471    0.3729        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5838       185
   macro avg     0.6458    0.5845    0.5546       185
weighted avg     0.6939    0.5838    0.5870       185

micro f-score: 0.5837837837837838

========== Train Epoch 21 ==========
Loss: 0.067	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4098    0.8065    0.5435        31
         cwx     0.7368    0.6364    0.6829        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.5838       185
   macro avg     0.5973    0.5668    0.5444       185
weighted avg     0.6421    0.5838    0.5812       185

micro f-score: 0.5837837837837838

========== Train Epoch 22 ==========
Loss: 0.051	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.3958    0.8636    0.5429        22
         hdx     0.2500    0.5294    0.3396        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.7931    0.5897    0.6765        39

    accuracy                         0.5514       185
   macro avg     0.5817    0.5495    0.5326       185
weighted avg     0.6485    0.5514    0.5674       185

micro f-score: 0.5513513513513514

========== Train Epoch 23 ==========
Loss: 0.038	Accuracy: 63.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.3793    0.6471    0.4783        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6378       185
   macro avg     0.6484    0.6220    0.6090       185
weighted avg     0.6640    0.6378    0.6308       185

micro f-score: 0.6378378378378379

========== Train Epoch 24 ==========
Loss: 0.043	Accuracy: 44.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.8000    0.2353    0.3636        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.9474    0.4000    0.5625        45
         zxx     0.3023    1.0000    0.4643        39

    accuracy                         0.4486       185
   macro avg     0.7316    0.3970    0.4081       185
weighted avg     0.6995    0.4486    0.4211       185

micro f-score: 0.4486486486486486

========== Train Epoch 25 ==========
Loss: 0.060	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4583    0.6471    0.5366        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.4933    0.8222    0.6167        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.5730       185
   macro avg     0.6076    0.5284    0.5117       185
weighted avg     0.6158    0.5730    0.5397       185

micro f-score: 0.572972972972973

========== Train Epoch 26 ==========
Loss: 0.054	Accuracy: 44.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.8750    0.3182    0.4667        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.1728    0.7368    0.2800        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.5909    0.6667    0.6265        39

    accuracy                         0.4432       185
   macro avg     0.5793    0.4099    0.4088       185
weighted avg     0.6208    0.4432    0.4553       185

micro f-score: 0.44324324324324327

========== Train Epoch 27 ==========
Loss: 0.087	Accuracy: 55.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8333    0.1613    0.2703        31
         cwx     0.4222    0.8636    0.5672        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.5217    0.8000    0.6316        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5568       185
   macro avg     0.5702    0.4809    0.4447       185
weighted avg     0.5742    0.5568    0.4951       185

micro f-score: 0.5567567567567567

========== Train Epoch 28 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 0.125	Accuracy: 52.97%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3846    0.6452    0.4819        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3846    0.8333    0.5263        12
         qtx     0.5424    0.7111    0.6154        45
         zxx     0.7879    0.6667    0.7222        39

    accuracy                         0.5297       185
   macro avg     0.6636    0.4855    0.4449       185
weighted avg     0.6592    0.5297    0.4950       185

micro f-score: 0.5297297297297298

========== Train Epoch 29 ==========
Loss: 0.146	Accuracy: 52.97%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.7143    0.2273    0.3448        22
         hdx     0.2333    0.8235    0.3636        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.8519    0.5897    0.6970        39

    accuracy                         0.5297       185
   macro avg     0.5924    0.5456    0.5183       185
weighted avg     0.6398    0.5297    0.5447       185

micro f-score: 0.5297297297297298

========== Train Epoch 30 ==========
Loss: 0.074	Accuracy: 53.51%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2373    0.7368    0.3590        19
         nqx     0.8571    0.5000    0.6316        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.7576    0.6410    0.6944        39

    accuracy                         0.5351       185
   macro avg     0.6210    0.5076    0.5094       185
weighted avg     0.6201    0.5351    0.5341       185

micro f-score: 0.5351351351351351

========== Train Epoch 31 ==========
Loss: 0.051	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.5294    0.5294    0.5294        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6216       185
   macro avg     0.6487    0.5869    0.5706       185
weighted avg     0.6527    0.6216    0.6028       185

micro f-score: 0.6216216216216216

========== Train Epoch 32 ==========
Loss: 0.041	Accuracy: 64.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.7619    0.7273    0.7442        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6432       185
   macro avg     0.6393    0.6329    0.6150       185
weighted avg     0.6594    0.6432    0.6321       185

micro f-score: 0.6432432432432432

========== Train Epoch 33 ==========
Loss: 0.035	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.7500    0.1765    0.2857        17
         mtx     0.2647    0.4737    0.3396        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.5833    0.7778    0.6667        45
         zxx     0.7500    0.6923    0.7200        39

    accuracy                         0.5622       185
   macro avg     0.6004    0.5184    0.5166       185
weighted avg     0.6151    0.5622    0.5566       185

micro f-score: 0.5621621621621622

========== Train Epoch 34 ==========
Loss: 0.054	Accuracy: 57.84%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.6429    0.8182    0.7200        22
         hdx     0.6667    0.2353    0.3478        17
         mtx     0.2750    0.5789    0.3729        19
         nqx     0.3333    0.9167    0.4889        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.5784       185
   macro avg     0.6067    0.5907    0.5452       185
weighted avg     0.6863    0.5784    0.5922       185

micro f-score: 0.5783783783783784

========== Train Epoch 35 ==========
Loss: 0.032	Accuracy: 62.70%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.3750    0.9545    0.5385        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.8000    0.8205    0.8101        39

    accuracy                         0.6270       185
   macro avg     0.6434    0.6086    0.5876       185
weighted avg     0.6882    0.6270    0.6233       185

micro f-score: 0.6270270270270271

========== Train Epoch 36 ==========
Loss: 0.025	Accuracy: 67.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.6552    0.8636    0.7451        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.4400    0.9167    0.5946        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6703       185
   macro avg     0.6616    0.6474    0.6194       185
weighted avg     0.6883    0.6703    0.6573       185

micro f-score: 0.6702702702702703

========== Train Epoch 37 ==========
Loss: 0.021	Accuracy: 61.62%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.6800    0.7727    0.7234        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.8276    0.5333    0.6486        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.6162       185
   macro avg     0.6511    0.6189    0.5971       185
weighted avg     0.6734    0.6162    0.6086       185

micro f-score: 0.6162162162162163

========== Train Epoch 38 ==========
Loss: 0.020	Accuracy: 68.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.7727    0.7727    0.7727        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.6429    0.4737    0.5455        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6811       185
   macro avg     0.6634    0.6604    0.6525       185
weighted avg     0.6816    0.6811    0.6749       185

micro f-score: 0.6810810810810811

========== Train Epoch 39 ==========
Loss: 0.016	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.7647    0.5909    0.6667        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     0.6875    0.9167    0.7857        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5455    0.9231    0.6857        39

    accuracy                         0.6432       185
   macro avg     0.6664    0.6227    0.6206       185
weighted avg     0.6666    0.6432    0.6318       185

micro f-score: 0.6432432432432432

========== Train Epoch 40 ==========
Loss: 0.015	Accuracy: 65.41%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.6667    0.4211    0.5161        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6541       185
   macro avg     0.6307    0.6468    0.6300       185
weighted avg     0.6620    0.6541    0.6519       185

micro f-score: 0.654054054054054

========== Train Epoch 41 ==========
Loss: 0.016	Accuracy: 63.78%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.6207    0.8182    0.7059        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6378       185
   macro avg     0.6437    0.6311    0.6072       185
weighted avg     0.6783    0.6378    0.6266       185

micro f-score: 0.6378378378378379

========== Train Epoch 42 ==========
Loss: 0.018	Accuracy: 63.24%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6324       185
   macro avg     0.6270    0.6245    0.5868       185
weighted avg     0.6548    0.6324    0.6162       185

micro f-score: 0.6324324324324324

========== Train Epoch 43 ==========
Loss: 0.015	Accuracy: 67.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7895    0.4839    0.6000        31
         cwx     0.6000    0.8182    0.6923        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.5500    0.5789    0.5641        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6757       185
   macro avg     0.6630    0.6442    0.6337       185
weighted avg     0.7005    0.6757    0.6685       185

micro f-score: 0.6756756756756757

========== Train Epoch 44 ==========
Loss: 0.015	Accuracy: 67.03%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.8182    0.8182    0.8182        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.7500    0.4737    0.5806        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6703       185
   macro avg     0.6552    0.6666    0.6448       185
weighted avg     0.6932    0.6703    0.6706       185

micro f-score: 0.6702702702702703

========== Train Epoch 45 ==========
Loss: 0.014	Accuracy: 66.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.6333    0.8636    0.7308        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.7778    0.3684    0.5000        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6649       185
   macro avg     0.6530    0.6546    0.6322       185
weighted avg     0.6696    0.6649    0.6504       185

micro f-score: 0.6648648648648648

========== Train Epoch 46 ==========
Loss: 0.017	Accuracy: 63.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.6333    0.8636    0.7308        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.6378       185
   macro avg     0.6167    0.6049    0.5920       185
weighted avg     0.6324    0.6378    0.6190       185

micro f-score: 0.6378378378378379

========== Train Epoch 47 ==========
Loss: 0.016	Accuracy: 63.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4400    0.9167    0.5946        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.6378       185
   macro avg     0.6104    0.6373    0.6034       185
weighted avg     0.6593    0.6378    0.6343       185

micro f-score: 0.6378378378378379

========== Train Epoch 48 ==========
Loss: 0.017	Accuracy: 63.24%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.6429    0.8182    0.7200        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5846    0.9744    0.7308        39

    accuracy                         0.6324       185
   macro avg     0.6678    0.6231    0.6047       185
weighted avg     0.6774    0.6324    0.6138       185

micro f-score: 0.6324324324324324

========== Train Epoch 49 ==========
Loss: 0.013	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6432       185
   macro avg     0.6060    0.6352    0.6135       185
weighted avg     0.6538    0.6432    0.6430       185

micro f-score: 0.6432432432432432

========== Train Epoch 50 ==========
Loss: 0.013	Accuracy: 66.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.6667    0.8182    0.7347        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.6649       185
   macro avg     0.6476    0.6532    0.6319       185
weighted avg     0.6698    0.6649    0.6553       185

micro f-score: 0.6648648648648648

========== Train Epoch 51 ==========
Loss: 0.010	Accuracy: 68.11%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.6957    0.7273    0.7111        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.8889    0.4211    0.5714        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6811       185
   macro avg     0.6872    0.6633    0.6501       185
weighted avg     0.6991    0.6811    0.6718       185

micro f-score: 0.6810810810810811

========== Train Epoch 52 ==========
Loss: 0.011	Accuracy: 65.95%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.6333    0.8636    0.7308        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6595       185
   macro avg     0.6558    0.6504    0.6190       185
weighted avg     0.6834    0.6595    0.6464       185

micro f-score: 0.6594594594594595

========== Train Epoch 53 ==========
Loss: 0.010	Accuracy: 67.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.7500    0.8182    0.7826        22
         hdx     0.7273    0.4706    0.5714        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6757       185
   macro avg     0.6722    0.6625    0.6459       185
weighted avg     0.6844    0.6757    0.6654       185

micro f-score: 0.6756756756756757

========== Train Epoch 54 ==========
Loss: 0.012	Accuracy: 63.78%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.7500    0.8182    0.7826        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.6378       185
   macro avg     0.6046    0.6320    0.6115       185
weighted avg     0.6498    0.6378    0.6378       185

micro f-score: 0.6378378378378379

========== Train Epoch 55 ==========
Loss: 0.015	Accuracy: 64.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.6552    0.8636    0.7451        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.6486       185
   macro avg     0.6415    0.6344    0.6231       185
weighted avg     0.6553    0.6486    0.6394       185

micro f-score: 0.6486486486486487

========== Train Epoch 56 ==========
Loss: 0.012	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6786    0.8636    0.7600        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.6378       185
   macro avg     0.6004    0.6306    0.6061       185
weighted avg     0.6438    0.6378    0.6344       185

micro f-score: 0.6378378378378379

========== Train Epoch 57 ==========
Loss: 0.014	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.6207    0.8182    0.7059        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.6432       185
   macro avg     0.6247    0.6313    0.6108       185
weighted avg     0.6563    0.6432    0.6340       185

micro f-score: 0.6432432432432432

========== Train Epoch 58 ==========
Loss: 0.013	Accuracy: 65.95%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.6207    0.8182    0.7059        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.6595       185
   macro avg     0.6309    0.6423    0.6216       185
weighted avg     0.6648    0.6595    0.6500       185

micro f-score: 0.6594594594594595

========== Train Epoch 59 ==========
Loss: 0.013	Accuracy: 64.32%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6667    0.8182    0.7347        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.6667    0.4211    0.5161        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6432       185
   macro avg     0.6166    0.6328    0.6118       185
weighted avg     0.6546    0.6432    0.6390       185

micro f-score: 0.6432432432432432

========== Train Epoch 60 ==========
Loss: 0.010	Accuracy: 64.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6429    0.8182    0.7200        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6432       185
   macro avg     0.6193    0.6304    0.6153       185
weighted avg     0.6503    0.6432    0.6374       185

micro f-score: 0.6432432432432432

========== Train Epoch 61 ==========
Loss: 0.010	Accuracy: 64.86%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.7200    0.8182    0.7660        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6486       185
   macro avg     0.6287    0.6374    0.6153       185
weighted avg     0.6664    0.6486    0.6445       185

micro f-score: 0.6486486486486487

========== Train Epoch 62 ==========
Loss: 0.011	Accuracy: 67.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6923    0.8182    0.7500        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.8000    0.4211    0.5517        19
         nqx     0.6111    0.9167    0.7333        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6757       185
   macro avg     0.6661    0.6592    0.6428       185
weighted avg     0.6806    0.6757    0.6617       185

micro f-score: 0.6756756756756757

========== Train Epoch 63 ==========
Loss: 0.009	Accuracy: 67.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.7500    0.8182    0.7826        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6757       185
   macro avg     0.6733    0.6644    0.6421       185
weighted avg     0.7011    0.6757    0.6689       185

micro f-score: 0.6756756756756757

========== Train Epoch 64 ==========
Loss: 0.010	Accuracy: 65.95%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.7826    0.8182    0.8000        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.6595       185
   macro avg     0.6493    0.6523    0.6409       185
weighted avg     0.6704    0.6595    0.6578       185

micro f-score: 0.6594594594594595

Finished training!!!

Min Loss = 0.009 in epoch 62;
Max Accuracy = 68.11% in epoch 37;
Total Cost 34 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
ReLU: 1-3                              [-1, 64, 160, 160]        --
SPP: 1-4                               [-1, 256, 160, 160]       --
|    MaxPool2d: 2-1                    [-1, 64, 160, 160]        --
|    MaxPool2d: 2-2                    [-1, 64, 160, 160]        --
|    MaxPool2d: 2-3                    [-1, 64, 160, 160]        --
Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
ReLU: 1-7                              [-1, 64, 80, 80]          --
Sequential: 1-8                        [-1, 64, 80, 80]          --
|    BasicBlock: 2-4                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    ReLU: 3-7                    [-1, 64, 80, 80]          --
|    BasicBlock: 2-5                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    ReLU: 3-14                   [-1, 64, 80, 80]          --
|    BasicBlock: 2-6                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-15                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-16            [-1, 64, 80, 80]          128
|    |    ReLU: 3-17                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-18                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-19            [-1, 64, 80, 80]          128
|    |    CBAM: 3-20                   [-1, 64, 80, 80]          680
|    |    ReLU: 3-21                   [-1, 64, 80, 80]          --
Sequential: 1-9                        [-1, 128, 40, 40]         --
|    BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-22                 [-1, 128, 40, 40]         73,728
|    |    BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    ReLU: 3-24                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-25                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-26            [-1, 128, 40, 40]         256
|    |    CBAM: 3-27                   [-1, 128, 40, 40]         2,284
|    |    Sequential: 3-28             [-1, 128, 40, 40]         8,448
|    |    ReLU: 3-29                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-8                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-30                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-31            [-1, 128, 40, 40]         256
|    |    ReLU: 3-32                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-33                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-34            [-1, 128, 40, 40]         256
|    |    CBAM: 3-35                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-36                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-9                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-37                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-38            [-1, 128, 40, 40]         256
|    |    ReLU: 3-39                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-40                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-41            [-1, 128, 40, 40]         256
|    |    CBAM: 3-42                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-43                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-10                  [-1, 128, 40, 40]         --
|    |    Conv2d: 3-44                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-45            [-1, 128, 40, 40]         256
|    |    ReLU: 3-46                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-47                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-48            [-1, 128, 40, 40]         256
|    |    CBAM: 3-49                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-50                   [-1, 128, 40, 40]         --
Sequential: 1-10                       [-1, 256, 20, 20]         --
|    BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-51                 [-1, 256, 20, 20]         294,912
|    |    BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    CBAM: 3-56                   [-1, 256, 20, 20]         8,564
|    |    Sequential: 3-57             [-1, 256, 20, 20]         33,280
|    |    ReLU: 3-58                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-59                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-60            [-1, 256, 20, 20]         512
|    |    ReLU: 3-61                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-62                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-63            [-1, 256, 20, 20]         512
|    |    CBAM: 3-64                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-65                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    ReLU: 3-68                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    CBAM: 3-71                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-72                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-14                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-73                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-74            [-1, 256, 20, 20]         512
|    |    ReLU: 3-75                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-76                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-77            [-1, 256, 20, 20]         512
|    |    CBAM: 3-78                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-79                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-15                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-80                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-81            [-1, 256, 20, 20]         512
|    |    ReLU: 3-82                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-83                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-84            [-1, 256, 20, 20]         512
|    |    CBAM: 3-85                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-86                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-16                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-87                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-88            [-1, 256, 20, 20]         512
|    |    ReLU: 3-89                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-90                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-91            [-1, 256, 20, 20]         512
|    |    CBAM: 3-92                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-93                   [-1, 256, 20, 20]         --
Sequential: 1-11                       [-1, 512, 10, 10]         --
|    BasicBlock: 2-17                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-94                 [-1, 512, 10, 10]         1,179,648
|    |    BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-99                   [-1, 512, 10, 10]         33,412
|    |    Sequential: 3-100            [-1, 512, 10, 10]         132,096
|    |    ReLU: 3-101                  [-1, 512, 10, 10]         --
|    BasicBlock: 2-18                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-102                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-103           [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-104                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-105                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-106           [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-107                  [-1, 512, 10, 10]         33,412
|    |    ReLU: 3-108                  [-1, 512, 10, 10]         --
|    BasicBlock: 2-19                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-109                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-110           [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-111                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-112                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-113           [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-114                  [-1, 512, 10, 10]         33,412
|    |    ReLU: 3-115                  [-1, 512, 10, 10]         --
AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 22,254,003
Trainable params: 22,254,003
Non-trainable params: 0
Total mult-adds (G): 12.66
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 122.66
Params size (MB): 84.89
Estimated Total Size (MB): 208.72
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 245, in <module>
    
  File "train.py", line 175, in train
    summary(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 363, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 340, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
