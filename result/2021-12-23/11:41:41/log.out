dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam_spp_resnet
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.925	Accuracy: 23.78%	Cost 105s
              precision    recall  f1-score   support

         bzx     0.2500    0.0645    0.1026        31
         cwx     0.1333    0.2727    0.1791        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.1579    0.1500        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.2188    0.1556    0.1818        45
         zxx     0.3433    0.5897    0.4340        39

    accuracy                         0.2378       185
   macro avg     0.1912    0.2129    0.1853       185
weighted avg     0.2142    0.2378    0.2058       185

micro f-score: 0.23783783783783785

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.809	Accuracy: 27.57%	Cost 106s
              precision    recall  f1-score   support

         bzx     0.1429    0.0323    0.0526        31
         cwx     0.1111    0.0455    0.0645        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.1538    0.1667    0.1600        12
         qtx     0.3714    0.2889    0.3250        45
         zxx     0.2696    0.7949    0.4026        39

    accuracy                         0.2757       185
   macro avg     0.3498    0.2132    0.1832       185
weighted avg     0.3273    0.2757    0.2181       185

micro f-score: 0.2756756756756757

========== Train Epoch 3 ==========
Loss: 1.770	Accuracy: 30.81%	Cost 108s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.1667    0.0455    0.0714        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.4783    0.4889    0.4835        45
         zxx     0.2404    0.6410    0.3497        39

    accuracy                         0.3081       185
   macro avg     0.2158    0.2313    0.2014       185
weighted avg     0.2659    0.3081    0.2588       185

micro f-score: 0.3081081081081081

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.744	Accuracy: 27.03%	Cost 100s
              precision    recall  f1-score   support

         bzx     0.2143    0.0968    0.1333        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.4286    0.2667    0.3288        45
         zxx     0.2645    0.8205    0.4000        39

    accuracy                         0.2703       185
   macro avg     0.1899    0.2005    0.1623       185
weighted avg     0.2309    0.2703    0.2076       185

micro f-score: 0.2702702702702703

========== Train Epoch 5 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.730	Accuracy: 31.35%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.2593    0.2258    0.2414        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.4118    0.3111    0.3544        45
         zxx     0.2963    0.8205    0.4354        39

    accuracy                         0.3135       185
   macro avg     0.2334    0.2372    0.2067       185
weighted avg     0.2673    0.3135    0.2559       185

micro f-score: 0.31351351351351353

========== Train Epoch 6 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.713	Accuracy: 32.43%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.4000    0.1935    0.2609        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.4444    0.4444    0.4444        45
         zxx     0.3034    0.6923    0.4219        39

    accuracy                         0.3243       185
   macro avg     0.2517    0.2473    0.2297       185
weighted avg     0.2981    0.3243    0.2864       185

micro f-score: 0.32432432432432434

========== Train Epoch 7 ==========
Loss: 1.697	Accuracy: 32.97%	Cost 94s
              precision    recall  f1-score   support

         bzx     0.3333    0.0968    0.1500        31
         cwx     0.3333    0.0909    0.1429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.1667    0.0833    0.1111        12
         qtx     0.5625    0.4000    0.4675        45
         zxx     0.2835    0.9231    0.4337        39

    accuracy                         0.3297       185
   macro avg     0.2756    0.2352    0.1989       185
weighted avg     0.3286    0.3297    0.2634       185

micro f-score: 0.32972972972972975

========== Train Epoch 8 ==========
Loss: 1.672	Accuracy: 33.51%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.2308    0.2500    0.2400        12
         qtx     0.5135    0.4222    0.4634        45
         zxx     0.3077    0.7179    0.4308        39

    accuracy                         0.3351       185
   macro avg     0.2610    0.2606    0.2378       185
weighted avg     0.3114    0.3351    0.2963       185

micro f-score: 0.33513513513513515

========== Train Epoch 9 ==========
Loss: 1.661	Accuracy: 32.97%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.3125    0.1613    0.2128        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1667    0.1667    0.1667        12
         qtx     0.4390    0.4000    0.4186        45
         zxx     0.3444    0.7949    0.4806        39

    accuracy                         0.3297       185
   macro avg     0.2416    0.2519    0.2263       185
weighted avg     0.2897    0.3297    0.2837       185

micro f-score: 0.32972972972972975

========== Train Epoch 10 ==========
Loss: 1.635	Accuracy: 36.22%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.2857    0.2581    0.2712        31
         cwx     0.2500    0.1364    0.1765        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.4400    0.4889    0.4632        45
         zxx     0.3824    0.6667    0.4860        39

    accuracy                         0.3622       185
   macro avg     0.2865    0.3035    0.2859       185
weighted avg     0.3160    0.3622    0.3278       185

micro f-score: 0.3621621621621622

========== Train Epoch 11 ==========
Loss: 1.651	Accuracy: 30.81%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.4091    0.2000    0.2687        45
         zxx     0.2661    0.7436    0.3919        39

    accuracy                         0.3081       185
   macro avg     0.3486    0.2795    0.2559       185
weighted avg     0.3557    0.3081    0.2708       185

micro f-score: 0.3081081081081081

========== Train Epoch 12 ==========
Loss: 1.607	Accuracy: 32.97%	Cost 93s
              precision    recall  f1-score   support

         bzx     0.2963    0.2581    0.2759        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.4375    0.3111    0.3636        45
         zxx     0.3297    0.7692    0.4615        39

    accuracy                         0.3297       185
   macro avg     0.2999    0.2698    0.2550       185
weighted avg     0.3272    0.3297    0.2951       185

micro f-score: 0.32972972972972975

========== Train Epoch 13 ==========
Loss: 1.592	Accuracy: 37.30%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.3448    0.3226    0.3333        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.4865    0.4000    0.4390        45
         zxx     0.3514    0.6667    0.4602        39

    accuracy                         0.3730       185
   macro avg     0.3611    0.3307    0.3301       185
weighted avg     0.3724    0.3730    0.3557       185

micro f-score: 0.37297297297297294

========== Train Epoch 14 ==========
Loss: 1.581	Accuracy: 37.30%	Cost 106s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.2174    0.2273    0.2222        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1429    0.0833    0.1053        12
         qtx     0.4444    0.4444    0.4444        45
         zxx     0.4103    0.8205    0.5470        39

    accuracy                         0.3730       185
   macro avg     0.2783    0.2796    0.2537       185
weighted avg     0.3274    0.3730    0.3257       185

micro f-score: 0.37297297297297294

========== Train Epoch 15 ==========
Loss: 1.583	Accuracy: 32.97%	Cost 105s
              precision    recall  f1-score   support

         bzx     0.3000    0.1935    0.2353        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5652    0.2889    0.3824        45
         zxx     0.2957    0.8718    0.4416        39

    accuracy                         0.3297       185
   macro avg     0.2992    0.2647    0.2400       185
weighted avg     0.3403    0.3297    0.2817       185

micro f-score: 0.32972972972972975

========== Train Epoch 16 ==========
Loss: 1.561	Accuracy: 40.54%	Cost 116s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.2632    0.2273    0.2439        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.4082    0.4444    0.4255        45
         zxx     0.4516    0.7179    0.5545        39

    accuracy                         0.4054       185
   macro avg     0.3644    0.3507    0.3410       185
weighted avg     0.3823    0.4054    0.3791       185

micro f-score: 0.40540540540540543

========== Train Epoch 17 ==========
Loss: 1.530	Accuracy: 35.68%	Cost 96s
              precision    recall  f1-score   support

         bzx     0.2727    0.3871    0.3200        31
         cwx     0.2609    0.2727    0.2667        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.1667    0.1579    0.1622        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.4884    0.4667    0.4773        45
         zxx     0.5294    0.4615    0.4932        39

    accuracy                         0.3568       185
   macro avg     0.3190    0.3138    0.3136       185
weighted avg     0.3626    0.3568    0.3568       185

micro f-score: 0.3567567567567568

========== Train Epoch 18 ==========
Loss: 1.552	Accuracy: 42.70%	Cost 95s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.2222    0.0909    0.1290        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5429    0.4222    0.4750        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.4270       185
   macro avg     0.3362    0.3535    0.3224       185
weighted avg     0.3802    0.4270    0.3772       185

micro f-score: 0.427027027027027

========== Train Epoch 19 ==========
Loss: 1.517	Accuracy: 43.78%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.6286    0.4889    0.5500        45
         zxx     0.3763    0.8974    0.5303        39

    accuracy                         0.4378       185
   macro avg     0.4174    0.3705    0.3481       185
weighted avg     0.4530    0.4378    0.3992       185

micro f-score: 0.43783783783783786

========== Train Epoch 20 ==========
Loss: 1.495	Accuracy: 46.49%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.4559    0.7949    0.5794        39

    accuracy                         0.4649       185
   macro avg     0.3980    0.3910    0.3777       185
weighted avg     0.4406    0.4649    0.4354       185

micro f-score: 0.4648648648648649

========== Train Epoch 21 ==========
Loss: 1.500	Accuracy: 41.62%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.3143    0.3548    0.3333        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.4516    0.7179    0.5545        39

    accuracy                         0.4162       185
   macro avg     0.3457    0.3537    0.3381       185
weighted avg     0.3853    0.4162    0.3892       185

micro f-score: 0.41621621621621624

========== Train Epoch 22 ==========
Loss: 1.470	Accuracy: 43.24%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.2353    0.1818    0.2051        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.4783    0.4889    0.4835        45
         zxx     0.4828    0.7179    0.5773        39

    accuracy                         0.4324       185
   macro avg     0.3679    0.3664    0.3569       185
weighted avg     0.3977    0.4324    0.4054       185

micro f-score: 0.43243243243243246

========== Train Epoch 23 ==========
Loss: 1.454	Accuracy: 45.95%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.1538    0.1667    0.1600        12
         qtx     0.5000    0.6000    0.5455        45
         zxx     0.5435    0.6410    0.5882        39

    accuracy                         0.4595       185
   macro avg     0.4015    0.3848    0.3844       185
weighted avg     0.4506    0.4595    0.4476       185

micro f-score: 0.4594594594594595

========== Train Epoch 24 ==========
Loss: 1.445	Accuracy: 49.73%	Cost 97s
              precision    recall  f1-score   support

         bzx     0.4222    0.6129    0.5000        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.6042    0.7436    0.6667        39

    accuracy                         0.4973       185
   macro avg     0.4335    0.4425    0.4228       185
weighted avg     0.4773    0.4973    0.4752       185

micro f-score: 0.4972972972972973

========== Train Epoch 25 ==========
Loss: 1.435	Accuracy: 44.86%	Cost 106s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.2500    0.4167    0.3125        12
         qtx     0.5400    0.6000    0.5684        45
         zxx     0.5263    0.7692    0.6250        39

    accuracy                         0.4486       185
   macro avg     0.3437    0.3728    0.3452       185
weighted avg     0.4048    0.4486    0.4152       185

micro f-score: 0.4486486486486486

========== Train Epoch 26 ==========
Loss: 1.412	Accuracy: 44.86%	Cost 107s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.5000    0.4000    0.4444        45
         zxx     0.4828    0.7179    0.5773        39

    accuracy                         0.4486       185
   macro avg     0.4282    0.4140    0.4044       185
weighted avg     0.4462    0.4486    0.4327       185

micro f-score: 0.4486486486486486

========== Train Epoch 27 ==========
Loss: 1.393	Accuracy: 40.54%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.4286    0.3871    0.4068        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.6000    0.4000    0.4800        45
         zxx     0.3636    0.9231    0.5217        39

    accuracy                         0.4054       185
   macro avg     0.3173    0.3190    0.2927       185
weighted avg     0.3698    0.4054    0.3540       185

micro f-score: 0.40540540540540543

========== Train Epoch 28 ==========
Loss: 1.389	Accuracy: 44.86%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.3333    0.5455    0.4138        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.2727    0.5000    0.3529        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.6296    0.4359    0.5152        39

    accuracy                         0.4486       185
   macro avg     0.4194    0.4258    0.4090       185
weighted avg     0.4755    0.4486    0.4513       185

micro f-score: 0.4486486486486486

========== Train Epoch 29 ==========
Loss: 1.337	Accuracy: 48.11%	Cost 96s
              precision    recall  f1-score   support

         bzx     0.4286    0.2903    0.3462        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.4459    0.8462    0.5841        39

    accuracy                         0.4811       185
   macro avg     0.4718    0.4225    0.4106       185
weighted avg     0.4964    0.4811    0.4555       185

micro f-score: 0.4810810810810811

========== Train Epoch 30 ==========
Loss: 1.355	Accuracy: 44.86%	Cost 97s
              precision    recall  f1-score   support

         bzx     0.4000    0.4516    0.4242        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.6207    0.4000    0.4865        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4486       185
   macro avg     0.3858    0.3856    0.3631       185
weighted avg     0.4197    0.4486    0.4083       185

micro f-score: 0.4486486486486486

========== Train Epoch 31 ==========
Loss: 1.357	Accuracy: 50.81%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6111    0.4889    0.5432        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5081       185
   macro avg     0.5006    0.4562    0.4507       185
weighted avg     0.5217    0.5081    0.4889       185

micro f-score: 0.5081081081081081

========== Train Epoch 32 ==========
Loss: 1.379	Accuracy: 50.81%	Cost 93s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4118    0.6364    0.5000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.3333    0.5833    0.4242        12
         qtx     0.6129    0.4222    0.5000        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.5081       185
   macro avg     0.4304    0.4812    0.4448       185
weighted avg     0.4989    0.5081    0.4939       185

micro f-score: 0.5081081081081081

========== Train Epoch 33 ==========
Loss: 1.350	Accuracy: 48.65%	Cost 108s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.7188    0.5111    0.5974        45
         zxx     0.4167    0.8974    0.5691        39

    accuracy                         0.4865       185
   macro avg     0.4686    0.4195    0.4148       185
weighted avg     0.5123    0.4865    0.4659       185

micro f-score: 0.4864864864864865

========== Train Epoch 34 ==========
Loss: 1.310	Accuracy: 47.57%	Cost 97s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5167    0.6889    0.5905        45
         zxx     0.5556    0.5128    0.5333        39

    accuracy                         0.4757       185
   macro avg     0.4166    0.4118    0.4005       185
weighted avg     0.4500    0.4757    0.4507       185

micro f-score: 0.4756756756756757

========== Train Epoch 35 ==========
Loss: 1.256	Accuracy: 47.57%	Cost 98s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.2000    0.1765    0.1875        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.5185    0.7179    0.6022        39

    accuracy                         0.4757       185
   macro avg     0.4047    0.4278    0.4067       185
weighted avg     0.4558    0.4757    0.4562       185

micro f-score: 0.4756756756756757

========== Train Epoch 36 ==========
Loss: 1.305	Accuracy: 48.65%	Cost 100s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.2000    0.4167    0.2703        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.4865       185
   macro avg     0.4566    0.4304    0.4220       185
weighted avg     0.5002    0.4865    0.4758       185

micro f-score: 0.4864864864864865

========== Train Epoch 37 ==========
Loss: 1.245	Accuracy: 49.19%	Cost 105s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.4054    0.6818    0.5085        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.6061    0.5128    0.5556        39

    accuracy                         0.4919       185
   macro avg     0.4511    0.4568    0.4447       185
weighted avg     0.5042    0.4919    0.4897       185

micro f-score: 0.4918918918918919

========== Train Epoch 38 ==========
Loss: 1.238	Accuracy: 51.89%	Cost 104s
              precision    recall  f1-score   support

         bzx     0.3750    0.5806    0.4557        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4693    0.4797    0.4628       185
weighted avg     0.5037    0.5189    0.5011       185

micro f-score: 0.518918918918919

========== Train Epoch 39 ==========
Loss: 1.232	Accuracy: 53.51%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.3939    0.5909    0.4727        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.3333    0.5833    0.4242        12
         qtx     0.6444    0.6444    0.6444        45
         zxx     0.7143    0.6410    0.6757        39

    accuracy                         0.5351       185
   macro avg     0.4911    0.4954    0.4800       185
weighted avg     0.5472    0.5351    0.5325       185

micro f-score: 0.5351351351351351

========== Train Epoch 40 ==========
Loss: 1.218	Accuracy: 50.81%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4643    0.5909    0.5200        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2941    0.4167    0.3448        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.4706    0.8205    0.5981        39

    accuracy                         0.5081       185
   macro avg     0.4789    0.4429    0.4226       185
weighted avg     0.5303    0.5081    0.4843       185

micro f-score: 0.5081081081081081

========== Train Epoch 41 ==========
Loss: 1.210	Accuracy: 51.89%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.4658    0.8718    0.6071        39

    accuracy                         0.5189       185
   macro avg     0.4503    0.4247    0.4141       185
weighted avg     0.4954    0.5189    0.4845       185

micro f-score: 0.518918918918919

========== Train Epoch 42 ==========
Loss: 1.192	Accuracy: 57.84%	Cost 97s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.5161    0.7273    0.6038        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5784       185
   macro avg     0.5313    0.5203    0.5028       185
weighted avg     0.5794    0.5784    0.5611       185

micro f-score: 0.5783783783783784

========== Train Epoch 43 ==========
Loss: 1.207	Accuracy: 51.89%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.3714    0.5909    0.4561        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.6136    0.6923    0.6506        39

    accuracy                         0.5189       185
   macro avg     0.4738    0.4785    0.4657       185
weighted avg     0.5340    0.5189    0.5175       185

micro f-score: 0.518918918918919

========== Train Epoch 44 ==========
Loss: 1.173	Accuracy: 52.97%	Cost 105s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.6222    0.6222    0.6222        45
         zxx     0.6364    0.7179    0.6747        39

    accuracy                         0.5297       185
   macro avg     0.4650    0.4652    0.4564       185
weighted avg     0.5143    0.5297    0.5153       185

micro f-score: 0.5297297297297298

========== Train Epoch 45 ==========
Loss: 1.158	Accuracy: 49.73%	Cost 101s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.2941    0.4167    0.3448        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.5085    0.7692    0.6122        39

    accuracy                         0.4973       185
   macro avg     0.4753    0.4481    0.4376       185
weighted avg     0.5149    0.4973    0.4851       185

micro f-score: 0.4972972972972973

========== Train Epoch 46 ==========
Loss: 1.170	Accuracy: 54.05%	Cost 93s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.5072    0.8974    0.6481        39

    accuracy                         0.5405       185
   macro avg     0.4829    0.4541    0.4527       185
weighted avg     0.5341    0.5405    0.5195       185

micro f-score: 0.5405405405405406

========== Train Epoch 47 ==========
Loss: 1.148	Accuracy: 54.59%	Cost 100s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.4000    0.6364    0.4912        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5459       185
   macro avg     0.5087    0.5051    0.4876       185
weighted avg     0.5539    0.5459    0.5330       185

micro f-score: 0.5459459459459459

========== Train Epoch 48 ==========
Loss: 1.084	Accuracy: 57.30%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5730       185
   macro avg     0.5410    0.5147    0.5101       185
weighted avg     0.5774    0.5730    0.5573       185

micro f-score: 0.572972972972973

========== Train Epoch 49 ==========
Loss: 1.118	Accuracy: 53.51%	Cost 105s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5351       185
   macro avg     0.4600    0.4650    0.4471       185
weighted avg     0.5170    0.5351    0.5118       185

micro f-score: 0.5351351351351351

========== Train Epoch 50 ==========
Loss: 1.083	Accuracy: 51.89%	Cost 94s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.7241    0.4667    0.5676        45
         zxx     0.4627    0.7949    0.5849        39

    accuracy                         0.5189       185
   macro avg     0.4994    0.4709    0.4612       185
weighted avg     0.5423    0.5189    0.5051       185

micro f-score: 0.518918918918919

========== Train Epoch 51 ==========
Loss: 1.076	Accuracy: 56.76%	Cost 99s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5676       185
   macro avg     0.5540    0.5244    0.5241       185
weighted avg     0.5767    0.5676    0.5558       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 1.065	Accuracy: 55.14%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7419    0.5111    0.6053        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5514       185
   macro avg     0.5362    0.5149    0.5044       185
weighted avg     0.5652    0.5514    0.5351       185

micro f-score: 0.5513513513513514

========== Train Epoch 53 ==========
Loss: 1.050	Accuracy: 56.22%	Cost 98s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.5143    0.8182    0.6316        22
         hdx     0.1429    0.1176    0.1290        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5622       185
   macro avg     0.4982    0.5179    0.4976       185
weighted avg     0.5600    0.5622    0.5512       185

micro f-score: 0.5621621621621622

========== Train Epoch 54 ==========
Loss: 1.043	Accuracy: 55.14%	Cost 102s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     1.0000    0.1765    0.3000        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.5357    0.7692    0.6316        39

    accuracy                         0.5514       185
   macro avg     0.5983    0.5243    0.5084       185
weighted avg     0.6118    0.5514    0.5439       185

micro f-score: 0.5513513513513514

========== Train Epoch 55 ==========
Loss: 1.047	Accuracy: 54.05%	Cost 93s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5000    0.6923    0.5806        39

    accuracy                         0.5405       185
   macro avg     0.5123    0.5017    0.5017       185
weighted avg     0.5446    0.5405    0.5360       185

micro f-score: 0.5405405405405406

========== Train Epoch 56 ==========
Loss: 1.040	Accuracy: 58.38%	Cost 97s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.6410    0.6410    0.6410        39

    accuracy                         0.5838       185
   macro avg     0.5357    0.5215    0.5203       185
weighted avg     0.5833    0.5838    0.5776       185

micro f-score: 0.5837837837837838

========== Train Epoch 57 ==========
Loss: 0.981	Accuracy: 48.65%	Cost 96s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.4444    0.7273    0.5517        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.2105    0.3333    0.2581        12
         qtx     0.7586    0.4889    0.5946        45
         zxx     0.5273    0.7436    0.6170        39

    accuracy                         0.4865       185
   macro avg     0.4441    0.4373    0.4171       185
weighted avg     0.5156    0.4865    0.4774       185

micro f-score: 0.4864864864864865

========== Train Epoch 58 ==========
Loss: 0.980	Accuracy: 58.38%	Cost 107s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.6512    0.7179    0.6829        39

    accuracy                         0.5838       185
   macro avg     0.5538    0.5301    0.5313       185
weighted avg     0.5895    0.5838    0.5788       185

micro f-score: 0.5837837837837838

========== Train Epoch 59 ==========
Loss: 0.998	Accuracy: 54.59%	Cost 96s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.5000    0.7273    0.5926        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.1765    0.1579    0.1667        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6842    0.6667    0.6753        39

    accuracy                         0.5459       185
   macro avg     0.4811    0.4971    0.4838       185
weighted avg     0.5454    0.5459    0.5416       185

micro f-score: 0.5459459459459459

========== Train Epoch 60 ==========
Loss: 0.989	Accuracy: 61.08%	Cost 96s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.7083    0.7727    0.7391        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.6108       185
   macro avg     0.5885    0.5856    0.5601       185
weighted avg     0.6239    0.6108    0.5959       185

micro f-score: 0.6108108108108108

========== Train Epoch 61 ==========
Loss: 0.975	Accuracy: 58.38%	Cost 103s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.5838       185
   macro avg     0.5638    0.5243    0.5227       185
weighted avg     0.5925    0.5838    0.5699       185

micro f-score: 0.5837837837837838

========== Train Epoch 62 ==========
Loss: 0.983	Accuracy: 54.59%	Cost 95s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7188    0.5111    0.5974        45
         zxx     0.5769    0.7692    0.6593        39

    accuracy                         0.5459       185
   macro avg     0.5092    0.5314    0.4949       185
weighted avg     0.5669    0.5459    0.5351       185

micro f-score: 0.5459459459459459

========== Train Epoch 63 ==========
Loss: 0.981	Accuracy: 54.05%	Cost 107s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5405       185
   macro avg     0.5119    0.4854    0.4791       185
weighted avg     0.5387    0.5405    0.5224       185

micro f-score: 0.5405405405405406

========== Train Epoch 64 ==========
Loss: 0.915	Accuracy: 57.30%	Cost 106s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.5139    0.9487    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5574    0.5293    0.5216       185
weighted avg     0.5957    0.5730    0.5585       185

micro f-score: 0.572972972972973

Finished training!!!

Min Loss = 0.915 in epoch 63;
Max Accuracy = 61.08% in epoch 59;
Total Cost 108 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
ReLU: 1-3                              [-1, 64, 160, 160]        --
SPP: 1-4                               [-1, 256, 160, 160]       --
|    MaxPool2d: 2-1                    [-1, 64, 160, 160]        --
|    MaxPool2d: 2-2                    [-1, 64, 160, 160]        --
|    MaxPool2d: 2-3                    [-1, 64, 160, 160]        --
Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
ReLU: 1-7                              [-1, 64, 80, 80]          --
Sequential: 1-8                        [-1, 64, 80, 80]          --
|    BasicBlock: 2-4                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    ReLU: 3-7                    [-1, 64, 80, 80]          --
|    BasicBlock: 2-5                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    ReLU: 3-14                   [-1, 64, 80, 80]          --
|    BasicBlock: 2-6                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-15                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-16            [-1, 64, 80, 80]          128
|    |    ReLU: 3-17                   [-1, 64, 80, 80]          --
|    |    Conv2d: 3-18                 [-1, 64, 80, 80]          36,864
|    |    BatchNorm2d: 3-19            [-1, 64, 80, 80]          128
|    |    CBAM: 3-20                   [-1, 64, 80, 80]          680
|    |    ReLU: 3-21                   [-1, 64, 80, 80]          --
Sequential: 1-9                        [-1, 128, 40, 40]         --
|    BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-22                 [-1, 128, 40, 40]         73,728
|    |    BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    ReLU: 3-24                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-25                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-26            [-1, 128, 40, 40]         256
|    |    CBAM: 3-27                   [-1, 128, 40, 40]         2,284
|    |    Sequential: 3-28             [-1, 128, 40, 40]         8,448
|    |    ReLU: 3-29                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-8                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-30                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-31            [-1, 128, 40, 40]         256
|    |    ReLU: 3-32                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-33                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-34            [-1, 128, 40, 40]         256
|    |    CBAM: 3-35                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-36                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-9                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-37                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-38            [-1, 128, 40, 40]         256
|    |    ReLU: 3-39                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-40                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-41            [-1, 128, 40, 40]         256
|    |    CBAM: 3-42                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-43                   [-1, 128, 40, 40]         --
|    BasicBlock: 2-10                  [-1, 128, 40, 40]         --
|    |    Conv2d: 3-44                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-45            [-1, 128, 40, 40]         256
|    |    ReLU: 3-46                   [-1, 128, 40, 40]         --
|    |    Conv2d: 3-47                 [-1, 128, 40, 40]         147,456
|    |    BatchNorm2d: 3-48            [-1, 128, 40, 40]         256
|    |    CBAM: 3-49                   [-1, 128, 40, 40]         2,284
|    |    ReLU: 3-50                   [-1, 128, 40, 40]         --
Sequential: 1-10                       [-1, 256, 20, 20]         --
|    BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-51                 [-1, 256, 20, 20]         294,912
|    |    BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    CBAM: 3-56                   [-1, 256, 20, 20]         8,564
|    |    Sequential: 3-57             [-1, 256, 20, 20]         33,280
|    |    ReLU: 3-58                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-59                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-60            [-1, 256, 20, 20]         512
|    |    ReLU: 3-61                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-62                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-63            [-1, 256, 20, 20]         512
|    |    CBAM: 3-64                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-65                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    ReLU: 3-68                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    CBAM: 3-71                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-72                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-14                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-73                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-74            [-1, 256, 20, 20]         512
|    |    ReLU: 3-75                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-76                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-77            [-1, 256, 20, 20]         512
|    |    CBAM: 3-78                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-79                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-15                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-80                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-81            [-1, 256, 20, 20]         512
|    |    ReLU: 3-82                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-83                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-84            [-1, 256, 20, 20]         512
|    |    CBAM: 3-85                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-86                   [-1, 256, 20, 20]         --
|    BasicBlock: 2-16                  [-1, 256, 20, 20]         --
|    |    Conv2d: 3-87                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-88            [-1, 256, 20, 20]         512
|    |    ReLU: 3-89                   [-1, 256, 20, 20]         --
|    |    Conv2d: 3-90                 [-1, 256, 20, 20]         589,824
|    |    BatchNorm2d: 3-91            [-1, 256, 20, 20]         512
|    |    CBAM: 3-92                   [-1, 256, 20, 20]         8,564
|    |    ReLU: 3-93                   [-1, 256, 20, 20]         --
Sequential: 1-11                       [-1, 512, 10, 10]         --
|    BasicBlock: 2-17                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-94                 [-1, 512, 10, 10]         1,179,648
|    |    BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-99                   [-1, 512, 10, 10]         33,412
|    |    Sequential: 3-100            [-1, 512, 10, 10]         132,096
|    |    ReLU: 3-101                  [-1, 512, 10, 10]         --
|    BasicBlock: 2-18                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-102                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-103           [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-104                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-105                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-106           [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-107                  [-1, 512, 10, 10]         33,412
|    |    ReLU: 3-108                  [-1, 512, 10, 10]         --
|    BasicBlock: 2-19                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-109                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-110           [-1, 512, 10, 10]         1,024
|    |    ReLU: 3-111                  [-1, 512, 10, 10]         --
|    |    Conv2d: 3-112                [-1, 512, 10, 10]         2,359,296
|    |    BatchNorm2d: 3-113           [-1, 512, 10, 10]         1,024
|    |    CBAM: 3-114                  [-1, 512, 10, 10]         33,412
|    |    ReLU: 3-115                  [-1, 512, 10, 10]         --
AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 22,254,003
Trainable params: 22,254,003
Non-trainable params: 0
Total mult-adds (G): 12.66
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 122.66
Params size (MB): 84.89
Estimated Total Size (MB): 208.72
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    cbam_spp_resnet.resnet34, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 363, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 340, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
