dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam_spp_resnet
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.821	Accuracy: 29.19%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3333    0.0323    0.0588        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.2846    0.8222    0.4229        45
         zxx     0.3250    0.3333    0.3291        39

    accuracy                         0.2919       185
   macro avg     0.2041    0.1946    0.1523       185
weighted avg     0.2405    0.2919    0.2061       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.575	Accuracy: 42.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.2286    0.2581    0.2424        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.4615    0.6667    0.5455        45
         zxx     0.5263    0.7692    0.6250        39

    accuracy                         0.4216       185
   macro avg     0.4682    0.3245    0.3158       185
weighted avg     0.4586    0.4216    0.3791       185

micro f-score: 0.42162162162162165

========== Train Epoch 3 ==========
Loss: 1.458	Accuracy: 40.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.2917    0.2258    0.2545        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.4545    0.5556    0.5000        45
         zxx     0.4324    0.8205    0.5664        39

    accuracy                         0.4054       185
   macro avg     0.4513    0.3198    0.3073       185
weighted avg     0.4443    0.4054    0.3616       185

micro f-score: 0.40540540540540543

========== Train Epoch 4 ==========
Loss: 1.409	Accuracy: 42.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.2759    0.2581    0.2667        31
         cwx     0.1818    0.0909    0.1212        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4444    0.7111    0.5470        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.4270       185
   macro avg     0.3693    0.3250    0.3060       185
weighted avg     0.3940    0.4270    0.3748       185

micro f-score: 0.427027027027027

========== Train Epoch 5 ==========
Loss: 1.373	Accuracy: 45.95%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3939    0.4194    0.4062        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5435    0.5556    0.5495        45
         zxx     0.4714    0.8462    0.6055        39

    accuracy                         0.4595       185
   macro avg     0.4361    0.3814    0.3692       185
weighted avg     0.4555    0.4595    0.4229       185

micro f-score: 0.4594594594594595

========== Train Epoch 6 ==========
Loss: 1.299	Accuracy: 44.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3448    0.3226    0.3333        31
         cwx     0.2727    0.1364    0.1818        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.4821    0.6000    0.5347        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.4486       185
   macro avg     0.4029    0.3710    0.3569       185
weighted avg     0.4267    0.4486    0.4114       185

micro f-score: 0.4486486486486486

========== Train Epoch 7 ==========
Loss: 1.292	Accuracy: 48.65%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3556    0.5161    0.4211        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.4865       185
   macro avg     0.4752    0.4354    0.4193       185
weighted avg     0.5091    0.4865    0.4632       185

micro f-score: 0.4864864864864865

========== Train Epoch 8 ==========
Loss: 1.232	Accuracy: 49.73%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5000    0.6889    0.5794        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.4973       185
   macro avg     0.4520    0.4045    0.4034       185
weighted avg     0.4873    0.4973    0.4719       185

micro f-score: 0.4972972972972973

========== Train Epoch 9 ==========
Loss: 1.205	Accuracy: 49.73%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4103    0.5161    0.4571        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.5417    0.5778    0.5591        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.4973       185
   macro avg     0.4443    0.4199    0.4199       185
weighted avg     0.4764    0.4973    0.4770       185

micro f-score: 0.4972972972972973

========== Train Epoch 10 ==========
Loss: 1.153	Accuracy: 50.81%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4146    0.5484    0.4722        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5081       185
   macro avg     0.4524    0.4445    0.4427       185
weighted avg     0.4958    0.5081    0.4968       185

micro f-score: 0.5081081081081081

========== Train Epoch 11 ==========
Loss: 1.085	Accuracy: 54.05%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4359    0.5484    0.4857        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5405       185
   macro avg     0.4923    0.4984    0.4825       185
weighted avg     0.5360    0.5405    0.5259       185

micro f-score: 0.5405405405405406

========== Train Epoch 12 ==========
Loss: 1.034	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4750    0.6129    0.5352        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.5730       185
   macro avg     0.5031    0.5149    0.4999       185
weighted avg     0.5545    0.5730    0.5557       185

micro f-score: 0.572972972972973

========== Train Epoch 13 ==========
Loss: 1.018	Accuracy: 57.84%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.5784       185
   macro avg     0.5181    0.5266    0.4942       185
weighted avg     0.5677    0.5784    0.5522       185

micro f-score: 0.5783783783783784

========== Train Epoch 14 ==========
Loss: 0.935	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4565    0.6774    0.5455        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5514       185
   macro avg     0.4954    0.5038    0.4898       185
weighted avg     0.5389    0.5514    0.5368       185

micro f-score: 0.5513513513513514

========== Train Epoch 15 ==========
Loss: 0.880	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.6452    0.5634        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5838       185
   macro avg     0.5303    0.5407    0.5221       185
weighted avg     0.5705    0.5838    0.5653       185

micro f-score: 0.5837837837837838

========== Train Epoch 16 ==========
Loss: 0.845	Accuracy: 57.30%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.5730       185
   macro avg     0.5185    0.5250    0.5049       185
weighted avg     0.5639    0.5730    0.5570       185

micro f-score: 0.572972972972973

========== Train Epoch 17 ==========
Loss: 0.767	Accuracy: 59.46%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.5946       185
   macro avg     0.5437    0.5408    0.5291       185
weighted avg     0.5797    0.5946    0.5777       185

micro f-score: 0.5945945945945946

========== Train Epoch 18 ==========
Loss: 0.733	Accuracy: 60.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6000       185
   macro avg     0.5391    0.5589    0.5396       185
weighted avg     0.5887    0.6000    0.5873       185

micro f-score: 0.6

========== Train Epoch 19 ==========
Loss: 0.668	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5892       185
   macro avg     0.5248    0.5511    0.5269       185
weighted avg     0.5827    0.5892    0.5771       185

micro f-score: 0.5891891891891892

========== Train Epoch 20 ==========
Loss: 0.601	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.5892       185
   macro avg     0.5160    0.5256    0.5143       185
weighted avg     0.5773    0.5892    0.5779       185

micro f-score: 0.5891891891891892

========== Train Epoch 21 ==========
Loss: 0.576	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5946    0.7097    0.6471        31
         cwx     0.4865    0.8182    0.6102        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.6162       185
   macro avg     0.5596    0.5832    0.5542       185
weighted avg     0.6304    0.6162    0.6090       185

micro f-score: 0.6162162162162163

========== Train Epoch 22 ==========
Loss: 0.538	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4231    0.7097    0.5301        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.5838       185
   macro avg     0.5533    0.5472    0.5093       185
weighted avg     0.6122    0.5838    0.5661       185

micro f-score: 0.5837837837837838

========== Train Epoch 23 ==========
Loss: 0.474	Accuracy: 58.38%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4286    0.5806    0.4932        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.5838       185
   macro avg     0.5677    0.5526    0.5347       185
weighted avg     0.6123    0.5838    0.5786       185

micro f-score: 0.5837837837837838

========== Train Epoch 24 ==========
Loss: 0.441	Accuracy: 59.46%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5946       185
   macro avg     0.5472    0.5595    0.5351       185
weighted avg     0.6129    0.5946    0.5922       185

micro f-score: 0.5945945945945946

========== Train Epoch 25 ==========
Loss: 0.388	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7308    0.6129    0.6667        31
         cwx     0.4571    0.7273    0.5614        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7949    0.7949    0.7949        39

    accuracy                         0.6378       185
   macro avg     0.5834    0.5974    0.5818       185
weighted avg     0.6410    0.6378    0.6327       185

micro f-score: 0.6378378378378379

========== Train Epoch 26 ==========
Loss: 0.386	Accuracy: 63.24%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5526    0.6774    0.6087        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6324       185
   macro avg     0.5952    0.5953    0.5779       185
weighted avg     0.6487    0.6324    0.6271       185

micro f-score: 0.6324324324324324

========== Train Epoch 27 ==========
Loss: 0.355	Accuracy: 60.54%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5000    0.6452    0.5634        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.6054       185
   macro avg     0.5557    0.5679    0.5540       185
weighted avg     0.6075    0.6054    0.5979       185

micro f-score: 0.6054054054054054

========== Train Epoch 28 ==========
Loss: 0.308	Accuracy: 58.92%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4259    0.7419    0.5412        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5892       185
   macro avg     0.5698    0.5635    0.5495       185
weighted avg     0.6037    0.5892    0.5798       185

micro f-score: 0.5891891891891892

========== Train Epoch 29 ==========
Loss: 0.294	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.4615    0.8182    0.5902        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6216       185
   macro avg     0.5768    0.5930    0.5638       185
weighted avg     0.6450    0.6216    0.6172       185

micro f-score: 0.6216216216216216

========== Train Epoch 30 ==========
Loss: 0.236	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7391    0.5484    0.6296        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.6378       185
   macro avg     0.6069    0.6019    0.5979       185
weighted avg     0.6592    0.6378    0.6423       185

micro f-score: 0.6378378378378379

========== Train Epoch 31 ==========
Loss: 0.209	Accuracy: 62.70%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2593    0.3684    0.3043        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.6270       185
   macro avg     0.6108    0.5833    0.5921       185
weighted avg     0.6568    0.6270    0.6377       185

micro f-score: 0.6270270270270271

========== Train Epoch 32 ==========
Loss: 0.208	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6162       185
   macro avg     0.5842    0.6069    0.5871       185
weighted avg     0.6541    0.6162    0.6266       185

micro f-score: 0.6162162162162163

========== Train Epoch 33 ==========
Loss: 0.174	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3226    0.5882    0.4167        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7500    0.7692    0.7595        39

    accuracy                         0.5892       185
   macro avg     0.5540    0.5582    0.5465       185
weighted avg     0.6120    0.5892    0.5931       185

micro f-score: 0.5891891891891892

========== Train Epoch 34 ==========
Loss: 0.151	Accuracy: 60.54%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3235    0.6471    0.4314        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.6054       185
   macro avg     0.5712    0.5898    0.5644       185
weighted avg     0.6458    0.6054    0.6119       185

micro f-score: 0.6054054054054054

========== Train Epoch 35 ==========
Loss: 0.136	Accuracy: 67.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.6296    0.7727    0.6939        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.8095    0.8718    0.8395        39

    accuracy                         0.6703       185
   macro avg     0.6288    0.6523    0.6232       185
weighted avg     0.6943    0.6703    0.6675       185

micro f-score: 0.6702702702702703

========== Train Epoch 36 ==========
Loss: 0.136	Accuracy: 64.32%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.5517    0.7273    0.6275        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6432       185
   macro avg     0.5849    0.6225    0.5949       185
weighted avg     0.6457    0.6432    0.6382       185

micro f-score: 0.6432432432432432

========== Train Epoch 37 ==========
Loss: 0.131	Accuracy: 66.49%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.6522    0.6818    0.6667        22
         hdx     0.4762    0.5882    0.5263        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6649       185
   macro avg     0.6283    0.6338    0.6271       185
weighted avg     0.6595    0.6649    0.6583       185

micro f-score: 0.6648648648648648

========== Train Epoch 38 ==========
Loss: 0.124	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7391    0.5484    0.6296        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.6432       185
   macro avg     0.6033    0.6321    0.6074       185
weighted avg     0.6608    0.6432    0.6440       185

micro f-score: 0.6432432432432432

========== Train Epoch 39 ==========
Loss: 0.099	Accuracy: 64.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.6774    0.6364        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.8571    0.7692    0.8108        39

    accuracy                         0.6432       185
   macro avg     0.5848    0.6033    0.5898       185
weighted avg     0.6528    0.6432    0.6446       185

micro f-score: 0.6432432432432432

========== Train Epoch 40 ==========
Loss: 0.090	Accuracy: 63.24%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6000    0.6774    0.6364        31
         cwx     0.6296    0.7727    0.6939        22
         hdx     0.3636    0.7059    0.4800        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8214    0.5111    0.6301        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6324       185
   macro avg     0.6139    0.6279    0.5973       185
weighted avg     0.6582    0.6324    0.6235       185

micro f-score: 0.6324324324324324

========== Train Epoch 41 ==========
Loss: 0.110	Accuracy: 62.16%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.2800    0.3684    0.3182        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.6216       185
   macro avg     0.5918    0.6056    0.5940       185
weighted avg     0.6458    0.6216    0.6290       185

micro f-score: 0.6216216216216216

========== Train Epoch 42 ==========
Loss: 0.102	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6774    0.6774    0.6774        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.8889    0.8205    0.8533        39

    accuracy                         0.6432       185
   macro avg     0.5805    0.6072    0.5861       185
weighted avg     0.6410    0.6432    0.6373       185

micro f-score: 0.6432432432432432

========== Train Epoch 43 ==========
Loss: 0.084	Accuracy: 65.95%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7407    0.6452    0.6897        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.4074    0.6471    0.5000        17
         mtx     0.2857    0.3158    0.3000        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.8049    0.8462    0.8250        39

    accuracy                         0.6595       185
   macro avg     0.6323    0.6407    0.6301       185
weighted avg     0.6863    0.6595    0.6667       185

micro f-score: 0.6594594594594595

========== Train Epoch 44 ==========
Loss: 0.073	Accuracy: 65.95%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7727    0.5484    0.6415        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4074    0.6471    0.5000        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.7857    0.8462    0.8148        39

    accuracy                         0.6595       185
   macro avg     0.6425    0.6451    0.6367       185
weighted avg     0.6771    0.6595    0.6619       185

micro f-score: 0.6594594594594595

========== Train Epoch 45 ==========
Loss: 0.082	Accuracy: 62.70%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5676    0.6774    0.6176        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.6270       185
   macro avg     0.5840    0.6019    0.5816       185
weighted avg     0.6292    0.6270    0.6181       185

micro f-score: 0.6270270270270271

========== Train Epoch 46 ==========
Loss: 0.083	Accuracy: 64.86%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.7308    0.6129    0.6667        31
         cwx     0.8667    0.5909    0.7027        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.3214    0.4737    0.3830        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6486       185
   macro avg     0.6363    0.6394    0.6250       185
weighted avg     0.6901    0.6486    0.6602       185

micro f-score: 0.6486486486486487

========== Train Epoch 47 ==========
Loss: 0.091	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.9286    0.4194    0.5778        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.3235    0.6471    0.4314        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.8788    0.7436    0.8056        39

    accuracy                         0.6108       185
   macro avg     0.6053    0.5991    0.5758       185
weighted avg     0.6840    0.6108    0.6228       185

micro f-score: 0.6108108108108108

========== Train Epoch 48 ==========
Loss: 0.074	Accuracy: 68.65%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6364    0.6774    0.6562        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.5625    0.5294    0.5455        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.8250    0.8462    0.8354        39

    accuracy                         0.6865       185
   macro avg     0.6436    0.6629    0.6415       185
weighted avg     0.6935    0.6865    0.6824       185

micro f-score: 0.6864864864864865

========== Train Epoch 49 ==========
Loss: 0.061	Accuracy: 64.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6486       185
   macro avg     0.6218    0.6273    0.6026       185
weighted avg     0.6751    0.6486    0.6450       185

micro f-score: 0.6486486486486487

========== Train Epoch 50 ==========
Loss: 0.076	Accuracy: 67.03%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6774    0.6774    0.6774        31
         cwx     0.5667    0.7727    0.6538        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.8250    0.8462    0.8354        39

    accuracy                         0.6703       185
   macro avg     0.6244    0.6489    0.6213       185
weighted avg     0.6724    0.6703    0.6598       185

micro f-score: 0.6702702702702703

========== Train Epoch 51 ==========
Loss: 0.061	Accuracy: 67.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6562    0.6774    0.6667        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6757       185
   macro avg     0.6381    0.6429    0.6225       185
weighted avg     0.6841    0.6757    0.6664       185

micro f-score: 0.6756756756756757

========== Train Epoch 52 ==========
Loss: 0.052	Accuracy: 65.41%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6541       185
   macro avg     0.6116    0.6450    0.6195       185
weighted avg     0.6603    0.6541    0.6504       185

micro f-score: 0.654054054054054

========== Train Epoch 53 ==========
Loss: 0.060	Accuracy: 63.78%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3548    0.6471    0.4583        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.8529    0.7436    0.7945        39

    accuracy                         0.6378       185
   macro avg     0.6239    0.6122    0.6099       185
weighted avg     0.6628    0.6378    0.6441       185

micro f-score: 0.6378378378378379

========== Train Epoch 54 ==========
Loss: 0.070	Accuracy: 64.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7083    0.5484    0.6182        31
         cwx     0.5333    0.7273    0.6154        22
         hdx     0.3529    0.7059    0.4706        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6486       185
   macro avg     0.6276    0.6066    0.5923       185
weighted avg     0.6670    0.6486    0.6406       185

micro f-score: 0.6486486486486487

========== Train Epoch 55 ==========
Loss: 0.084	Accuracy: 64.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6897    0.6452    0.6667        31
         cwx     0.4839    0.6818    0.5660        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4400    0.9167    0.5946        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.6486       185
   macro avg     0.6156    0.6254    0.5870       185
weighted avg     0.6722    0.6486    0.6386       185

micro f-score: 0.6486486486486487

========== Train Epoch 56 ==========
Loss: 0.059	Accuracy: 60.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5128    0.6452    0.5714        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.6000       185
   macro avg     0.5696    0.5690    0.5597       185
weighted avg     0.6047    0.6000    0.5947       185

micro f-score: 0.6

========== Train Epoch 57 ==========
Loss: 0.054	Accuracy: 66.49%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6649       185
   macro avg     0.6347    0.6362    0.6308       185
weighted avg     0.6681    0.6649    0.6622       185

micro f-score: 0.6648648648648648

========== Train Epoch 58 ==========
Loss: 0.060	Accuracy: 65.95%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5676    0.6774    0.6176        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5882    0.5882    0.5882        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6595       185
   macro avg     0.6389    0.6221    0.6189       185
weighted avg     0.6556    0.6595    0.6470       185

micro f-score: 0.6594594594594595

========== Train Epoch 59 ==========
Loss: 0.049	Accuracy: 68.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.6538    0.7727    0.7083        22
         hdx     0.5789    0.6471    0.6111        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.8333    0.8333    0.8333        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.7442    0.8205    0.7805        39

    accuracy                         0.6811       185
   macro avg     0.6641    0.6745    0.6666       185
weighted avg     0.6903    0.6811    0.6822       185

micro f-score: 0.6810810810810811

========== Train Epoch 60 ==========
Loss: 0.048	Accuracy: 68.11%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6786    0.6129    0.6441        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6811       185
   macro avg     0.6405    0.6486    0.6382       185
weighted avg     0.6815    0.6811    0.6753       185

micro f-score: 0.6810810810810811

========== Train Epoch 61 ==========
Loss: 0.050	Accuracy: 66.49%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.5217    0.7059    0.6000        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.7692    0.8333    0.8000        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.6649       185
   macro avg     0.6251    0.6453    0.6320       185
weighted avg     0.6586    0.6649    0.6595       185

micro f-score: 0.6648648648648648

========== Train Epoch 62 ==========
Loss: 0.055	Accuracy: 66.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.6250    0.6818    0.6522        22
         hdx     0.4545    0.5882    0.5128        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7949    0.7949    0.7949        39

    accuracy                         0.6649       185
   macro avg     0.6325    0.6410    0.6259       185
weighted avg     0.6638    0.6649    0.6566       185

micro f-score: 0.6648648648648648

========== Train Epoch 63 ==========
Loss: 0.044	Accuracy: 65.41%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6541       185
   macro avg     0.6147    0.6228    0.6114       185
weighted avg     0.6590    0.6541    0.6510       185

micro f-score: 0.654054054054054

========== Train Epoch 64 ==========
Loss: 0.050	Accuracy: 64.86%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8095    0.5484    0.6538        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.2857    0.3158    0.3000        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.6486       185
   macro avg     0.6222    0.6205    0.6158       185
weighted avg     0.6666    0.6486    0.6521       185

micro f-score: 0.6486486486486487

Finished training!!!

Min Loss = 0.044 in epoch 62;
Max Accuracy = 68.65% in epoch 47;
Total Cost 34 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPP: 1-4                               [-1, 256, 160, 160]       --
|    └─MaxPool2d: 2-1                    [-1, 64, 160, 160]        --
|    └─MaxPool2d: 2-2                    [-1, 64, 160, 160]        --
|    └─MaxPool2d: 2-3                    [-1, 64, 160, 160]        --
├─Conv2d: 1-5                            [-1, 64, 80, 80]          802,816
├─BatchNorm2d: 1-6                       [-1, 64, 80, 80]          128
├─ReLU: 1-7                              [-1, 64, 80, 80]          --
├─Sequential: 1-8                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-4                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-5                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-6                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-15                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-16            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-17                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-18                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-19            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-20                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-21                   [-1, 64, 80, 80]          --
├─Sequential: 1-9                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-22                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-24                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-25                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-26            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-27                   [-1, 128, 40, 40]         2,284
|    |    └─Sequential: 3-28             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-8                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-30                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-31            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-32                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-33                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-34            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-35                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-36                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-9                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-37                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-38            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-39                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-40                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-41            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-42                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-43                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-46                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-49                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-50                   [-1, 128, 40, 40]         --
├─Sequential: 1-10                       [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-51                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-56                   [-1, 256, 20, 20]         8,564
|    |    └─Sequential: 3-57             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-58                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-59                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-60            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-61                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-62                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-63            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-64                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-65                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-68                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-71                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-72                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-14                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-73                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-74            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-75                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-76                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-77            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-78                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-79                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-15                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-80                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-81            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-82                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-83                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-84            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-85                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-86                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-89                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-91            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-92                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-93                   [-1, 256, 20, 20]         --
├─Sequential: 1-11                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-17                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-94                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-99                   [-1, 512, 10, 10]         33,412
|    |    └─Sequential: 3-100            [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-101                  [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-18                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-102                [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-103           [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-104                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-105                [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-106           [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-107                  [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-108                  [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-19                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-109                [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-110           [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-111                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-112                [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-113           [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-114                  [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-115                  [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-12                [-1, 512, 1, 1]           --
├─Linear: 1-13                           [-1, 7]                   3,591
==========================================================================================
Total params: 22,254,003
Trainable params: 22,254,003
Non-trainable params: 0
Total mult-adds (G): 12.66
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 122.66
Params size (MB): 84.89
Estimated Total Size (MB): 208.72
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    cbam_spp_resnet.resnet34, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 363, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_spp_resnet.py", line 340, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
