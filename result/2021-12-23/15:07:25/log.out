dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.856	Accuracy: 30.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.4286    0.1364    0.2069        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.3871    0.5333    0.4486        45
         zxx     0.2385    0.6667    0.3514        39

    accuracy                         0.3027       185
   macro avg     0.4125    0.2149    0.1854       185
weighted avg     0.4359    0.3027    0.2367       185

micro f-score: 0.3027027027027027

========== Train Epoch 2 ==========
Loss: 1.579	Accuracy: 40.54%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.5758    0.4222    0.4872        45
         zxx     0.3656    0.8718    0.5152        39

    accuracy                         0.4054       185
   macro avg     0.3648    0.3508    0.3341       185
weighted avg     0.3898    0.4054    0.3669       185

micro f-score: 0.40540540540540543

========== Train Epoch 3 ==========
Loss: 1.443	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4091    0.2903    0.3396        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5714    0.4444    0.5000        45
         zxx     0.3617    0.8718    0.5113        39

    accuracy                         0.4054       185
   macro avg     0.3547    0.3437    0.3219       185
weighted avg     0.3835    0.4054    0.3619       185

micro f-score: 0.40540540540540543

========== Train Epoch 4 ==========
Loss: 1.423	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3214    0.2903    0.3051        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.5556    0.4444    0.4938        45
         zxx     0.3924    0.7949    0.5254        39

    accuracy                         0.4054       185
   macro avg     0.3462    0.3614    0.3399       185
weighted avg     0.3715    0.4054    0.3700       185

micro f-score: 0.40540540540540543

========== Train Epoch 5 ==========
Loss: 1.362	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3824    0.4194    0.4000        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.4507    0.8205    0.5818        39

    accuracy                         0.4486       185
   macro avg     0.3797    0.3997    0.3786       185
weighted avg     0.4126    0.4486    0.4156       185

micro f-score: 0.4486486486486486

========== Train Epoch 6 ==========
Loss: 1.332	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4571    0.8205    0.5872        39

    accuracy                         0.4324       185
   macro avg     0.3613    0.3784    0.3489       185
weighted avg     0.4086    0.4324    0.4001       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 1.276	Accuracy: 44.86%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4348    0.3226    0.3704        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4571    0.8205    0.5872        39

    accuracy                         0.4486       185
   macro avg     0.3888    0.3962    0.3787       185
weighted avg     0.4317    0.4486    0.4235       185

micro f-score: 0.4486486486486486

========== Train Epoch 8 ==========
Loss: 1.249	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7037    0.4222    0.5278        45
         zxx     0.3846    0.8974    0.5385        39

    accuracy                         0.4432       185
   macro avg     0.3881    0.3951    0.3676       185
weighted avg     0.4323    0.4432    0.4041       185

micro f-score: 0.44324324324324327

========== Train Epoch 9 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.193	Accuracy: 46.49%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.3333    0.4091    0.3673        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.4649       185
   macro avg     0.3935    0.4069    0.3791       185
weighted avg     0.4340    0.4649    0.4273       185

micro f-score: 0.4648648648648649

========== Train Epoch 10 ==========
Loss: 1.150	Accuracy: 47.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.4789    0.8718    0.6182        39

    accuracy                         0.4757       185
   macro avg     0.4233    0.4103    0.3917       185
weighted avg     0.4606    0.4757    0.4435       185

micro f-score: 0.4756756756756757

========== Train Epoch 11 ==========
Loss: 1.090	Accuracy: 52.97%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5297       185
   macro avg     0.4843    0.4784    0.4661       185
weighted avg     0.5264    0.5297    0.5136       185

micro f-score: 0.5297297297297298

========== Train Epoch 12 ==========
Loss: 1.039	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.6279    0.6000    0.6136        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.5135       185
   macro avg     0.4509    0.4627    0.4473       185
weighted avg     0.5038    0.5135    0.5017       185

micro f-score: 0.5135135135135135

========== Train Epoch 13 ==========
Loss: 0.999	Accuracy: 52.43%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5243       185
   macro avg     0.4749    0.4762    0.4663       185
weighted avg     0.5261    0.5243    0.5142       185

micro f-score: 0.5243243243243243

========== Train Epoch 14 ==========
Loss: 0.947	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5676       185
   macro avg     0.5465    0.5116    0.5052       185
weighted avg     0.5761    0.5676    0.5519       185

micro f-score: 0.5675675675675675

========== Train Epoch 15 ==========
Loss: 0.905	Accuracy: 55.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5514       185
   macro avg     0.4940    0.5094    0.4913       185
weighted avg     0.5606    0.5514    0.5487       185

micro f-score: 0.5513513513513514

========== Train Epoch 16 ==========
Loss: 0.832	Accuracy: 55.68%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4800    0.7742    0.5926        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5568       185
   macro avg     0.5162    0.5224    0.5052       185
weighted avg     0.5877    0.5568    0.5555       185

micro f-score: 0.5567567567567567

========== Train Epoch 17 ==========
Loss: 0.816	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.3125    0.4545    0.3704        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6207    0.8000    0.6990        45
         zxx     0.8065    0.6410    0.7143        39

    accuracy                         0.5514       185
   macro avg     0.5027    0.4866    0.4749       185
weighted avg     0.5496    0.5514    0.5334       185

micro f-score: 0.5513513513513514

========== Train Epoch 18 ==========
Loss: 0.744	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5459       185
   macro avg     0.4955    0.5092    0.4953       185
weighted avg     0.5495    0.5459    0.5417       185

micro f-score: 0.5459459459459459

========== Train Epoch 19 ==========
Loss: 0.705	Accuracy: 52.43%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.4500    0.9231    0.6050        39

    accuracy                         0.5243       185
   macro avg     0.5258    0.4441    0.4349       185
weighted avg     0.5532    0.5243    0.4931       185

micro f-score: 0.5243243243243243

========== Train Epoch 20 ==========
Loss: 0.653	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7000    0.7778    0.7368        45
         zxx     0.5538    0.9231    0.6923        39

    accuracy                         0.5514       185
   macro avg     0.5436    0.4791    0.4620       185
weighted avg     0.5917    0.5514    0.5173       185

micro f-score: 0.5513513513513514

========== Train Epoch 21 ==========
Loss: 0.606	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5676       185
   macro avg     0.5245    0.5212    0.5124       185
weighted avg     0.5711    0.5676    0.5589       185

micro f-score: 0.5675675675675675

========== Train Epoch 22 ==========
Loss: 0.585	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.6604    0.7778    0.7143        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.6000       185
   macro avg     0.5640    0.5527    0.5329       185
weighted avg     0.6026    0.6000    0.5839       185

micro f-score: 0.6

========== Train Epoch 23 ==========
Loss: 0.558	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5784       185
   macro avg     0.5307    0.5182    0.5088       185
weighted avg     0.5709    0.5784    0.5623       185

micro f-score: 0.5783783783783784

========== Train Epoch 24 ==========
Loss: 0.478	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.3889    0.6364    0.4828        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.1667    0.2500        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5568       185
   macro avg     0.5404    0.4712    0.4709       185
weighted avg     0.5872    0.5568    0.5442       185

micro f-score: 0.5567567567567567

========== Train Epoch 25 ==========
Loss: 0.473	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.4118    0.6364    0.5000        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.8438    0.6923    0.7606        39

    accuracy                         0.6000       185
   macro avg     0.5646    0.5418    0.5454       185
weighted avg     0.6228    0.6000    0.6054       185

micro f-score: 0.6

========== Train Epoch 26 ==========
Loss: 0.424	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6296    0.5484    0.5862        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6000       185
   macro avg     0.5501    0.5613    0.5474       185
weighted avg     0.6011    0.6000    0.5944       185

micro f-score: 0.6

========== Train Epoch 27 ==========
Loss: 0.393	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6842    0.8667    0.7647        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.6162       185
   macro avg     0.5587    0.5482    0.5421       185
weighted avg     0.6100    0.6162    0.6035       185

micro f-score: 0.6162162162162163

========== Train Epoch 28 ==========
Loss: 0.374	Accuracy: 51.89%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5000    0.6129    0.5507        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6444    0.6444    0.6444        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4799    0.4797    0.4745       185
weighted avg     0.5403    0.5189    0.5230       185

micro f-score: 0.518918918918919

========== Train Epoch 29 ==========
Loss: 0.328	Accuracy: 56.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.8056    0.7436    0.7733        39

    accuracy                         0.5622       185
   macro avg     0.5335    0.5278    0.5180       185
weighted avg     0.5971    0.5622    0.5697       185

micro f-score: 0.5621621621621622

========== Train Epoch 30 ==========
Loss: 0.314	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.8462    0.5641    0.6769        39

    accuracy                         0.5676       185
   macro avg     0.5490    0.5489    0.5321       185
weighted avg     0.6162    0.5676    0.5771       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.282	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.9231    0.5333    0.6761        45
         zxx     0.4146    0.8718    0.5620        39

    accuracy                         0.5459       185
   macro avg     0.5909    0.4845    0.4991       185
weighted avg     0.6248    0.5459    0.5427       185

micro f-score: 0.5459459459459459

========== Train Epoch 32 ==========
Loss: 0.276	Accuracy: 58.38%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5000    0.6452    0.5634        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.8125    0.6667    0.7324        39

    accuracy                         0.5838       185
   macro avg     0.5648    0.5421    0.5376       185
weighted avg     0.6282    0.5838    0.5921       185

micro f-score: 0.5837837837837838

========== Train Epoch 33 ==========
Loss: 0.252	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5676    0.6774    0.6176        31
         cwx     0.4333    0.5909    0.5000        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.5892       185
   macro avg     0.5435    0.5350    0.5330       185
weighted avg     0.6104    0.5892    0.5933       185

micro f-score: 0.5891891891891892

========== Train Epoch 34 ==========
Loss: 0.239	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.2647    0.5294    0.3529        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.6000       185
   macro avg     0.5834    0.5877    0.5739       185
weighted avg     0.6456    0.6000    0.6118       185

micro f-score: 0.6

========== Train Epoch 35 ==========
Loss: 0.215	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.5730       185
   macro avg     0.5315    0.5262    0.5168       185
weighted avg     0.5943    0.5730    0.5755       185

micro f-score: 0.572972972972973

========== Train Epoch 36 ==========
Loss: 0.214	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.2963    0.4706    0.3636        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6552    0.8444    0.7379        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.5946       185
   macro avg     0.5874    0.5538    0.5472       185
weighted avg     0.6309    0.5946    0.5936       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.177	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.5892       185
   macro avg     0.5725    0.5436    0.5421       185
weighted avg     0.6198    0.5892    0.5919       185

micro f-score: 0.5891891891891892

========== Train Epoch 38 ==========
Loss: 0.183	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6667    0.8000    0.7273        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6216       185
   macro avg     0.5924    0.5594    0.5575       185
weighted avg     0.6355    0.6216    0.6142       185

micro f-score: 0.6216216216216216

========== Train Epoch 39 ==========
Loss: 0.171	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.4118    0.6364    0.5000        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6108       185
   macro avg     0.5861    0.5557    0.5542       185
weighted avg     0.6511    0.6108    0.6182       185

micro f-score: 0.6108108108108108

========== Train Epoch 40 ==========
Loss: 0.155	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6167    0.8222    0.7048        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6054       185
   macro avg     0.5955    0.5486    0.5415       185
weighted avg     0.6271    0.6054    0.5894       185

micro f-score: 0.6054054054054054

========== Train Epoch 41 ==========
Loss: 0.154	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.2500    0.4118    0.3111        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.5892       185
   macro avg     0.5514    0.5583    0.5484       185
weighted avg     0.6180    0.5892    0.5983       185

micro f-score: 0.5891891891891892

========== Train Epoch 42 ==========
Loss: 0.154	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.6774    0.7119        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6378       185
   macro avg     0.5938    0.5845    0.5777       185
weighted avg     0.6533    0.6378    0.6370       185

micro f-score: 0.6378378378378379

========== Train Epoch 43 ==========
Loss: 0.145	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6000       185
   macro avg     0.5680    0.5623    0.5541       185
weighted avg     0.6152    0.6000    0.5970       185

micro f-score: 0.6

========== Train Epoch 44 ==========
Loss: 0.136	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6176    0.6774    0.6462        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.6270       185
   macro avg     0.5978    0.5797    0.5749       185
weighted avg     0.6379    0.6270    0.6219       185

micro f-score: 0.6270270270270271

========== Train Epoch 45 ==========
Loss: 0.119	Accuracy: 63.78%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7037    0.6129    0.6552        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6378       185
   macro avg     0.6107    0.6152    0.6033       185
weighted avg     0.6598    0.6378    0.6417       185

micro f-score: 0.6378378378378379

========== Train Epoch 46 ==========
Loss: 0.131	Accuracy: 63.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6324       185
   macro avg     0.5980    0.5888    0.5858       185
weighted avg     0.6429    0.6324    0.6319       185

micro f-score: 0.6324324324324324

========== Train Epoch 47 ==========
Loss: 0.110	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.7097    0.5867        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.8889    0.5333    0.6667        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5838       185
   macro avg     0.5619    0.5244    0.5224       185
weighted avg     0.6138    0.5838    0.5762       185

micro f-score: 0.5837837837837838

========== Train Epoch 48 ==========
Loss: 0.117	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3448    0.5882    0.4348        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.6108       185
   macro avg     0.5830    0.5569    0.5503       185
weighted avg     0.6400    0.6108    0.6095       185

micro f-score: 0.6108108108108108

========== Train Epoch 49 ==========
Loss: 0.117	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3030    0.5882    0.4000        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.6054       185
   macro avg     0.5870    0.5776    0.5666       185
weighted avg     0.6412    0.6054    0.6115       185

micro f-score: 0.6054054054054054

========== Train Epoch 50 ==========
Loss: 0.113	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.2941    0.5882    0.3922        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8333    0.5556    0.6667        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.5892       185
   macro avg     0.5717    0.5739    0.5610       185
weighted avg     0.6382    0.5892    0.6018       185

micro f-score: 0.5891891891891892

========== Train Epoch 51 ==========
Loss: 0.110	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6562    0.6774    0.6667        31
         cwx     0.6250    0.6818    0.6522        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.6324       185
   macro avg     0.5942    0.6028    0.5916       185
weighted avg     0.6633    0.6324    0.6414       185

micro f-score: 0.6324324324324324

========== Train Epoch 52 ==========
Loss: 0.097	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6324       185
   macro avg     0.6042    0.5893    0.5804       185
weighted avg     0.6372    0.6324    0.6228       185

micro f-score: 0.6324324324324324

========== Train Epoch 53 ==========
Loss: 0.093	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6108       185
   macro avg     0.5778    0.5506    0.5533       185
weighted avg     0.6180    0.6108    0.6053       185

micro f-score: 0.6108108108108108

========== Train Epoch 54 ==========
Loss: 0.107	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.2821    0.6471    0.3929        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6378       185
   macro avg     0.6389    0.6267    0.6174       185
weighted avg     0.6968    0.6378    0.6548       185

micro f-score: 0.6378378378378379

========== Train Epoch 55 ==========
Loss: 0.093	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7778    0.4516    0.5714        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7255    0.8222    0.7708        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.6216       185
   macro avg     0.5964    0.5830    0.5669       185
weighted avg     0.6647    0.6216    0.6240       185

micro f-score: 0.6216216216216216

========== Train Epoch 56 ==========
Loss: 0.085	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.5838       185
   macro avg     0.5528    0.5575    0.5447       185
weighted avg     0.6087    0.5838    0.5878       185

micro f-score: 0.5837837837837838

========== Train Epoch 57 ==========
Loss: 0.090	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7037    0.6129    0.6552        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6378       185
   macro avg     0.6020    0.5941    0.5885       185
weighted avg     0.6492    0.6378    0.6367       185

micro f-score: 0.6378378378378379

========== Train Epoch 58 ==========
Loss: 0.093	Accuracy: 63.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.7442    0.8205    0.7805        39

    accuracy                         0.6324       185
   macro avg     0.6147    0.6020    0.5878       185
weighted avg     0.6590    0.6324    0.6304       185

micro f-score: 0.6324324324324324

========== Train Epoch 59 ==========
Loss: 0.085	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.4324    0.7273    0.5424        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.8387    0.6667    0.7429        39

    accuracy                         0.5838       185
   macro avg     0.5649    0.5655    0.5542       185
weighted avg     0.6286    0.5838    0.5932       185

micro f-score: 0.5837837837837838

========== Train Epoch 60 ==========
Loss: 0.088	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7647    0.4194    0.5417        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.2778    0.5882    0.3774        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.3600    0.7500    0.4865        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.5946       185
   macro avg     0.5947    0.5770    0.5543       185
weighted avg     0.6656    0.5946    0.6060       185

micro f-score: 0.5945945945945946

========== Train Epoch 61 ==========
Loss: 0.074	Accuracy: 63.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6500    0.8667    0.7429        45
         zxx     0.8611    0.7949    0.8267        39

    accuracy                         0.6324       185
   macro avg     0.5899    0.5662    0.5639       185
weighted avg     0.6352    0.6324    0.6211       185

micro f-score: 0.6324324324324324

========== Train Epoch 62 ==========
Loss: 0.071	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6429    0.9231    0.7579        39

    accuracy                         0.6324       185
   macro avg     0.6046    0.5804    0.5736       185
weighted avg     0.6455    0.6324    0.6211       185

micro f-score: 0.6324324324324324

========== Train Epoch 63 ==========
Loss: 0.074	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6432       185
   macro avg     0.6111    0.5957    0.5893       185
weighted avg     0.6428    0.6432    0.6318       185

micro f-score: 0.6432432432432432

========== Train Epoch 64 ==========
Loss: 0.067	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5789    0.7097    0.6377        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.6216       185
   macro avg     0.5855    0.5926    0.5798       185
weighted avg     0.6407    0.6216    0.6227       185

micro f-score: 0.6216216216216216

Finished training!!!

Min Loss = 0.067 in epoch 63;
Max Accuracy = 64.32% in epoch 62;
Total Cost 31 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-6                     [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-13                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-3                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-15                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-16                 [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-17                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-18                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-19                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-20                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-21                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-22                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-23                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-24                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-25                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-26                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-27                    [-1, 128, 40, 40]         3,352
|    |    └─Sequential: 3-28                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-5                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-30                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-31                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-32                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-33                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-34                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-35                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-36                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-6                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-37                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-38                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-39                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-40                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-41                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-42                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-43                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-44                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-45                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-46                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-47                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-48                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-49                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-50                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-8                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-51                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-52                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-53                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-54                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-55                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-56                    [-1, 256, 20, 20]         6,680
|    |    └─Sequential: 3-57                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-58                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-9                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-59                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-60                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-61                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-62                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-63                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-64                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-65                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-10                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-66                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-67                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-68                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-69                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-70                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-71                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-72                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-11                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-73                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-74                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-75                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-76                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-77                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-78                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-79                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-12                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-80                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-81                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-82                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-83                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-84                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-85                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-86                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-13                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-87                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-88                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-89                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-90                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-91                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-92                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-93                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-14                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-94                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-95                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-96                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-97                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-98                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-99                    [-1, 512, 10, 10]         25,648
|    |    └─Sequential: 3-100                 [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-101                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-15                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-102                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-103                [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-104                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-105                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-106                [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-107                   [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-108                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-16                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-109                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-110                [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-111                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-112                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-113                [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-114                   [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-115                       [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 21,423,759
Trainable params: 21,423,759
Non-trainable params: 0
Total mult-adds (G): 7.52
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 117.80
Params size (MB): 81.73
Estimated Total Size (MB): 200.69
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet34, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
