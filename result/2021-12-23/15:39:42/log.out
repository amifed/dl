dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.821	Accuracy: 27.57%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3043    0.2258    0.2593        31
         cwx     0.2593    0.3182    0.2857        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.1667    0.3333    0.2222        12
         qtx     0.3023    0.5778    0.3969        45
         zxx     0.3125    0.1282    0.1818        39

    accuracy                         0.2757       185
   macro avg     0.2636    0.2421    0.2177       185
weighted avg     0.2816    0.2757    0.2440       185

micro f-score: 0.2756756756756757

========== Train Epoch 2 ==========
Loss: 1.589	Accuracy: 37.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.4906    0.5778    0.5306        45
         zxx     0.3537    0.7436    0.4793        39

    accuracy                         0.3730       185
   macro avg     0.2500    0.2773    0.2493       185
weighted avg     0.3066    0.3730    0.3206       185

micro f-score: 0.37297297297297294

========== Train Epoch 3 ==========
Loss: 1.469	Accuracy: 40.54%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.1111    0.0588    0.0769        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5098    0.5778    0.5417        45
         zxx     0.3780    0.7949    0.5124        39

    accuracy                         0.4054       185
   macro avg     0.3487    0.3171    0.3046       185
weighted avg     0.3878    0.4054    0.3653       185

micro f-score: 0.40540540540540543

========== Train Epoch 4 ==========
Loss: 1.425	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.3182    0.3182    0.3182        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.4432       185
   macro avg     0.3821    0.3690    0.3551       185
weighted avg     0.4217    0.4432    0.4113       185

micro f-score: 0.44324324324324327

========== Train Epoch 5 ==========
Loss: 1.377	Accuracy: 45.95%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4521    0.8462    0.5893        39

    accuracy                         0.4595       185
   macro avg     0.4085    0.3895    0.3800       185
weighted avg     0.4568    0.4595    0.4357       185

micro f-score: 0.4594594594594595

========== Train Epoch 6 ==========
Loss: 1.322	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4486       185
   macro avg     0.3943    0.3686    0.3552       185
weighted avg     0.4457    0.4486    0.4180       185

micro f-score: 0.4486486486486486

========== Train Epoch 7 ==========
Loss: 1.291	Accuracy: 48.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6429    0.6000    0.6207        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4865       185
   macro avg     0.4574    0.4098    0.3945       185
weighted avg     0.4897    0.4865    0.4524       185

micro f-score: 0.4864864864864865

========== Train Epoch 8 ==========
Loss: 1.241	Accuracy: 48.11%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.4811       185
   macro avg     0.4281    0.4133    0.4013       185
weighted avg     0.4674    0.4811    0.4552       185

micro f-score: 0.4810810810810811

========== Train Epoch 9 ==========
Loss: 1.187	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.3125    0.4545    0.3704        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5778    0.5778    0.5778        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5027       185
   macro avg     0.4486    0.4428    0.4294       185
weighted avg     0.4935    0.5027    0.4856       185

micro f-score: 0.5027027027027027

========== Train Epoch 10 ==========
Loss: 1.156	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5135       185
   macro avg     0.4664    0.4607    0.4376       185
weighted avg     0.5148    0.5135    0.4911       185

micro f-score: 0.5135135135135135

========== Train Epoch 11 ==========
Loss: 1.118	Accuracy: 49.19%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.4919       185
   macro avg     0.4256    0.4201    0.4020       185
weighted avg     0.4808    0.4919    0.4638       185

micro f-score: 0.4918918918918919

========== Train Epoch 12 ==========
Loss: 1.059	Accuracy: 51.35%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.3333    0.4545    0.3846        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5135       185
   macro avg     0.4488    0.4534    0.4391       185
weighted avg     0.5054    0.5135    0.4966       185

micro f-score: 0.5135135135135135

========== Train Epoch 13 ==========
Loss: 1.026	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.6000    0.6667    0.6316        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.5568       185
   macro avg     0.5290    0.5102    0.4951       185
weighted avg     0.5756    0.5568    0.5495       185

micro f-score: 0.5567567567567567

========== Train Epoch 14 ==========
Loss: 0.980	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.4643    0.5909    0.5200        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5514       185
   macro avg     0.4976    0.5045    0.4857       185
weighted avg     0.5595    0.5514    0.5397       185

micro f-score: 0.5513513513513514

========== Train Epoch 15 ==========
Loss: 0.925	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5676       185
   macro avg     0.4943    0.5132    0.4947       185
weighted avg     0.5499    0.5676    0.5526       185

micro f-score: 0.5675675675675675

========== Train Epoch 16 ==========
Loss: 0.905	Accuracy: 55.14%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.3548    0.5000    0.4151        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6400    0.7111    0.6737        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5514       185
   macro avg     0.4834    0.4915    0.4778       185
weighted avg     0.5459    0.5514    0.5411       185

micro f-score: 0.5513513513513514

========== Train Epoch 17 ==========
Loss: 0.834	Accuracy: 57.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.5784       185
   macro avg     0.5094    0.5161    0.4929       185
weighted avg     0.5720    0.5784    0.5564       185

micro f-score: 0.5783783783783784

========== Train Epoch 18 ==========
Loss: 0.798	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5224    0.8974    0.6604        39

    accuracy                         0.5568       185
   macro avg     0.5605    0.5073    0.4914       185
weighted avg     0.5856    0.5568    0.5352       185

micro f-score: 0.5567567567567567

========== Train Epoch 19 ==========
Loss: 0.748	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6162       185
   macro avg     0.5720    0.5704    0.5660       185
weighted avg     0.6120    0.6162    0.6077       185

micro f-score: 0.6162162162162163

========== Train Epoch 20 ==========
Loss: 0.702	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5784       185
   macro avg     0.5936    0.5265    0.5224       185
weighted avg     0.6175    0.5784    0.5638       185

micro f-score: 0.5783783783783784

========== Train Epoch 21 ==========
Loss: 0.659	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.6108       185
   macro avg     0.5602    0.5577    0.5501       185
weighted avg     0.6037    0.6108    0.5996       185

micro f-score: 0.6108108108108108

========== Train Epoch 22 ==========
Loss: 0.637	Accuracy: 60.00%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6000       185
   macro avg     0.5415    0.5634    0.5438       185
weighted avg     0.5855    0.6000    0.5851       185

micro f-score: 0.6

========== Train Epoch 23 ==========
Loss: 0.590	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.6162       185
   macro avg     0.5879    0.5574    0.5533       185
weighted avg     0.6170    0.6162    0.5987       185

micro f-score: 0.6162162162162163

========== Train Epoch 24 ==========
Loss: 0.562	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.4474    0.7727    0.5667        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.5946       185
   macro avg     0.5889    0.5632    0.5573       185
weighted avg     0.6180    0.5946    0.5868       185

micro f-score: 0.5945945945945946

========== Train Epoch 25 ==========
Loss: 0.520	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5135    0.6129    0.5588        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.6054       185
   macro avg     0.5519    0.5498    0.5411       185
weighted avg     0.5964    0.6054    0.5919       185

micro f-score: 0.6054054054054054

========== Train Epoch 26 ==========
Loss: 0.490	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6108       185
   macro avg     0.5666    0.5876    0.5606       185
weighted avg     0.6291    0.6108    0.6032       185

micro f-score: 0.6108108108108108

========== Train Epoch 27 ==========
Loss: 0.435	Accuracy: 57.30%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.5730       185
   macro avg     0.5963    0.5263    0.5260       185
weighted avg     0.6198    0.5730    0.5628       185

micro f-score: 0.572972972972973

========== Train Epoch 28 ==========
Loss: 0.401	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5946       185
   macro avg     0.5634    0.5737    0.5537       185
weighted avg     0.6155    0.5946    0.5887       185

micro f-score: 0.5945945945945946

========== Train Epoch 29 ==========
Loss: 0.413	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.6190    0.5909    0.6047        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5838       185
   macro avg     0.5752    0.5427    0.5306       185
weighted avg     0.6107    0.5838    0.5719       185

micro f-score: 0.5837837837837838

========== Train Epoch 30 ==========
Loss: 0.364	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.4211    0.7273    0.5333        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2857    0.4211    0.3404        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5676       185
   macro avg     0.5460    0.5373    0.5235       185
weighted avg     0.6315    0.5676    0.5786       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.337	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6054       185
   macro avg     0.5655    0.5572    0.5514       185
weighted avg     0.6103    0.6054    0.5988       185

micro f-score: 0.6054054054054054

========== Train Epoch 32 ==========
Loss: 0.304	Accuracy: 61.08%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.6108       185
   macro avg     0.5751    0.5782    0.5677       185
weighted avg     0.6357    0.6108    0.6113       185

micro f-score: 0.6108108108108108

========== Train Epoch 33 ==========
Loss: 0.298	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5838       185
   macro avg     0.5725    0.5469    0.5409       185
weighted avg     0.6028    0.5838    0.5749       185

micro f-score: 0.5837837837837838

========== Train Epoch 34 ==========
Loss: 0.284	Accuracy: 59.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.5946       185
   macro avg     0.5695    0.5698    0.5425       185
weighted avg     0.6177    0.5946    0.5884       185

micro f-score: 0.5945945945945946

========== Train Epoch 35 ==========
Loss: 0.245	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.5484    0.7727    0.6415        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6162       185
   macro avg     0.5850    0.5827    0.5700       185
weighted avg     0.6278    0.6162    0.6089       185

micro f-score: 0.6162162162162163

========== Train Epoch 36 ==========
Loss: 0.247	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.6054       185
   macro avg     0.5853    0.5540    0.5494       185
weighted avg     0.6110    0.6054    0.5925       185

micro f-score: 0.6054054054054054

========== Train Epoch 37 ==========
Loss: 0.213	Accuracy: 65.95%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6296    0.5484    0.5862        31
         cwx     0.6957    0.7273    0.7111        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.8000    0.4211    0.5517        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.6595       185
   macro avg     0.6525    0.6458    0.6304       185
weighted avg     0.6823    0.6595    0.6544       185

micro f-score: 0.6594594594594595

========== Train Epoch 38 ==========
Loss: 0.207	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.8000    0.4211    0.5517        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6432       185
   macro avg     0.6369    0.6263    0.6122       185
weighted avg     0.6686    0.6432    0.6431       185

micro f-score: 0.6432432432432432

========== Train Epoch 39 ==========
Loss: 0.195	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.6154    0.4211    0.5000        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.7879    0.6667    0.7222        39

    accuracy                         0.6108       185
   macro avg     0.5847    0.5731    0.5736       185
weighted avg     0.6214    0.6108    0.6111       185

micro f-score: 0.6108108108108108

========== Train Epoch 40 ==========
Loss: 0.199	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3667    0.6471    0.4681        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6270       185
   macro avg     0.6311    0.6127    0.5993       185
weighted avg     0.6655    0.6270    0.6252       185

micro f-score: 0.6270270270270271

========== Train Epoch 41 ==========
Loss: 0.181	Accuracy: 61.62%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6162       185
   macro avg     0.6081    0.6075    0.5858       185
weighted avg     0.6534    0.6162    0.6121       185

micro f-score: 0.6162162162162163

========== Train Epoch 42 ==========
Loss: 0.167	Accuracy: 63.78%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.7647    0.5909    0.6667        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.7778    0.3684    0.5000        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.6378       185
   macro avg     0.6375    0.6121    0.6052       185
weighted avg     0.6643    0.6378    0.6341       185

micro f-score: 0.6378378378378379

========== Train Epoch 43 ==========
Loss: 0.153	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.6162       185
   macro avg     0.6343    0.5886    0.5861       185
weighted avg     0.6519    0.6162    0.6122       185

micro f-score: 0.6162162162162163

========== Train Epoch 44 ==========
Loss: 0.149	Accuracy: 61.62%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.6162       185
   macro avg     0.5950    0.5930    0.5771       185
weighted avg     0.6412    0.6162    0.6162       185

micro f-score: 0.6162162162162163

========== Train Epoch 45 ==========
Loss: 0.133	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.6000       185
   macro avg     0.5985    0.5960    0.5736       185
weighted avg     0.6432    0.6000    0.5943       185

micro f-score: 0.6

========== Train Epoch 46 ==========
Loss: 0.135	Accuracy: 62.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.6270       185
   macro avg     0.6346    0.6135    0.5952       185
weighted avg     0.6695    0.6270    0.6213       185

micro f-score: 0.6270270270270271

========== Train Epoch 47 ==========
Loss: 0.128	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.6000    0.4737    0.5294        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6216       185
   macro avg     0.5919    0.5777    0.5806       185
weighted avg     0.6246    0.6216    0.6191       185

micro f-score: 0.6216216216216216

========== Train Epoch 48 ==========
Loss: 0.127	Accuracy: 62.70%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6270       185
   macro avg     0.6169    0.6125    0.5868       185
weighted avg     0.6562    0.6270    0.6219       185

micro f-score: 0.6270270270270271

========== Train Epoch 49 ==========
Loss: 0.118	Accuracy: 62.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.6270       185
   macro avg     0.6338    0.6028    0.5905       185
weighted avg     0.6574    0.6270    0.6216       185

micro f-score: 0.6270270270270271

========== Train Epoch 50 ==========
Loss: 0.120	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6458    0.6889    0.6667        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.6108       185
   macro avg     0.5915    0.5834    0.5790       185
weighted avg     0.6183    0.6108    0.6084       185

micro f-score: 0.6108108108108108

========== Train Epoch 51 ==========
Loss: 0.117	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6108       185
   macro avg     0.5795    0.5737    0.5710       185
weighted avg     0.6177    0.6108    0.6081       185

micro f-score: 0.6108108108108108

========== Train Epoch 52 ==========
Loss: 0.101	Accuracy: 65.41%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.6000    0.4737    0.5294        19
         nqx     0.5789    0.9167    0.7097        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6541       185
   macro avg     0.6189    0.6314    0.6159       185
weighted avg     0.6543    0.6541    0.6483       185

micro f-score: 0.654054054054054

========== Train Epoch 53 ==========
Loss: 0.109	Accuracy: 65.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.7000    0.8974    0.7865        39

    accuracy                         0.6595       185
   macro avg     0.6567    0.6386    0.6225       185
weighted avg     0.6941    0.6595    0.6573       185

micro f-score: 0.6594594594594595

========== Train Epoch 54 ==========
Loss: 0.101	Accuracy: 64.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.5667    0.7727    0.6538        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.5000    0.4737    0.4865        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6432       185
   macro avg     0.6210    0.6099    0.6059       185
weighted avg     0.6593    0.6432    0.6421       185

micro f-score: 0.6432432432432432

========== Train Epoch 55 ==========
Loss: 0.117	Accuracy: 67.03%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.6111    0.5789    0.5946        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6703       185
   macro avg     0.6415    0.6608    0.6455       185
weighted avg     0.6795    0.6703    0.6708       185

micro f-score: 0.6702702702702703

========== Train Epoch 56 ==========
Loss: 0.098	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6432       185
   macro avg     0.6340    0.6298    0.6241       185
weighted avg     0.6688    0.6432    0.6468       185

micro f-score: 0.6432432432432432

========== Train Epoch 57 ==========
Loss: 0.101	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.6667    0.4211    0.5161        19
         nqx     0.6471    0.9167    0.7586        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6324       185
   macro avg     0.6284    0.6276    0.6076       185
weighted avg     0.6578    0.6324    0.6268       185

micro f-score: 0.6324324324324324

========== Train Epoch 58 ==========
Loss: 0.093	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3448    0.5882    0.4348        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6108       185
   macro avg     0.5978    0.6052    0.5809       185
weighted avg     0.6450    0.6108    0.6076       185

micro f-score: 0.6108108108108108

========== Train Epoch 59 ==========
Loss: 0.079	Accuracy: 67.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.8182    0.4737    0.6000        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.6757       185
   macro avg     0.6799    0.6585    0.6572       185
weighted avg     0.7012    0.6757    0.6768       185

micro f-score: 0.6756756756756757

========== Train Epoch 60 ==========
Loss: 0.077	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.6667    0.4211    0.5161        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.6364    0.8974    0.7447        39

    accuracy                         0.6378       185
   macro avg     0.6316    0.6146    0.6073       185
weighted avg     0.6728    0.6378    0.6376       185

micro f-score: 0.6378378378378379

========== Train Epoch 61 ==========
Loss: 0.087	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8333    0.3226    0.4651        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.5000    0.9167    0.6471        12
         qtx     0.8293    0.7556    0.7907        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.6324       185
   macro avg     0.6573    0.6099    0.5844       185
weighted avg     0.6940    0.6324    0.6191       185

micro f-score: 0.6324324324324324

========== Train Epoch 62 ==========
Loss: 0.079	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6324       185
   macro avg     0.6304    0.5984    0.5925       185
weighted avg     0.6455    0.6324    0.6221       185

micro f-score: 0.6324324324324324

========== Train Epoch 63 ==========
Loss: 0.074	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5714    0.9231    0.7059        39

    accuracy                         0.6432       185
   macro avg     0.6439    0.6297    0.6105       185
weighted avg     0.6731    0.6432    0.6322       185

micro f-score: 0.6432432432432432

========== Train Epoch 64 ==========
Loss: 0.081	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.6108       185
   macro avg     0.6212    0.5716    0.5702       185
weighted avg     0.6335    0.6108    0.6023       185

micro f-score: 0.6108108108108108

Finished training!!!

Min Loss = 0.074 in epoch 62;
Max Accuracy = 67.57% in epoch 58;
Total Cost 31 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-6                     [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-13                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-3                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-15                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-16                 [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-17                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-18                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-19                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-20                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-21                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-22                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-23                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-24                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-25                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-26                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-27                    [-1, 128, 40, 40]         3,352
|    |    └─Sequential: 3-28                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-5                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-30                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-31                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-32                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-33                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-34                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-35                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-36                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-6                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-37                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-38                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-39                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-40                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-41                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-42                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-43                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-44                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-45                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-46                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-47                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-48                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-49                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-50                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-8                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-51                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-52                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-53                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-54                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-55                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-56                    [-1, 256, 20, 20]         6,680
|    |    └─Sequential: 3-57                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-58                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-9                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-59                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-60                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-61                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-62                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-63                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-64                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-65                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-10                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-66                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-67                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-68                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-69                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-70                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-71                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-72                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-11                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-73                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-74                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-75                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-76                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-77                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-78                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-79                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-12                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-80                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-81                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-82                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-83                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-84                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-85                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-86                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-13                       [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-87                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-88                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-89                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-90                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-91                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-92                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-93                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-14                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-94                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-95                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-96                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-97                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-98                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-99                    [-1, 512, 10, 10]         25,648
|    |    └─Sequential: 3-100                 [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-101                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-15                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-102                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-103                [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-104                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-105                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-106                [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-107                   [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-108                       [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-16                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-109                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-110                [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-111                       [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-112                     [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-113                [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-114                   [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-115                       [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 21,423,759
Trainable params: 21,423,759
Non-trainable params: 0
Total mult-adds (G): 7.52
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 117.80
Params size (MB): 81.73
Estimated Total Size (MB): 200.69
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet34, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
