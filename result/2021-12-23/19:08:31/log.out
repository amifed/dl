dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.844	Accuracy: 24.86%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0667    0.0526    0.0588        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.2500    0.1333    0.1739        45
         zxx     0.2463    0.8462    0.3815        39

    accuracy                         0.2486       185
   macro avg     0.3593    0.1935    0.1651       185
weighted avg     0.3301    0.2486    0.1834       185

micro f-score: 0.24864864864864866

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.665	Accuracy: 39.46%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.4583    0.4889    0.4731        45
         zxx     0.3483    0.7949    0.4844        39

    accuracy                         0.3946       185
   macro avg     0.5031    0.3222    0.3207       185
weighted avg     0.4918    0.3946    0.3640       185

micro f-score: 0.3945945945945946

========== Train Epoch 3 ==========
Loss: 1.573	Accuracy: 40.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4348    0.3226    0.3704        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.5000    0.5111    0.5055        45
         zxx     0.3605    0.7949    0.4960        39

    accuracy                         0.4000       185
   macro avg     0.4759    0.3178    0.3057       185
weighted avg     0.4693    0.4000    0.3615       185

micro f-score: 0.4000000000000001

========== Train Epoch 4 ==========
Loss: 1.537	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.3690    0.7949    0.5041        39

    accuracy                         0.4054       185
   macro avg     0.3497    0.3205    0.3034       185
weighted avg     0.3863    0.4054    0.3644       185

micro f-score: 0.40540540540540543

========== Train Epoch 5 ==========
Loss: 1.507	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4583    0.3548    0.4000        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.3563    0.7949    0.4921        39

    accuracy                         0.4054       185
   macro avg     0.4086    0.3224    0.3117       185
weighted avg     0.4278    0.4054    0.3688       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.490	Accuracy: 43.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5217    0.5333    0.5275        45
         zxx     0.4026    0.7949    0.5345        39

    accuracy                         0.4324       185
   macro avg     0.4241    0.3589    0.3537       185
weighted avg     0.4372    0.4324    0.4009       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 1.474	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.3684    0.8974    0.5224        39

    accuracy                         0.4054       185
   macro avg     0.3065    0.3041    0.2777       185
weighted avg     0.3645    0.4054    0.3522       185

micro f-score: 0.40540540540540543

========== Train Epoch 8 ==========
Loss: 1.448	Accuracy: 42.70%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4096    0.8718    0.5574        39

    accuracy                         0.4270       185
   macro avg     0.3894    0.3345    0.3227       185
weighted avg     0.4238    0.4270    0.3881       185

micro f-score: 0.427027027027027

========== Train Epoch 9 ==========
Loss: 1.429	Accuracy: 43.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.4231    0.8462    0.5641        39

    accuracy                         0.4324       185
   macro avg     0.3933    0.3492    0.3332       185
weighted avg     0.4247    0.4324    0.3936       185

micro f-score: 0.43243243243243246

========== Train Epoch 10 ==========
Loss: 1.412	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.4430    0.8974    0.5932        39

    accuracy                         0.4432       185
   macro avg     0.4106    0.3580    0.3457       185
weighted avg     0.4409    0.4432    0.4060       185

micro f-score: 0.44324324324324327

========== Train Epoch 11 ==========
Loss: 1.387	Accuracy: 44.86%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4268    0.8974    0.5785        39

    accuracy                         0.4486       185
   macro avg     0.5007    0.3722    0.3625       185
weighted avg     0.5053    0.4486    0.4145       185

micro f-score: 0.4486486486486486

========== Train Epoch 12 ==========
Loss: 1.362	Accuracy: 44.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.4432       185
   macro avg     0.4460    0.3750    0.3610       185
weighted avg     0.4605    0.4432    0.4080       185

micro f-score: 0.44324324324324327

========== Train Epoch 13 ==========
Loss: 1.358	Accuracy: 47.03%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5217    0.5333    0.5275        45
         zxx     0.4384    0.8205    0.5714        39

    accuracy                         0.4703       185
   macro avg     0.4764    0.4042    0.4047       185
weighted avg     0.4820    0.4703    0.4445       185

micro f-score: 0.4702702702702703

========== Train Epoch 14 ==========
Loss: 1.322	Accuracy: 45.41%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     1.0000    0.2105    0.3478        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.4541       185
   macro avg     0.4944    0.3900    0.3854       185
weighted avg     0.4959    0.4541    0.4261       185

micro f-score: 0.4540540540540541

========== Train Epoch 15 ==========
Loss: 1.310	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5027       185
   macro avg     0.4834    0.4317    0.4299       185
weighted avg     0.5063    0.5027    0.4798       185

micro f-score: 0.5027027027027027

========== Train Epoch 16 ==========
Loss: 1.281	Accuracy: 47.03%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.4605    0.8974    0.6087        39

    accuracy                         0.4703       185
   macro avg     0.5077    0.3942    0.3790       185
weighted avg     0.5131    0.4703    0.4322       185

micro f-score: 0.4702702702702703

========== Train Epoch 17 ==========
Loss: 1.249	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.3804    0.8974    0.5344        39

    accuracy                         0.4432       185
   macro avg     0.5131    0.3696    0.3661       185
weighted avg     0.5141    0.4432    0.4122       185

micro f-score: 0.44324324324324327

========== Train Epoch 18 ==========
Loss: 1.247	Accuracy: 51.89%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.5194    0.4503    0.4451       185
weighted avg     0.5352    0.5189    0.4964       185

micro f-score: 0.518918918918919

========== Train Epoch 19 ==========
Loss: 1.223	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5435    0.5556    0.5495        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.5027       185
   macro avg     0.5262    0.4323    0.4321       185
weighted avg     0.5252    0.5027    0.4747       185

micro f-score: 0.5027027027027027

========== Train Epoch 20 ==========
Loss: 1.214	Accuracy: 45.95%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.4198    0.8718    0.5667        39

    accuracy                         0.4595       185
   macro avg     0.4878    0.3964    0.3931       185
weighted avg     0.4931    0.4595    0.4315       185

micro f-score: 0.4594594594594595

========== Train Epoch 21 ==========
Loss: 1.182	Accuracy: 50.27%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5319    0.5556    0.5435        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5027       185
   macro avg     0.4969    0.4323    0.4296       185
weighted avg     0.5076    0.5027    0.4747       185

micro f-score: 0.5027027027027027

========== Train Epoch 22 ==========
Loss: 1.180	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5135       185
   macro avg     0.5313    0.4620    0.4472       185
weighted avg     0.5418    0.5135    0.4850       185

micro f-score: 0.5135135135135135

========== Train Epoch 23 ==========
Loss: 1.166	Accuracy: 49.19%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4919       185
   macro avg     0.5143    0.4283    0.4266       185
weighted avg     0.5275    0.4919    0.4700       185

micro f-score: 0.4918918918918919

========== Train Epoch 24 ==========
Loss: 1.139	Accuracy: 51.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5189       185
   macro avg     0.5178    0.4629    0.4519       185
weighted avg     0.5405    0.5189    0.4975       185

micro f-score: 0.518918918918919

========== Train Epoch 25 ==========
Loss: 1.118	Accuracy: 52.97%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6765    0.5111    0.5823        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5297       185
   macro avg     0.4838    0.4794    0.4626       185
weighted avg     0.5257    0.5297    0.5100       185

micro f-score: 0.5297297297297298

========== Train Epoch 26 ==========
Loss: 1.106	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5189       185
   macro avg     0.4769    0.4799    0.4634       185
weighted avg     0.5180    0.5189    0.5049       185

micro f-score: 0.518918918918919

========== Train Epoch 27 ==========
Loss: 1.079	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5027       185
   macro avg     0.4751    0.4355    0.4252       185
weighted avg     0.5029    0.5027    0.4766       185

micro f-score: 0.5027027027027027

========== Train Epoch 28 ==========
Loss: 1.077	Accuracy: 51.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.5957    0.6222    0.6087        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5189       185
   macro avg     0.5116    0.4548    0.4478       185
weighted avg     0.5296    0.5189    0.4964       185

micro f-score: 0.518918918918919

========== Train Epoch 29 ==========
Loss: 1.040	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4865    0.5806    0.5294        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5135       185
   macro avg     0.4812    0.4641    0.4505       185
weighted avg     0.5160    0.5135    0.4951       185

micro f-score: 0.5135135135135135

========== Train Epoch 30 ==========
Loss: 1.016	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4634    0.6129    0.5278        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.5135       185
   macro avg     0.4680    0.4635    0.4553       185
weighted avg     0.5100    0.5135    0.5030       185

micro f-score: 0.5135135135135135

========== Train Epoch 31 ==========
Loss: 1.002	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5135       185
   macro avg     0.4719    0.4554    0.4441       185
weighted avg     0.5096    0.5135    0.4941       185

micro f-score: 0.5135135135135135

========== Train Epoch 32 ==========
Loss: 0.975	Accuracy: 57.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5730       185
   macro avg     0.5800    0.5347    0.5179       185
weighted avg     0.6165    0.5730    0.5585       185

micro f-score: 0.572972972972973

========== Train Epoch 33 ==========
Loss: 0.968	Accuracy: 52.43%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.5243       185
   macro avg     0.5110    0.4832    0.4719       185
weighted avg     0.5424    0.5243    0.5097       185

micro f-score: 0.5243243243243243

========== Train Epoch 34 ==========
Loss: 0.957	Accuracy: 56.22%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.6207    0.9231    0.7423        39

    accuracy                         0.5622       185
   macro avg     0.5192    0.5171    0.5041       185
weighted avg     0.5752    0.5622    0.5497       185

micro f-score: 0.5621621621621622

========== Train Epoch 35 ==========
Loss: 0.950	Accuracy: 54.05%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5405       185
   macro avg     0.5390    0.4948    0.4833       185
weighted avg     0.5767    0.5405    0.5262       185

micro f-score: 0.5405405405405406

========== Train Epoch 36 ==========
Loss: 0.920	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5568       185
   macro avg     0.5285    0.5318    0.5171       185
weighted avg     0.5623    0.5568    0.5468       185

micro f-score: 0.5567567567567567

========== Train Epoch 37 ==========
Loss: 0.920	Accuracy: 55.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.8387    0.6667    0.7429        39

    accuracy                         0.5568       185
   macro avg     0.5095    0.5265    0.5052       185
weighted avg     0.5772    0.5568    0.5587       185

micro f-score: 0.5567567567567567

========== Train Epoch 38 ==========
Loss: 0.890	Accuracy: 55.68%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5568       185
   macro avg     0.5230    0.5078    0.4956       185
weighted avg     0.5584    0.5568    0.5393       185

micro f-score: 0.5567567567567567

========== Train Epoch 39 ==========
Loss: 0.868	Accuracy: 55.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5568       185
   macro avg     0.5298    0.5047    0.4918       185
weighted avg     0.5649    0.5568    0.5392       185

micro f-score: 0.5567567567567567

========== Train Epoch 40 ==========
Loss: 0.847	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5622       185
   macro avg     0.5245    0.5229    0.5130       185
weighted avg     0.5619    0.5622    0.5546       185

micro f-score: 0.5621621621621622

========== Train Epoch 41 ==========
Loss: 0.832	Accuracy: 57.30%	Cost 51s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5730       185
   macro avg     0.5452    0.5432    0.5240       185
weighted avg     0.5916    0.5730    0.5685       185

micro f-score: 0.572972972972973

========== Train Epoch 42 ==========
Loss: 0.810	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5784       185
   macro avg     0.5389    0.5185    0.5111       185
weighted avg     0.5740    0.5784    0.5629       185

micro f-score: 0.5783783783783784

========== Train Epoch 43 ==========
Loss: 0.786	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5135    0.6129    0.5588        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5838       185
   macro avg     0.5433    0.5288    0.5216       185
weighted avg     0.5850    0.5838    0.5735       185

micro f-score: 0.5837837837837838

========== Train Epoch 44 ==========
Loss: 0.771	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6275    0.7111    0.6667        45
         zxx     0.6304    0.7436    0.6824        39

    accuracy                         0.5514       185
   macro avg     0.5017    0.4935    0.4889       185
weighted avg     0.5346    0.5514    0.5361       185

micro f-score: 0.5513513513513514

========== Train Epoch 45 ==========
Loss: 0.758	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5730       185
   macro avg     0.5783    0.5447    0.5332       185
weighted avg     0.6001    0.5730    0.5614       185

micro f-score: 0.572972972972973

========== Train Epoch 46 ==========
Loss: 0.749	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6596    0.6889    0.6739        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5676       185
   macro avg     0.5513    0.5339    0.5170       185
weighted avg     0.5836    0.5676    0.5547       185

micro f-score: 0.5675675675675675

========== Train Epoch 47 ==========
Loss: 0.714	Accuracy: 57.30%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5730       185
   macro avg     0.5475    0.5381    0.5216       185
weighted avg     0.5956    0.5730    0.5647       185

micro f-score: 0.572972972972973

========== Train Epoch 48 ==========
Loss: 0.716	Accuracy: 58.92%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.5892       185
   macro avg     0.5266    0.5442    0.5219       185
weighted avg     0.5860    0.5892    0.5786       185

micro f-score: 0.5891891891891892

========== Train Epoch 49 ==========
Loss: 0.688	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.5784       185
   macro avg     0.5427    0.5502    0.5266       185
weighted avg     0.5970    0.5784    0.5719       185

micro f-score: 0.5783783783783784

========== Train Epoch 50 ==========
Loss: 0.679	Accuracy: 57.84%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.6939    0.7556    0.7234        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5784       185
   macro avg     0.5502    0.5455    0.5278       185
weighted avg     0.5894    0.5784    0.5703       185

micro f-score: 0.5783783783783784

========== Train Epoch 51 ==========
Loss: 0.675	Accuracy: 60.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6596    0.6889    0.6739        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6000       185
   macro avg     0.5652    0.5561    0.5501       185
weighted avg     0.5960    0.6000    0.5890       185

micro f-score: 0.6

========== Train Epoch 52 ==========
Loss: 0.650	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5730       185
   macro avg     0.5580    0.5351    0.5210       185
weighted avg     0.5893    0.5730    0.5557       185

micro f-score: 0.572972972972973

========== Train Epoch 53 ==========
Loss: 0.649	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5730       185
   macro avg     0.5241    0.5379    0.5272       185
weighted avg     0.5842    0.5730    0.5758       185

micro f-score: 0.572972972972973

========== Train Epoch 54 ==========
Loss: 0.620	Accuracy: 59.46%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5946       185
   macro avg     0.5535    0.5439    0.5359       185
weighted avg     0.5941    0.5946    0.5810       185

micro f-score: 0.5945945945945946

========== Train Epoch 55 ==========
Loss: 0.598	Accuracy: 56.76%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5676       185
   macro avg     0.5605    0.5291    0.5363       185
weighted avg     0.5682    0.5676    0.5586       185

micro f-score: 0.5675675675675675

========== Train Epoch 56 ==========
Loss: 0.583	Accuracy: 58.92%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.5892       185
   macro avg     0.5636    0.5642    0.5440       185
weighted avg     0.6051    0.5892    0.5826       185

micro f-score: 0.5891891891891892

========== Train Epoch 57 ==========
Loss: 0.576	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5946       185
   macro avg     0.5646    0.5615    0.5451       185
weighted avg     0.6168    0.5946    0.5920       185

micro f-score: 0.5945945945945946

========== Train Epoch 58 ==========
Loss: 0.549	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5514       185
   macro avg     0.5540    0.5037    0.5046       185
weighted avg     0.5714    0.5514    0.5314       185

micro f-score: 0.5513513513513514

========== Train Epoch 59 ==========
Loss: 0.541	Accuracy: 56.76%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.5676       185
   macro avg     0.5535    0.5301    0.5183       185
weighted avg     0.5805    0.5676    0.5480       185

micro f-score: 0.5675675675675675

========== Train Epoch 60 ==========
Loss: 0.517	Accuracy: 61.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6108       185
   macro avg     0.5761    0.5639    0.5550       185
weighted avg     0.6187    0.6108    0.5994       185

micro f-score: 0.6108108108108108

========== Train Epoch 61 ==========
Loss: 0.503	Accuracy: 57.84%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5784       185
   macro avg     0.5726    0.5473    0.5449       185
weighted avg     0.5894    0.5784    0.5662       185

micro f-score: 0.5783783783783784

========== Train Epoch 62 ==========
Loss: 0.497	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5892       185
   macro avg     0.5500    0.5650    0.5531       185
weighted avg     0.5994    0.5892    0.5912       185

micro f-score: 0.5891891891891892

========== Train Epoch 63 ==========
Loss: 0.464	Accuracy: 59.46%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5946       185
   macro avg     0.5510    0.5544    0.5424       185
weighted avg     0.6025    0.5946    0.5890       185

micro f-score: 0.5945945945945946

========== Train Epoch 64 ==========
Loss: 0.472	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5892       185
   macro avg     0.5491    0.5578    0.5423       185
weighted avg     0.5988    0.5892    0.5858       185

micro f-score: 0.5891891891891892

Finished training!!!

Min Loss = 0.464 in epoch 62;
Max Accuracy = 61.08% in epoch 59;
Total Cost 39 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-6                     [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-13                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-20                    [-1, 128, 40, 40]         3,352
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-28                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-35                    [-1, 256, 20, 20]         6,680
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-43                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-50                    [-1, 512, 10, 10]         25,648
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-58                    [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,254,839
Trainable params: 11,254,839
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.05
Params size (MB): 42.93
Estimated Total Size (MB): 122.15
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
