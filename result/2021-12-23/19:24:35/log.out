dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.836	Accuracy: 29.19%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2750    0.3548    0.3099        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0833    0.0526    0.0645        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4390    0.4000    0.4186        45
         zxx     0.2609    0.6154    0.3664        39

    accuracy                         0.2919       185
   macro avg     0.1512    0.2033    0.1656       185
weighted avg     0.2164    0.2919    0.2376       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.573	Accuracy: 41.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3333    0.1290    0.1860        31
         cwx     0.2759    0.3636    0.3137        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.4200    0.4667    0.4421        45
         zxx     0.5000    0.7692    0.6061        39

    accuracy                         0.4108       185
   macro avg     0.3970    0.3684    0.3520       185
weighted avg     0.4057    0.4108    0.3800       185

micro f-score: 0.4108108108108109

========== Train Epoch 3 ==========
Loss: 1.400	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4366    0.7949    0.5636        39

    accuracy                         0.4432       185
   macro avg     0.4133    0.3851    0.3687       185
weighted avg     0.4478    0.4432    0.4178       185

micro f-score: 0.44324324324324327

========== Train Epoch 4 ==========
Loss: 1.334	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.4156    0.8205    0.5517        39

    accuracy                         0.4378       185
   macro avg     0.4007    0.3850    0.3651       185
weighted avg     0.4366    0.4378    0.4095       185

micro f-score: 0.43783783783783786

========== Train Epoch 5 ==========
Loss: 1.296	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.2903    0.3462        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4703       185
   macro avg     0.4441    0.4134    0.3994       185
weighted avg     0.4823    0.4703    0.4462       185

micro f-score: 0.4702702702702703

========== Train Epoch 6 ==========
Loss: 1.253	Accuracy: 47.57%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.5085    0.7692    0.6122        39

    accuracy                         0.4757       185
   macro avg     0.4379    0.4238    0.4064       185
weighted avg     0.4682    0.4757    0.4525       185

micro f-score: 0.4756756756756757

========== Train Epoch 7 ==========
Loss: 1.204	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.6286    0.4889    0.5500        45
         zxx     0.4638    0.8205    0.5926        39

    accuracy                         0.4703       185
   macro avg     0.4395    0.4273    0.4091       185
weighted avg     0.4749    0.4703    0.4490       185

micro f-score: 0.4702702702702703

========== Train Epoch 8 ==========
Loss: 1.171	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3714    0.4194    0.3939        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.6471    0.4889    0.5570        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4757       185
   macro avg     0.4367    0.4291    0.4122       185
weighted avg     0.4728    0.4757    0.4550       185

micro f-score: 0.4756756756756757

========== Train Epoch 9 ==========
Loss: 1.116	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5000    0.8974    0.6422        39

    accuracy                         0.5297       185
   macro avg     0.5262    0.4823    0.4588       185
weighted avg     0.5610    0.5297    0.5052       185

micro f-score: 0.5297297297297298

========== Train Epoch 10 ==========
Loss: 1.067	Accuracy: 48.65%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.4789    0.8718    0.6182        39

    accuracy                         0.4865       185
   macro avg     0.4466    0.4325    0.4069       185
weighted avg     0.4928    0.4865    0.4586       185

micro f-score: 0.4864864864864865

========== Train Epoch 11 ==========
Loss: 1.030	Accuracy: 49.73%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.6875    0.4889    0.5714        45
         zxx     0.4615    0.9231    0.6154        39

    accuracy                         0.4973       185
   macro avg     0.4784    0.4566    0.4348       185
weighted avg     0.5117    0.4973    0.4710       185

micro f-score: 0.4972972972972973

========== Train Epoch 12 ==========
Loss: 0.980	Accuracy: 54.59%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5459       185
   macro avg     0.4767    0.4895    0.4686       185
weighted avg     0.5269    0.5459    0.5250       185

micro f-score: 0.5459459459459459

========== Train Epoch 13 ==========
Loss: 0.945	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.5243       185
   macro avg     0.4841    0.4811    0.4646       185
weighted avg     0.5226    0.5243    0.5089       185

micro f-score: 0.5243243243243243

========== Train Epoch 14 ==========
Loss: 0.897	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5351       185
   macro avg     0.4716    0.4907    0.4707       185
weighted avg     0.5296    0.5351    0.5228       185

micro f-score: 0.5351351351351351

========== Train Epoch 15 ==========
Loss: 0.837	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.5000    0.9231    0.6486        39

    accuracy                         0.5459       185
   macro avg     0.5336    0.4822    0.4658       185
weighted avg     0.5655    0.5459    0.5190       185

micro f-score: 0.5459459459459459

========== Train Epoch 16 ==========
Loss: 0.788	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5514       185
   macro avg     0.4956    0.5026    0.4750       185
weighted avg     0.5543    0.5514    0.5341       185

micro f-score: 0.5513513513513514

========== Train Epoch 17 ==========
Loss: 0.766	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5514       185
   macro avg     0.4789    0.4850    0.4777       185
weighted avg     0.5386    0.5514    0.5394       185

micro f-score: 0.5513513513513514

========== Train Epoch 18 ==========
Loss: 0.714	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6667    0.7556    0.7083        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.5892       185
   macro avg     0.5366    0.5321    0.5188       185
weighted avg     0.5752    0.5892    0.5686       185

micro f-score: 0.5891891891891892

========== Train Epoch 19 ==========
Loss: 0.666	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.5892       185
   macro avg     0.5566    0.5517    0.5433       185
weighted avg     0.6060    0.5892    0.5891       185

micro f-score: 0.5891891891891892

========== Train Epoch 20 ==========
Loss: 0.629	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4681    0.7097    0.5641        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.8333    0.5556    0.6667        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5405       185
   macro avg     0.4997    0.4864    0.4642       185
weighted avg     0.5624    0.5405    0.5249       185

micro f-score: 0.5405405405405406

========== Train Epoch 21 ==========
Loss: 0.590	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4651    0.6452    0.5405        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8621    0.5556    0.6757        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.5730       185
   macro avg     0.5489    0.5289    0.5068       185
weighted avg     0.5926    0.5730    0.5515       185

micro f-score: 0.572972972972973

========== Train Epoch 22 ==========
Loss: 0.566	Accuracy: 53.51%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4681    0.7097    0.5641        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.8947    0.4359    0.5862        39

    accuracy                         0.5351       185
   macro avg     0.5102    0.5087    0.4855       185
weighted avg     0.5778    0.5351    0.5301       185

micro f-score: 0.5351351351351351

========== Train Epoch 23 ==========
Loss: 0.525	Accuracy: 55.68%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3478    0.4211    0.3810        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6970    0.5897    0.6389        39

    accuracy                         0.5568       185
   macro avg     0.5191    0.5332    0.5206       185
weighted avg     0.5697    0.5568    0.5598       185

micro f-score: 0.5567567567567567

========== Train Epoch 24 ==========
Loss: 0.488	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6316    0.8000    0.7059        45
         zxx     0.6857    0.6154    0.6486        39

    accuracy                         0.5622       185
   macro avg     0.5189    0.5030    0.5037       185
weighted avg     0.5609    0.5622    0.5548       185

micro f-score: 0.5621621621621622

========== Train Epoch 25 ==========
Loss: 0.456	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.7083    0.5484    0.6182        31
         cwx     0.5926    0.7273    0.6531        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5892       185
   macro avg     0.5555    0.5654    0.5488       185
weighted avg     0.6310    0.5892    0.5964       185

micro f-score: 0.5891891891891892

========== Train Epoch 26 ==========
Loss: 0.413	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.4857    0.7727    0.5965        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.6054       185
   macro avg     0.5578    0.5750    0.5486       185
weighted avg     0.6184    0.6054    0.5981       185

micro f-score: 0.6054054054054054

========== Train Epoch 27 ==========
Loss: 0.380	Accuracy: 59.46%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.7895    0.4839    0.6000        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5946       185
   macro avg     0.5716    0.5660    0.5503       185
weighted avg     0.6245    0.5946    0.5933       185

micro f-score: 0.5945945945945946

========== Train Epoch 28 ==========
Loss: 0.355	Accuracy: 55.68%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5122    0.6774    0.5833        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.7407    0.5128    0.6061        39

    accuracy                         0.5568       185
   macro avg     0.5317    0.5215    0.5159       185
weighted avg     0.5819    0.5568    0.5582       185

micro f-score: 0.5567567567567567

========== Train Epoch 29 ==========
Loss: 0.346	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.4444    0.4211    0.4324        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.6000       185
   macro avg     0.5629    0.5802    0.5613       185
weighted avg     0.6298    0.6000    0.6069       185

micro f-score: 0.6

========== Train Epoch 30 ==========
Loss: 0.301	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5784       185
   macro avg     0.5524    0.5493    0.5318       185
weighted avg     0.5961    0.5784    0.5710       185

micro f-score: 0.5783783783783784

========== Train Epoch 31 ==========
Loss: 0.300	Accuracy: 60.54%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.8500    0.5484    0.6667        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.6054       185
   macro avg     0.5768    0.5823    0.5639       185
weighted avg     0.6570    0.6054    0.6195       185

micro f-score: 0.6054054054054054

========== Train Epoch 32 ==========
Loss: 0.278	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6250    0.6452    0.6349        31
         cwx     0.6071    0.7727    0.6800        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6216       185
   macro avg     0.5773    0.5857    0.5696       185
weighted avg     0.6403    0.6216    0.6176       185

micro f-score: 0.6216216216216216

========== Train Epoch 33 ==========
Loss: 0.234	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5838       185
   macro avg     0.5514    0.5673    0.5501       185
weighted avg     0.6086    0.5838    0.5880       185

micro f-score: 0.5837837837837838

========== Train Epoch 34 ==========
Loss: 0.232	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5833    0.6774    0.6269        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2917    0.3684    0.3256        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.6054       185
   macro avg     0.5686    0.5866    0.5716       185
weighted avg     0.6257    0.6054    0.6094       185

micro f-score: 0.6054054054054054

========== Train Epoch 35 ==========
Loss: 0.226	Accuracy: 61.08%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.3810    0.4211    0.4000        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.6108       185
   macro avg     0.6026    0.5751    0.5735       185
weighted avg     0.6331    0.6108    0.6070       185

micro f-score: 0.6108108108108108

========== Train Epoch 36 ==========
Loss: 0.200	Accuracy: 54.59%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.2571    0.5294    0.3462        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5459       185
   macro avg     0.5347    0.5264    0.5086       185
weighted avg     0.5956    0.5459    0.5521       185

micro f-score: 0.5459459459459459

========== Train Epoch 37 ==========
Loss: 0.199	Accuracy: 58.38%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5838       185
   macro avg     0.5447    0.5543    0.5336       185
weighted avg     0.6001    0.5838    0.5766       185

micro f-score: 0.5837837837837838

========== Train Epoch 38 ==========
Loss: 0.180	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.6000       185
   macro avg     0.6023    0.5745    0.5644       185
weighted avg     0.6274    0.6000    0.5931       185

micro f-score: 0.6

========== Train Epoch 39 ==========
Loss: 0.163	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.5892       185
   macro avg     0.5541    0.5521    0.5400       185
weighted avg     0.5965    0.5892    0.5836       185

micro f-score: 0.5891891891891892

========== Train Epoch 40 ==========
Loss: 0.161	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8333    0.3226    0.4651        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.6054       185
   macro avg     0.6021    0.5829    0.5548       185
weighted avg     0.6495    0.6054    0.5925       185

micro f-score: 0.6054054054054054

========== Train Epoch 41 ==========
Loss: 0.141	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6250    0.8974    0.7368        39

    accuracy                         0.6162       185
   macro avg     0.5880    0.5799    0.5736       185
weighted avg     0.6243    0.6162    0.6088       185

micro f-score: 0.6162162162162163

========== Train Epoch 42 ==========
Loss: 0.156	Accuracy: 58.92%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.5892       185
   macro avg     0.5802    0.5558    0.5488       185
weighted avg     0.6189    0.5892    0.5824       185

micro f-score: 0.5891891891891892

========== Train Epoch 43 ==========
Loss: 0.141	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.6774    0.5753        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5946       185
   macro avg     0.6002    0.5673    0.5613       185
weighted avg     0.6301    0.5946    0.5906       185

micro f-score: 0.5945945945945946

========== Train Epoch 44 ==========
Loss: 0.120	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.7500    0.6818    0.7143        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.6162       185
   macro avg     0.6059    0.5890    0.5654       185
weighted avg     0.6452    0.6162    0.6026       185

micro f-score: 0.6162162162162163

========== Train Epoch 45 ==========
Loss: 0.121	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.6000    0.4737    0.5294        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.6054       185
   macro avg     0.5950    0.5843    0.5775       185
weighted avg     0.6190    0.6054    0.6023       185

micro f-score: 0.6054054054054054

========== Train Epoch 46 ==========
Loss: 0.116	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.7000    0.3684    0.4828        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.6923    0.6000    0.6429        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5946       185
   macro avg     0.5858    0.5798    0.5620       185
weighted avg     0.6272    0.5946    0.5974       185

micro f-score: 0.5945945945945946

========== Train Epoch 47 ==========
Loss: 0.115	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3810    0.4211    0.4000        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6667    0.8205    0.7356        39

    accuracy                         0.6108       185
   macro avg     0.5872    0.5835    0.5755       185
weighted avg     0.6391    0.6108    0.6155       185

micro f-score: 0.6108108108108108

========== Train Epoch 48 ==========
Loss: 0.110	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.4167    0.5263    0.4651        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.6108       185
   macro avg     0.5934    0.6040    0.5902       185
weighted avg     0.6426    0.6108    0.6191       185

micro f-score: 0.6108108108108108

========== Train Epoch 49 ==========
Loss: 0.103	Accuracy: 62.70%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.6429    0.4737    0.5455        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6270       185
   macro avg     0.6183    0.5992    0.5983       185
weighted avg     0.6523    0.6270    0.6266       185

micro f-score: 0.6270270270270271

========== Train Epoch 50 ==========
Loss: 0.100	Accuracy: 63.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6765    0.7419    0.7077        31
         cwx     0.6000    0.8182    0.6923        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.6324       185
   macro avg     0.5799    0.5986    0.5808       185
weighted avg     0.6357    0.6324    0.6256       185

micro f-score: 0.6324324324324324

========== Train Epoch 51 ==========
Loss: 0.095	Accuracy: 64.86%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.7097    0.6875        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.6486       185
   macro avg     0.5977    0.6088    0.5968       185
weighted avg     0.6601    0.6486    0.6495       185

micro f-score: 0.6486486486486487

========== Train Epoch 52 ==========
Loss: 0.101	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.5000    0.5263    0.5128        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5892       185
   macro avg     0.5879    0.5663    0.5563       185
weighted avg     0.6111    0.5892    0.5798       185

micro f-score: 0.5891891891891892

========== Train Epoch 53 ==========
Loss: 0.094	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7391    0.5484    0.6296        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.6216       185
   macro avg     0.5915    0.5975    0.5775       185
weighted avg     0.6483    0.6216    0.6232       185

micro f-score: 0.6216216216216216

========== Train Epoch 54 ==========
Loss: 0.085	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7895    0.4839    0.6000        31
         cwx     0.5312    0.7727    0.6296        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.6162       185
   macro avg     0.6035    0.5665    0.5652       185
weighted avg     0.6369    0.6162    0.6079       185

micro f-score: 0.6162162162162163

========== Train Epoch 55 ==========
Loss: 0.080	Accuracy: 62.70%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.6429    0.4737    0.5455        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6270       185
   macro avg     0.6117    0.6099    0.5948       185
weighted avg     0.6646    0.6270    0.6356       185

micro f-score: 0.6270270270270271

========== Train Epoch 56 ==========
Loss: 0.075	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7407    0.6452    0.6897        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.6378       185
   macro avg     0.6388    0.6043    0.5930       185
weighted avg     0.6767    0.6378    0.6380       185

micro f-score: 0.6378378378378379

========== Train Epoch 57 ==========
Loss: 0.090	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6471    0.7097    0.6769        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.6324       185
   macro avg     0.5884    0.5883    0.5821       185
weighted avg     0.6360    0.6324    0.6296       185

micro f-score: 0.6324324324324324

========== Train Epoch 58 ==========
Loss: 0.079	Accuracy: 62.70%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.6522    0.6818    0.6667        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.6270       185
   macro avg     0.6116    0.6068    0.5839       185
weighted avg     0.6597    0.6270    0.6271       185

micro f-score: 0.6270270270270271

========== Train Epoch 59 ==========
Loss: 0.074	Accuracy: 65.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6970    0.7419    0.7188        31
         cwx     0.6207    0.8182    0.7059        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.6541       185
   macro avg     0.6141    0.6248    0.6122       185
weighted avg     0.6644    0.6541    0.6518       185

micro f-score: 0.654054054054054

========== Train Epoch 60 ==========
Loss: 0.083	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4167    0.5263    0.4651        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6400    0.7111    0.6737        45
         zxx     0.7576    0.6410    0.6944        39

    accuracy                         0.6054       185
   macro avg     0.5934    0.5852    0.5813       185
weighted avg     0.6270    0.6054    0.6094       185

micro f-score: 0.6054054054054054

========== Train Epoch 61 ==========
Loss: 0.075	Accuracy: 64.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.6400    0.7273    0.6809        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6432       185
   macro avg     0.6054    0.6072    0.6035       185
weighted avg     0.6433    0.6432    0.6402       185

micro f-score: 0.6432432432432432

========== Train Epoch 62 ==========
Loss: 0.067	Accuracy: 62.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.6000    0.8182    0.6923        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.6216       185
   macro avg     0.5799    0.6014    0.5760       185
weighted avg     0.6383    0.6216    0.6183       185

micro f-score: 0.6216216216216216

========== Train Epoch 63 ==========
Loss: 0.070	Accuracy: 65.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.6800    0.7727    0.7234        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.7292    0.8974    0.8046        39

    accuracy                         0.6541       185
   macro avg     0.6360    0.6249    0.6044       185
weighted avg     0.6921    0.6541    0.6509       185

micro f-score: 0.654054054054054

========== Train Epoch 64 ==========
Loss: 0.075	Accuracy: 62.16%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6216       185
   macro avg     0.6123    0.5997    0.5827       185
weighted avg     0.6361    0.6216    0.6115       185

micro f-score: 0.6216216216216216

Finished training!!!

Min Loss = 0.067 in epoch 61;
Max Accuracy = 65.41% in epoch 58;
Total Cost 39 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
