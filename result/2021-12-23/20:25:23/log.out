dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max2
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.837	Accuracy: 35.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1333    0.1176    0.1250        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.4717    0.5556    0.5102        45
         zxx     0.3333    0.7179    0.4553        39

    accuracy                         0.3568       185
   macro avg     0.2176    0.2567    0.2227       185
weighted avg     0.2747    0.3568    0.2980       185

micro f-score: 0.3567567567567568

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.663	Accuracy: 35.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.3000    0.1364    0.1875        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.9375    0.3333    0.4918        45
         zxx     0.2868    1.0000    0.4457        39

    accuracy                         0.3568       185
   macro avg     0.3912    0.2718    0.2480       185
weighted avg     0.4858    0.3568    0.3082       185

micro f-score: 0.3567567567567568

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.533	Accuracy: 38.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.2727    0.1364    0.1818        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.6552    0.4222    0.5135        45
         zxx     0.3246    0.9487    0.4837        39

    accuracy                         0.3838       185
   macro avg     0.3417    0.2983    0.2730       185
weighted avg     0.3972    0.3838    0.3335       185

micro f-score: 0.3837837837837838

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.493	Accuracy: 40.00%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3235    0.3548    0.3385        31
         cwx     0.2500    0.1364    0.1765        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.4023    0.8974    0.5556        39

    accuracy                         0.4000       185
   macro avg     0.2914    0.2995    0.2688       185
weighted avg     0.3479    0.4000    0.3441       185

micro f-score: 0.4000000000000001

========== Train Epoch 5 ==========
Loss: 1.473	Accuracy: 38.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3030    0.3226    0.3125        31
         cwx     0.2308    0.1364    0.1714        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.4000    0.8718    0.5484        39

    accuracy                         0.3892       185
   macro avg     0.2783    0.2913    0.2628       185
weighted avg     0.3365    0.3892    0.3373       185

micro f-score: 0.3891891891891892

========== Train Epoch 6 ==========
Loss: 1.446	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3636    0.3871    0.3750        31
         cwx     0.2308    0.1364    0.1714        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5526    0.4667    0.5060        45
         zxx     0.4118    0.8974    0.5645        39

    accuracy                         0.4054       185
   macro avg     0.3346    0.3094    0.2858       185
weighted avg     0.3770    0.4054    0.3560       185

micro f-score: 0.40540540540540543

========== Train Epoch 7 ==========
Loss: 1.438	Accuracy: 41.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3333    0.4516    0.3836        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.4286    0.8462    0.5690        39

    accuracy                         0.4108       185
   macro avg     0.3017    0.3125    0.2836       185
weighted avg     0.3593    0.4108    0.3600       185

micro f-score: 0.4108108108108109

========== Train Epoch 8 ==========
Loss: 1.417	Accuracy: 38.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3077    0.2581    0.2807        31
         cwx     0.2308    0.1364    0.1714        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.4048    0.8718    0.5528        39

    accuracy                         0.3892       185
   macro avg     0.3175    0.2980    0.2789       185
weighted avg     0.3588    0.3892    0.3441       185

micro f-score: 0.3891891891891892

========== Train Epoch 9 ==========
Loss: 1.396	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.1429    0.0833    0.1053        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3953    0.8718    0.5440        39

    accuracy                         0.4000       185
   macro avg     0.3376    0.3075    0.2932       185
weighted avg     0.3836    0.4000    0.3608       185

micro f-score: 0.4000000000000001

========== Train Epoch 10 ==========
Loss: 1.364	Accuracy: 41.62%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3448    0.3226    0.3333        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5000    0.5111    0.5055        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.4162       185
   macro avg     0.3517    0.3335    0.3222       185
weighted avg     0.3855    0.4162    0.3811       185

micro f-score: 0.41621621621621624

========== Train Epoch 11 ==========
Loss: 1.345	Accuracy: 41.62%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4217    0.8974    0.5738        39

    accuracy                         0.4162       185
   macro avg     0.3446    0.3252    0.3085       185
weighted avg     0.3935    0.4162    0.3761       185

micro f-score: 0.41621621621621624

========== Train Epoch 12 ==========
Loss: 1.330	Accuracy: 42.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3235    0.3548    0.3385        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.4270       185
   macro avg     0.3538    0.3411    0.3323       185
weighted avg     0.3991    0.4270    0.3974       185

micro f-score: 0.427027027027027

========== Train Epoch 13 ==========
Loss: 1.294	Accuracy: 41.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.1429    0.0833    0.1053        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.3864    0.8718    0.5354        39

    accuracy                         0.4162       185
   macro avg     0.4006    0.3184    0.3062       185
weighted avg     0.4305    0.4162    0.3746       185

micro f-score: 0.41621621621621624

========== Train Epoch 14 ==========
Loss: 1.282	Accuracy: 45.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3556    0.5161    0.4211        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.4595       185
   macro avg     0.3812    0.3798    0.3665       185
weighted avg     0.4366    0.4595    0.4341       185

micro f-score: 0.4594594594594595

========== Train Epoch 15 ==========
Loss: 1.257	Accuracy: 44.32%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4583    0.3548    0.4000        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4231    0.8462    0.5641        39

    accuracy                         0.4432       185
   macro avg     0.4314    0.3662    0.3562       185
weighted avg     0.4588    0.4432    0.4122       185

micro f-score: 0.44324324324324327

========== Train Epoch 16 ==========
Loss: 1.236	Accuracy: 43.78%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4378       185
   macro avg     0.3900    0.3436    0.3279       185
weighted avg     0.4285    0.4378    0.3980       185

micro f-score: 0.43783783783783786

========== Train Epoch 17 ==========
Loss: 1.199	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.2857    0.2727    0.2791        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5217    0.5333    0.5275        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.4432       185
   macro avg     0.3585    0.3642    0.3498       185
weighted avg     0.4089    0.4432    0.4132       185

micro f-score: 0.44324324324324327

========== Train Epoch 18 ==========
Loss: 1.194	Accuracy: 46.49%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3750    0.3871    0.3810        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6765    0.5111    0.5823        45
         zxx     0.4605    0.8974    0.6087        39

    accuracy                         0.4649       185
   macro avg     0.4412    0.3996    0.3798       185
weighted avg     0.4733    0.4649    0.4308       185

micro f-score: 0.4648648648648649

========== Train Epoch 19 ==========
Loss: 1.176	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.3182    0.3182    0.3182        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.4919       185
   macro avg     0.4294    0.4327    0.4177       185
weighted avg     0.4833    0.4919    0.4749       185

micro f-score: 0.4918918918918919

========== Train Epoch 20 ==========
Loss: 1.172	Accuracy: 45.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.3043    0.3182    0.3111        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.5167    0.7949    0.6263        39

    accuracy                         0.4595       185
   macro avg     0.4044    0.3890    0.3796       185
weighted avg     0.4534    0.4595    0.4404       185

micro f-score: 0.4594594594594595

========== Train Epoch 21 ==========
Loss: 1.123	Accuracy: 49.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.4973       185
   macro avg     0.4554    0.4458    0.4287       185
weighted avg     0.4921    0.4973    0.4741       185

micro f-score: 0.4972972972972973

========== Train Epoch 22 ==========
Loss: 1.104	Accuracy: 48.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4865       185
   macro avg     0.4204    0.4336    0.4076       185
weighted avg     0.4632    0.4865    0.4566       185

micro f-score: 0.4864864864864865

========== Train Epoch 23 ==========
Loss: 1.079	Accuracy: 48.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.5652    0.5778    0.5714        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.4865       185
   macro avg     0.4271    0.4303    0.4055       185
weighted avg     0.4600    0.4865    0.4526       185

micro f-score: 0.4864864864864865

========== Train Epoch 24 ==========
Loss: 1.083	Accuracy: 49.73%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.3077    0.3636    0.3333        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.4973       185
   macro avg     0.4519    0.4441    0.4278       185
weighted avg     0.4971    0.4973    0.4779       185

micro f-score: 0.4972972972972973

========== Train Epoch 25 ==========
Loss: 1.044	Accuracy: 50.27%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5027       185
   macro avg     0.4459    0.4507    0.4268       185
weighted avg     0.4875    0.5027    0.4765       185

micro f-score: 0.5027027027027027

========== Train Epoch 26 ==========
Loss: 1.041	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5189       185
   macro avg     0.4988    0.4786    0.4601       185
weighted avg     0.5266    0.5189    0.4982       185

micro f-score: 0.518918918918919

========== Train Epoch 27 ==========
Loss: 0.997	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.3333    0.4091    0.3673        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4771    0.4687    0.4556       185
weighted avg     0.5323    0.5189    0.5059       185

micro f-score: 0.518918918918919

========== Train Epoch 28 ==========
Loss: 0.980	Accuracy: 52.97%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5556    0.8974    0.6863        39

    accuracy                         0.5297       185
   macro avg     0.5049    0.4764    0.4520       185
weighted avg     0.5352    0.5297    0.5007       185

micro f-score: 0.5297297297297298

========== Train Epoch 29 ==========
Loss: 0.975	Accuracy: 50.81%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5081       185
   macro avg     0.4611    0.4655    0.4435       185
weighted avg     0.5003    0.5081    0.4873       185

micro f-score: 0.5081081081081081

========== Train Epoch 30 ==========
Loss: 0.946	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5135       185
   macro avg     0.5016    0.4581    0.4391       185
weighted avg     0.5294    0.5135    0.4861       185

micro f-score: 0.5135135135135135

========== Train Epoch 31 ==========
Loss: 0.926	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3182    0.3182    0.3182        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.5081       185
   macro avg     0.4663    0.4544    0.4371       185
weighted avg     0.5004    0.5081    0.4858       185

micro f-score: 0.5081081081081081

========== Train Epoch 32 ==========
Loss: 0.899	Accuracy: 49.19%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3478    0.3636    0.3556        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5370    0.7436    0.6237        39

    accuracy                         0.4919       185
   macro avg     0.4420    0.4564    0.4337       185
weighted avg     0.4847    0.4919    0.4755       185

micro f-score: 0.4918918918918919

========== Train Epoch 33 ==========
Loss: 0.879	Accuracy: 51.89%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5189       185
   macro avg     0.4579    0.4724    0.4499       185
weighted avg     0.4989    0.5189    0.4964       185

micro f-score: 0.518918918918919

========== Train Epoch 34 ==========
Loss: 0.854	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4103    0.5161    0.4571        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5135       185
   macro avg     0.4629    0.4716    0.4506       185
weighted avg     0.5137    0.5135    0.4957       185

micro f-score: 0.5135135135135135

========== Train Epoch 35 ==========
Loss: 0.821	Accuracy: 52.97%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5297       185
   macro avg     0.4589    0.4718    0.4528       185
weighted avg     0.5075    0.5297    0.5087       185

micro f-score: 0.5297297297297298

========== Train Epoch 36 ==========
Loss: 0.824	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5459       185
   macro avg     0.5029    0.5065    0.4927       185
weighted avg     0.5510    0.5459    0.5348       185

micro f-score: 0.5459459459459459

========== Train Epoch 37 ==========
Loss: 0.793	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5459       185
   macro avg     0.5302    0.4900    0.4765       185
weighted avg     0.5695    0.5459    0.5311       185

micro f-score: 0.5459459459459459

========== Train Epoch 38 ==========
Loss: 0.760	Accuracy: 54.59%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5459       185
   macro avg     0.4917    0.5058    0.4872       185
weighted avg     0.5368    0.5459    0.5333       185

micro f-score: 0.5459459459459459

========== Train Epoch 39 ==========
Loss: 0.742	Accuracy: 52.97%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.5297       185
   macro avg     0.4919    0.4850    0.4684       185
weighted avg     0.5305    0.5297    0.5120       185

micro f-score: 0.5297297297297298

========== Train Epoch 40 ==========
Loss: 0.723	Accuracy: 54.05%	Cost 40s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5405       185
   macro avg     0.4916    0.5013    0.4837       185
weighted avg     0.5325    0.5405    0.5260       185

micro f-score: 0.5405405405405406

========== Train Epoch 41 ==========
Loss: 0.707	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.5147    0.8974    0.6542        39

    accuracy                         0.5622       185
   macro avg     0.5930    0.5097    0.4945       185
weighted avg     0.6104    0.5622    0.5395       185

micro f-score: 0.5621621621621622

========== Train Epoch 42 ==========
Loss: 0.684	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.5297       185
   macro avg     0.5025    0.4670    0.4575       185
weighted avg     0.5392    0.5297    0.5098       185

micro f-score: 0.5297297297297298

========== Train Epoch 43 ==========
Loss: 0.666	Accuracy: 54.59%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5459       185
   macro avg     0.5096    0.5173    0.4962       185
weighted avg     0.5635    0.5459    0.5371       185

micro f-score: 0.5459459459459459

========== Train Epoch 44 ==========
Loss: 0.649	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5514       185
   macro avg     0.5075    0.5134    0.4973       185
weighted avg     0.5604    0.5514    0.5425       185

micro f-score: 0.5513513513513514

========== Train Epoch 45 ==========
Loss: 0.630	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5405       185
   macro avg     0.4849    0.5036    0.4821       185
weighted avg     0.5413    0.5405    0.5302       185

micro f-score: 0.5405405405405406

========== Train Epoch 46 ==========
Loss: 0.624	Accuracy: 55.68%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5568       185
   macro avg     0.5183    0.5099    0.4913       185
weighted avg     0.5560    0.5568    0.5358       185

micro f-score: 0.5567567567567567

========== Train Epoch 47 ==========
Loss: 0.601	Accuracy: 55.14%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8438    0.6000    0.7013        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5514       185
   macro avg     0.5138    0.5095    0.4917       185
weighted avg     0.5628    0.5514    0.5362       185

micro f-score: 0.5513513513513514

========== Train Epoch 48 ==========
Loss: 0.565	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5303    0.8974    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5423    0.5164    0.4965       185
weighted avg     0.5839    0.5622    0.5434       185

micro f-score: 0.5621621621621622

========== Train Epoch 49 ==========
Loss: 0.543	Accuracy: 55.68%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5568       185
   macro avg     0.4978    0.5137    0.4952       185
weighted avg     0.5500    0.5568    0.5455       185

micro f-score: 0.5567567567567567

========== Train Epoch 50 ==========
Loss: 0.547	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5676       185
   macro avg     0.5417    0.5222    0.5053       185
weighted avg     0.5814    0.5676    0.5525       185

micro f-score: 0.5675675675675675

========== Train Epoch 51 ==========
Loss: 0.535	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5568       185
   macro avg     0.5261    0.5136    0.4928       185
weighted avg     0.5706    0.5568    0.5422       185

micro f-score: 0.5567567567567567

========== Train Epoch 52 ==========
Loss: 0.531	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5459       185
   macro avg     0.5082    0.5184    0.4989       185
weighted avg     0.5537    0.5459    0.5354       185

micro f-score: 0.5459459459459459

========== Train Epoch 53 ==========
Loss: 0.504	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5514       185
   macro avg     0.5068    0.5133    0.4919       185
weighted avg     0.5482    0.5514    0.5363       185

micro f-score: 0.5513513513513514

========== Train Epoch 54 ==========
Loss: 0.486	Accuracy: 55.14%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5514       185
   macro avg     0.5114    0.5086    0.4864       185
weighted avg     0.5532    0.5514    0.5354       185

micro f-score: 0.5513513513513514

========== Train Epoch 55 ==========
Loss: 0.457	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4583    0.3548    0.4000        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5568       185
   macro avg     0.5019    0.5011    0.4842       185
weighted avg     0.5473    0.5568    0.5383       185

micro f-score: 0.5567567567567567

========== Train Epoch 56 ==========
Loss: 0.458	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5838       185
   macro avg     0.5349    0.5524    0.5262       185
weighted avg     0.5909    0.5838    0.5719       185

micro f-score: 0.5837837837837838

========== Train Epoch 57 ==========
Loss: 0.434	Accuracy: 56.22%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5622       185
   macro avg     0.5229    0.5269    0.5066       185
weighted avg     0.5707    0.5622    0.5488       185

micro f-score: 0.5621621621621622

========== Train Epoch 58 ==========
Loss: 0.431	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7692    0.3226    0.4545        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.5622       185
   macro avg     0.5751    0.5130    0.4887       185
weighted avg     0.6146    0.5622    0.5392       185

micro f-score: 0.5621621621621622

========== Train Epoch 59 ==========
Loss: 0.399	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5568       185
   macro avg     0.5127    0.5055    0.4893       185
weighted avg     0.5596    0.5568    0.5410       185

micro f-score: 0.5567567567567567

========== Train Epoch 60 ==========
Loss: 0.393	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5622       185
   macro avg     0.5157    0.5156    0.4935       185
weighted avg     0.5676    0.5622    0.5493       185

micro f-score: 0.5621621621621622

========== Train Epoch 61 ==========
Loss: 0.375	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.5514       185
   macro avg     0.4858    0.5128    0.4845       185
weighted avg     0.5520    0.5514    0.5417       185

micro f-score: 0.5513513513513514

========== Train Epoch 62 ==========
Loss: 0.357	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5459       185
   macro avg     0.4957    0.5059    0.4784       185
weighted avg     0.5490    0.5459    0.5272       185

micro f-score: 0.5459459459459459

========== Train Epoch 63 ==========
Loss: 0.361	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5730       185
   macro avg     0.5261    0.5432    0.5195       185
weighted avg     0.5797    0.5730    0.5641       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Loss: 0.328	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.5568       185
   macro avg     0.5255    0.5185    0.4943       185
weighted avg     0.5743    0.5568    0.5419       185

micro f-score: 0.5567567567567567

Finished training!!!

Min Loss = 0.328 in epoch 63;
Max Accuracy = 58.38% in epoch 55;
Total Cost 38 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt2: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt2: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt2: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt2: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt2: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt2: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt2: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt2: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.05
Params size (MB): 43.22
Estimated Total Size (MB): 122.44
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
