dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max3
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.829	Accuracy: 29.73%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2609    0.5806    0.3600        31
         cwx     0.2105    0.1818    0.1951        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3590    0.3111    0.3333        45
         zxx     0.3276    0.4872    0.3918        39

    accuracy                         0.2973       185
   macro avg     0.1654    0.2230    0.1829       185
weighted avg     0.2251    0.2973    0.2472       185

micro f-score: 0.2972972972972973

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.639	Accuracy: 36.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4884    0.4667    0.4773        45
         zxx     0.3333    0.7692    0.4651        39

    accuracy                         0.3622       185
   macro avg     0.2898    0.2854    0.2668       185
weighted avg     0.3271    0.3622    0.3197       185

micro f-score: 0.3621621621621622

========== Train Epoch 3 ==========
Loss: 1.545	Accuracy: 38.92%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3434    0.8718    0.4928        39

    accuracy                         0.3892       185
   macro avg     0.3181    0.3068    0.2826       185
weighted avg     0.3605    0.3892    0.3384       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
Loss: 1.494	Accuracy: 38.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.3511    0.8462    0.4962        39

    accuracy                         0.3892       185
   macro avg     0.3293    0.3167    0.2964       185
weighted avg     0.3661    0.3892    0.3456       185

micro f-score: 0.3891891891891892

========== Train Epoch 5 ==========
Loss: 1.480	Accuracy: 38.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2800    0.2258    0.2500        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.3827    0.7949    0.5167        39

    accuracy                         0.3892       185
   macro avg     0.3174    0.3195    0.2993       185
weighted avg     0.3521    0.3892    0.3480       185

micro f-score: 0.3891891891891892

========== Train Epoch 6 ==========
Loss: 1.467	Accuracy: 40.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3827    0.7949    0.5167        39

    accuracy                         0.4000       185
   macro avg     0.3355    0.3432    0.3242       185
weighted avg     0.3685    0.4000    0.3643       185

micro f-score: 0.4000000000000001

========== Train Epoch 7 ==========
Loss: 1.430	Accuracy: 42.16%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.3977    0.8974    0.5512        39

    accuracy                         0.4216       185
   macro avg     0.3497    0.3366    0.3187       185
weighted avg     0.3893    0.4216    0.3757       185

micro f-score: 0.42162162162162165

========== Train Epoch 8 ==========
Loss: 1.403	Accuracy: 41.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5476    0.5111    0.5287        45
         zxx     0.3763    0.8974    0.5303        39

    accuracy                         0.4108       185
   macro avg     0.3492    0.3342    0.3129       185
weighted avg     0.3827    0.4108    0.3620       185

micro f-score: 0.4108108108108109

========== Train Epoch 9 ==========
Loss: 1.384	Accuracy: 43.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4091    0.2903    0.3396        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.3933    0.8974    0.5469        39

    accuracy                         0.4324       185
   macro avg     0.4051    0.3660    0.3568       185
weighted avg     0.4317    0.4324    0.3987       185

micro f-score: 0.43243243243243246

========== Train Epoch 10 ==========
Loss: 1.371	Accuracy: 43.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4267    0.8205    0.5614        39

    accuracy                         0.4324       185
   macro avg     0.3923    0.3688    0.3638       185
weighted avg     0.4218    0.4324    0.4076       185

micro f-score: 0.43243243243243246

========== Train Epoch 11 ==========
Loss: 1.372	Accuracy: 41.62%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.3951    0.8205    0.5333        39

    accuracy                         0.4162       185
   macro avg     0.3419    0.3492    0.3301       185
weighted avg     0.3770    0.4162    0.3761       185

micro f-score: 0.41621621621621624

========== Train Epoch 12 ==========
Loss: 1.333	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4400    0.8462    0.5789        39

    accuracy                         0.4378       185
   macro avg     0.3770    0.3736    0.3577       185
weighted avg     0.4157    0.4378    0.4058       185

micro f-score: 0.43783783783783786

========== Train Epoch 13 ==========
Loss: 1.302	Accuracy: 47.03%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.4703       185
   macro avg     0.4196    0.4049    0.3988       185
weighted avg     0.4562    0.4703    0.4468       185

micro f-score: 0.4702702702702703

========== Train Epoch 14 ==========
Loss: 1.305	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.4703       185
   macro avg     0.4252    0.4175    0.4014       185
weighted avg     0.4579    0.4703    0.4425       185

micro f-score: 0.4702702702702703

========== Train Epoch 15 ==========
Loss: 1.268	Accuracy: 47.03%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4286    0.3871    0.4068        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.4714    0.8462    0.6055        39

    accuracy                         0.4703       185
   macro avg     0.4310    0.4156    0.3996       185
weighted avg     0.4630    0.4703    0.4428       185

micro f-score: 0.4702702702702703

========== Train Epoch 16 ==========
Loss: 1.256	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4737    0.2903    0.3600        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.4595       185
   macro avg     0.3979    0.3941    0.3825       185
weighted avg     0.4402    0.4595    0.4330       185

micro f-score: 0.4594594594594595

========== Train Epoch 17 ==========
Loss: 1.231	Accuracy: 48.11%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.4811       185
   macro avg     0.4478    0.4344    0.4258       185
weighted avg     0.4751    0.4811    0.4604       185

micro f-score: 0.4810810810810811

========== Train Epoch 18 ==========
Loss: 1.211	Accuracy: 44.32%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.3820    0.8718    0.5312        39

    accuracy                         0.4432       185
   macro avg     0.3767    0.3670    0.3513       185
weighted avg     0.4214    0.4432    0.4052       185

micro f-score: 0.44324324324324327

========== Train Epoch 19 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.218	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5027       185
   macro avg     0.4361    0.4524    0.4305       185
weighted avg     0.4913    0.5027    0.4803       185

micro f-score: 0.5027027027027027

========== Train Epoch 20 ==========
Loss: 1.169	Accuracy: 49.73%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.4973       185
   macro avg     0.4569    0.4392    0.4284       185
weighted avg     0.4863    0.4973    0.4717       185

micro f-score: 0.4972972972972973

========== Train Epoch 21 ==========
Loss: 1.172	Accuracy: 51.89%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.4865    0.9231    0.6372        39

    accuracy                         0.5189       185
   macro avg     0.4866    0.4587    0.4376       185
weighted avg     0.5248    0.5189    0.4883       185

micro f-score: 0.518918918918919

========== Train Epoch 22 ==========
Loss: 1.140	Accuracy: 49.73%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.4605    0.8974    0.6087        39

    accuracy                         0.4973       185
   macro avg     0.4576    0.4391    0.4288       185
weighted avg     0.4907    0.4973    0.4710       185

micro f-score: 0.4972972972972973

========== Train Epoch 23 ==========
Loss: 1.133	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.5027       185
   macro avg     0.4449    0.4467    0.4236       185
weighted avg     0.4890    0.5027    0.4739       185

micro f-score: 0.5027027027027027

========== Train Epoch 24 ==========
Loss: 1.105	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.1111    0.0526    0.0714        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5081       185
   macro avg     0.4421    0.4589    0.4394       185
weighted avg     0.4904    0.5081    0.4860       185

micro f-score: 0.5081081081081081

========== Train Epoch 25 ==========
Loss: 1.074	Accuracy: 53.51%	Cost 40s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5351       185
   macro avg     0.4740    0.4845    0.4659       185
weighted avg     0.5177    0.5351    0.5123       185

micro f-score: 0.5351351351351351

========== Train Epoch 26 ==========
Loss: 1.056	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3667    0.5000    0.4231        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5135       185
   macro avg     0.4534    0.4495    0.4265       185
weighted avg     0.5113    0.5135    0.4888       185

micro f-score: 0.5135135135135135

========== Train Epoch 27 ==========
Loss: 1.050	Accuracy: 53.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.5351       185
   macro avg     0.4608    0.4809    0.4593       185
weighted avg     0.5130    0.5351    0.5121       185

micro f-score: 0.5351351351351351

========== Train Epoch 28 ==========
Loss: 1.026	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.3235    0.5000    0.3929        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.5027       185
   macro avg     0.4682    0.4793    0.4670       185
weighted avg     0.5263    0.5027    0.5088       185

micro f-score: 0.5027027027027027

========== Train Epoch 29 ==========
Loss: 1.006	Accuracy: 50.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5081       185
   macro avg     0.4482    0.4529    0.4242       185
weighted avg     0.4978    0.5081    0.4795       185

micro f-score: 0.5081081081081081

========== Train Epoch 30 ==========
Loss: 0.992	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4434    0.4556    0.4367       185
weighted avg     0.4980    0.5189    0.4954       185

micro f-score: 0.518918918918919

========== Train Epoch 31 ==========
Loss: 0.982	Accuracy: 56.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5622       185
   macro avg     0.5056    0.5070    0.4923       185
weighted avg     0.5578    0.5622    0.5455       185

micro f-score: 0.5621621621621622

========== Train Epoch 32 ==========
Loss: 0.960	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5568       185
   macro avg     0.5050    0.4966    0.4822       185
weighted avg     0.5456    0.5568    0.5352       185

micro f-score: 0.5567567567567567

========== Train Epoch 33 ==========
Loss: 0.931	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.4932    0.9231    0.6429        39

    accuracy                         0.5297       185
   macro avg     0.4825    0.4810    0.4559       185
weighted avg     0.5167    0.5297    0.4974       185

micro f-score: 0.5297297297297298

========== Train Epoch 34 ==========
Loss: 0.916	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5514       185
   macro avg     0.5055    0.4953    0.4861       185
weighted avg     0.5412    0.5514    0.5325       185

micro f-score: 0.5513513513513514

========== Train Epoch 35 ==========
Loss: 0.898	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5730       185
   macro avg     0.4982    0.5151    0.4987       185
weighted avg     0.5428    0.5730    0.5515       185

micro f-score: 0.572972972972973

========== Train Epoch 36 ==========
Loss: 0.893	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5514       185
   macro avg     0.4859    0.5080    0.4793       185
weighted avg     0.5410    0.5514    0.5309       185

micro f-score: 0.5513513513513514

========== Train Epoch 37 ==========
Loss: 0.863	Accuracy: 56.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6429    0.8000    0.7129        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5622       185
   macro avg     0.4840    0.4892    0.4724       185
weighted avg     0.5277    0.5622    0.5307       185

micro f-score: 0.5621621621621622

========== Train Epoch 38 ==========
Loss: 0.842	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5568       185
   macro avg     0.4983    0.5112    0.4888       185
weighted avg     0.5415    0.5568    0.5348       185

micro f-score: 0.5567567567567567

========== Train Epoch 39 ==========
Loss: 0.820	Accuracy: 54.05%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5405       185
   macro avg     0.4634    0.4992    0.4697       185
weighted avg     0.5153    0.5405    0.5180       185

micro f-score: 0.5405405405405406

========== Train Epoch 40 ==========
Loss: 0.804	Accuracy: 57.84%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5784       185
   macro avg     0.5111    0.5291    0.5118       185
weighted avg     0.5536    0.5784    0.5579       185

micro f-score: 0.5783783783783784

========== Train Epoch 41 ==========
Loss: 0.795	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5892       185
   macro avg     0.5558    0.5334    0.5199       185
weighted avg     0.5882    0.5892    0.5692       185

micro f-score: 0.5891891891891892

========== Train Epoch 42 ==========
Loss: 0.780	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5838       185
   macro avg     0.5358    0.5375    0.5289       185
weighted avg     0.5646    0.5838    0.5670       185

micro f-score: 0.5837837837837838

========== Train Epoch 43 ==========
Loss: 0.769	Accuracy: 56.76%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5676       185
   macro avg     0.5312    0.5112    0.4991       185
weighted avg     0.5636    0.5676    0.5446       185

micro f-score: 0.5675675675675675

========== Train Epoch 44 ==========
Loss: 0.720	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5676       185
   macro avg     0.5308    0.5303    0.5030       185
weighted avg     0.5602    0.5676    0.5413       185

micro f-score: 0.5675675675675675

========== Train Epoch 45 ==========
Loss: 0.715	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4773    0.6774    0.5600        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6585    0.6923    0.6750        39

    accuracy                         0.5622       185
   macro avg     0.5151    0.5352    0.5077       185
weighted avg     0.5631    0.5622    0.5486       185

micro f-score: 0.5621621621621622

========== Train Epoch 46 ==========
Loss: 0.697	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.6000       185
   macro avg     0.5465    0.5664    0.5402       185
weighted avg     0.5974    0.6000    0.5838       185

micro f-score: 0.6

========== Train Epoch 47 ==========
Loss: 0.683	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6216       185
   macro avg     0.5816    0.5799    0.5634       185
weighted avg     0.6076    0.6216    0.6007       185

micro f-score: 0.6216216216216216

========== Train Epoch 48 ==========
Loss: 0.669	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5946       185
   macro avg     0.5526    0.5583    0.5367       185
weighted avg     0.6016    0.5946    0.5823       185

micro f-score: 0.5945945945945946

========== Train Epoch 49 ==========
Loss: 0.648	Accuracy: 56.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5622       185
   macro avg     0.5073    0.5263    0.5023       185
weighted avg     0.5527    0.5622    0.5453       185

micro f-score: 0.5621621621621622

========== Train Epoch 50 ==========
Loss: 0.621	Accuracy: 57.84%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5784       185
   macro avg     0.5286    0.5544    0.5337       185
weighted avg     0.5814    0.5784    0.5738       185

micro f-score: 0.5783783783783784

========== Train Epoch 51 ==========
Loss: 0.610	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.6667    0.8000    0.7273        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5838       185
   macro avg     0.5510    0.5401    0.5187       185
weighted avg     0.5791    0.5838    0.5584       185

micro f-score: 0.5837837837837838

========== Train Epoch 52 ==========
Loss: 0.596	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.5946       185
   macro avg     0.5495    0.5519    0.5361       185
weighted avg     0.5883    0.5946    0.5766       185

micro f-score: 0.5945945945945946

========== Train Epoch 53 ==========
Loss: 0.584	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6054       185
   macro avg     0.5504    0.5666    0.5470       185
weighted avg     0.6013    0.6054    0.5941       185

micro f-score: 0.6054054054054054

========== Train Epoch 54 ==========
Loss: 0.566	Accuracy: 63.24%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.6324       185
   macro avg     0.5772    0.5982    0.5807       185
weighted avg     0.6230    0.6324    0.6220       185

micro f-score: 0.6324324324324324

========== Train Epoch 55 ==========
Loss: 0.544	Accuracy: 59.46%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4231    0.9167    0.5789        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5946       185
   macro avg     0.5536    0.5728    0.5357       185
weighted avg     0.6088    0.5946    0.5794       185

micro f-score: 0.5945945945945946

========== Train Epoch 56 ==========
Loss: 0.545	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5784       185
   macro avg     0.5465    0.5501    0.5298       185
weighted avg     0.5835    0.5784    0.5632       185

micro f-score: 0.5783783783783784

========== Train Epoch 57 ==========
Loss: 0.531	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.2632    0.2941    0.2778        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5622       185
   macro avg     0.5522    0.5201    0.5026       185
weighted avg     0.5816    0.5622    0.5387       185

micro f-score: 0.5621621621621622

========== Train Epoch 58 ==========
Loss: 0.506	Accuracy: 62.16%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.6216       185
   macro avg     0.5664    0.5895    0.5639       185
weighted avg     0.6252    0.6216    0.6095       185

micro f-score: 0.6216216216216216

========== Train Epoch 59 ==========
Loss: 0.488	Accuracy: 64.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.6154    0.7273    0.6667        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6486       185
   macro avg     0.5937    0.6158    0.5972       185
weighted avg     0.6357    0.6486    0.6368       185

micro f-score: 0.6486486486486487

========== Train Epoch 60 ==========
Loss: 0.495	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.7222    0.5909    0.6500        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6000       185
   macro avg     0.5544    0.5687    0.5503       185
weighted avg     0.6013    0.6000    0.5900       185

micro f-score: 0.6

========== Train Epoch 61 ==========
Loss: 0.460	Accuracy: 62.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5500    0.9167    0.6875        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6270       185
   macro avg     0.6052    0.6121    0.5874       185
weighted avg     0.6545    0.6270    0.6210       185

micro f-score: 0.6270270270270271

========== Train Epoch 62 ==========
Loss: 0.454	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5676       185
   macro avg     0.5530    0.5396    0.5164       185
weighted avg     0.5944    0.5676    0.5499       185

micro f-score: 0.5675675675675675

========== Train Epoch 63 ==========
Loss: 0.431	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3043    0.4118    0.3500        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.5838       185
   macro avg     0.5427    0.5538    0.5316       185
weighted avg     0.5950    0.5838    0.5740       185

micro f-score: 0.5837837837837838

========== Train Epoch 64 ==========
Loss: 0.440	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.5892       185
   macro avg     0.5734    0.5614    0.5366       185
weighted avg     0.6138    0.5892    0.5755       185

micro f-score: 0.5891891891891892

Finished training!!!

Min Loss = 0.431 in epoch 62;
Max Accuracy = 64.86% in epoch 58;
Total Cost 38 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt2: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt2: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt2: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt2: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt2: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt2: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt2: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt2: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    dspp_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
