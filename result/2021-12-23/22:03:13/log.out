dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: dspp_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.837	Accuracy: 29.19%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     0.1512    0.5909    0.2407        22
         hdx     0.2500    0.2941    0.2703        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.7500    0.2000    0.3158        45
         zxx     0.4107    0.5897    0.4842        39

    accuracy                         0.2919       185
   macro avg     0.3558    0.2650    0.2303       185
weighted avg     0.4142    0.2919    0.2681       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
Loss: 1.633	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3659    0.4839    0.4167        31
         cwx     0.0769    0.0455    0.0571        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.4085    0.7436    0.5273        39

    accuracy                         0.4162       185
   macro avg     0.3668    0.3454    0.3117       185
weighted avg     0.4251    0.4162    0.3815       185

micro f-score: 0.41621621621621624

========== Train Epoch 3 ==========
Loss: 1.448	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.3750    0.9231    0.5333        39

    accuracy                         0.4324       185
   macro avg     0.4131    0.3486    0.3217       185
weighted avg     0.4496    0.4324    0.3817       185

micro f-score: 0.43243243243243246

========== Train Epoch 4 ==========
Loss: 1.410	Accuracy: 44.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5625    0.2903    0.3830        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4167    0.8974    0.5691        39

    accuracy                         0.4432       185
   macro avg     0.3751    0.3713    0.3438       185
weighted avg     0.4250    0.4432    0.4007       185

micro f-score: 0.44324324324324327

========== Train Epoch 5 ==========
Loss: 1.369	Accuracy: 45.95%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.2963    0.3636    0.3265        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4714    0.8462    0.6055        39

    accuracy                         0.4595       185
   macro avg     0.4185    0.3984    0.3807       185
weighted avg     0.4536    0.4595    0.4300       185

micro f-score: 0.4594594594594595

========== Train Epoch 6 ==========
Loss: 1.350	Accuracy: 46.49%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.3333    0.4545    0.3846        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5098    0.5778    0.5417        45
         zxx     0.5510    0.6923    0.6136        39

    accuracy                         0.4649       185
   macro avg     0.4277    0.3988    0.3940       185
weighted avg     0.4527    0.4649    0.4443       185

micro f-score: 0.4648648648648649

========== Train Epoch 7 ==========
Loss: 1.295	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4658    0.8718    0.6071        39

    accuracy                         0.4919       185
   macro avg     0.4867    0.4270    0.4059       185
weighted avg     0.5209    0.4919    0.4633       185

micro f-score: 0.4918918918918919

========== Train Epoch 8 ==========
Loss: 1.283	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.3333    0.4545    0.3846        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.4919       185
   macro avg     0.4316    0.4364    0.4240       185
weighted avg     0.4749    0.4919    0.4754       185

micro f-score: 0.4918918918918919

========== Train Epoch 9 ==========
Loss: 1.232	Accuracy: 49.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.5294    0.6000    0.5625        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.4973       185
   macro avg     0.4553    0.4475    0.4334       185
weighted avg     0.4730    0.4973    0.4678       185

micro f-score: 0.4972972972972973

========== Train Epoch 10 ==========
Loss: 1.204	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6970    0.5111    0.5897        45
         zxx     0.4430    0.8974    0.5932        39

    accuracy                         0.5135       185
   macro avg     0.5176    0.4688    0.4474       185
weighted avg     0.5401    0.5135    0.4853       185

micro f-score: 0.5135135135135135

========== Train Epoch 11 ==========
Loss: 1.148	Accuracy: 49.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.2821    0.5000    0.3607        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.4973       185
   macro avg     0.4730    0.4625    0.4315       185
weighted avg     0.5176    0.4973    0.4810       185

micro f-score: 0.4972972972972973

========== Train Epoch 12 ==========
Loss: 1.148	Accuracy: 53.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6970    0.5111    0.5897        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5351       185
   macro avg     0.4903    0.5024    0.4813       185
weighted avg     0.5300    0.5351    0.5183       185

micro f-score: 0.5351351351351351

========== Train Epoch 13 ==========
Loss: 1.095	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.3478    0.3636    0.3556        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5297       185
   macro avg     0.4705    0.4940    0.4742       185
weighted avg     0.5242    0.5297    0.5221       185

micro f-score: 0.5297297297297298

========== Train Epoch 14 ==========
Loss: 1.045	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.3438    0.5000    0.4074        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6667    0.8205    0.7356        39

    accuracy                         0.5622       185
   macro avg     0.5212    0.5163    0.4999       185
weighted avg     0.5547    0.5622    0.5446       185

micro f-score: 0.5621621621621622

========== Train Epoch 15 ==========
Loss: 1.029	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.5892       185
   macro avg     0.5238    0.5429    0.5139       185
weighted avg     0.5798    0.5892    0.5706       185

micro f-score: 0.5891891891891892

========== Train Epoch 16 ==========
Loss: 0.991	Accuracy: 59.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4333    0.5909    0.5000        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.5946       185
   macro avg     0.5371    0.5645    0.5395       185
weighted avg     0.6000    0.5946    0.5893       185

micro f-score: 0.5945945945945946

========== Train Epoch 17 ==========
Loss: 0.928	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6054       185
   macro avg     0.5750    0.5491    0.5270       185
weighted avg     0.6103    0.6054    0.5816       185

micro f-score: 0.6054054054054054

========== Train Epoch 18 ==========
Loss: 0.907	Accuracy: 55.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.7297    0.6923    0.7105        39

    accuracy                         0.5514       185
   macro avg     0.4833    0.5130    0.4919       185
weighted avg     0.5408    0.5514    0.5428       185

micro f-score: 0.5513513513513514

========== Train Epoch 19 ==========
Loss: 0.874	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5645    0.8974    0.6931        39

    accuracy                         0.6054       185
   macro avg     0.5752    0.5575    0.5423       185
weighted avg     0.6200    0.6054    0.5907       185

micro f-score: 0.6054054054054054

========== Train Epoch 20 ==========
Loss: 0.873	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6000       185
   macro avg     0.5389    0.5611    0.5368       185
weighted avg     0.6076    0.6000    0.5946       185

micro f-score: 0.6

========== Train Epoch 21 ==========
Loss: 0.835	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.5892       185
   macro avg     0.5367    0.5549    0.5315       185
weighted avg     0.6000    0.5892    0.5807       185

micro f-score: 0.5891891891891892

========== Train Epoch 22 ==========
Loss: 0.779	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.2982    0.7727    0.4304        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6731    0.7778    0.7216        45
         zxx     1.0000    0.5128    0.6780        39

    accuracy                         0.5405       185
   macro avg     0.5657    0.5090    0.4925       185
weighted avg     0.6332    0.5405    0.5425       185

micro f-score: 0.5405405405405406

========== Train Epoch 23 ==========
Loss: 0.779	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5676       185
   macro avg     0.5341    0.5228    0.5161       185
weighted avg     0.5743    0.5676    0.5574       185

micro f-score: 0.5675675675675675

========== Train Epoch 24 ==========
Loss: 0.727	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.5838       185
   macro avg     0.5219    0.5196    0.5167       185
weighted avg     0.5792    0.5838    0.5773       185

micro f-score: 0.5837837837837838

========== Train Epoch 25 ==========
Loss: 0.721	Accuracy: 61.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.3617    0.7727    0.4928        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.8000    0.8205    0.8101        39

    accuracy                         0.6108       185
   macro avg     0.6294    0.5566    0.5367       185
weighted avg     0.6627    0.6108    0.5957       185

micro f-score: 0.6108108108108108

========== Train Epoch 26 ==========
Loss: 0.693	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.4557    0.9231    0.6102        39

    accuracy                         0.5946       185
   macro avg     0.6725    0.5497    0.5452       185
weighted avg     0.6815    0.5946    0.5796       185

micro f-score: 0.5945945945945946

========== Train Epoch 27 ==========
Loss: 0.665	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2222    0.2105    0.2162        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.6066    0.9487    0.7400        39

    accuracy                         0.6108       185
   macro avg     0.5737    0.5601    0.5570       185
weighted avg     0.6275    0.6108    0.6052       185

micro f-score: 0.6108108108108108

========== Train Epoch 28 ==========
Loss: 0.629	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.4839    0.6818    0.5660        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.6108       185
   macro avg     0.5733    0.5994    0.5684       185
weighted avg     0.6604    0.6108    0.6213       185

micro f-score: 0.6108108108108108

========== Train Epoch 29 ==========
Loss: 0.561	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7778    0.4516    0.5714        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.2609    0.3529    0.3000        17
         mtx     0.3333    0.3158    0.3243        19
         nqx     0.3448    0.8333    0.4878        12
         qtx     0.6538    0.7556    0.7010        45
         zxx     0.9565    0.5641    0.7097        39

    accuracy                         0.5514       185
   macro avg     0.5402    0.5326    0.5070       185
weighted avg     0.6256    0.5514    0.5625       185

micro f-score: 0.5513513513513514

========== Train Epoch 30 ==========
Loss: 0.588	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5500    0.7097    0.6197        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.9545    0.5385    0.6885        39

    accuracy                         0.5676       185
   macro avg     0.5310    0.5390    0.5169       185
weighted avg     0.6200    0.5676    0.5756       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.559	Accuracy: 62.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.7742    0.6076        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6270       185
   macro avg     0.5930    0.5853    0.5770       185
weighted avg     0.6452    0.6270    0.6218       185

micro f-score: 0.6270270270270271

========== Train Epoch 32 ==========
Loss: 0.511	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5385    0.6774    0.6000        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3158    0.3158    0.3158        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.9524    0.5128    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5553    0.5662    0.5360       185
weighted avg     0.6503    0.5730    0.5870       185

micro f-score: 0.572972972972973

========== Train Epoch 33 ==========
Loss: 0.529	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.5606    0.9487    0.7048        39

    accuracy                         0.6000       185
   macro avg     0.5653    0.5562    0.5445       185
weighted avg     0.6056    0.6000    0.5837       185

micro f-score: 0.6

========== Train Epoch 34 ==========
Loss: 0.490	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5405    0.6452    0.5882        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2727    0.3158    0.2927        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5838       185
   macro avg     0.5472    0.5505    0.5397       185
weighted avg     0.6183    0.5838    0.5885       185

micro f-score: 0.5837837837837838

========== Train Epoch 35 ==========
Loss: 0.452	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.3448    0.8333    0.4878        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6863    0.8974    0.7778        39

    accuracy                         0.5838       185
   macro avg     0.5526    0.5585    0.5257       185
weighted avg     0.6183    0.5838    0.5772       185

micro f-score: 0.5837837837837838

========== Train Epoch 36 ==========
Loss: 0.447	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.8485    0.7179    0.7778        39

    accuracy                         0.5892       185
   macro avg     0.5591    0.5606    0.5484       185
weighted avg     0.6488    0.5892    0.6080       185

micro f-score: 0.5891891891891892

========== Train Epoch 37 ==========
Loss: 0.435	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.3750    0.6818    0.4839        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6607    0.8222    0.7327        45
         zxx     0.8649    0.8205    0.8421        39

    accuracy                         0.6270       185
   macro avg     0.6200    0.5831    0.5613       185
weighted avg     0.6660    0.6270    0.6135       185

micro f-score: 0.6270270270270271

========== Train Epoch 38 ==========
Loss: 0.406	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3810    0.4211    0.4000        19
         nqx     0.3846    0.8333    0.5263        12
         qtx     0.9394    0.6889    0.7949        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6270       185
   macro avg     0.5789    0.5977    0.5723       185
weighted avg     0.6688    0.6270    0.6363       185

micro f-score: 0.6270270270270271

========== Train Epoch 39 ==========
Loss: 0.374	Accuracy: 64.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.8000    0.5161    0.6275        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7778    0.7778    0.7778        45
         zxx     0.7857    0.8462    0.8148        39

    accuracy                         0.6432       185
   macro avg     0.6045    0.6066    0.5851       185
weighted avg     0.6688    0.6432    0.6416       185

micro f-score: 0.6432432432432432

========== Train Epoch 40 ==========
Loss: 0.380	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7895    0.4839    0.6000        31
         cwx     0.5185    0.6364    0.5714        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.7442    0.8205    0.7805        39

    accuracy                         0.6378       185
   macro avg     0.6069    0.5925    0.5818       185
weighted avg     0.6526    0.6378    0.6298       185

micro f-score: 0.6378378378378379

========== Train Epoch 41 ==========
Loss: 0.361	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.2821    0.9167    0.4314        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.8519    0.5897    0.6970        39

    accuracy                         0.5676       185
   macro avg     0.5600    0.5661    0.5304       185
weighted avg     0.6422    0.5676    0.5834       185

micro f-score: 0.5675675675675675

========== Train Epoch 42 ==========
Loss: 0.343	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5238    0.7097    0.6027        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7292    0.7778    0.7527        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.6270       185
   macro avg     0.5923    0.5752    0.5679       185
weighted avg     0.6404    0.6270    0.6206       185

micro f-score: 0.6270270270270271

========== Train Epoch 43 ==========
Loss: 0.319	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6162       185
   macro avg     0.5710    0.5786    0.5544       185
weighted avg     0.6357    0.6162    0.6108       185

micro f-score: 0.6162162162162163

========== Train Epoch 44 ==========
Loss: 0.304	Accuracy: 66.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.4857    0.7727    0.5965        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8947    0.7556    0.8193        45
         zxx     0.6792    0.9231    0.7826        39

    accuracy                         0.6649       185
   macro avg     0.6633    0.6112    0.6130       185
weighted avg     0.6935    0.6649    0.6583       185

micro f-score: 0.6648648648648648

========== Train Epoch 45 ==========
Loss: 0.298	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7619    0.5161    0.6154        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2667    0.4706    0.3404        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.7826    0.8000    0.7912        45
         zxx     0.8485    0.7179    0.7778        39

    accuracy                         0.6324       185
   macro avg     0.6271    0.6118    0.5877       185
weighted avg     0.6902    0.6324    0.6395       185

micro f-score: 0.6324324324324324

========== Train Epoch 46 ==========
Loss: 0.289	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.2812    0.5294    0.3673        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.8800    0.5641    0.6875        39

    accuracy                         0.5838       185
   macro avg     0.5678    0.5678    0.5526       185
weighted avg     0.6534    0.5838    0.6027       185

micro f-score: 0.5837837837837838

========== Train Epoch 47 ==========
Loss: 0.273	Accuracy: 64.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8140    0.7778    0.7955        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6432       185
   macro avg     0.6014    0.6044    0.5958       185
weighted avg     0.6568    0.6432    0.6450       185

micro f-score: 0.6432432432432432

========== Train Epoch 48 ==========
Loss: 0.261	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4615    0.7742    0.5783        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.6216       185
   macro avg     0.6077    0.6023    0.5858       185
weighted avg     0.6686    0.6216    0.6254       185

micro f-score: 0.6216216216216216

========== Train Epoch 49 ==========
Loss: 0.226	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.6452    0.5970        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2444    0.5789    0.3438        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8824    0.6667    0.7595        45
         zxx     0.9286    0.6667    0.7761        39

    accuracy                         0.5946       185
   macro avg     0.6163    0.5605    0.5694       185
weighted avg     0.6840    0.5946    0.6212       185

micro f-score: 0.5945945945945946

========== Train Epoch 50 ==========
Loss: 0.238	Accuracy: 63.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.5385    0.6364    0.5833        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8537    0.7778    0.8140        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.6324       185
   macro avg     0.6023    0.6096    0.5819       185
weighted avg     0.6819    0.6324    0.6395       185

micro f-score: 0.6324324324324324

========== Train Epoch 51 ==========
Loss: 0.223	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.7419    0.5974        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.2340    0.5789    0.3333        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.9545    0.4667    0.6269        45
         zxx     0.9167    0.5641    0.6984        39

    accuracy                         0.5405       185
   macro avg     0.5955    0.5381    0.5276       185
weighted avg     0.6842    0.5405    0.5661       185

micro f-score: 0.5405405405405406

========== Train Epoch 52 ==========
Loss: 0.232	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3934    0.7742    0.5217        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.6054       185
   macro avg     0.6318    0.5739    0.5849       185
weighted avg     0.6645    0.6054    0.6151       185

micro f-score: 0.6054054054054054

========== Train Epoch 53 ==========
Loss: 0.194	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6486       185
   macro avg     0.6080    0.6140    0.6019       185
weighted avg     0.6540    0.6486    0.6439       185

micro f-score: 0.6486486486486487

========== Train Epoch 54 ==========
Loss: 0.182	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.6250    0.2941    0.4000        17
         mtx     0.5333    0.4211    0.4706        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8684    0.7333    0.7952        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6486       185
   macro avg     0.6332    0.5897    0.5938       185
weighted avg     0.6627    0.6486    0.6412       185

micro f-score: 0.6486486486486487

========== Train Epoch 55 ==========
Loss: 0.179	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.6667    0.3529    0.4615        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.9118    0.6889    0.7848        45
         zxx     0.4684    0.9487    0.6271        39

    accuracy                         0.6324       185
   macro avg     0.6805    0.5693    0.5951       185
weighted avg     0.6918    0.6324    0.6301       185

micro f-score: 0.6324324324324324

========== Train Epoch 56 ==========
Loss: 0.168	Accuracy: 64.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8333    0.4839    0.6122        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.5238    0.9167    0.6667        12
         qtx     0.7170    0.8444    0.7755        45
         zxx     0.8649    0.8205    0.8421        39

    accuracy                         0.6486       185
   macro avg     0.6258    0.6114    0.5921       185
weighted avg     0.6802    0.6486    0.6433       185

micro f-score: 0.6486486486486487

========== Train Epoch 57 ==========
Loss: 0.167	Accuracy: 62.16%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.5833    0.4118    0.4828        17
         mtx     0.3793    0.5789    0.4583        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5932    0.8974    0.7143        39

    accuracy                         0.6216       185
   macro avg     0.6241    0.6022    0.5888       185
weighted avg     0.6699    0.6216    0.6184       185

micro f-score: 0.6216216216216216

========== Train Epoch 58 ==========
Loss: 0.152	Accuracy: 65.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7619    0.5161    0.6154        31
         cwx     0.6667    0.6364    0.6512        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.6538    0.8718    0.7473        39

    accuracy                         0.6541       185
   macro avg     0.6490    0.6314    0.6083       185
weighted avg     0.6996    0.6541    0.6512       185

micro f-score: 0.654054054054054

========== Train Epoch 59 ==========
Loss: 0.141	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.9000    0.2903    0.4390        31
         cwx     0.3889    0.6364    0.4828        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6108       185
   macro avg     0.6052    0.5838    0.5556       185
weighted avg     0.6616    0.6108    0.5978       185

micro f-score: 0.6108108108108108

========== Train Epoch 60 ==========
Loss: 0.142	Accuracy: 66.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8182    0.5806    0.6792        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.7857    0.8462    0.8148        39

    accuracy                         0.6649       185
   macro avg     0.6408    0.6281    0.6092       185
weighted avg     0.6959    0.6649    0.6620       185

micro f-score: 0.6648648648648648

========== Train Epoch 61 ==========
Loss: 0.140	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.5873    0.9487    0.7255        39

    accuracy                         0.6324       185
   macro avg     0.6598    0.5634    0.5523       185
weighted avg     0.6743    0.6324    0.6062       185

micro f-score: 0.6324324324324324

========== Train Epoch 62 ==========
Loss: 0.149	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4490    0.7097    0.5500        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8095    0.7556    0.7816        45
         zxx     0.8621    0.6410    0.7353        39

    accuracy                         0.6162       185
   macro avg     0.6223    0.5925    0.5726       185
weighted avg     0.6689    0.6162    0.6146       185

micro f-score: 0.6162162162162163

========== Train Epoch 63 ==========
Loss: 0.126	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5128    0.6452    0.5714        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.3200    0.4211    0.3636        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.8667    0.6667    0.7536        39

    accuracy                         0.6054       185
   macro avg     0.5834    0.5905    0.5776       185
weighted avg     0.6501    0.6054    0.6180       185

micro f-score: 0.6054054054054054

========== Train Epoch 64 ==========
Loss: 0.128	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.8000    0.5161    0.6275        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.2812    0.4737    0.3529        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.8438    0.6923    0.7606        39

    accuracy                         0.6000       185
   macro avg     0.5909    0.5775    0.5677       185
weighted avg     0.6766    0.6000    0.6229       185

micro f-score: 0.6

Finished training!!!

Min Loss = 0.126 in epoch 62;
Max Accuracy = 66.49% in epoch 43;
Total Cost 32 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPP: 1-4                               [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-5                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-22                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-23            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-24                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-25                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-26            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-27             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-28                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-29                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-30            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-31                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-32                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-33            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-35                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-36            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-37                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-40             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-41                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-8                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-42                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-43            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-44                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-45                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-46            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-47                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-9                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-49            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-50                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-51                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-52            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-53             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-54                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-10                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-55                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-56            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-57                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-58                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-59            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-60                   [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,190,535
Trainable params: 11,190,535
Non-trainable params: 0
Total mult-adds (G): 14.37
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 271.88
Params size (MB): 42.69
Estimated Total Size (MB): 315.74
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    dspp_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/dspp_resnet.py", line 357, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/dspp_resnet.py", line 334, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
