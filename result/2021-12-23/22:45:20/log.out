dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max1
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.837	Accuracy: 30.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2273    0.2273    0.2273        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4600    0.5111    0.4842        45
         zxx     0.2569    0.7179    0.3784        39

    accuracy                         0.3081       185
   macro avg     0.1706    0.2165    0.1693       185
weighted avg     0.2160    0.3081    0.2333       185

micro f-score: 0.3081081081081081

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.644	Accuracy: 32.43%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.3226    0.3279        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.5000    0.2000    0.2857        45
         zxx     0.3204    0.8462    0.4648        39

    accuracy                         0.3243       185
   macro avg     0.2516    0.2637    0.2294       185
weighted avg     0.3037    0.3243    0.2717       185

micro f-score: 0.32432432432432434

========== Train Epoch 3 ==========
Loss: 1.525	Accuracy: 37.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3810    0.2581    0.3077        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5714    0.4444    0.5000        45
         zxx     0.3542    0.8718    0.5037        39

    accuracy                         0.3730       185
   macro avg     0.2573    0.2812    0.2498       185
weighted avg     0.3264    0.3730    0.3219       185

micro f-score: 0.37297297297297294

========== Train Epoch 4 ==========
Loss: 1.498	Accuracy: 36.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3125    0.3226    0.3175        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.3537    0.7436    0.4793        39

    accuracy                         0.3676       185
   macro avg     0.3183    0.2828    0.2630       185
weighted avg     0.3653    0.3676    0.3312       185

micro f-score: 0.3675675675675676

========== Train Epoch 5 ==========
Loss: 1.458	Accuracy: 39.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.3708    0.8462    0.5156        39

    accuracy                         0.3946       185
   macro avg     0.3298    0.2996    0.2800       185
weighted avg     0.3772    0.3946    0.3504       185

micro f-score: 0.3945945945945946

========== Train Epoch 6 ==========
Loss: 1.431	Accuracy: 38.92%	Cost 39s
              precision    recall  f1-score   support

         bzx     0.3333    0.3226    0.3279        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.3827    0.7949    0.5167        39

    accuracy                         0.3892       185
   macro avg     0.3183    0.3017    0.2851       185
weighted avg     0.3677    0.3892    0.3526       185

micro f-score: 0.3891891891891892

========== Train Epoch 7 ==========
Loss: 1.414	Accuracy: 39.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.3678    0.8205    0.5079        39

    accuracy                         0.3946       185
   macro avg     0.3572    0.3115    0.2996       185
weighted avg     0.3924    0.3946    0.3588       185

micro f-score: 0.3945945945945946

========== Train Epoch 8 ==========
Loss: 1.381	Accuracy: 37.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3571    0.8974    0.5109        39

    accuracy                         0.3784       185
   macro avg     0.3355    0.2906    0.2674       185
weighted avg     0.3714    0.3784    0.3261       185

micro f-score: 0.37837837837837834

========== Train Epoch 9 ==========
Loss: 1.362	Accuracy: 40.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.3976    0.8462    0.5410        39

    accuracy                         0.4054       185
   macro avg     0.3495    0.3160    0.2998       185
weighted avg     0.3915    0.4054    0.3659       185

micro f-score: 0.40540540540540543

========== Train Epoch 10 ==========
Loss: 1.331	Accuracy: 39.46%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.3721    0.8205    0.5120        39

    accuracy                         0.3946       185
   macro avg     0.3347    0.3063    0.2914       185
weighted avg     0.3780    0.3946    0.3559       185

micro f-score: 0.3945945945945946

========== Train Epoch 11 ==========
Loss: 1.307	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.3924    0.7949    0.5254        39

    accuracy                         0.4162       185
   macro avg     0.3782    0.3338    0.3283       185
weighted avg     0.4207    0.4162    0.3905       185

micro f-score: 0.41621621621621624

========== Train Epoch 12 ==========
Loss: 1.281	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.4571    0.8205    0.5872        39

    accuracy                         0.4486       185
   macro avg     0.3887    0.3604    0.3491       185
weighted avg     0.4327    0.4486    0.4169       185

micro f-score: 0.4486486486486486

========== Train Epoch 13 ==========
Loss: 1.248	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4342    0.8462    0.5739        39

    accuracy                         0.4486       185
   macro avg     0.3972    0.3629    0.3586       185
weighted avg     0.4442    0.4486    0.4234       185

micro f-score: 0.4486486486486486

========== Train Epoch 14 ==========
Loss: 1.215	Accuracy: 41.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.1935    0.2791        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.4000    0.9231    0.5581        39

    accuracy                         0.4162       185
   macro avg     0.3662    0.3228    0.3013       185
weighted avg     0.4118    0.4162    0.3675       185

micro f-score: 0.41621621621621624

========== Train Epoch 15 ==========
Loss: 1.186	Accuracy: 47.03%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.4844    0.7949    0.6019        39

    accuracy                         0.4703       185
   macro avg     0.4145    0.3919    0.3866       185
weighted avg     0.4599    0.4703    0.4485       185

micro f-score: 0.4702702702702703

========== Train Epoch 16 ==========
Loss: 1.172	Accuracy: 48.11%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.3043    0.3182    0.3111        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.6667    0.5778    0.6190        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.4811       185
   macro avg     0.4479    0.4042    0.3996       185
weighted avg     0.4916    0.4811    0.4602       185

micro f-score: 0.4810810810810811

========== Train Epoch 17 ==========
Loss: 1.134	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.4231    0.8462    0.5641        39

    accuracy                         0.4432       185
   macro avg     0.4127    0.3695    0.3573       185
weighted avg     0.4522    0.4432    0.4149       185

micro f-score: 0.44324324324324327

========== Train Epoch 18 ==========
Loss: 1.091	Accuracy: 50.81%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.3333    0.3636    0.3478        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5081       185
   macro avg     0.4485    0.4324    0.4285       185
weighted avg     0.4963    0.5081    0.4904       185

micro f-score: 0.5081081081081081

========== Train Epoch 19 ==========
Loss: 1.065	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.4844    0.7949    0.6019        39

    accuracy                         0.5081       185
   macro avg     0.4907    0.4463    0.4421       185
weighted avg     0.5281    0.5081    0.4943       185

micro f-score: 0.5081081081081081

========== Train Epoch 20 ==========
Loss: 1.025	Accuracy: 50.81%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.5081       185
   macro avg     0.5043    0.4418    0.4343       185
weighted avg     0.5297    0.5081    0.4851       185

micro f-score: 0.5081081081081081

========== Train Epoch 21 ==========
Loss: 0.994	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6364    0.6222    0.6292        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5135       185
   macro avg     0.4759    0.4437    0.4327       185
weighted avg     0.5154    0.5135    0.4913       185

micro f-score: 0.5135135135135135

========== Train Epoch 22 ==========
Loss: 0.965	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.5135       185
   macro avg     0.5116    0.4470    0.4318       185
weighted avg     0.5417    0.5135    0.4859       185

micro f-score: 0.5135135135135135

========== Train Epoch 23 ==========
Loss: 0.935	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.4471    0.4411    0.4298       185
weighted avg     0.4972    0.5243    0.4978       185

micro f-score: 0.5243243243243243

========== Train Epoch 24 ==========
Loss: 0.898	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5514       185
   macro avg     0.5080    0.4896    0.4690       185
weighted avg     0.5542    0.5514    0.5278       185

micro f-score: 0.5513513513513514

========== Train Epoch 25 ==========
Loss: 0.857	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5351       185
   macro avg     0.4744    0.4682    0.4501       185
weighted avg     0.5215    0.5351    0.5107       185

micro f-score: 0.5351351351351351

========== Train Epoch 26 ==========
Loss: 0.819	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.5405       185
   macro avg     0.4933    0.4886    0.4634       185
weighted avg     0.5356    0.5405    0.5182       185

micro f-score: 0.5405405405405406

========== Train Epoch 27 ==========
Loss: 0.793	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5730       185
   macro avg     0.5234    0.5126    0.4881       185
weighted avg     0.5647    0.5730    0.5453       185

micro f-score: 0.572972972972973

========== Train Epoch 28 ==========
Loss: 0.750	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.5514       185
   macro avg     0.5028    0.4990    0.4720       185
weighted avg     0.5457    0.5514    0.5272       185

micro f-score: 0.5513513513513514

========== Train Epoch 29 ==========
Loss: 0.726	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4634    0.6129    0.5278        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5568       185
   macro avg     0.4849    0.4991    0.4798       185
weighted avg     0.5418    0.5568    0.5392       185

micro f-score: 0.5567567567567567

========== Train Epoch 30 ==========
Loss: 0.691	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.5686    0.7436    0.6444        39

    accuracy                         0.5730       185
   macro avg     0.5056    0.5164    0.4997       185
weighted avg     0.5446    0.5730    0.5497       185

micro f-score: 0.572972972972973

========== Train Epoch 31 ==========
Loss: 0.652	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.5838       185
   macro avg     0.5557    0.5323    0.5151       185
weighted avg     0.5868    0.5838    0.5620       185

micro f-score: 0.5837837837837838

========== Train Epoch 32 ==========
Loss: 0.642	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.5283    0.7179    0.6087        39

    accuracy                         0.5676       185
   macro avg     0.5166    0.5127    0.4878       185
weighted avg     0.5515    0.5676    0.5401       185

micro f-score: 0.5675675675675675

========== Train Epoch 33 ==========
Loss: 0.610	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.5000    0.7692    0.6061        39

    accuracy                         0.5730       185
   macro avg     0.5223    0.5207    0.5049       185
weighted avg     0.5654    0.5730    0.5546       185

micro f-score: 0.572972972972973

========== Train Epoch 34 ==========
Loss: 0.569	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7000    0.7778    0.7368        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.5838       185
   macro avg     0.5310    0.5379    0.5251       185
weighted avg     0.5604    0.5838    0.5642       185

micro f-score: 0.5837837837837838

========== Train Epoch 35 ==========
Loss: 0.546	Accuracy: 57.30%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.5730       185
   macro avg     0.5284    0.5251    0.5235       185
weighted avg     0.5661    0.5730    0.5662       185

micro f-score: 0.572972972972973

========== Train Epoch 36 ==========
Loss: 0.533	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.5625    0.6923    0.6207        39

    accuracy                         0.5784       185
   macro avg     0.5155    0.5284    0.5187       185
weighted avg     0.5628    0.5784    0.5676       185

micro f-score: 0.5783783783783784

========== Train Epoch 37 ==========
Loss: 0.505	Accuracy: 57.84%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6667    0.8000    0.7273        45
         zxx     0.5952    0.6410    0.6173        39

    accuracy                         0.5784       185
   macro avg     0.5261    0.5414    0.5243       185
weighted avg     0.5604    0.5784    0.5621       185

micro f-score: 0.5783783783783784

========== Train Epoch 38 ==========
Loss: 0.470	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5892       185
   macro avg     0.5472    0.5521    0.5471       185
weighted avg     0.5818    0.5892    0.5825       185

micro f-score: 0.5891891891891892

========== Train Epoch 39 ==========
Loss: 0.441	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.7143    0.8333    0.7692        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.5088    0.7436    0.6042        39

    accuracy                         0.6000       185
   macro avg     0.5848    0.5711    0.5681       185
weighted avg     0.6078    0.6000    0.5933       185

micro f-score: 0.6

========== Train Epoch 40 ==========
Loss: 0.423	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2000    0.1579    0.1765        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5892       185
   macro avg     0.5664    0.5351    0.5455       185
weighted avg     0.5861    0.5892    0.5828       185

micro f-score: 0.5891891891891892

========== Train Epoch 41 ==========
Loss: 0.382	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.5892       185
   macro avg     0.5432    0.5608    0.5426       185
weighted avg     0.5853    0.5892    0.5801       185

micro f-score: 0.5891891891891892

========== Train Epoch 42 ==========
Loss: 0.365	Accuracy: 58.38%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.5957    0.7179    0.6512        39

    accuracy                         0.5838       185
   macro avg     0.5673    0.5533    0.5559       185
weighted avg     0.5902    0.5838    0.5829       185

micro f-score: 0.5837837837837838

========== Train Epoch 43 ==========
Loss: 0.348	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4865    0.5806    0.5294        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.1579    0.1579    0.1579        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6000    0.6923    0.6429        39

    accuracy                         0.5730       185
   macro avg     0.5554    0.5367    0.5424       185
weighted avg     0.5821    0.5730    0.5738       185

micro f-score: 0.572972972972973

========== Train Epoch 44 ==========
Loss: 0.325	Accuracy: 54.05%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.2222    0.2105    0.2162        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.5294    0.6923    0.6000        39

    accuracy                         0.5405       185
   macro avg     0.5461    0.5128    0.5174       185
weighted avg     0.5776    0.5405    0.5478       185

micro f-score: 0.5405405405405406

========== Train Epoch 45 ==========
Loss: 0.310	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.1875    0.1579    0.1714        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.5676       185
   macro avg     0.5253    0.5389    0.5266       185
weighted avg     0.5728    0.5676    0.5661       185

micro f-score: 0.5675675675675675

========== Train Epoch 46 ==========
Loss: 0.300	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5283    0.7179    0.6087        39

    accuracy                         0.5676       185
   macro avg     0.5357    0.5399    0.5296       185
weighted avg     0.5729    0.5676    0.5625       185

micro f-score: 0.5675675675675675

========== Train Epoch 47 ==========
Loss: 0.276	Accuracy: 56.22%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.2692    0.3684    0.3111        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.6667    0.6667    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5458    0.5368    0.5299       185
weighted avg     0.5838    0.5622    0.5636       185

micro f-score: 0.5621621621621622

========== Train Epoch 48 ==========
Loss: 0.259	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.7500    0.7500    0.7500        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5000    0.7436    0.5979        39

    accuracy                         0.5730       185
   macro avg     0.5707    0.5417    0.5429       185
weighted avg     0.5908    0.5730    0.5687       185

micro f-score: 0.572972972972973

========== Train Epoch 49 ==========
Loss: 0.243	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.2000    0.2105    0.2051        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5952    0.6410    0.6173        39

    accuracy                         0.5459       185
   macro avg     0.5366    0.5214    0.5221       185
weighted avg     0.5626    0.5459    0.5484       185

micro f-score: 0.5459459459459459

========== Train Epoch 50 ==========
Loss: 0.221	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.6190    0.6667    0.6420        39

    accuracy                         0.5838       185
   macro avg     0.5746    0.5590    0.5580       185
weighted avg     0.5894    0.5838    0.5794       185

micro f-score: 0.5837837837837838

========== Train Epoch 51 ==========
Loss: 0.221	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.5676       185
   macro avg     0.5395    0.5403    0.5307       185
weighted avg     0.5831    0.5676    0.5672       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 0.201	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.3235    0.6471    0.4314        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.5784       185
   macro avg     0.5916    0.5551    0.5564       185
weighted avg     0.6182    0.5784    0.5856       185

micro f-score: 0.5783783783783784

========== Train Epoch 53 ==========
Loss: 0.189	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.7857    0.5000    0.6111        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.2727    0.4737    0.3462        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6000    0.6923    0.6429        39

    accuracy                         0.5622       185
   macro avg     0.5617    0.5339    0.5361       185
weighted avg     0.6027    0.5622    0.5718       185

micro f-score: 0.5621621621621622

========== Train Epoch 54 ==========
Loss: 0.169	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.2800    0.3684    0.3182        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6154    0.6154    0.6154        39

    accuracy                         0.5514       185
   macro avg     0.5523    0.5361    0.5336       185
weighted avg     0.5845    0.5514    0.5595       185

micro f-score: 0.5513513513513514

========== Train Epoch 55 ==========
Loss: 0.162	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.3214    0.4737    0.3830        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.5622       185
   macro avg     0.5865    0.5428    0.5406       185
weighted avg     0.6090    0.5622    0.5617       185

micro f-score: 0.5621621621621622

========== Train Epoch 56 ==========
Loss: 0.149	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6136    0.6923    0.6506        39

    accuracy                         0.5622       185
   macro avg     0.5455    0.5482    0.5332       185
weighted avg     0.5908    0.5622    0.5658       185

micro f-score: 0.5621621621621622

========== Train Epoch 57 ==========
Loss: 0.148	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6341    0.6667    0.6500        39

    accuracy                         0.5676       185
   macro avg     0.5331    0.5381    0.5304       185
weighted avg     0.5798    0.5676    0.5699       185

micro f-score: 0.5675675675675675

========== Train Epoch 58 ==========
Loss: 0.136	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.5345    0.7949    0.6392        39

    accuracy                         0.5730       185
   macro avg     0.5616    0.5403    0.5358       185
weighted avg     0.6016    0.5730    0.5718       185

micro f-score: 0.572972972972973

========== Train Epoch 59 ==========
Loss: 0.141	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6364    0.4516    0.5283        31
         cwx     0.9091    0.4545    0.6061        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.8182    0.7500    0.7826        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5838       185
   macro avg     0.6110    0.5539    0.5630       185
weighted avg     0.6263    0.5838    0.5852       185

micro f-score: 0.5837837837837838

========== Train Epoch 60 ==========
Loss: 0.122	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5784       185
   macro avg     0.5555    0.5483    0.5342       185
weighted avg     0.5970    0.5784    0.5749       185

micro f-score: 0.5783783783783784

========== Train Epoch 61 ==========
Loss: 0.132	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3478    0.4211    0.3810        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5784       185
   macro avg     0.6007    0.5533    0.5518       185
weighted avg     0.6353    0.5784    0.5776       185

micro f-score: 0.5783783783783784

========== Train Epoch 62 ==========
Loss: 0.116	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7368    0.4516    0.5600        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3333    0.3684    0.3500        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.6000       185
   macro avg     0.5959    0.5669    0.5647       185
weighted avg     0.6261    0.6000    0.5964       185

micro f-score: 0.6

========== Train Epoch 63 ==========
Loss: 0.108	Accuracy: 60.00%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.8000    0.5455    0.6486        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.3478    0.4211    0.3810        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.6000       185
   macro avg     0.5897    0.5793    0.5665       185
weighted avg     0.6356    0.6000    0.5987       185

micro f-score: 0.6

========== Train Epoch 64 ==========
Loss: 0.101	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.8000    0.3636    0.5000        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.5730       185
   macro avg     0.5596    0.5452    0.5322       185
weighted avg     0.6060    0.5730    0.5727       185

micro f-score: 0.572972972972973

Finished training!!!

Min Loss = 0.101 in epoch 63;
Max Accuracy = 60.00% in epoch 38;
Total Cost 48 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         2,284
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         8,564
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         33,412
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,269,983
Trainable params: 11,269,983
Non-trainable params: 0
Total mult-adds (G): 3.72
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 77.34
Params size (MB): 42.99
Estimated Total Size (MB): 121.51
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    cbam_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_resnet.py", line 357, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_resnet.py", line 339, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
