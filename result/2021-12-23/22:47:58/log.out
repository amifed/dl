dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max3
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.835	Accuracy: 25.41%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.2632    0.1111    0.1562        45
         zxx     0.2368    0.9231    0.3770        39

    accuracy                         0.2541       185
   macro avg     0.2186    0.2046    0.1427       185
weighted avg     0.2492    0.2541    0.1598       185

micro f-score: 0.25405405405405407

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.604	Accuracy: 36.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1667    0.0833    0.1111        12
         qtx     0.5128    0.4444    0.4762        45
         zxx     0.3140    0.9744    0.4750        39

    accuracy                         0.3676       185
   macro avg     0.2832    0.2636    0.2230       185
weighted avg     0.3497    0.3676    0.2950       185

micro f-score: 0.3675675675675676

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.476	Accuracy: 40.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3721    0.5161    0.4324        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5758    0.4222    0.4872        45
         zxx     0.3750    0.8462    0.5197        39

    accuracy                         0.4000       185
   macro avg     0.2779    0.3047    0.2685       185
weighted avg     0.3434    0.4000    0.3426       185

micro f-score: 0.4000000000000001

========== Train Epoch 4 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.435	Accuracy: 39.46%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3030    0.3226    0.3125        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5385    0.4667    0.5000        45
         zxx     0.3929    0.8462    0.5366        39

    accuracy                         0.3946       185
   macro avg     0.3228    0.3086    0.2913       185
weighted avg     0.3628    0.3946    0.3519       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.409	Accuracy: 38.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5278    0.4222    0.4691        45
         zxx     0.3673    0.9231    0.5255        39

    accuracy                         0.3838       185
   macro avg     0.2910    0.2918    0.2630       185
weighted avg     0.3445    0.3838    0.3293       185

micro f-score: 0.3837837837837838

========== Train Epoch 6 ==========
Loss: 1.395	Accuracy: 42.16%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3810    0.5161    0.4384        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.4412    0.7692    0.5607        39

    accuracy                         0.4216       185
   macro avg     0.3365    0.3350    0.3187       185
weighted avg     0.3807    0.4216    0.3837       185

micro f-score: 0.42162162162162165

========== Train Epoch 7 ==========
Loss: 1.352	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.4429    0.7949    0.5688        39

    accuracy                         0.4378       185
   macro avg     0.3430    0.3589    0.3394       185
weighted avg     0.3946    0.4378    0.4017       185

micro f-score: 0.43783783783783786

========== Train Epoch 8 ==========
Loss: 1.325	Accuracy: 42.70%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3611    0.4194    0.3881        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5526    0.4667    0.5060        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.4270       185
   macro avg     0.3821    0.3401    0.3260       185
weighted avg     0.4180    0.4270    0.3888       185

micro f-score: 0.427027027027027

========== Train Epoch 9 ==========
Loss: 1.303	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3590    0.4516    0.4000        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.4848    0.8205    0.6095        39

    accuracy                         0.4595       185
   macro avg     0.4061    0.3706    0.3641       185
weighted avg     0.4492    0.4595    0.4318       185

micro f-score: 0.4594594594594595

========== Train Epoch 10 ==========
Loss: 1.275	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6136    0.6000    0.6067        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.4865       185
   macro avg     0.3872    0.4008    0.3852       185
weighted avg     0.4391    0.4865    0.4515       185

micro f-score: 0.4864864864864865

========== Train Epoch 11 ==========
Loss: 1.264	Accuracy: 45.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3784    0.4516    0.4118        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.4541       185
   macro avg     0.3431    0.3645    0.3442       185
weighted avg     0.4022    0.4541    0.4159       185

micro f-score: 0.4540540540540541

========== Train Epoch 12 ==========
Loss: 1.233	Accuracy: 46.49%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.3333    0.3636    0.3478        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.2308    0.2500    0.2400        12
         qtx     0.5946    0.4889    0.5366        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.4649       185
   macro avg     0.4010    0.3896    0.3737       185
weighted avg     0.4513    0.4649    0.4383       185

micro f-score: 0.4648648648648649

========== Train Epoch 13 ==========
Loss: 1.212	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4919       185
   macro avg     0.4718    0.4162    0.4073       185
weighted avg     0.5032    0.4919    0.4667       185

micro f-score: 0.4918918918918919

========== Train Epoch 14 ==========
Loss: 1.189	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.3333    0.4091    0.3673        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.4919       185
   macro avg     0.4423    0.4161    0.3988       185
weighted avg     0.4896    0.4919    0.4666       185

micro f-score: 0.4918918918918919

========== Train Epoch 15 ==========
Loss: 1.150	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.4811       185
   macro avg     0.4620    0.3992    0.3921       185
weighted avg     0.4931    0.4811    0.4545       185

micro f-score: 0.4810810810810811

========== Train Epoch 16 ==========
Loss: 1.132	Accuracy: 49.73%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4359    0.5484    0.4857        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.4973       185
   macro avg     0.4603    0.4337    0.4153       185
weighted avg     0.4962    0.4973    0.4712       185

micro f-score: 0.4972972972972973

========== Train Epoch 17 ==========
Loss: 1.086	Accuracy: 49.19%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.4919       185
   macro avg     0.4529    0.4194    0.4042       185
weighted avg     0.4913    0.4919    0.4646       185

micro f-score: 0.4918918918918919

========== Train Epoch 18 ==========
Loss: 1.054	Accuracy: 48.65%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.5455    0.7692    0.6383        39

    accuracy                         0.4865       185
   macro avg     0.4505    0.4240    0.4059       185
weighted avg     0.4880    0.4865    0.4624       185

micro f-score: 0.4864864864864865

========== Train Epoch 19 ==========
Loss: 1.038	Accuracy: 50.27%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5027       185
   macro avg     0.4904    0.4440    0.4320       185
weighted avg     0.5223    0.5027    0.4832       185

micro f-score: 0.5027027027027027

========== Train Epoch 20 ==========
Loss: 1.000	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5189       185
   macro avg     0.4971    0.4521    0.4386       185
weighted avg     0.5343    0.5189    0.4967       185

micro f-score: 0.518918918918919

========== Train Epoch 21 ==========
Loss: 0.973	Accuracy: 52.43%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.5243       185
   macro avg     0.5177    0.4742    0.4581       185
weighted avg     0.5476    0.5243    0.5047       185

micro f-score: 0.5243243243243243

========== Train Epoch 22 ==========
Loss: 0.937	Accuracy: 50.27%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5027       185
   macro avg     0.4847    0.4388    0.4249       185
weighted avg     0.5219    0.5027    0.4820       185

micro f-score: 0.5027027027027027

========== Train Epoch 23 ==========
Loss: 0.917	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5297       185
   macro avg     0.5155    0.4701    0.4549       185
weighted avg     0.5548    0.5297    0.5105       185

micro f-score: 0.5297297297297298

========== Train Epoch 24 ==========
Loss: 0.859	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4211    0.5161    0.4638        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.5243       185
   macro avg     0.5069    0.4840    0.4540       185
weighted avg     0.5462    0.5243    0.5057       185

micro f-score: 0.5243243243243243

========== Train Epoch 25 ==========
Loss: 0.843	Accuracy: 53.51%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5556    0.7692    0.6452        39

    accuracy                         0.5351       185
   macro avg     0.5295    0.4839    0.4726       185
weighted avg     0.5633    0.5351    0.5227       185

micro f-score: 0.5351351351351351

========== Train Epoch 26 ==========
Loss: 0.801	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4000    0.3871    0.3934        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5556    0.7692    0.6452        39

    accuracy                         0.5189       185
   macro avg     0.4957    0.4652    0.4426       185
weighted avg     0.5351    0.5189    0.4979       185

micro f-score: 0.518918918918919

========== Train Epoch 27 ==========
Loss: 0.783	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5459       185
   macro avg     0.5381    0.4979    0.4833       185
weighted avg     0.5812    0.5459    0.5369       185

micro f-score: 0.5459459459459459

========== Train Epoch 28 ==========
Loss: 0.740	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5351       185
   macro avg     0.5340    0.4834    0.4714       185
weighted avg     0.5646    0.5351    0.5190       185

micro f-score: 0.5351351351351351

========== Train Epoch 29 ==========
Loss: 0.709	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5405       185
   macro avg     0.5342    0.4914    0.4787       185
weighted avg     0.5660    0.5405    0.5261       185

micro f-score: 0.5405405405405406

========== Train Epoch 30 ==========
Loss: 0.686	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5660    0.7692    0.6522        39

    accuracy                         0.5297       185
   macro avg     0.5319    0.4893    0.4747       185
weighted avg     0.5718    0.5297    0.5208       185

micro f-score: 0.5297297297297298

========== Train Epoch 31 ==========
Loss: 0.649	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5459       185
   macro avg     0.4987    0.4912    0.4745       185
weighted avg     0.5487    0.5459    0.5306       185

micro f-score: 0.5459459459459459

========== Train Epoch 32 ==========
Loss: 0.624	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5568       185
   macro avg     0.5502    0.5110    0.4959       185
weighted avg     0.5866    0.5568    0.5444       185

micro f-score: 0.5567567567567567

========== Train Epoch 33 ==========
Loss: 0.581	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5459       185
   macro avg     0.5219    0.4999    0.4816       185
weighted avg     0.5684    0.5459    0.5353       185

micro f-score: 0.5459459459459459

========== Train Epoch 34 ==========
Loss: 0.555	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5351       185
   macro avg     0.4703    0.4747    0.4579       185
weighted avg     0.5248    0.5351    0.5151       185

micro f-score: 0.5351351351351351

========== Train Epoch 35 ==========
Loss: 0.534	Accuracy: 56.22%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.5957    0.7179    0.6512        39

    accuracy                         0.5622       185
   macro avg     0.5150    0.5189    0.5041       185
weighted avg     0.5612    0.5622    0.5520       185

micro f-score: 0.5621621621621622

========== Train Epoch 36 ==========
Loss: 0.514	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4103    0.5161    0.4571        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5459       185
   macro avg     0.5100    0.4955    0.4846       185
weighted avg     0.5568    0.5459    0.5358       185

micro f-score: 0.5459459459459459

========== Train Epoch 37 ==========
Loss: 0.474	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3333    0.5833    0.4242        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6279    0.6923    0.6585        39

    accuracy                         0.5189       185
   macro avg     0.4631    0.4824    0.4627       185
weighted avg     0.5274    0.5189    0.5162       185

micro f-score: 0.518918918918919

========== Train Epoch 38 ==========
Loss: 0.445	Accuracy: 52.97%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5297       185
   macro avg     0.4735    0.4829    0.4716       185
weighted avg     0.5255    0.5297    0.5213       185

micro f-score: 0.5297297297297298

========== Train Epoch 39 ==========
Loss: 0.428	Accuracy: 54.59%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.3462    0.7500    0.4737        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5769    0.7692    0.6593        39

    accuracy                         0.5459       185
   macro avg     0.5029    0.5191    0.4862       185
weighted avg     0.5639    0.5459    0.5345       185

micro f-score: 0.5459459459459459

========== Train Epoch 40 ==========
Loss: 0.397	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5833    0.7179    0.6437        39

    accuracy                         0.5189       185
   macro avg     0.4767    0.4704    0.4684       185
weighted avg     0.5213    0.5189    0.5149       185

micro f-score: 0.518918918918919

========== Train Epoch 41 ==========
Loss: 0.388	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.5297       185
   macro avg     0.4809    0.4926    0.4787       185
weighted avg     0.5382    0.5297    0.5281       185

micro f-score: 0.5297297297297298

========== Train Epoch 42 ==========
Loss: 0.340	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5459       185
   macro avg     0.4943    0.5016    0.4932       185
weighted avg     0.5458    0.5459    0.5409       185

micro f-score: 0.5459459459459459

========== Train Epoch 43 ==========
Loss: 0.343	Accuracy: 54.05%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3684    0.5833    0.4516        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5957    0.7179    0.6512        39

    accuracy                         0.5405       185
   macro avg     0.4852    0.5018    0.4862       185
weighted avg     0.5461    0.5405    0.5373       185

micro f-score: 0.5405405405405406

========== Train Epoch 44 ==========
Loss: 0.336	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6136    0.6923    0.6506        39

    accuracy                         0.5459       185
   macro avg     0.4964    0.5218    0.4978       185
weighted avg     0.5588    0.5459    0.5441       185

micro f-score: 0.5459459459459459

========== Train Epoch 45 ==========
Loss: 0.297	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5676       185
   macro avg     0.5128    0.5262    0.5057       185
weighted avg     0.5792    0.5676    0.5613       185

micro f-score: 0.5675675675675675

========== Train Epoch 46 ==========
Loss: 0.272	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5556    0.7692    0.6452        39

    accuracy                         0.5189       185
   macro avg     0.4896    0.4932    0.4605       185
weighted avg     0.5507    0.5189    0.5030       185

micro f-score: 0.518918918918919

========== Train Epoch 47 ==========
Loss: 0.248	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.2857    0.5882    0.3846        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5459       185
   macro avg     0.5337    0.5044    0.4916       185
weighted avg     0.5827    0.5459    0.5373       185

micro f-score: 0.5459459459459459

========== Train Epoch 48 ==========
Loss: 0.246	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3871    0.3871    0.3871        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5459       185
   macro avg     0.5253    0.5051    0.4968       185
weighted avg     0.5673    0.5459    0.5410       185

micro f-score: 0.5459459459459459

========== Train Epoch 49 ==========
Loss: 0.215	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5459       185
   macro avg     0.5308    0.5143    0.5022       185
weighted avg     0.5741    0.5459    0.5451       185

micro f-score: 0.5459459459459459

========== Train Epoch 50 ==========
Loss: 0.215	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.2727    0.5294    0.3600        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5676       185
   macro avg     0.5613    0.5172    0.5213       185
weighted avg     0.5974    0.5676    0.5676       185

micro f-score: 0.5675675675675675

========== Train Epoch 51 ==========
Loss: 0.198	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5676       185
   macro avg     0.5186    0.5264    0.5141       185
weighted avg     0.5767    0.5676    0.5652       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 0.174	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.2692    0.4118    0.3256        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6042    0.7436    0.6667        39

    accuracy                         0.5351       185
   macro avg     0.4910    0.4933    0.4849       185
weighted avg     0.5537    0.5351    0.5363       185

micro f-score: 0.5351351351351351

========== Train Epoch 53 ==========
Loss: 0.167	Accuracy: 55.14%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.7368    0.6222    0.6747        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5514       185
   macro avg     0.5334    0.5016    0.5050       185
weighted avg     0.5667    0.5514    0.5472       185

micro f-score: 0.5513513513513514

========== Train Epoch 54 ==========
Loss: 0.163	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.6304    0.7436    0.6824        39

    accuracy                         0.5622       185
   macro avg     0.5199    0.5216    0.5153       185
weighted avg     0.5750    0.5622    0.5635       185

micro f-score: 0.5621621621621622

========== Train Epoch 55 ==========
Loss: 0.164	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2593    0.4118    0.3182        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5568       185
   macro avg     0.5012    0.4950    0.4836       185
weighted avg     0.5603    0.5568    0.5467       185

micro f-score: 0.5567567567567567

========== Train Epoch 56 ==========
Loss: 0.146	Accuracy: 55.14%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.3529    0.5000    0.4138        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5514       185
   macro avg     0.5039    0.4991    0.4897       185
weighted avg     0.5639    0.5514    0.5465       185

micro f-score: 0.5513513513513514

========== Train Epoch 57 ==========
Loss: 0.132	Accuracy: 54.59%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5459       185
   macro avg     0.5093    0.5011    0.4917       185
weighted avg     0.5697    0.5459    0.5440       185

micro f-score: 0.5459459459459459

========== Train Epoch 58 ==========
Loss: 0.128	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5622       185
   macro avg     0.5493    0.5116    0.5151       185
weighted avg     0.5890    0.5622    0.5613       185

micro f-score: 0.5621621621621622

========== Train Epoch 59 ==========
Loss: 0.129	Accuracy: 56.22%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5622       185
   macro avg     0.5399    0.5236    0.5150       185
weighted avg     0.5864    0.5622    0.5575       185

micro f-score: 0.5621621621621622

========== Train Epoch 60 ==========
Loss: 0.110	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.2581    0.4706    0.3333        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5459       185
   macro avg     0.5406    0.5065    0.4961       185
weighted avg     0.5856    0.5459    0.5399       185

micro f-score: 0.5459459459459459

========== Train Epoch 61 ==========
Loss: 0.107	Accuracy: 55.14%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5514       185
   macro avg     0.5102    0.5095    0.5027       185
weighted avg     0.5697    0.5514    0.5534       185

micro f-score: 0.5513513513513514

========== Train Epoch 62 ==========
Loss: 0.099	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5514       185
   macro avg     0.4954    0.5055    0.4886       185
weighted avg     0.5473    0.5514    0.5398       185

micro f-score: 0.5513513513513514

========== Train Epoch 63 ==========
Loss: 0.110	Accuracy: 56.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5622       185
   macro avg     0.5177    0.5058    0.5028       185
weighted avg     0.5616    0.5622    0.5542       185

micro f-score: 0.5621621621621622

========== Train Epoch 64 ==========
Loss: 0.088	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.5514       185
   macro avg     0.5074    0.5218    0.5013       185
weighted avg     0.5703    0.5514    0.5509       185

micro f-score: 0.5513513513513514

Finished training!!!

Min Loss = 0.088 in epoch 63;
Max Accuracy = 56.76% in epoch 44;
Total Cost 48 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         2,284
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         8,564
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         33,412
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,269,983
Trainable params: 11,269,983
Non-trainable params: 0
Total mult-adds (G): 3.72
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 77.34
Params size (MB): 42.99
Estimated Total Size (MB): 121.51
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    cbam_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_resnet.py", line 357, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_resnet.py", line 339, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
