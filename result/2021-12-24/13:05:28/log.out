dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max1
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.795	Accuracy: 31.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.3750    0.1364    0.2000        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.3418    0.6000    0.4355        45
         zxx     0.2985    0.5128    0.3774        39

    accuracy                         0.3189       185
   macro avg     0.3105    0.2470    0.2391       185
weighted avg     0.3192    0.3189    0.2777       185

micro f-score: 0.31891891891891894

========== Train Epoch 2 ==========
Loss: 1.562	Accuracy: 38.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5357    0.3333    0.4110        45
         zxx     0.3364    0.9231    0.4932        39

    accuracy                         0.3838       185
   macro avg     0.3875    0.3208    0.3067       185
weighted avg     0.4097    0.3838    0.3425       185

micro f-score: 0.3837837837837838

========== Train Epoch 3 ==========
Loss: 1.361	Accuracy: 46.49%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3714    0.4194    0.3939        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6562    0.4667    0.5455        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.4649       185
   macro avg     0.4403    0.4184    0.4032       185
weighted avg     0.4694    0.4649    0.4399       185

micro f-score: 0.4648648648648649

========== Train Epoch 4 ==========
Loss: 1.308	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.4177    0.8462    0.5593        39

    accuracy                         0.4432       185
   macro avg     0.4520    0.3641    0.3607       185
weighted avg     0.4624    0.4432    0.4115       185

micro f-score: 0.44324324324324327

========== Train Epoch 5 ==========
Loss: 1.277	Accuracy: 44.86%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3810    0.2581    0.3077        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5319    0.5556    0.5435        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.4486       185
   macro avg     0.3883    0.3771    0.3685       185
weighted avg     0.4221    0.4486    0.4199       185

micro f-score: 0.4486486486486486

========== Train Epoch 6 ==========
Loss: 1.217	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.4757       185
   macro avg     0.4332    0.4116    0.4064       185
weighted avg     0.4602    0.4757    0.4511       185

micro f-score: 0.4756756756756757

========== Train Epoch 7 ==========
Loss: 1.223	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4595    0.8718    0.6018        39

    accuracy                         0.4595       185
   macro avg     0.4237    0.4002    0.3902       185
weighted avg     0.4506    0.4595    0.4306       185

micro f-score: 0.4594594594594595

========== Train Epoch 8 ==========
Loss: 1.163	Accuracy: 48.65%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6000    0.4667    0.5250        45
         zxx     0.4730    0.8974    0.6195        39

    accuracy                         0.4865       185
   macro avg     0.4830    0.4222    0.4106       185
weighted avg     0.5047    0.4865    0.4572       185

micro f-score: 0.4864864864864865

========== Train Epoch 9 ==========
Loss: 1.111	Accuracy: 48.65%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5333    0.5333    0.5333        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.4865       185
   macro avg     0.4548    0.4105    0.3957       185
weighted avg     0.4793    0.4865    0.4510       185

micro f-score: 0.4864864864864865

========== Train Epoch 10 ==========
Loss: 1.096	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5081       185
   macro avg     0.4479    0.4522    0.4450       185
weighted avg     0.4894    0.5081    0.4934       185

micro f-score: 0.5081081081081081

========== Train Epoch 11 ==========
Loss: 1.057	Accuracy: 46.49%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6562    0.4667    0.5455        45
         zxx     0.3933    0.8974    0.5469        39

    accuracy                         0.4649       185
   macro avg     0.4768    0.4175    0.4143       185
weighted avg     0.4903    0.4649    0.4402       185

micro f-score: 0.4648648648648649

========== Train Epoch 12 ==========
Loss: 1.012	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3929    0.3548    0.3729        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.4973       185
   macro avg     0.4308    0.4552    0.4382       185
weighted avg     0.4811    0.4973    0.4847       185

micro f-score: 0.4972972972972973

========== Train Epoch 13 ==========
Loss: 0.963	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5135       185
   macro avg     0.5017    0.4613    0.4508       185
weighted avg     0.5213    0.5135    0.4892       185

micro f-score: 0.5135135135135135

========== Train Epoch 14 ==========
Loss: 0.937	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5135       185
   macro avg     0.4590    0.4597    0.4525       185
weighted avg     0.5027    0.5135    0.5000       185

micro f-score: 0.5135135135135135

========== Train Epoch 15 ==========
Loss: 0.890	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.3667    0.5000    0.4231        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.6444    0.6444    0.6444        45
         zxx     0.5345    0.7949    0.6392        39

    accuracy                         0.5243       185
   macro avg     0.4993    0.4535    0.4503       185
weighted avg     0.5288    0.5243    0.5049       185

micro f-score: 0.5243243243243243

========== Train Epoch 16 ==========
Loss: 0.854	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5135       185
   macro avg     0.4661    0.4643    0.4550       185
weighted avg     0.4928    0.5135    0.4925       185

micro f-score: 0.5135135135135135

========== Train Epoch 17 ==========
Loss: 0.802	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5297       185
   macro avg     0.4821    0.4765    0.4713       185
weighted avg     0.5267    0.5297    0.5222       185

micro f-score: 0.5297297297297298

========== Train Epoch 18 ==========
Loss: 0.770	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5459       185
   macro avg     0.4933    0.5141    0.4929       185
weighted avg     0.5408    0.5459    0.5332       185

micro f-score: 0.5459459459459459

========== Train Epoch 19 ==========
Loss: 0.729	Accuracy: 54.05%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.2927    0.5455    0.3810        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.6400    0.7111    0.6737        45
         zxx     0.8235    0.7179    0.7671        39

    accuracy                         0.5405       185
   macro avg     0.5271    0.4753    0.4758       185
weighted avg     0.5726    0.5405    0.5372       185

micro f-score: 0.5405405405405406

========== Train Epoch 20 ==========
Loss: 0.683	Accuracy: 53.51%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.2500    0.2632    0.2564        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.5351       185
   macro avg     0.4774    0.4856    0.4793       185
weighted avg     0.5302    0.5351    0.5312       185

micro f-score: 0.5351351351351351

========== Train Epoch 21 ==========
Loss: 0.652	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.5568       185
   macro avg     0.5238    0.5024    0.4983       185
weighted avg     0.5671    0.5568    0.5507       185

micro f-score: 0.5567567567567567

========== Train Epoch 22 ==========
Loss: 0.618	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5784       185
   macro avg     0.5271    0.5270    0.5232       185
weighted avg     0.5710    0.5784    0.5701       185

micro f-score: 0.5783783783783784

========== Train Epoch 23 ==========
Loss: 0.558	Accuracy: 54.59%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.5459       185
   macro avg     0.5230    0.4978    0.5005       185
weighted avg     0.5530    0.5459    0.5368       185

micro f-score: 0.5459459459459459

========== Train Epoch 24 ==========
Loss: 0.518	Accuracy: 55.14%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5514       185
   macro avg     0.5156    0.4886    0.4862       185
weighted avg     0.5534    0.5514    0.5332       185

micro f-score: 0.5513513513513514

========== Train Epoch 25 ==========
Loss: 0.509	Accuracy: 56.22%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4048    0.5484    0.4658        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.5622       185
   macro avg     0.5435    0.5194    0.5246       185
weighted avg     0.5826    0.5622    0.5648       185

micro f-score: 0.5621621621621622

========== Train Epoch 26 ==========
Loss: 0.461	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5676       185
   macro avg     0.5238    0.5180    0.5130       185
weighted avg     0.5662    0.5676    0.5581       185

micro f-score: 0.5675675675675675

========== Train Epoch 27 ==========
Loss: 0.420	Accuracy: 56.22%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5622       185
   macro avg     0.5505    0.5090    0.5161       185
weighted avg     0.5859    0.5622    0.5564       185

micro f-score: 0.5621621621621622

========== Train Epoch 28 ==========
Loss: 0.381	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5568       185
   macro avg     0.5126    0.5000    0.4986       185
weighted avg     0.5411    0.5568    0.5410       185

micro f-score: 0.5567567567567567

========== Train Epoch 29 ==========
Loss: 0.366	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4524    0.6129    0.5205        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6000       185
   macro avg     0.5671    0.5591    0.5553       185
weighted avg     0.5992    0.6000    0.5924       185

micro f-score: 0.6

========== Train Epoch 30 ==========
Loss: 0.333	Accuracy: 61.62%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.6774    0.5753        31
         cwx     0.5000    0.6818    0.5769        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8710    0.6000    0.7105        45
         zxx     0.8000    0.8205    0.8101        39

    accuracy                         0.6162       185
   macro avg     0.5800    0.5769    0.5684       185
weighted avg     0.6401    0.6162    0.6164       185

micro f-score: 0.6162162162162163

========== Train Epoch 31 ==========
Loss: 0.325	Accuracy: 56.22%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.5622       185
   macro avg     0.5303    0.5264    0.5206       185
weighted avg     0.5842    0.5622    0.5626       185

micro f-score: 0.5621621621621622

========== Train Epoch 32 ==========
Loss: 0.284	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.7500    0.5455    0.6316        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5838       185
   macro avg     0.5526    0.5553    0.5334       185
weighted avg     0.6064    0.5838    0.5765       185

micro f-score: 0.5837837837837838

========== Train Epoch 33 ==========
Loss: 0.278	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5784       185
   macro avg     0.5486    0.5579    0.5332       185
weighted avg     0.6095    0.5784    0.5728       185

micro f-score: 0.5783783783783784

========== Train Epoch 34 ==========
Loss: 0.237	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4286    0.4839    0.4545        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5838       185
   macro avg     0.5384    0.5398    0.5352       185
weighted avg     0.5856    0.5838    0.5821       185

micro f-score: 0.5837837837837838

========== Train Epoch 35 ==========
Loss: 0.231	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3684    0.6774    0.4773        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.5514       185
   macro avg     0.5480    0.5112    0.5116       185
weighted avg     0.5804    0.5514    0.5485       185

micro f-score: 0.5513513513513514

========== Train Epoch 36 ==========
Loss: 0.226	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.5946       185
   macro avg     0.5595    0.5721    0.5480       185
weighted avg     0.6199    0.5946    0.5956       185

micro f-score: 0.5945945945945946

========== Train Epoch 37 ==========
Loss: 0.195	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6054       185
   macro avg     0.5673    0.5756    0.5644       185
weighted avg     0.6114    0.6054    0.6022       185

micro f-score: 0.6054054054054054

========== Train Epoch 38 ==========
Loss: 0.184	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5622       185
   macro avg     0.5563    0.5446    0.5280       185
weighted avg     0.5892    0.5622    0.5530       185

micro f-score: 0.5621621621621622

========== Train Epoch 39 ==========
Loss: 0.198	Accuracy: 55.68%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6250    0.3226    0.4255        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6957    0.7111    0.7033        45
         zxx     0.4789    0.8718    0.6182        39

    accuracy                         0.5568       185
   macro avg     0.5546    0.5074    0.5032       185
weighted avg     0.5757    0.5568    0.5367       185

micro f-score: 0.5567567567567567

========== Train Epoch 40 ==========
Loss: 0.159	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6000       185
   macro avg     0.5690    0.5705    0.5549       185
weighted avg     0.6196    0.6000    0.5953       185

micro f-score: 0.6

========== Train Epoch 41 ==========
Loss: 0.171	Accuracy: 61.08%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6600    0.8462    0.7416        39

    accuracy                         0.6108       185
   macro avg     0.5716    0.5673    0.5560       185
weighted avg     0.6140    0.6108    0.6024       185

micro f-score: 0.6108108108108108

========== Train Epoch 42 ==========
Loss: 0.144	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6000       185
   macro avg     0.5635    0.5590    0.5483       185
weighted avg     0.6076    0.6000    0.5943       185

micro f-score: 0.6

========== Train Epoch 43 ==========
Loss: 0.148	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6162       185
   macro avg     0.5639    0.5696    0.5597       185
weighted avg     0.6137    0.6162    0.6106       185

micro f-score: 0.6162162162162163

========== Train Epoch 44 ==========
Loss: 0.142	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6000       185
   macro avg     0.5603    0.5505    0.5400       185
weighted avg     0.5981    0.6000    0.5864       185

micro f-score: 0.6

========== Train Epoch 45 ==========
Loss: 0.127	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6000       185
   macro avg     0.5620    0.5658    0.5529       185
weighted avg     0.6105    0.6000    0.5971       185

micro f-score: 0.6

========== Train Epoch 46 ==========
Loss: 0.125	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.6939    0.8718    0.7727        39

    accuracy                         0.5784       185
   macro avg     0.5346    0.5500    0.5258       185
weighted avg     0.5904    0.5784    0.5709       185

micro f-score: 0.5783783783783784

========== Train Epoch 47 ==========
Loss: 0.117	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6000       185
   macro avg     0.5747    0.5821    0.5648       185
weighted avg     0.6231    0.6000    0.5997       185

micro f-score: 0.6

========== Train Epoch 48 ==========
Loss: 0.111	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5838       185
   macro avg     0.5830    0.5384    0.5394       185
weighted avg     0.6017    0.5838    0.5706       185

micro f-score: 0.5837837837837838

========== Train Epoch 49 ==========
Loss: 0.124	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.4643    0.5909    0.5200        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8519    0.5111    0.6389        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.5676       185
   macro avg     0.5278    0.5472    0.5213       185
weighted avg     0.5987    0.5676    0.5669       185

micro f-score: 0.5675675675675675

========== Train Epoch 50 ==========
Loss: 0.098	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4250    0.5484    0.4789        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.5892       185
   macro avg     0.5638    0.5661    0.5530       185
weighted avg     0.6081    0.5892    0.5890       185

micro f-score: 0.5891891891891892

========== Train Epoch 51 ==========
Loss: 0.099	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.5784       185
   macro avg     0.5502    0.5468    0.5348       185
weighted avg     0.5892    0.5784    0.5722       185

micro f-score: 0.5783783783783784

========== Train Epoch 52 ==========
Loss: 0.094	Accuracy: 58.38%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4737    0.4737    0.4737        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.5838       185
   macro avg     0.5542    0.5602    0.5426       185
weighted avg     0.6043    0.5838    0.5822       185

micro f-score: 0.5837837837837838

========== Train Epoch 53 ==========
Loss: 0.093	Accuracy: 58.92%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.4444    0.5161    0.4776        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.5892       185
   macro avg     0.5535    0.5522    0.5391       185
weighted avg     0.5988    0.5892    0.5841       185

micro f-score: 0.5891891891891892

========== Train Epoch 54 ==========
Loss: 0.086	Accuracy: 57.84%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.4211    0.4706    0.4444        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5784       185
   macro avg     0.5494    0.5511    0.5372       185
weighted avg     0.5917    0.5784    0.5744       185

micro f-score: 0.5783783783783784

========== Train Epoch 55 ==========
Loss: 0.085	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.8125    0.5778    0.6753        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5730       185
   macro avg     0.5433    0.5374    0.5249       185
weighted avg     0.5882    0.5730    0.5647       185

micro f-score: 0.572972972972973

========== Train Epoch 56 ==========
Loss: 0.082	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.5784       185
   macro avg     0.5466    0.5416    0.5281       185
weighted avg     0.5877    0.5784    0.5705       185

micro f-score: 0.5783783783783784

========== Train Epoch 57 ==========
Loss: 0.085	Accuracy: 54.59%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.9091    0.4444    0.5970        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5459       185
   macro avg     0.5574    0.5290    0.5210       185
weighted avg     0.6057    0.5459    0.5462       185

micro f-score: 0.5459459459459459

========== Train Epoch 58 ==========
Loss: 0.085	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6000       185
   macro avg     0.5655    0.5605    0.5522       185
weighted avg     0.6108    0.6000    0.5942       185

micro f-score: 0.6

========== Train Epoch 59 ==========
Loss: 0.074	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.6000       185
   macro avg     0.5849    0.5573    0.5475       185
weighted avg     0.6210    0.6000    0.5890       185

micro f-score: 0.6

========== Train Epoch 60 ==========
Loss: 0.079	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.5000    0.4706    0.4848        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6054       185
   macro avg     0.5733    0.5609    0.5487       185
weighted avg     0.6097    0.6054    0.5902       185

micro f-score: 0.6054054054054054

========== Train Epoch 61 ==========
Loss: 0.068	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6108       185
   macro avg     0.5703    0.5759    0.5647       185
weighted avg     0.6183    0.6108    0.6090       185

micro f-score: 0.6108108108108108

========== Train Epoch 62 ==========
Loss: 0.077	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6000       185
   macro avg     0.5512    0.5533    0.5398       185
weighted avg     0.5964    0.6000    0.5875       185

micro f-score: 0.6

========== Train Epoch 63 ==========
Loss: 0.071	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.5892       185
   macro avg     0.5396    0.5541    0.5402       185
weighted avg     0.6059    0.5892    0.5937       185

micro f-score: 0.5891891891891892

========== Train Epoch 64 ==========
Loss: 0.060	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5784       185
   macro avg     0.5350    0.5306    0.5199       185
weighted avg     0.5781    0.5784    0.5663       185

micro f-score: 0.5783783783783784

Finished training!!!

Min Loss = 0.060 in epoch 63;
Max Accuracy = 61.62% in epoch 29;
Total Cost 49 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
