dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18max3
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.818	Accuracy: 26.49%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2000    0.0968    0.1304        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3793    0.2444    0.2973        45
         zxx     0.2459    0.7692    0.3727        39

    accuracy                         0.2649       185
   macro avg     0.1877    0.1921    0.1596       185
weighted avg     0.2337    0.2649    0.2092       185

micro f-score: 0.2648648648648649

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.631	Accuracy: 38.38%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3333    0.2903    0.3103        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.3373    0.7179    0.4590        39

    accuracy                         0.3838       185
   macro avg     0.3794    0.3054    0.2957       185
weighted avg     0.3972    0.3838    0.3510       185

micro f-score: 0.3837837837837838

========== Train Epoch 3 ==========
Loss: 1.539	Accuracy: 40.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5385    0.2258    0.3182        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.3462    0.9231    0.5035        39

    accuracy                         0.4054       185
   macro avg     0.3465    0.3139    0.2921       185
weighted avg     0.4028    0.4054    0.3574       185

micro f-score: 0.40540540540540543

========== Train Epoch 4 ==========
Loss: 1.495	Accuracy: 39.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.3364    0.9231    0.4932        39

    accuracy                         0.3946       185
   macro avg     0.3467    0.2974    0.2741       185
weighted avg     0.4009    0.3946    0.3425       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.478	Accuracy: 40.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.3646    0.8974    0.5185        39

    accuracy                         0.4054       185
   macro avg     0.3190    0.3061    0.2842       185
weighted avg     0.3814    0.4054    0.3589       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.454	Accuracy: 43.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.4000    0.8718    0.5484        39

    accuracy                         0.4324       185
   macro avg     0.3473    0.3359    0.3140       185
weighted avg     0.3991    0.4324    0.3860       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 1.440	Accuracy: 40.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.3723    0.8974    0.5263        39

    accuracy                         0.4000       185
   macro avg     0.3141    0.3029    0.2813       185
weighted avg     0.3740    0.4000    0.3541       185

micro f-score: 0.4000000000000001

========== Train Epoch 8 ==========
Loss: 1.402	Accuracy: 41.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3871    0.3871    0.3871        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.4108       185
   macro avg     0.3101    0.3130    0.2909       185
weighted avg     0.3752    0.4108    0.3681       185

micro f-score: 0.4108108108108109

========== Train Epoch 9 ==========
Loss: 1.391	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.4267    0.8205    0.5614        39

    accuracy                         0.4432       185
   macro avg     0.3660    0.3459    0.3356       185
weighted avg     0.4210    0.4432    0.4105       185

micro f-score: 0.44324324324324327

========== Train Epoch 10 ==========
Loss: 1.378	Accuracy: 43.78%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5238    0.3548    0.4231        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4048    0.8718    0.5528        39

    accuracy                         0.4378       185
   macro avg     0.3939    0.3558    0.3509       185
weighted avg     0.4370    0.4378    0.4094       185

micro f-score: 0.43783783783783786

========== Train Epoch 11 ==========
Loss: 1.335	Accuracy: 44.32%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4048    0.8718    0.5528        39

    accuracy                         0.4432       185
   macro avg     0.4018    0.3575    0.3490       185
weighted avg     0.4424    0.4432    0.4105       185

micro f-score: 0.44324324324324327

========== Train Epoch 12 ==========
Loss: 1.333	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.1667    0.1176    0.1379        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.4125    0.8462    0.5546        39

    accuracy                         0.4432       185
   macro avg     0.3875    0.3575    0.3507       185
weighted avg     0.4381    0.4432    0.4158       185

micro f-score: 0.44324324324324327

========== Train Epoch 13 ==========
Loss: 1.314	Accuracy: 47.57%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4757       185
   macro avg     0.4001    0.3898    0.3803       185
weighted avg     0.4524    0.4757    0.4492       185

micro f-score: 0.4756756756756757

========== Train Epoch 14 ==========
Loss: 1.287	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4811       185
   macro avg     0.4281    0.4025    0.3887       185
weighted avg     0.4710    0.4811    0.4492       185

micro f-score: 0.4810810810810811

========== Train Epoch 15 ==========
Loss: 1.268	Accuracy: 45.41%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.4074    0.8462    0.5500        39

    accuracy                         0.4541       185
   macro avg     0.4038    0.3681    0.3623       185
weighted avg     0.4475    0.4541    0.4251       185

micro f-score: 0.4540540540540541

========== Train Epoch 16 ==========
Loss: 1.248	Accuracy: 51.35%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6279    0.6000    0.6136        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.5135       185
   macro avg     0.4730    0.4535    0.4483       185
weighted avg     0.5072    0.5135    0.4962       185

micro f-score: 0.5135135135135135

========== Train Epoch 17 ==========
Loss: 1.224	Accuracy: 45.95%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.3804    0.8974    0.5344        39

    accuracy                         0.4595       185
   macro avg     0.4892    0.3833    0.3810       185
weighted avg     0.5088    0.4595    0.4311       185

micro f-score: 0.4594594594594595

========== Train Epoch 18 ==========
Loss: 1.203	Accuracy: 50.27%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.5027       185
   macro avg     0.4488    0.4406    0.4298       185
weighted avg     0.4938    0.5027    0.4830       185

micro f-score: 0.5027027027027027

========== Train Epoch 19 ==========
Loss: 1.186	Accuracy: 51.89%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.4789    0.8718    0.6182        39

    accuracy                         0.5189       185
   macro avg     0.4855    0.4534    0.4477       185
weighted avg     0.5266    0.5189    0.4998       185

micro f-score: 0.518918918918919

========== Train Epoch 20 ==========
Loss: 1.164	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.7059    0.5333    0.6076        45
         zxx     0.4605    0.8974    0.6087        39

    accuracy                         0.5081       185
   macro avg     0.4745    0.4399    0.4287       185
weighted avg     0.5113    0.5081    0.4802       185

micro f-score: 0.5081081081081081

========== Train Epoch 21 ==========
Loss: 1.160	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6875    0.4889    0.5714        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5027       185
   macro avg     0.4594    0.4410    0.4243       185
weighted avg     0.5020    0.5027    0.4759       185

micro f-score: 0.5027027027027027

========== Train Epoch 22 ==========
Loss: 1.129	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.4521    0.8462    0.5893        39

    accuracy                         0.5027       185
   macro avg     0.4800    0.4467    0.4429       185
weighted avg     0.5186    0.5027    0.4874       185

micro f-score: 0.5027027027027027

========== Train Epoch 23 ==========
Loss: 1.110	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.6923    0.6000    0.6429        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5243       185
   macro avg     0.4603    0.4599    0.4510       185
weighted avg     0.5088    0.5243    0.5076       185

micro f-score: 0.5243243243243243

========== Train Epoch 24 ==========
Loss: 1.068	Accuracy: 52.97%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.4658    0.8718    0.6071        39

    accuracy                         0.5297       185
   macro avg     0.5089    0.4762    0.4573       185
weighted avg     0.5448    0.5297    0.5043       185

micro f-score: 0.5297297297297298

========== Train Epoch 25 ==========
Loss: 1.061	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5135    0.6129    0.5588        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.5297       185
   macro avg     0.4951    0.4786    0.4585       185
weighted avg     0.5298    0.5297    0.5030       185

micro f-score: 0.5297297297297298

========== Train Epoch 26 ==========
Loss: 1.033	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5297       185
   macro avg     0.4668    0.4656    0.4474       185
weighted avg     0.5183    0.5297    0.5049       185

micro f-score: 0.5297297297297298

========== Train Epoch 27 ==========
Loss: 1.015	Accuracy: 54.05%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.5172    0.7692    0.6186        39

    accuracy                         0.5405       185
   macro avg     0.4944    0.4988    0.4711       185
weighted avg     0.5440    0.5405    0.5202       185

micro f-score: 0.5405405405405406

========== Train Epoch 28 ==========
Loss: 1.002	Accuracy: 52.43%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.4648    0.8462    0.6000        39

    accuracy                         0.5243       185
   macro avg     0.5221    0.4798    0.4543       185
weighted avg     0.5578    0.5243    0.5007       185

micro f-score: 0.5243243243243243

========== Train Epoch 29 ==========
Loss: 0.962	Accuracy: 53.51%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4545    0.6452    0.5333        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.5351       185
   macro avg     0.4663    0.4836    0.4596       185
weighted avg     0.5263    0.5351    0.5193       185

micro f-score: 0.5351351351351351

========== Train Epoch 30 ==========
Loss: 0.973	Accuracy: 52.43%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.5243       185
   macro avg     0.4988    0.4796    0.4595       185
weighted avg     0.5468    0.5243    0.5022       185

micro f-score: 0.5243243243243243

========== Train Epoch 31 ==========
Loss: 0.934	Accuracy: 53.51%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5400    0.6923    0.6067        39

    accuracy                         0.5351       185
   macro avg     0.4875    0.4970    0.4851       185
weighted avg     0.5392    0.5351    0.5299       185

micro f-score: 0.5351351351351351

========== Train Epoch 32 ==========
Loss: 0.940	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.7500    0.5000    0.6000        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.6757    0.6410    0.6579        39

    accuracy                         0.5405       185
   macro avg     0.5040    0.4840    0.4855       185
weighted avg     0.5378    0.5405    0.5333       185

micro f-score: 0.5405405405405406

========== Train Epoch 33 ==========
Loss: 0.907	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4375    0.6774    0.5316        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6279    0.6923    0.6585        39

    accuracy                         0.5514       185
   macro avg     0.4991    0.4955    0.4797       185
weighted avg     0.5487    0.5514    0.5360       185

micro f-score: 0.5513513513513514

========== Train Epoch 34 ==========
Loss: 0.868	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6786    0.6129    0.6441        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.7879    0.5778    0.6667        45
         zxx     0.5161    0.8205    0.6337        39

    accuracy                         0.5676       185
   macro avg     0.5331    0.5331    0.5087       185
weighted avg     0.5809    0.5676    0.5526       185

micro f-score: 0.5675675675675675

========== Train Epoch 35 ==========
Loss: 0.847	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.8571    0.5333    0.6575        45
         zxx     0.5000    0.7949    0.6139        39

    accuracy                         0.5514       185
   macro avg     0.5282    0.5214    0.5008       185
weighted avg     0.5810    0.5514    0.5414       185

micro f-score: 0.5513513513513514

========== Train Epoch 36 ==========
Loss: 0.842	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5784       185
   macro avg     0.5097    0.5224    0.5093       185
weighted avg     0.5662    0.5784    0.5661       185

micro f-score: 0.5783783783783784

========== Train Epoch 37 ==========
Loss: 0.795	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.4833    0.7436    0.5859        39

    accuracy                         0.5243       185
   macro avg     0.4852    0.4742    0.4709       185
weighted avg     0.5227    0.5243    0.5127       185

micro f-score: 0.5243243243243243

========== Train Epoch 38 ==========
Loss: 0.802	Accuracy: 58.92%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5238    0.7097    0.6027        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8667    0.5778    0.6933        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5892       185
   macro avg     0.5720    0.5543    0.5234       185
weighted avg     0.6175    0.5892    0.5703       185

micro f-score: 0.5891891891891892

========== Train Epoch 39 ==========
Loss: 0.771	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.6000       185
   macro avg     0.5649    0.5596    0.5517       185
weighted avg     0.6082    0.6000    0.5931       185

micro f-score: 0.6

========== Train Epoch 40 ==========
Loss: 0.764	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5622       185
   macro avg     0.5113    0.5303    0.5038       185
weighted avg     0.5653    0.5622    0.5517       185

micro f-score: 0.5621621621621622

========== Train Epoch 41 ==========
Loss: 0.740	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.5870    0.6923    0.6353        39

    accuracy                         0.5622       185
   macro avg     0.5152    0.5379    0.5149       185
weighted avg     0.5674    0.5622    0.5551       185

micro f-score: 0.5621621621621622

========== Train Epoch 42 ==========
Loss: 0.719	Accuracy: 57.84%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.5909    0.6667    0.6265        39

    accuracy                         0.5784       185
   macro avg     0.5476    0.5255    0.5152       185
weighted avg     0.5843    0.5784    0.5658       185

micro f-score: 0.5783783783783784

========== Train Epoch 43 ==========
Loss: 0.689	Accuracy: 56.22%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5622       185
   macro avg     0.5037    0.5119    0.4977       185
weighted avg     0.5470    0.5622    0.5468       185

micro f-score: 0.5621621621621622

========== Train Epoch 44 ==========
Loss: 0.677	Accuracy: 59.46%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5882    0.7692    0.6667        39

    accuracy                         0.5946       185
   macro avg     0.5534    0.5657    0.5495       185
weighted avg     0.6029    0.5946    0.5904       185

micro f-score: 0.5945945945945946

========== Train Epoch 45 ==========
Loss: 0.669	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4468    0.6774    0.5385        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6042    0.7436    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5869    0.5298    0.5091       185
weighted avg     0.6125    0.5730    0.5565       185

micro f-score: 0.572972972972973

========== Train Epoch 46 ==========
Loss: 0.652	Accuracy: 58.38%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5686    0.7436    0.6444        39

    accuracy                         0.5838       185
   macro avg     0.5333    0.5464    0.5268       185
weighted avg     0.5835    0.5838    0.5732       185

micro f-score: 0.5837837837837838

========== Train Epoch 47 ==========
Loss: 0.636	Accuracy: 60.00%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5250    0.6774    0.5915        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.6000       185
   macro avg     0.5582    0.5711    0.5554       185
weighted avg     0.5926    0.6000    0.5898       185

micro f-score: 0.6

========== Train Epoch 48 ==========
Loss: 0.611	Accuracy: 60.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.6000       185
   macro avg     0.5529    0.5601    0.5477       185
weighted avg     0.5997    0.6000    0.5925       185

micro f-score: 0.6

========== Train Epoch 49 ==========
Loss: 0.593	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6800    0.7556    0.7158        45
         zxx     0.6222    0.7179    0.6667        39

    accuracy                         0.5730       185
   macro avg     0.5381    0.5259    0.5174       185
weighted avg     0.5731    0.5730    0.5623       185

micro f-score: 0.572972972972973

========== Train Epoch 50 ==========
Loss: 0.560	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5946       185
   macro avg     0.5541    0.5593    0.5485       185
weighted avg     0.5924    0.5946    0.5871       185

micro f-score: 0.5945945945945946

========== Train Epoch 51 ==========
Loss: 0.553	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6054       185
   macro avg     0.5734    0.5700    0.5572       185
weighted avg     0.6182    0.6054    0.5996       185

micro f-score: 0.6054054054054054

========== Train Epoch 52 ==========
Loss: 0.549	Accuracy: 61.08%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6108       185
   macro avg     0.5626    0.5675    0.5501       185
weighted avg     0.6044    0.6108    0.5962       185

micro f-score: 0.6108108108108108

========== Train Epoch 53 ==========
Loss: 0.528	Accuracy: 60.54%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.6054       185
   macro avg     0.5814    0.5696    0.5578       185
weighted avg     0.6177    0.6054    0.5956       185

micro f-score: 0.6054054054054054

========== Train Epoch 54 ==========
Loss: 0.507	Accuracy: 61.08%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6786    0.6129    0.6441        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.6108       185
   macro avg     0.5884    0.5636    0.5588       185
weighted avg     0.6345    0.6108    0.6040       185

micro f-score: 0.6108108108108108

========== Train Epoch 55 ==========
Loss: 0.491	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6000    0.6774    0.6364        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.6054       185
   macro avg     0.5712    0.5703    0.5556       185
weighted avg     0.6141    0.6054    0.5995       185

micro f-score: 0.6054054054054054

========== Train Epoch 56 ==========
Loss: 0.479	Accuracy: 60.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6667    0.5806    0.6207        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.6054       185
   macro avg     0.5611    0.5566    0.5469       185
weighted avg     0.6015    0.6054    0.5933       185

micro f-score: 0.6054054054054054

========== Train Epoch 57 ==========
Loss: 0.470	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.5676       185
   macro avg     0.5332    0.5328    0.5159       185
weighted avg     0.5709    0.5676    0.5579       185

micro f-score: 0.5675675675675675

========== Train Epoch 58 ==========
Loss: 0.437	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6897    0.6452    0.6667        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.5882    0.7692    0.6667        39

    accuracy                         0.6000       185
   macro avg     0.5586    0.5455    0.5444       185
weighted avg     0.5989    0.6000    0.5927       185

micro f-score: 0.6

========== Train Epoch 59 ==========
Loss: 0.450	Accuracy: 60.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.6000       185
   macro avg     0.5565    0.5586    0.5464       185
weighted avg     0.5966    0.6000    0.5907       185

micro f-score: 0.6

========== Train Epoch 60 ==========
Loss: 0.434	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.4658    0.8718    0.6071        39

    accuracy                         0.5838       185
   macro avg     0.6038    0.5458    0.5422       185
weighted avg     0.6451    0.5838    0.5806       185

micro f-score: 0.5837837837837838

========== Train Epoch 61 ==========
Loss: 0.405	Accuracy: 59.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6667    0.4516    0.5385        31
         cwx     0.4667    0.6364    0.5385        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5946       185
   macro avg     0.5516    0.5482    0.5279       185
weighted avg     0.6002    0.5946    0.5797       185

micro f-score: 0.5945945945945946

========== Train Epoch 62 ==========
Loss: 0.417	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5676    0.6774    0.6176        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.6054       185
   macro avg     0.5606    0.5567    0.5538       185
weighted avg     0.6091    0.6054    0.6032       185

micro f-score: 0.6054054054054054

========== Train Epoch 63 ==========
Loss: 0.371	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6538    0.5484    0.5965        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.6054       185
   macro avg     0.5899    0.5727    0.5591       185
weighted avg     0.6205    0.6054    0.5976       185

micro f-score: 0.6054054054054054

========== Train Epoch 64 ==========
Loss: 0.380	Accuracy: 62.16%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.6216       185
   macro avg     0.5795    0.5707    0.5706       185
weighted avg     0.6163    0.6216    0.6146       185

micro f-score: 0.6216216216216216

Finished training!!!

Min Loss = 0.371 in epoch 62;
Max Accuracy = 62.16% in epoch 63;
Total Cost 49 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt3: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt3: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt3: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt3: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt3: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt3: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt3: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt3: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
