dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.835	Accuracy: 24.86%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.2222    0.0909    0.1290        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3077    0.1778    0.2254        45
         zxx     0.2292    0.8462    0.3607        39

    accuracy                         0.2486       185
   macro avg     0.2156    0.1731    0.1266       185
weighted avg     0.2753    0.2486    0.1749       185

micro f-score: 0.24864864864864866

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.644	Accuracy: 36.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.2500    0.1364    0.1765        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1250    0.0833    0.1000        12
         qtx     0.8095    0.3778    0.5152        45
         zxx     0.3136    0.9487    0.4713        39

    accuracy                         0.3622       185
   macro avg     0.3124    0.2699    0.2459       185
weighted avg     0.3995    0.3622    0.3173       185

micro f-score: 0.3621621621621622

========== Train Epoch 3 ==========
Loss: 1.532	Accuracy: 38.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.3556    0.8205    0.4961        39

    accuracy                         0.3892       185
   macro avg     0.3352    0.2998    0.2848       185
weighted avg     0.3762    0.3892    0.3482       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
Loss: 1.503	Accuracy: 39.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.3548    0.8462    0.5000        39

    accuracy                         0.3946       185
   macro avg     0.3080    0.2958    0.2730       185
weighted avg     0.3659    0.3946    0.3472       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.480	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.3608    0.8974    0.5147        39

    accuracy                         0.4054       185
   macro avg     0.3232    0.3051    0.2815       185
weighted avg     0.3808    0.4054    0.3555       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.466	Accuracy: 43.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6047    0.5778    0.5909        45
         zxx     0.3953    0.8718    0.5440        39

    accuracy                         0.4324       185
   macro avg     0.3441    0.3272    0.3083       185
weighted avg     0.4015    0.4324    0.3872       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 1.437	Accuracy: 41.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.3636    0.9231    0.5217        39

    accuracy                         0.4108       185
   macro avg     0.3498    0.3121    0.2932       185
weighted avg     0.4016    0.4108    0.3643       185

micro f-score: 0.4108108108108109

========== Train Epoch 8 ==========
Loss: 1.417	Accuracy: 43.78%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.3820    0.8718    0.5312        39

    accuracy                         0.4378       185
   macro avg     0.3808    0.3389    0.3286       185
weighted avg     0.4334    0.4378    0.4019       185

micro f-score: 0.43783783783783786

========== Train Epoch 9 ==========
Loss: 1.409	Accuracy: 43.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4583    0.3548    0.4000        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.3889    0.8974    0.5426        39

    accuracy                         0.4324       185
   macro avg     0.3708    0.3357    0.3226       185
weighted avg     0.4217    0.4324    0.3933       185

micro f-score: 0.43243243243243246

========== Train Epoch 10 ==========
Loss: 1.369	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.3837    0.8462    0.5280        39

    accuracy                         0.4324       185
   macro avg     0.3725    0.3380    0.3273       185
weighted avg     0.4199    0.4324    0.3964       185

micro f-score: 0.43243243243243246

========== Train Epoch 11 ==========
Loss: 1.368	Accuracy: 44.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4194    0.4194    0.4194        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.4486       185
   macro avg     0.3777    0.3596    0.3462       185
weighted avg     0.4220    0.4486    0.4116       185

micro f-score: 0.4486486486486486

========== Train Epoch 12 ==========
Loss: 1.333	Accuracy: 44.86%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.4198    0.8718    0.5667        39

    accuracy                         0.4486       185
   macro avg     0.3945    0.3538    0.3443       185
weighted avg     0.4410    0.4486    0.4146       185

micro f-score: 0.4486486486486486

========== Train Epoch 13 ==========
Loss: 1.315	Accuracy: 47.03%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.4545    0.8974    0.6034        39

    accuracy                         0.4703       185
   macro avg     0.4205    0.3897    0.3815       185
weighted avg     0.4615    0.4703    0.4405       185

micro f-score: 0.4702702702702703

========== Train Epoch 14 ==========
Loss: 1.293	Accuracy: 45.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.3333    0.3636    0.3478        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5179    0.6444    0.5743        45
         zxx     0.4697    0.7949    0.5905        39

    accuracy                         0.4541       185
   macro avg     0.3806    0.3672    0.3500       185
weighted avg     0.4198    0.4541    0.4131       185

micro f-score: 0.4540540540540541

========== Train Epoch 15 ==========
Loss: 1.272	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3929    0.3548    0.3729        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.4167    0.8974    0.5691        39

    accuracy                         0.4432       185
   macro avg     0.4029    0.3497    0.3396       185
weighted avg     0.4496    0.4432    0.4095       185

micro f-score: 0.44324324324324327

========== Train Epoch 16 ==========
Loss: 1.267	Accuracy: 48.65%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4118    0.4516    0.4308        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.4865       185
   macro avg     0.4295    0.4184    0.4089       185
weighted avg     0.4761    0.4865    0.4648       185

micro f-score: 0.4864864864864865

========== Train Epoch 17 ==========
Loss: 1.221	Accuracy: 49.73%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.6136    0.6000    0.6067        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.4973       185
   macro avg     0.4269    0.4174    0.4108       185
weighted avg     0.4707    0.4973    0.4728       185

micro f-score: 0.4972972972972973

========== Train Epoch 18 ==========
Loss: 1.229	Accuracy: 49.19%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5833    0.6222    0.6022        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.4919       185
   macro avg     0.4324    0.4123    0.4072       185
weighted avg     0.4686    0.4919    0.4663       185

micro f-score: 0.4918918918918919

========== Train Epoch 19 ==========
Loss: 1.196	Accuracy: 48.65%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.4321    0.8974    0.5833        39

    accuracy                         0.4865       185
   macro avg     0.4736    0.4219    0.4117       185
weighted avg     0.5114    0.4865    0.4617       185

micro f-score: 0.4864864864864865

========== Train Epoch 20 ==========
Loss: 1.172	Accuracy: 50.81%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5081       185
   macro avg     0.4772    0.4533    0.4380       185
weighted avg     0.5108    0.5081    0.4850       185

micro f-score: 0.5081081081081081

========== Train Epoch 21 ==========
Loss: 1.157	Accuracy: 51.89%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5189       185
   macro avg     0.5462    0.4474    0.4368       185
weighted avg     0.5677    0.5189    0.4944       185

micro f-score: 0.518918918918919

========== Train Epoch 22 ==========
Loss: 1.147	Accuracy: 51.35%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6875    0.4889    0.5714        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.5135       185
   macro avg     0.4674    0.4669    0.4497       185
weighted avg     0.5076    0.5135    0.4924       185

micro f-score: 0.5135135135135135

========== Train Epoch 23 ==========
Loss: 1.106	Accuracy: 52.43%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5243       185
   macro avg     0.5136    0.4661    0.4516       185
weighted avg     0.5387    0.5243    0.4999       185

micro f-score: 0.5243243243243243

========== Train Epoch 24 ==========
Loss: 1.098	Accuracy: 52.43%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.3143    0.5000    0.3860        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5243       185
   macro avg     0.4654    0.4805    0.4613       185
weighted avg     0.5202    0.5243    0.5126       185

micro f-score: 0.5243243243243243

========== Train Epoch 25 ==========
Loss: 1.077	Accuracy: 54.05%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5405       185
   macro avg     0.4825    0.4867    0.4665       185
weighted avg     0.5269    0.5405    0.5203       185

micro f-score: 0.5405405405405406

========== Train Epoch 26 ==========
Loss: 1.049	Accuracy: 49.19%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.7586    0.4889    0.5946        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.4919       185
   macro avg     0.4924    0.4337    0.4244       185
weighted avg     0.5244    0.4919    0.4684       185

micro f-score: 0.4918918918918919

========== Train Epoch 27 ==========
Loss: 1.042	Accuracy: 53.51%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5351       185
   macro avg     0.5183    0.4869    0.4706       185
weighted avg     0.5432    0.5351    0.5106       185

micro f-score: 0.5351351351351351

========== Train Epoch 28 ==========
Loss: 1.003	Accuracy: 56.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5622       185
   macro avg     0.5483    0.5105    0.5002       185
weighted avg     0.5763    0.5622    0.5434       185

micro f-score: 0.5621621621621622

========== Train Epoch 29 ==========
Loss: 0.998	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.4684    0.9487    0.6271        39

    accuracy                         0.5459       185
   macro avg     0.5353    0.4722    0.4547       185
weighted avg     0.5627    0.5459    0.5094       185

micro f-score: 0.5459459459459459

========== Train Epoch 30 ==========
Loss: 0.989	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5405       185
   macro avg     0.4805    0.4977    0.4746       185
weighted avg     0.5366    0.5405    0.5290       185

micro f-score: 0.5405405405405406

========== Train Epoch 31 ==========
Loss: 0.965	Accuracy: 52.97%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.3226    0.4545    0.3774        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.5297       185
   macro avg     0.4752    0.4909    0.4741       185
weighted avg     0.5333    0.5297    0.5248       185

micro f-score: 0.5297297297297298

========== Train Epoch 32 ==========
Loss: 0.950	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.4000    0.5455    0.4615        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.6744    0.7436    0.7073        39

    accuracy                         0.5514       185
   macro avg     0.4816    0.4973    0.4798       185
weighted avg     0.5301    0.5514    0.5336       185

micro f-score: 0.5513513513513514

========== Train Epoch 33 ==========
Loss: 0.923	Accuracy: 54.05%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5405       185
   macro avg     0.4972    0.4940    0.4782       185
weighted avg     0.5426    0.5405    0.5253       185

micro f-score: 0.5405405405405406

========== Train Epoch 34 ==========
Loss: 0.894	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.3448    0.4545    0.3922        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7250    0.6444    0.6824        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5568       185
   macro avg     0.5310    0.5107    0.4983       185
weighted avg     0.5706    0.5568    0.5466       185

micro f-score: 0.5567567567567567

========== Train Epoch 35 ==========
Loss: 0.893	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5730       185
   macro avg     0.5944    0.5173    0.5071       185
weighted avg     0.6072    0.5730    0.5532       185

micro f-score: 0.572972972972973

========== Train Epoch 36 ==========
Loss: 0.864	Accuracy: 55.68%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.5593    0.8462    0.6735        39

    accuracy                         0.5568       185
   macro avg     0.5812    0.5021    0.4916       185
weighted avg     0.5924    0.5568    0.5355       185

micro f-score: 0.5567567567567567

========== Train Epoch 37 ==========
Loss: 0.857	Accuracy: 54.59%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.5459       185
   macro avg     0.4788    0.4913    0.4801       185
weighted avg     0.5336    0.5459    0.5360       185

micro f-score: 0.5459459459459459

========== Train Epoch 38 ==========
Loss: 0.833	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3824    0.5909    0.4643        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5568       185
   macro avg     0.4981    0.5096    0.4937       185
weighted avg     0.5528    0.5568    0.5466       185

micro f-score: 0.5567567567567567

========== Train Epoch 39 ==========
Loss: 0.812	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5730       185
   macro avg     0.5398    0.5268    0.5096       185
weighted avg     0.5825    0.5730    0.5600       185

micro f-score: 0.572972972972973

========== Train Epoch 40 ==========
Loss: 0.806	Accuracy: 55.14%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5514       185
   macro avg     0.4982    0.4993    0.4805       185
weighted avg     0.5466    0.5514    0.5332       185

micro f-score: 0.5513513513513514

========== Train Epoch 41 ==========
Loss: 0.773	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5838       185
   macro avg     0.5388    0.5254    0.5179       185
weighted avg     0.5837    0.5838    0.5730       185

micro f-score: 0.5837837837837838

========== Train Epoch 42 ==========
Loss: 0.755	Accuracy: 52.97%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.3226    0.4545    0.3774        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6136    0.6000    0.6067        45
         zxx     0.6809    0.8205    0.7442        39

    accuracy                         0.5297       185
   macro avg     0.4932    0.4794    0.4694       185
weighted avg     0.5366    0.5297    0.5201       185

micro f-score: 0.5297297297297298

========== Train Epoch 43 ==========
Loss: 0.742	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5405       185
   macro avg     0.4854    0.4919    0.4806       185
weighted avg     0.5358    0.5405    0.5318       185

micro f-score: 0.5405405405405406

========== Train Epoch 44 ==========
Loss: 0.740	Accuracy: 60.54%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6054       185
   macro avg     0.5723    0.5573    0.5515       185
weighted avg     0.6014    0.6054    0.5926       185

micro f-score: 0.6054054054054054

========== Train Epoch 45 ==========
Loss: 0.693	Accuracy: 54.59%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5459       185
   macro avg     0.4957    0.5053    0.4939       185
weighted avg     0.5409    0.5459    0.5378       185

micro f-score: 0.5459459459459459

========== Train Epoch 46 ==========
Loss: 0.676	Accuracy: 51.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.2258    0.3111        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.5075    0.8718    0.6415        39

    accuracy                         0.5189       185
   macro avg     0.4856    0.4736    0.4604       185
weighted avg     0.5185    0.5189    0.4964       185

micro f-score: 0.518918918918919

========== Train Epoch 47 ==========
Loss: 0.694	Accuracy: 56.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.4932    0.9231    0.6429        39

    accuracy                         0.5622       185
   macro avg     0.5539    0.5123    0.5081       185
weighted avg     0.5821    0.5622    0.5449       185

micro f-score: 0.5621621621621622

========== Train Epoch 48 ==========
Loss: 0.672	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.7561    0.7949    0.7750        39

    accuracy                         0.5838       185
   macro avg     0.5365    0.5390    0.5334       185
weighted avg     0.5777    0.5838    0.5778       185

micro f-score: 0.5837837837837838

========== Train Epoch 49 ==========
Loss: 0.640	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.6481    0.8974    0.7527        39

    accuracy                         0.5784       185
   macro avg     0.5268    0.5362    0.5237       185
weighted avg     0.5752    0.5784    0.5674       185

micro f-score: 0.5783783783783784

========== Train Epoch 50 ==========
Loss: 0.621	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6744    0.6444    0.6591        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5514       185
   macro avg     0.5083    0.5061    0.4936       185
weighted avg     0.5442    0.5514    0.5367       185

micro f-score: 0.5513513513513514

========== Train Epoch 51 ==========
Loss: 0.605	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4490    0.7097    0.5500        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7429    0.6667    0.7027        39

    accuracy                         0.5676       185
   macro avg     0.5275    0.5163    0.5125       185
weighted avg     0.5703    0.5676    0.5600       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 0.601	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.5838       185
   macro avg     0.5336    0.5327    0.5314       185
weighted avg     0.5767    0.5838    0.5789       185

micro f-score: 0.5837837837837838

========== Train Epoch 53 ==========
Loss: 0.580	Accuracy: 56.76%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5676       185
   macro avg     0.5271    0.5237    0.5159       185
weighted avg     0.5635    0.5676    0.5575       185

micro f-score: 0.5675675675675675

========== Train Epoch 54 ==========
Loss: 0.576	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5730       185
   macro avg     0.5391    0.5302    0.5287       185
weighted avg     0.5638    0.5730    0.5619       185

micro f-score: 0.572972972972973

========== Train Epoch 55 ==========
Loss: 0.537	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.5514       185
   macro avg     0.5028    0.5080    0.5004       185
weighted avg     0.5612    0.5514    0.5514       185

micro f-score: 0.5513513513513514

========== Train Epoch 56 ==========
Loss: 0.548	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5730       185
   macro avg     0.5365    0.5262    0.5211       185
weighted avg     0.5708    0.5730    0.5596       185

micro f-score: 0.572972972972973

========== Train Epoch 57 ==========
Loss: 0.524	Accuracy: 61.08%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6102    0.9231    0.7347        39

    accuracy                         0.6108       185
   macro avg     0.5734    0.5476    0.5495       185
weighted avg     0.6095    0.6108    0.5983       185

micro f-score: 0.6108108108108108

========== Train Epoch 58 ==========
Loss: 0.514	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.5676       185
   macro avg     0.5238    0.5373    0.5267       185
weighted avg     0.5682    0.5676    0.5649       185

micro f-score: 0.5675675675675675

========== Train Epoch 59 ==========
Loss: 0.479	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5455    0.9231    0.6857        39

    accuracy                         0.5838       185
   macro avg     0.5570    0.5322    0.5296       185
weighted avg     0.5946    0.5838    0.5704       185

micro f-score: 0.5837837837837838

========== Train Epoch 60 ==========
Loss: 0.495	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.8286    0.6444    0.7250        45
         zxx     0.5455    0.9231    0.6857        39

    accuracy                         0.5730       185
   macro avg     0.5414    0.5258    0.5171       185
weighted avg     0.5797    0.5730    0.5553       185

micro f-score: 0.572972972972973

========== Train Epoch 61 ==========
Loss: 0.465	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5838       185
   macro avg     0.5479    0.5449    0.5383       185
weighted avg     0.5844    0.5838    0.5756       185

micro f-score: 0.5837837837837838

========== Train Epoch 62 ==========
Loss: 0.445	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5946       185
   macro avg     0.5698    0.5543    0.5511       185
weighted avg     0.6004    0.5946    0.5877       185

micro f-score: 0.5945945945945946

========== Train Epoch 63 ==========
Loss: 0.444	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5514       185
   macro avg     0.5098    0.5107    0.5034       185
weighted avg     0.5456    0.5514    0.5408       185

micro f-score: 0.5513513513513514

========== Train Epoch 64 ==========
Loss: 0.433	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5676       185
   macro avg     0.5311    0.5240    0.5196       185
weighted avg     0.5672    0.5676    0.5594       185

micro f-score: 0.5675675675675675

Finished training!!!

Min Loss = 0.433 in epoch 63;
Max Accuracy = 61.08% in epoch 56;
Total Cost 30 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-6                     [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt: 3-13                    [-1, 64, 80, 80]          1,688
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-20                    [-1, 128, 40, 40]         3,352
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt: 3-28                    [-1, 128, 40, 40]         3,352
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-35                    [-1, 256, 20, 20]         6,680
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt: 3-43                    [-1, 256, 20, 20]         6,680
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-50                    [-1, 512, 10, 10]         25,648
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt: 3-58                    [-1, 512, 10, 10]         25,648
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,254,839
Trainable params: 11,254,839
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.05
Params size (MB): 42.93
Estimated Total Size (MB): 122.15
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
