dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18_max1
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.826	Accuracy: 32.43%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.2500    0.0323    0.0571        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.3623    0.5556    0.4386        45
         zxx     0.3059    0.6667    0.4194        39

    accuracy                         0.3243       185
   macro avg     0.2148    0.2636    0.2040       185
weighted avg     0.2479    0.3243    0.2454       185

micro f-score: 0.32432432432432434

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.584	Accuracy: 44.86%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3778    0.5484    0.4474        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5192    0.6000    0.5567        45
         zxx     0.4219    0.6923    0.5243        39

    accuracy                         0.4486       185
   macro avg     0.4805    0.3703    0.3666       185
weighted avg     0.4760    0.4486    0.4139       185

micro f-score: 0.4486486486486486

========== Train Epoch 3 ==========
Loss: 1.389	Accuracy: 41.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.2778    0.2273    0.2500        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2500    0.2105    0.2286        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.4681    0.4889    0.4783        45
         zxx     0.4068    0.6154    0.4898        39

    accuracy                         0.4108       185
   macro avg     0.3924    0.3614    0.3686       185
weighted avg     0.4077    0.4108    0.4012       185

micro f-score: 0.4108108108108109

========== Train Epoch 4 ==========
Loss: 1.324	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3000    0.2727    0.2857        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5111    0.5111    0.5111        45
         zxx     0.4828    0.7179    0.5773        39

    accuracy                         0.4378       185
   macro avg     0.3996    0.3739    0.3765       185
weighted avg     0.4256    0.4378    0.4223       185

micro f-score: 0.43783783783783786

========== Train Epoch 5 ==========
Loss: 1.279	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.4378       185
   macro avg     0.3783    0.3596    0.3489       185
weighted avg     0.4087    0.4378    0.4012       185

micro f-score: 0.43783783783783786

========== Train Epoch 6 ==========
Loss: 1.241	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6875    0.4889    0.5714        45
         zxx     0.4848    0.8205    0.6095        39

    accuracy                         0.4865       185
   macro avg     0.4557    0.4548    0.4344       185
weighted avg     0.4889    0.4865    0.4669       185

micro f-score: 0.4864864864864865

========== Train Epoch 7 ==========
Loss: 1.207	Accuracy: 45.95%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6774    0.4667    0.5526        45
         zxx     0.4286    0.8462    0.5690        39

    accuracy                         0.4595       185
   macro avg     0.4345    0.4192    0.4028       185
weighted avg     0.4642    0.4595    0.4345       185

micro f-score: 0.4594594594594595

========== Train Epoch 8 ==========
Loss: 1.153	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4762    0.3226    0.3846        31
         cwx     0.3200    0.3636    0.3404        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.5476    0.5111    0.5287        45
         zxx     0.5082    0.7949    0.6200        39

    accuracy                         0.4811       185
   macro avg     0.4594    0.4554    0.4433       185
weighted avg     0.4712    0.4811    0.4621       185

micro f-score: 0.4810810810810811

========== Train Epoch 9 ==========
Loss: 1.112	Accuracy: 48.11%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7241    0.4667    0.5676        45
         zxx     0.4286    0.9231    0.5854        39

    accuracy                         0.4811       185
   macro avg     0.4739    0.4431    0.4253       185
weighted avg     0.4979    0.4811    0.4525       185

micro f-score: 0.4810810810810811

========== Train Epoch 10 ==========
Loss: 1.085	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6667    0.4889    0.5641        45
         zxx     0.4805    0.9487    0.6379        39

    accuracy                         0.5027       185
   macro avg     0.4727    0.4610    0.4363       185
weighted avg     0.5028    0.5027    0.4715       185

micro f-score: 0.5027027027027027

========== Train Epoch 11 ==========
Loss: 1.039	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6087    0.6222    0.6154        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.5297       185
   macro avg     0.5106    0.4878    0.4713       185
weighted avg     0.5313    0.5297    0.5066       185

micro f-score: 0.5297297297297298

========== Train Epoch 12 ==========
Loss: 1.001	Accuracy: 55.14%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6923    0.6000    0.6429        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5514       185
   macro avg     0.5203    0.5143    0.5029       185
weighted avg     0.5482    0.5514    0.5342       185

micro f-score: 0.5513513513513514

========== Train Epoch 13 ==========
Loss: 0.956	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.5833    0.6222    0.6022        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5459       185
   macro avg     0.5127    0.5140    0.5083       185
weighted avg     0.5305    0.5459    0.5333       185

micro f-score: 0.5459459459459459

========== Train Epoch 14 ==========
Loss: 0.929	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5243       185
   macro avg     0.4854    0.4779    0.4560       185
weighted avg     0.5164    0.5243    0.4963       185

micro f-score: 0.5243243243243243

========== Train Epoch 15 ==========
Loss: 0.880	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.3846    0.6818    0.4918        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2667    0.2105    0.2353        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.5568       185
   macro avg     0.5377    0.4982    0.5018       185
weighted avg     0.5759    0.5568    0.5540       185

micro f-score: 0.5567567567567567

========== Train Epoch 16 ==========
Loss: 0.826	Accuracy: 53.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.7097    0.5867        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6222    0.6222    0.6222        45
         zxx     0.8148    0.5641    0.6667        39

    accuracy                         0.5351       185
   macro avg     0.4988    0.4968    0.4902       185
weighted avg     0.5515    0.5351    0.5344       185

micro f-score: 0.5351351351351351

========== Train Epoch 17 ==========
Loss: 0.792	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6182    0.7556    0.6800        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5892       185
   macro avg     0.5417    0.5299    0.5204       185
weighted avg     0.5687    0.5892    0.5653       185

micro f-score: 0.5891891891891892

========== Train Epoch 18 ==========
Loss: 0.761	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6226    0.7333    0.6735        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5784       185
   macro avg     0.5303    0.5320    0.5249       185
weighted avg     0.5787    0.5784    0.5729       185

micro f-score: 0.5783783783783784

========== Train Epoch 19 ==========
Loss: 0.696	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.5459       185
   macro avg     0.5207    0.5035    0.4871       185
weighted avg     0.5545    0.5459    0.5290       185

micro f-score: 0.5459459459459459

========== Train Epoch 20 ==========
Loss: 0.693	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5238    0.7097    0.6027        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.6207    0.8000    0.6990        45
         zxx     0.8846    0.5897    0.7077        39

    accuracy                         0.5676       185
   macro avg     0.5266    0.5009    0.5020       185
weighted avg     0.5751    0.5676    0.5574       185

micro f-score: 0.5675675675675675

========== Train Epoch 21 ==========
Loss: 0.620	Accuracy: 60.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7000    0.4516    0.5490        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.6957    0.8205    0.7529        39

    accuracy                         0.6054       185
   macro avg     0.5716    0.5681    0.5538       185
weighted avg     0.6157    0.6054    0.5982       185

micro f-score: 0.6054054054054054

========== Train Epoch 22 ==========
Loss: 0.599	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7619    0.5161    0.6154        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3000    0.3158    0.3077        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6207    0.8000    0.6990        45
         zxx     0.7714    0.6923    0.7297        39

    accuracy                         0.5838       185
   macro avg     0.5565    0.5291    0.5339       185
weighted avg     0.6050    0.5838    0.5846       185

micro f-score: 0.5837837837837838

========== Train Epoch 23 ==========
Loss: 0.557	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.6108       185
   macro avg     0.5835    0.5749    0.5681       185
weighted avg     0.6115    0.6108    0.5999       185

micro f-score: 0.6108108108108108

========== Train Epoch 24 ==========
Loss: 0.523	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5333    0.7742    0.6316        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7568    0.6222    0.6829        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5838       185
   macro avg     0.5440    0.5467    0.5365       185
weighted avg     0.6043    0.5838    0.5852       185

micro f-score: 0.5837837837837838

========== Train Epoch 25 ==========
Loss: 0.478	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.9167    0.3548    0.5116        31
         cwx     0.5769    0.6818    0.6250        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.4512    0.9487    0.6116        39

    accuracy                         0.5838       185
   macro avg     0.6277    0.5285    0.5366       185
weighted avg     0.6671    0.5838    0.5751       185

micro f-score: 0.5837837837837838

========== Train Epoch 26 ==========
Loss: 0.465	Accuracy: 60.54%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.8421    0.5161    0.6400        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.6054       185
   macro avg     0.5663    0.5693    0.5563       185
weighted avg     0.6310    0.6054    0.6088       185

micro f-score: 0.6054054054054054

========== Train Epoch 27 ==========
Loss: 0.432	Accuracy: 61.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7200    0.5806    0.6429        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6162       185
   macro avg     0.5791    0.5625    0.5571       185
weighted avg     0.6263    0.6162    0.6076       185

micro f-score: 0.6162162162162163

========== Train Epoch 28 ==========
Loss: 0.385	Accuracy: 61.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6061    0.6452    0.6250        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.6108       185
   macro avg     0.5792    0.5583    0.5425       185
weighted avg     0.6171    0.6108    0.5945       185

micro f-score: 0.6108108108108108

========== Train Epoch 29 ==========
Loss: 0.371	Accuracy: 65.95%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6176    0.6774    0.6462        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8718    0.7556    0.8095        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6595       185
   macro avg     0.6087    0.6295    0.6135       185
weighted avg     0.6677    0.6595    0.6599       185

micro f-score: 0.6594594594594595

========== Train Epoch 30 ==========
Loss: 0.346	Accuracy: 59.46%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7500    0.2903    0.4186        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5946       185
   macro avg     0.5788    0.5714    0.5407       185
weighted avg     0.6356    0.5946    0.5842       185

micro f-score: 0.5945945945945946

========== Train Epoch 31 ==========
Loss: 0.319	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7368    0.4516    0.5600        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.3235    0.5789    0.4151        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7234    0.7556    0.7391        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.5838       185
   macro avg     0.5567    0.5415    0.5343       185
weighted avg     0.6343    0.5838    0.5955       185

micro f-score: 0.5837837837837838

========== Train Epoch 32 ==========
Loss: 0.307	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.5784       185
   macro avg     0.5469    0.5537    0.5424       185
weighted avg     0.6040    0.5784    0.5848       185

micro f-score: 0.5783783783783784

========== Train Epoch 33 ==========
Loss: 0.269	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.6000       185
   macro avg     0.5493    0.5537    0.5470       185
weighted avg     0.6183    0.6000    0.6051       185

micro f-score: 0.6

========== Train Epoch 34 ==========
Loss: 0.257	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5892       185
   macro avg     0.5468    0.5382    0.5343       185
weighted avg     0.5945    0.5892    0.5854       185

micro f-score: 0.5891891891891892

========== Train Epoch 35 ==========
Loss: 0.243	Accuracy: 58.92%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5892       185
   macro avg     0.5477    0.5358    0.5333       185
weighted avg     0.6010    0.5892    0.5863       185

micro f-score: 0.5891891891891892

========== Train Epoch 36 ==========
Loss: 0.223	Accuracy: 61.62%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6216    0.7419    0.6765        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.2609    0.3529    0.3000        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8182    0.8000    0.8090        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.6162       185
   macro avg     0.5744    0.5629    0.5580       185
weighted avg     0.6400    0.6162    0.6191       185

micro f-score: 0.6162162162162163

========== Train Epoch 37 ==========
Loss: 0.211	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6162       185
   macro avg     0.5593    0.5633    0.5533       185
weighted avg     0.6219    0.6162    0.6134       185

micro f-score: 0.6162162162162163

========== Train Epoch 38 ==========
Loss: 0.190	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.7273    0.3636    0.4848        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5892       185
   macro avg     0.5730    0.5482    0.5464       185
weighted avg     0.6199    0.5892    0.5928       185

micro f-score: 0.5891891891891892

========== Train Epoch 39 ==========
Loss: 0.190	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5294    0.5806    0.5538        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.5676       185
   macro avg     0.5489    0.5073    0.5097       185
weighted avg     0.5921    0.5676    0.5595       185

micro f-score: 0.5675675675675675

========== Train Epoch 40 ==========
Loss: 0.181	Accuracy: 60.54%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.7500    0.4839    0.5882        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.4400    0.5789    0.5000        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.6054       185
   macro avg     0.5691    0.5737    0.5635       185
weighted avg     0.6338    0.6054    0.6117       185

micro f-score: 0.6054054054054054

========== Train Epoch 41 ==========
Loss: 0.158	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6154    0.5161    0.5614        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3077    0.4706    0.3721        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5838       185
   macro avg     0.5534    0.5431    0.5378       185
weighted avg     0.6012    0.5838    0.5816       185

micro f-score: 0.5837837837837838

========== Train Epoch 42 ==========
Loss: 0.135	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2414    0.4118    0.3043        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5676       185
   macro avg     0.5440    0.5410    0.5298       185
weighted avg     0.6104    0.5676    0.5771       185

micro f-score: 0.5675675675675675

========== Train Epoch 43 ==========
Loss: 0.152	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7500    0.5806    0.6545        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.5946       185
   macro avg     0.5585    0.5620    0.5523       185
weighted avg     0.6364    0.5946    0.6071       185

micro f-score: 0.5945945945945946

========== Train Epoch 44 ==========
Loss: 0.139	Accuracy: 61.08%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6296    0.5484    0.5862        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3810    0.4211    0.4000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.8750    0.7179    0.7887        39

    accuracy                         0.6108       185
   macro avg     0.5673    0.5724    0.5663       185
weighted avg     0.6369    0.6108    0.6203       185

micro f-score: 0.6108108108108108

========== Train Epoch 45 ==========
Loss: 0.133	Accuracy: 58.92%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2778    0.5882    0.3774        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5892       185
   macro avg     0.6173    0.5602    0.5665       185
weighted avg     0.6431    0.5892    0.5963       185

micro f-score: 0.5891891891891892

========== Train Epoch 46 ==========
Loss: 0.124	Accuracy: 61.62%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5897    0.7419    0.6571        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.6162       185
   macro avg     0.5747    0.5693    0.5661       185
weighted avg     0.6228    0.6162    0.6133       185

micro f-score: 0.6162162162162163

========== Train Epoch 47 ==========
Loss: 0.112	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6786    0.6129    0.6441        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.3462    0.4737    0.4000        19
         nqx     0.7778    0.5833    0.6667        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.8000    0.7179    0.7568        39

    accuracy                         0.6162       185
   macro avg     0.5948    0.5695    0.5764       185
weighted avg     0.6450    0.6162    0.6267       185

micro f-score: 0.6162162162162163

========== Train Epoch 48 ==========
Loss: 0.112	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6333    0.6129    0.6230        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.3929    0.5789    0.4681        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6000       185
   macro avg     0.5542    0.5644    0.5541       185
weighted avg     0.6196    0.6000    0.6053       185

micro f-score: 0.6

========== Train Epoch 49 ==========
Loss: 0.113	Accuracy: 62.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.4500    0.4737    0.4615        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.6216       185
   macro avg     0.5785    0.5805    0.5722       185
weighted avg     0.6412    0.6216    0.6262       185

micro f-score: 0.6216216216216216

========== Train Epoch 50 ==========
Loss: 0.099	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4500    0.4737    0.4615        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5784       185
   macro avg     0.5672    0.5383    0.5317       185
weighted avg     0.6188    0.5784    0.5750       185

micro f-score: 0.5783783783783784

========== Train Epoch 51 ==========
Loss: 0.092	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5946       185
   macro avg     0.5757    0.5566    0.5535       185
weighted avg     0.6218    0.5946    0.5932       185

micro f-score: 0.5945945945945946

========== Train Epoch 52 ==========
Loss: 0.094	Accuracy: 61.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7647    0.4194    0.5417        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4545    0.5263    0.4878        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6909    0.8444    0.7600        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6162       185
   macro avg     0.5858    0.5764    0.5643       185
weighted avg     0.6454    0.6162    0.6146       185

micro f-score: 0.6162162162162163

========== Train Epoch 53 ==========
Loss: 0.092	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3000    0.5294    0.3830        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8235    0.6222    0.7089        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5892       185
   macro avg     0.5692    0.5554    0.5519       185
weighted avg     0.6183    0.5892    0.5937       185

micro f-score: 0.5891891891891892

========== Train Epoch 54 ==========
Loss: 0.097	Accuracy: 62.70%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6111    0.7097    0.6567        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4500    0.4737    0.4615        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.6270       185
   macro avg     0.5951    0.5870    0.5821       185
weighted avg     0.6352    0.6270    0.6227       185

micro f-score: 0.6270270270270271

========== Train Epoch 55 ==========
Loss: 0.090	Accuracy: 57.30%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.3000    0.3529    0.3243        17
         mtx     0.4706    0.4211    0.4444        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5730       185
   macro avg     0.5366    0.5295    0.5199       185
weighted avg     0.5860    0.5730    0.5661       185

micro f-score: 0.572972972972973

========== Train Epoch 56 ==========
Loss: 0.089	Accuracy: 61.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.5000    0.4737    0.4865        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.6108       185
   macro avg     0.5796    0.5775    0.5714       185
weighted avg     0.6315    0.6108    0.6138       185

micro f-score: 0.6108108108108108

========== Train Epoch 57 ==========
Loss: 0.090	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7333    0.3548    0.4783        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5838       185
   macro avg     0.5514    0.5471    0.5297       185
weighted avg     0.6064    0.5838    0.5766       185

micro f-score: 0.5837837837837838

========== Train Epoch 58 ==========
Loss: 0.076	Accuracy: 59.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.8125    0.4194    0.5532        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.4500    0.4737    0.4615        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5946       185
   macro avg     0.5691    0.5498    0.5402       185
weighted avg     0.6218    0.5946    0.5889       185

micro f-score: 0.5945945945945946

========== Train Epoch 59 ==========
Loss: 0.068	Accuracy: 62.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7619    0.5161    0.6154        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.6216       185
   macro avg     0.6080    0.5942    0.5927       185
weighted avg     0.6567    0.6216    0.6312       185

micro f-score: 0.6216216216216216

========== Train Epoch 60 ==========
Loss: 0.071	Accuracy: 62.70%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.4545    0.5263    0.4878        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7660    0.8000    0.7826        45
         zxx     0.7317    0.7692    0.7500        39

    accuracy                         0.6270       185
   macro avg     0.5849    0.5875    0.5815       185
weighted avg     0.6353    0.6270    0.6267       185

micro f-score: 0.6270270270270271

========== Train Epoch 61 ==========
Loss: 0.076	Accuracy: 61.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6923    0.5806    0.6316        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.6162       185
   macro avg     0.5691    0.5757    0.5687       185
weighted avg     0.6362    0.6162    0.6234       185

micro f-score: 0.6162162162162163

========== Train Epoch 62 ==========
Loss: 0.084	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7895    0.4839    0.6000        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4000    0.5263    0.4545        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.6054       185
   macro avg     0.5752    0.5715    0.5599       185
weighted avg     0.6331    0.6054    0.6070       185

micro f-score: 0.6054054054054054

========== Train Epoch 63 ==========
Loss: 0.068	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.5892       185
   macro avg     0.5563    0.5542    0.5495       185
weighted avg     0.6056    0.5892    0.5922       185

micro f-score: 0.5891891891891892

========== Train Epoch 64 ==========
Loss: 0.070	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6800    0.5484    0.6071        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.7436    0.7436    0.7436        39

    accuracy                         0.6054       185
   macro avg     0.5585    0.5631    0.5562       185
weighted avg     0.6195    0.6054    0.6091       185

micro f-score: 0.6054054054054054

Finished training!!!

Min Loss = 0.068 in epoch 62;
Max Accuracy = 65.95% in epoch 28;
Total Cost 49 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
