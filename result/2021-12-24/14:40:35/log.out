dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_resnet18_max3
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.847	Accuracy: 24.32%	Cost 42s
              precision    recall  f1-score   support

         bzx     0.1667    0.0323    0.0541        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.3333    0.2000    0.2500        45
         zxx     0.2313    0.7949    0.3584        39

    accuracy                         0.2432       185
   macro avg     0.1878    0.1781    0.1401       185
weighted avg     0.2136    0.2432    0.1765       185

micro f-score: 0.24324324324324326

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.649	Accuracy: 36.76%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.4364    0.5333    0.4800        45
         zxx     0.3412    0.7436    0.4677        39

    accuracy                         0.3676       185
   macro avg     0.2709    0.2883    0.2570       185
weighted avg     0.3146    0.3676    0.3139       185

micro f-score: 0.3675675675675676

========== Train Epoch 3 ==========
Loss: 1.537	Accuracy: 39.46%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.3596    0.8205    0.5000        39

    accuracy                         0.3946       185
   macro avg     0.3316    0.3143    0.2891       185
weighted avg     0.3734    0.3946    0.3489       185

micro f-score: 0.3945945945945946

========== Train Epoch 4 ==========
Loss: 1.507	Accuracy: 39.46%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.3723    0.8974    0.5263        39

    accuracy                         0.3946       185
   macro avg     0.4028    0.3027    0.2716       185
weighted avg     0.4237    0.3946    0.3375       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.481	Accuracy: 40.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.5476    0.5111    0.5287        45
         zxx     0.3708    0.8462    0.5156        39

    accuracy                         0.4054       185
   macro avg     0.4683    0.3271    0.3135       185
weighted avg     0.4691    0.4054    0.3658       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.453	Accuracy: 42.70%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.3953    0.8718    0.5440        39

    accuracy                         0.4270       185
   macro avg     0.4160    0.3479    0.3401       185
weighted avg     0.4365    0.4270    0.3916       185

micro f-score: 0.427027027027027

========== Train Epoch 7 ==========
Loss: 1.442	Accuracy: 42.16%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4096    0.8718    0.5574        39

    accuracy                         0.4216       185
   macro avg     0.3992    0.3404    0.3259       185
weighted avg     0.4215    0.4216    0.3807       185

micro f-score: 0.42162162162162165

========== Train Epoch 8 ==========
Loss: 1.422	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2593    0.2258    0.2414        31
         cwx     0.4286    0.2727    0.3333        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.4000    0.8718    0.5484        39

    accuracy                         0.4162       185
   macro avg     0.3945    0.3320    0.3168       185
weighted avg     0.4237    0.4162    0.3767       185

micro f-score: 0.41621621621621624

========== Train Epoch 9 ==========
Loss: 1.400	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3333    0.3226    0.3279        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.4286    0.8462    0.5690        39

    accuracy                         0.4432       185
   macro avg     0.4209    0.3632    0.3590       185
weighted avg     0.4453    0.4432    0.4131       185

micro f-score: 0.44324324324324327

========== Train Epoch 10 ==========
Loss: 1.382	Accuracy: 41.62%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.3908    0.8718    0.5397        39

    accuracy                         0.4162       185
   macro avg     0.3890    0.3233    0.3066       185
weighted avg     0.4174    0.4162    0.3712       185

micro f-score: 0.41621621621621624

========== Train Epoch 11 ==========
Loss: 1.349	Accuracy: 43.24%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.2917    0.2258    0.2545        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4324       185
   macro avg     0.3849    0.3596    0.3506       185
weighted avg     0.4205    0.4324    0.4028       185

micro f-score: 0.43243243243243246

========== Train Epoch 12 ==========
Loss: 1.329	Accuracy: 45.95%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5294    0.6000    0.5625        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.4595       185
   macro avg     0.4187    0.3731    0.3649       185
weighted avg     0.4420    0.4595    0.4229       185

micro f-score: 0.4594594594594595

========== Train Epoch 13 ==========
Loss: 1.310	Accuracy: 44.32%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.4432       185
   macro avg     0.4131    0.3655    0.3563       185
weighted avg     0.4403    0.4432    0.4097       185

micro f-score: 0.44324324324324327

========== Train Epoch 14 ==========
Loss: 1.288	Accuracy: 44.86%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4486       185
   macro avg     0.4441    0.3711    0.3671       185
weighted avg     0.4622    0.4486    0.4189       185

micro f-score: 0.4486486486486486

========== Train Epoch 15 ==========
Loss: 1.257	Accuracy: 46.49%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.3438    0.3548    0.3492        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.4649       185
   macro avg     0.4506    0.3931    0.3937       185
weighted avg     0.4748    0.4649    0.4433       185

micro f-score: 0.4648648648648649

========== Train Epoch 16 ==========
Loss: 1.263	Accuracy: 45.95%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3750    0.3871    0.3810        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.4595       185
   macro avg     0.4312    0.3817    0.3698       185
weighted avg     0.4566    0.4595    0.4260       185

micro f-score: 0.4594594594594595

========== Train Epoch 17 ==========
Loss: 1.228	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.3448    0.4545    0.3922        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.4919       185
   macro avg     0.4802    0.4155    0.4114       185
weighted avg     0.5052    0.4919    0.4685       185

micro f-score: 0.4918918918918919

========== Train Epoch 18 ==========
Loss: 1.235	Accuracy: 49.19%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.4919       185
   macro avg     0.4635    0.4123    0.4099       185
weighted avg     0.4932    0.4919    0.4680       185

micro f-score: 0.4918918918918919

========== Train Epoch 19 ==========
Loss: 1.191	Accuracy: 43.78%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4211    0.2581    0.3200        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.7000    0.4667    0.5600        45
         zxx     0.3846    0.8974    0.5385        39

    accuracy                         0.4378       185
   macro avg     0.4628    0.3824    0.3707       185
weighted avg     0.4850    0.4378    0.4085       185

micro f-score: 0.43783783783783786

========== Train Epoch 20 ==========
Loss: 1.181	Accuracy: 52.43%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5243       185
   macro avg     0.5080    0.4762    0.4700       185
weighted avg     0.5305    0.5243    0.5100       185

micro f-score: 0.5243243243243243

========== Train Epoch 21 ==========
Loss: 1.159	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5027       185
   macro avg     0.4790    0.4339    0.4277       185
weighted avg     0.5069    0.5027    0.4778       185

micro f-score: 0.5027027027027027

========== Train Epoch 22 ==========
Loss: 1.151	Accuracy: 49.73%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.4973       185
   macro avg     0.4522    0.4311    0.4195       185
weighted avg     0.4807    0.4973    0.4703       185

micro f-score: 0.4972972972972973

========== Train Epoch 23 ==========
Loss: 1.112	Accuracy: 52.43%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4737    0.2903    0.3600        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.5957    0.6222    0.6087        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5243       185
   macro avg     0.5148    0.4782    0.4710       185
weighted avg     0.5292    0.5243    0.5037       185

micro f-score: 0.5243243243243243

========== Train Epoch 24 ==========
Loss: 1.088	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6875    0.4889    0.5714        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5027       185
   macro avg     0.4830    0.4520    0.4301       185
weighted avg     0.5128    0.5027    0.4741       185

micro f-score: 0.5027027027027027

========== Train Epoch 25 ==========
Loss: 1.067	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4919       185
   macro avg     0.4652    0.4417    0.4336       185
weighted avg     0.4871    0.4919    0.4708       185

micro f-score: 0.4918918918918919

========== Train Epoch 26 ==========
Loss: 1.062	Accuracy: 55.68%	Cost 52s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5568       185
   macro avg     0.5397    0.4903    0.4794       185
weighted avg     0.5655    0.5568    0.5307       185

micro f-score: 0.5567567567567567

========== Train Epoch 27 ==========
Loss: 1.024	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5135       185
   macro avg     0.4744    0.4636    0.4492       185
weighted avg     0.5071    0.5135    0.4919       185

micro f-score: 0.5135135135135135

========== Train Epoch 28 ==========
Loss: 1.032	Accuracy: 50.81%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.3333    0.4091    0.3673        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6667    0.5778    0.6190        45
         zxx     0.4925    0.8462    0.6226        39

    accuracy                         0.5081       185
   macro avg     0.4976    0.4751    0.4523       185
weighted avg     0.5265    0.5081    0.4851       185

micro f-score: 0.5081081081081081

========== Train Epoch 29 ==========
Loss: 1.005	Accuracy: 53.51%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5351       185
   macro avg     0.4767    0.4838    0.4606       185
weighted avg     0.5238    0.5351    0.5146       185

micro f-score: 0.5351351351351351

========== Train Epoch 30 ==========
Loss: 0.982	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4800    0.3871    0.4286        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6429    0.6000    0.6207        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5297       185
   macro avg     0.4843    0.4879    0.4725       185
weighted avg     0.5229    0.5297    0.5151       185

micro f-score: 0.5297297297297298

========== Train Epoch 31 ==========
Loss: 0.965	Accuracy: 52.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5500    0.8462    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.4868    0.4864    0.4668       185
weighted avg     0.5308    0.5243    0.5089       185

micro f-score: 0.5243243243243243

========== Train Epoch 32 ==========
Loss: 0.937	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5405       185
   macro avg     0.5126    0.4826    0.4829       185
weighted avg     0.5350    0.5405    0.5229       185

micro f-score: 0.5405405405405406

========== Train Epoch 33 ==========
Loss: 0.911	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5622       185
   macro avg     0.5275    0.5180    0.4980       185
weighted avg     0.5638    0.5622    0.5422       185

micro f-score: 0.5621621621621622

========== Train Epoch 34 ==========
Loss: 0.913	Accuracy: 57.84%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.5784       185
   macro avg     0.5483    0.5254    0.5159       185
weighted avg     0.5726    0.5784    0.5596       185

micro f-score: 0.5783783783783784

========== Train Epoch 35 ==========
Loss: 0.875	Accuracy: 58.92%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5892       185
   macro avg     0.5776    0.5349    0.5235       185
weighted avg     0.5977    0.5892    0.5676       185

micro f-score: 0.5891891891891892

========== Train Epoch 36 ==========
Loss: 0.854	Accuracy: 56.76%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.5072    0.8974    0.6481        39

    accuracy                         0.5676       185
   macro avg     0.5684    0.5242    0.5162       185
weighted avg     0.6025    0.5676    0.5529       185

micro f-score: 0.5675675675675675

========== Train Epoch 37 ==========
Loss: 0.825	Accuracy: 62.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.5000    0.7273    0.5926        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8750    0.6222    0.7273        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6216       185
   macro avg     0.5949    0.5873    0.5708       185
weighted avg     0.6455    0.6216    0.6146       185

micro f-score: 0.6216216216216216

========== Train Epoch 38 ==========
Loss: 0.824	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5892       185
   macro avg     0.5685    0.5335    0.5191       185
weighted avg     0.6004    0.5892    0.5713       185

micro f-score: 0.5891891891891892

========== Train Epoch 39 ==========
Loss: 0.783	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.4828    0.6364    0.5490        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6000       185
   macro avg     0.5696    0.5622    0.5444       185
weighted avg     0.6144    0.6000    0.5885       185

micro f-score: 0.6

========== Train Epoch 40 ==========
Loss: 0.775	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.4643    0.5909    0.5200        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.6667    0.7556    0.7083        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.6054       185
   macro avg     0.6100    0.5602    0.5562       185
weighted avg     0.6230    0.6054    0.5896       185

micro f-score: 0.6054054054054054

========== Train Epoch 41 ==========
Loss: 0.761	Accuracy: 57.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5730       185
   macro avg     0.5414    0.5208    0.5159       185
weighted avg     0.5742    0.5730    0.5588       185

micro f-score: 0.572972972972973

========== Train Epoch 42 ==========
Loss: 0.732	Accuracy: 62.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6270       185
   macro avg     0.6068    0.5794    0.5761       185
weighted avg     0.6374    0.6270    0.6169       185

micro f-score: 0.6270270270270271

========== Train Epoch 43 ==========
Loss: 0.732	Accuracy: 58.38%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5838       185
   macro avg     0.5595    0.5363    0.5203       185
weighted avg     0.5885    0.5838    0.5585       185

micro f-score: 0.5837837837837838

========== Train Epoch 44 ==========
Loss: 0.710	Accuracy: 60.00%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.5763    0.8718    0.6939        39

    accuracy                         0.6000       185
   macro avg     0.5813    0.5634    0.5492       185
weighted avg     0.6070    0.6000    0.5828       185

micro f-score: 0.6

========== Train Epoch 45 ==========
Loss: 0.679	Accuracy: 57.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5784       185
   macro avg     0.5594    0.5405    0.5290       185
weighted avg     0.5908    0.5784    0.5646       185

micro f-score: 0.5783783783783784

========== Train Epoch 46 ==========
Loss: 0.660	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.6000       185
   macro avg     0.5806    0.5638    0.5559       185
weighted avg     0.6153    0.6000    0.5906       185

micro f-score: 0.6

========== Train Epoch 47 ==========
Loss: 0.643	Accuracy: 61.62%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6111    0.3548    0.4490        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7200    0.8000    0.7579        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.6162       185
   macro avg     0.5927    0.5635    0.5652       185
weighted avg     0.6169    0.6162    0.6041       185

micro f-score: 0.6162162162162163

========== Train Epoch 48 ==========
Loss: 0.629	Accuracy: 62.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6863    0.7778    0.7292        45
         zxx     0.8462    0.8462    0.8462        39

    accuracy                         0.6270       185
   macro avg     0.5861    0.5966    0.5763       185
weighted avg     0.6301    0.6270    0.6183       185

micro f-score: 0.6270270270270271

========== Train Epoch 49 ==========
Loss: 0.601	Accuracy: 61.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5417    0.4194    0.4727        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7674    0.7333    0.7500        45
         zxx     0.7083    0.8718    0.7816        39

    accuracy                         0.6162       185
   macro avg     0.5654    0.5772    0.5584       185
weighted avg     0.6112    0.6162    0.6041       185

micro f-score: 0.6162162162162163

========== Train Epoch 50 ==========
Loss: 0.585	Accuracy: 57.84%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7500    0.6000    0.6667        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5784       185
   macro avg     0.5559    0.5568    0.5432       185
weighted avg     0.5884    0.5784    0.5687       185

micro f-score: 0.5783783783783784

========== Train Epoch 51 ==========
Loss: 0.584	Accuracy: 62.70%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.6270       185
   macro avg     0.6099    0.5877    0.5857       185
weighted avg     0.6315    0.6270    0.6172       185

micro f-score: 0.6270270270270271

========== Train Epoch 52 ==========
Loss: 0.562	Accuracy: 63.24%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.4737    0.5294    0.5000        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.6800    0.8718    0.7640        39

    accuracy                         0.6324       185
   macro avg     0.6099    0.5938    0.5915       185
weighted avg     0.6358    0.6324    0.6227       185

micro f-score: 0.6324324324324324

========== Train Epoch 53 ==========
Loss: 0.533	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6923    0.2903    0.4091        31
         cwx     0.4483    0.5909    0.5098        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5946       185
   macro avg     0.5722    0.5556    0.5433       185
weighted avg     0.6079    0.5946    0.5794       185

micro f-score: 0.5945945945945946

========== Train Epoch 54 ==========
Loss: 0.526	Accuracy: 63.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.4194    0.5909    0.4906        22
         hdx     0.4500    0.5294    0.4865        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6378       185
   macro avg     0.6071    0.6066    0.5993       185
weighted avg     0.6451    0.6378    0.6350       185

micro f-score: 0.6378378378378379

========== Train Epoch 55 ==========
Loss: 0.509	Accuracy: 63.24%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.3226    0.4348        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.5000    0.5882    0.5405        17
         mtx     0.6364    0.3684    0.4667        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7556    0.7556    0.7556        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6324       185
   macro avg     0.6187    0.6068    0.5947       185
weighted avg     0.6407    0.6324    0.6177       185

micro f-score: 0.6324324324324324

========== Train Epoch 56 ==========
Loss: 0.505	Accuracy: 60.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.7333    0.3548    0.4783        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.6054       185
   macro avg     0.5791    0.5705    0.5574       185
weighted avg     0.6236    0.6054    0.5951       185

micro f-score: 0.6054054054054054

========== Train Epoch 57 ==========
Loss: 0.464	Accuracy: 62.16%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.4839    0.6818    0.5660        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6731    0.8974    0.7692        39

    accuracy                         0.6216       185
   macro avg     0.6023    0.6023    0.5826       185
weighted avg     0.6454    0.6216    0.6118       185

micro f-score: 0.6216216216216216

========== Train Epoch 58 ==========
Loss: 0.450	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.4000    0.5882    0.4762        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.6000       185
   macro avg     0.5865    0.5768    0.5591       185
weighted avg     0.6181    0.6000    0.5858       185

micro f-score: 0.6

========== Train Epoch 59 ==========
Loss: 0.442	Accuracy: 58.92%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7500    0.7333    0.7416        45
         zxx     0.7750    0.7949    0.7848        39

    accuracy                         0.5892       185
   macro avg     0.5342    0.5421    0.5353       185
weighted avg     0.5882    0.5892    0.5867       185

micro f-score: 0.5891891891891892

========== Train Epoch 60 ==========
Loss: 0.436	Accuracy: 61.08%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.7500    0.3871    0.5106        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5455    0.3158    0.4000        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6108       185
   macro avg     0.5844    0.5788    0.5621       185
weighted avg     0.6267    0.6108    0.5998       185

micro f-score: 0.6108108108108108

========== Train Epoch 61 ==========
Loss: 0.401	Accuracy: 58.92%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.4643    0.5909    0.5200        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.5385    0.3684    0.4375        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6182    0.8718    0.7234        39

    accuracy                         0.5892       185
   macro avg     0.5661    0.5573    0.5436       185
weighted avg     0.6066    0.5892    0.5777       185

micro f-score: 0.5891891891891892

========== Train Epoch 62 ==========
Loss: 0.401	Accuracy: 62.70%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.4286    0.5294    0.4737        17
         mtx     0.5000    0.4211    0.4571        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.6316    0.9231    0.7500        39

    accuracy                         0.6270       185
   macro avg     0.5984    0.5825    0.5743       185
weighted avg     0.6484    0.6270    0.6185       185

micro f-score: 0.6270270270270271

========== Train Epoch 63 ==========
Loss: 0.398	Accuracy: 60.54%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.8000    0.2581    0.3902        31
         cwx     0.5000    0.6364    0.5600        22
         hdx     0.3929    0.6471    0.4889        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6054       185
   macro avg     0.5943    0.5704    0.5526       185
weighted avg     0.6414    0.6054    0.5912       185

micro f-score: 0.6054054054054054

========== Train Epoch 64 ==========
Loss: 0.384	Accuracy: 62.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.4516    0.6364    0.5283        22
         hdx     0.5000    0.6471    0.5641        17
         mtx     0.5000    0.3684    0.4242        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.7273    0.8205    0.7711        39

    accuracy                         0.6216       185
   macro avg     0.5898    0.6007    0.5804       185
weighted avg     0.6373    0.6216    0.6152       185

micro f-score: 0.6216216216216216

Finished training!!!

Min Loss = 0.384 in epoch 63;
Max Accuracy = 63.78% in epoch 53;
Total Cost 49 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt3: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt3: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt3: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt3: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt3: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt3: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt3: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt3: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.13
Params size (MB): 43.22
Estimated Total Size (MB): 122.52
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_resnet.py", line 330, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_resnet.py", line 313, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
