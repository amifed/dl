dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_cbam_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.871	Accuracy: 24.32%	Cost 41s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.3125    0.1111    0.1639        45
         zxx     0.2215    0.8974    0.3553        39

    accuracy                         0.2432       185
   macro avg     0.2906    0.1982    0.1437       185
weighted avg     0.2741    0.2432    0.1511       185

micro f-score: 0.24324324324324326

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.687	Accuracy: 34.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.2857    0.5161    0.3678        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.4783    0.4889    0.4835        45
         zxx     0.3226    0.5128    0.3960        39

    accuracy                         0.3459       185
   macro avg     0.2357    0.2666    0.2388       185
weighted avg     0.2884    0.3459    0.3034       185

micro f-score: 0.34594594594594597

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.618	Accuracy: 34.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3030    0.3226    0.3125        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.4681    0.4889    0.4783        45
         zxx     0.3210    0.6667    0.4333        39

    accuracy                         0.3459       185
   macro avg     0.2317    0.2609    0.2347       185
weighted avg     0.2833    0.3459    0.2996       185

micro f-score: 0.34594594594594597

========== Train Epoch 4 ==========
Loss: 1.599	Accuracy: 36.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.4583    0.4889    0.4731        45
         zxx     0.3412    0.7436    0.4677        39

    accuracy                         0.3676       185
   macro avg     0.2539    0.2838    0.2553       185
weighted avg     0.3015    0.3676    0.3163       185

micro f-score: 0.3675675675675676

========== Train Epoch 5 ==========
Loss: 1.598	Accuracy: 37.30%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.3226    0.3279        31
         cwx     0.3333    0.1818    0.2353        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5000    0.4889    0.4944        45
         zxx     0.3488    0.7692    0.4800        39

    accuracy                         0.3730       185
   macro avg     0.2555    0.2875    0.2569       185
weighted avg     0.3083    0.3730    0.3213       185

micro f-score: 0.37297297297297294

========== Train Epoch 6 ==========
Loss: 1.583	Accuracy: 37.84%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3333    0.2903    0.3103        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5000    0.5111    0.5055        45
         zxx     0.3444    0.7949    0.4806        39

    accuracy                         0.3784       185
   macro avg     0.2683    0.2897    0.2599       185
weighted avg     0.3171    0.3784    0.3237       185

micro f-score: 0.37837837837837834

========== Train Epoch 7 ==========
Loss: 1.558	Accuracy: 38.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3448    0.3226    0.3333        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3478    0.8205    0.4885        39

    accuracy                         0.3838       185
   macro avg     0.2704    0.2948    0.2641       185
weighted avg     0.3243    0.3838    0.3298       185

micro f-score: 0.3837837837837838

========== Train Epoch 8 ==========
Loss: 1.548	Accuracy: 41.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3548    0.3548    0.3548        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5217    0.5333    0.5275        45
         zxx     0.3810    0.8205    0.5203        39

    accuracy                         0.4108       185
   macro avg     0.3427    0.3252    0.2999       185
weighted avg     0.3774    0.4108    0.3600       185

micro f-score: 0.4108108108108109

========== Train Epoch 9 ==========
Loss: 1.533	Accuracy: 38.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.3587    0.8462    0.5038        39

    accuracy                         0.3892       185
   macro avg     0.2738    0.2985    0.2671       185
weighted avg     0.3278    0.3892    0.3335       185

micro f-score: 0.3891891891891892

========== Train Epoch 10 ==========
Loss: 1.520	Accuracy: 42.16%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.3711    0.9231    0.5294        39

    accuracy                         0.4216       185
   macro avg     0.3778    0.3306    0.3012       185
weighted avg     0.4121    0.4216    0.3640       185

micro f-score: 0.42162162162162165

========== Train Epoch 11 ==========
Loss: 1.504	Accuracy: 40.54%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.3587    0.8462    0.5038        39

    accuracy                         0.4054       185
   macro avg     0.3384    0.3138    0.2914       185
weighted avg     0.3828    0.4054    0.3575       185

micro f-score: 0.40540540540540543

========== Train Epoch 12 ==========
Loss: 1.490	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3250    0.4194    0.3662        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4026    0.7949    0.5345        39

    accuracy                         0.4162       185
   macro avg     0.3705    0.3308    0.3068       185
weighted avg     0.4029    0.4162    0.3697       185

micro f-score: 0.41621621621621624

========== Train Epoch 13 ==========
Loss: 1.474	Accuracy: 41.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4231    0.3548    0.3860        31
         cwx     0.5000    0.2273    0.3125        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3579    0.8718    0.5075        39

    accuracy                         0.4162       185
   macro avg     0.3870    0.3327    0.3104       185
weighted avg     0.4180    0.4162    0.3686       185

micro f-score: 0.41621621621621624

========== Train Epoch 14 ==========
Loss: 1.457	Accuracy: 42.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.3908    0.8718    0.5397        39

    accuracy                         0.4216       185
   macro avg     0.3444    0.3290    0.3103       185
weighted avg     0.3827    0.4216    0.3736       185

micro f-score: 0.42162162162162165

========== Train Epoch 15 ==========
Loss: 1.434	Accuracy: 42.16%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3871    0.3871    0.3871        31
         cwx     0.5000    0.1818    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.4216       185
   macro avg     0.3476    0.3335    0.3112       185
weighted avg     0.3884    0.4216    0.3736       185

micro f-score: 0.42162162162162165

========== Train Epoch 16 ==========
Loss: 1.420	Accuracy: 43.78%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3846    0.4839    0.4286        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4306    0.7949    0.5586        39

    accuracy                         0.4378       185
   macro avg     0.3592    0.3530    0.3281       185
weighted avg     0.4046    0.4378    0.3943       185

micro f-score: 0.43783783783783786

========== Train Epoch 17 ==========
Loss: 1.412	Accuracy: 42.70%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.3636    0.3871    0.3750        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4024    0.8462    0.5455        39

    accuracy                         0.4270       185
   macro avg     0.3638    0.3400    0.3161       185
weighted avg     0.4035    0.4270    0.3798       185

micro f-score: 0.427027027027027

========== Train Epoch 18 ==========
Loss: 1.388	Accuracy: 41.62%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3929    0.8462    0.5366        39

    accuracy                         0.4162       185
   macro avg     0.3356    0.3263    0.3065       185
weighted avg     0.3755    0.4162    0.3697       185

micro f-score: 0.41621621621621624

========== Train Epoch 19 ==========
Loss: 1.383	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.4615    0.2727    0.3429        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4024    0.8462    0.5455        39

    accuracy                         0.4378       185
   macro avg     0.3643    0.3511    0.3326       185
weighted avg     0.4026    0.4378    0.3935       185

micro f-score: 0.43783783783783786

========== Train Epoch 20 ==========
Loss: 1.360	Accuracy: 44.32%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4333    0.4194    0.4262        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.4074    0.8462    0.5500        39

    accuracy                         0.4432       185
   macro avg     0.3700    0.3663    0.3484       185
weighted avg     0.4126    0.4432    0.4046       185

micro f-score: 0.44324324324324327

========== Train Epoch 21 ==========
Loss: 1.347	Accuracy: 43.78%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4000    0.3871    0.3934        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.4074    0.8462    0.5500        39

    accuracy                         0.4378       185
   macro avg     0.3947    0.3603    0.3480       185
weighted avg     0.4146    0.4378    0.3969       185

micro f-score: 0.43783783783783786

========== Train Epoch 22 ==========
Loss: 1.355	Accuracy: 47.03%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.4688    0.7692    0.5825        39

    accuracy                         0.4703       185
   macro avg     0.3967    0.3931    0.3733       185
weighted avg     0.4339    0.4703    0.4327       185

micro f-score: 0.4702702702702703

========== Train Epoch 23 ==========
Loss: 1.326	Accuracy: 45.41%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.5333    0.3636    0.4324        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.4000    0.8205    0.5378        39

    accuracy                         0.4541       185
   macro avg     0.3944    0.3754    0.3619       185
weighted avg     0.4305    0.4541    0.4174       185

micro f-score: 0.4540540540540541

========== Train Epoch 24 ==========
Loss: 1.324	Accuracy: 49.73%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.5439    0.7949    0.6458        39

    accuracy                         0.4973       185
   macro avg     0.4405    0.4266    0.4199       185
weighted avg     0.4699    0.4973    0.4712       185

micro f-score: 0.4972972972972973

========== Train Epoch 25 ==========
Loss: 1.302	Accuracy: 48.11%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5102    0.5556    0.5319        45
         zxx     0.5172    0.7692    0.6186        39

    accuracy                         0.4811       185
   macro avg     0.4196    0.4115    0.3918       185
weighted avg     0.4438    0.4811    0.4425       185

micro f-score: 0.4810810810810811

========== Train Epoch 26 ==========
Loss: 1.297	Accuracy: 49.73%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.4973       185
   macro avg     0.4521    0.4349    0.4254       185
weighted avg     0.4783    0.4973    0.4703       185

micro f-score: 0.4972972972972973

========== Train Epoch 27 ==========
Loss: 1.294	Accuracy: 50.81%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.4928    0.8718    0.6296        39

    accuracy                         0.5081       185
   macro avg     0.4880    0.4413    0.4297       185
weighted avg     0.5069    0.5081    0.4772       185

micro f-score: 0.5081081081081081

========== Train Epoch 28 ==========
Loss: 1.267	Accuracy: 49.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.5345    0.7949    0.6392        39

    accuracy                         0.4919       185
   macro avg     0.4438    0.4294    0.4180       185
weighted avg     0.4736    0.4919    0.4670       185

micro f-score: 0.4918918918918919

========== Train Epoch 29 ==========
Loss: 1.263	Accuracy: 48.11%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5435    0.5556    0.5495        45
         zxx     0.4615    0.7692    0.5769        39

    accuracy                         0.4811       185
   macro avg     0.4608    0.4176    0.4189       185
weighted avg     0.4755    0.4811    0.4600       185

micro f-score: 0.4810810810810811

========== Train Epoch 30 ==========
Loss: 1.253	Accuracy: 51.35%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5135       185
   macro avg     0.4893    0.4559    0.4548       185
weighted avg     0.5027    0.5135    0.4926       185

micro f-score: 0.5135135135135135

========== Train Epoch 31 ==========
Loss: 1.236	Accuracy: 48.65%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.4865       185
   macro avg     0.4871    0.4180    0.4085       185
weighted avg     0.4966    0.4865    0.4518       185

micro f-score: 0.4864864864864865

========== Train Epoch 32 ==========
Loss: 1.222	Accuracy: 50.27%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4474    0.5484    0.4928        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6250    0.5556    0.5882        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5027       185
   macro avg     0.4528    0.4347    0.4163       185
weighted avg     0.4850    0.5027    0.4696       185

micro f-score: 0.5027027027027027

========== Train Epoch 33 ==========
Loss: 1.213	Accuracy: 50.27%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4615    0.5806    0.5143        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.5077    0.8462    0.6346        39

    accuracy                         0.5027       185
   macro avg     0.4329    0.4396    0.4176       185
weighted avg     0.4753    0.5027    0.4699       185

micro f-score: 0.5027027027027027

========== Train Epoch 34 ==========
Loss: 1.219	Accuracy: 50.81%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6047    0.5778    0.5909        45
         zxx     0.5000    0.7949    0.6139        39

    accuracy                         0.5081       185
   macro avg     0.4732    0.4538    0.4434       185
weighted avg     0.4960    0.5081    0.4841       185

micro f-score: 0.5081081081081081

========== Train Epoch 35 ==========
Loss: 1.187	Accuracy: 49.19%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6047    0.5778    0.5909        45
         zxx     0.4706    0.8205    0.5981        39

    accuracy                         0.4919       185
   macro avg     0.4093    0.4259    0.4091       185
weighted avg     0.4492    0.4919    0.4592       185

micro f-score: 0.4918918918918919

========== Train Epoch 36 ==========
Loss: 1.183	Accuracy: 51.89%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5189       185
   macro avg     0.4627    0.4668    0.4555       185
weighted avg     0.4996    0.5189    0.5003       185

micro f-score: 0.518918918918919

========== Train Epoch 37 ==========
Loss: 1.174	Accuracy: 52.97%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.5517    0.8205    0.6598        39

    accuracy                         0.5297       185
   macro avg     0.4980    0.4750    0.4622       185
weighted avg     0.5249    0.5297    0.5067       185

micro f-score: 0.5297297297297298

========== Train Epoch 38 ==========
Loss: 1.173	Accuracy: 51.89%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.4697    0.7949    0.5905        39

    accuracy                         0.5189       185
   macro avg     0.5181    0.4684    0.4566       185
weighted avg     0.5264    0.5189    0.4923       185

micro f-score: 0.518918918918919

========== Train Epoch 39 ==========
Loss: 1.164	Accuracy: 51.35%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5135       185
   macro avg     0.4569    0.4574    0.4472       185
weighted avg     0.4912    0.5135    0.4921       185

micro f-score: 0.5135135135135135

========== Train Epoch 40 ==========
Loss: 1.142	Accuracy: 53.51%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5263    0.6452    0.5797        31
         cwx     0.4211    0.3636    0.3902        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5161    0.8205    0.6337        39

    accuracy                         0.5351       185
   macro avg     0.5163    0.4811    0.4710       185
weighted avg     0.5351    0.5351    0.5107       185

micro f-score: 0.5351351351351351

========== Train Epoch 41 ==========
Loss: 1.116	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.6129    0.5507        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.4776    0.8205    0.6038        39

    accuracy                         0.5297       185
   macro avg     0.5403    0.4727    0.4612       185
weighted avg     0.5528    0.5297    0.5030       185

micro f-score: 0.5297297297297298

========== Train Epoch 42 ==========
Loss: 1.132	Accuracy: 52.97%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5297       185
   macro avg     0.4748    0.4788    0.4658       185
weighted avg     0.5149    0.5297    0.5113       185

micro f-score: 0.5297297297297298

========== Train Epoch 43 ==========
Loss: 1.106	Accuracy: 55.14%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6667    0.5778    0.6190        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5514       185
   macro avg     0.5043    0.5103    0.4967       185
weighted avg     0.5424    0.5514    0.5382       185

micro f-score: 0.5513513513513514

========== Train Epoch 44 ==========
Loss: 1.089	Accuracy: 54.05%	Cost 50s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5405       185
   macro avg     0.5058    0.4992    0.4896       185
weighted avg     0.5352    0.5405    0.5252       185

micro f-score: 0.5405405405405406

========== Train Epoch 45 ==========
Loss: 1.099	Accuracy: 51.35%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5135       185
   macro avg     0.4571    0.4679    0.4555       185
weighted avg     0.4991    0.5135    0.4996       185

micro f-score: 0.5135135135135135

========== Train Epoch 46 ==========
Loss: 1.072	Accuracy: 54.05%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.6129    0.5507        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.4839    0.7692    0.5941        39

    accuracy                         0.5405       185
   macro avg     0.5436    0.4875    0.4782       185
weighted avg     0.5485    0.5405    0.5141       185

micro f-score: 0.5405405405405406

========== Train Epoch 47 ==========
Loss: 1.079	Accuracy: 51.89%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5189       185
   macro avg     0.4604    0.4729    0.4591       185
weighted avg     0.5100    0.5189    0.5058       185

micro f-score: 0.518918918918919

========== Train Epoch 48 ==========
Loss: 1.049	Accuracy: 52.97%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4667    0.6774    0.5526        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6857    0.5333    0.6000        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5297       185
   macro avg     0.4610    0.4740    0.4495       185
weighted avg     0.5088    0.5297    0.5023       185

micro f-score: 0.5297297297297298

========== Train Epoch 49 ==========
Loss: 1.051	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5459       185
   macro avg     0.4950    0.5082    0.4843       185
weighted avg     0.5431    0.5459    0.5289       185

micro f-score: 0.5459459459459459

========== Train Epoch 50 ==========
Loss: 1.042	Accuracy: 52.97%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4667    0.6774    0.5526        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.5769    0.7692    0.6593        39

    accuracy                         0.5297       185
   macro avg     0.5223    0.4918    0.4657       185
weighted avg     0.5549    0.5297    0.5079       185

micro f-score: 0.5297297297297298

========== Train Epoch 51 ==========
Loss: 1.025	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5536    0.7949    0.6526        39

    accuracy                         0.5459       185
   macro avg     0.5366    0.4940    0.4812       185
weighted avg     0.5562    0.5459    0.5241       185

micro f-score: 0.5459459459459459

========== Train Epoch 52 ==========
Loss: 1.012	Accuracy: 54.59%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4878    0.6452    0.5556        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6842    0.5778    0.6265        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5459       185
   macro avg     0.4937    0.5085    0.4912       185
weighted avg     0.5420    0.5459    0.5362       185

micro f-score: 0.5459459459459459

========== Train Epoch 53 ==========
Loss: 1.011	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5189       185
   macro avg     0.4659    0.4717    0.4505       185
weighted avg     0.5105    0.5189    0.4961       185

micro f-score: 0.518918918918919

========== Train Epoch 54 ==========
Loss: 0.999	Accuracy: 53.51%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4318    0.6129    0.5067        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5351       185
   macro avg     0.4911    0.4974    0.4783       185
weighted avg     0.5351    0.5351    0.5200       185

micro f-score: 0.5351351351351351

========== Train Epoch 55 ==========
Loss: 0.986	Accuracy: 55.68%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.6452    0.5634        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5568       185
   macro avg     0.5429    0.5049    0.4836       185
weighted avg     0.5757    0.5568    0.5315       185

micro f-score: 0.5567567567567567

========== Train Epoch 56 ==========
Loss: 0.988	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5459       185
   macro avg     0.4960    0.5063    0.4852       185
weighted avg     0.5430    0.5459    0.5280       185

micro f-score: 0.5459459459459459

========== Train Epoch 57 ==========
Loss: 0.960	Accuracy: 52.97%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.5297       185
   macro avg     0.4913    0.4852    0.4704       185
weighted avg     0.5263    0.5297    0.5094       185

micro f-score: 0.5297297297297298

========== Train Epoch 58 ==========
Loss: 0.958	Accuracy: 56.22%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5622       185
   macro avg     0.5068    0.5245    0.5016       185
weighted avg     0.5534    0.5622    0.5455       185

micro f-score: 0.5621621621621622

========== Train Epoch 59 ==========
Loss: 0.943	Accuracy: 55.14%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5514       185
   macro avg     0.5061    0.5156    0.4919       185
weighted avg     0.5500    0.5514    0.5349       185

micro f-score: 0.5513513513513514

========== Train Epoch 60 ==========
Loss: 0.930	Accuracy: 55.68%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.5636    0.7949    0.6596        39

    accuracy                         0.5568       185
   macro avg     0.5408    0.5193    0.4922       185
weighted avg     0.5758    0.5568    0.5364       185

micro f-score: 0.5567567567567567

========== Train Epoch 61 ==========
Loss: 0.918	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6383    0.6667    0.6522        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5514       185
   macro avg     0.4963    0.5026    0.4832       185
weighted avg     0.5401    0.5514    0.5338       185

micro f-score: 0.5513513513513514

========== Train Epoch 62 ==========
Loss: 0.921	Accuracy: 53.51%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4634    0.6129    0.5278        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.6500    0.6667    0.6582        39

    accuracy                         0.5351       185
   macro avg     0.4899    0.5151    0.4926       185
weighted avg     0.5398    0.5351    0.5284       185

micro f-score: 0.5351351351351351

========== Train Epoch 63 ==========
Loss: 0.886	Accuracy: 57.30%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5938    0.6129    0.6032        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5730       185
   macro avg     0.5543    0.5336    0.5170       185
weighted avg     0.5821    0.5730    0.5550       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Loss: 0.887	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5622       185
   macro avg     0.5204    0.5287    0.5085       185
weighted avg     0.5593    0.5622    0.5475       185

micro f-score: 0.5621621621621622

Finished training!!!

Min Loss = 0.886 in epoch 62;
Max Accuracy = 57.30% in epoch 62;
Total Cost 50 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          1,788
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          1,788
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         3,452
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         3,452
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         6,780
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         6,780
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         25,748
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         25,748
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,255,639
Trainable params: 11,255,639
Non-trainable params: 0
Total mult-adds (G): 3.72
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 77.34
Params size (MB): 42.94
Estimated Total Size (MB): 121.45
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_cbam_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_cbam_resnet.py", line 329, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_cbam_resnet.py", line 312, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
