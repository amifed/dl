dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_cbam_resnet18_max
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.832	Accuracy: 29.19%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.2667    0.3871    0.3158        31
         cwx     0.1875    0.1364    0.1579        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.3258    0.6444    0.4328        45
         zxx     0.2222    0.1026    0.1404        39

    accuracy                         0.2919       185
   macro avg     0.2424    0.2442    0.2251       185
weighted avg     0.2476    0.2919    0.2465       185

micro f-score: 0.2918918918918919

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.616	Accuracy: 37.30%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.2500    0.2903    0.2687        31
         cwx     0.3000    0.1364    0.1875        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.4750    0.4222    0.4471        45
         zxx     0.4024    0.8462    0.5455        39

    accuracy                         0.3730       185
   macro avg     0.2797    0.2973    0.2681       185
weighted avg     0.3187    0.3730    0.3218       185

micro f-score: 0.37297297297297294

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.492	Accuracy: 41.62%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.3929    0.3548    0.3729        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5122    0.4667    0.4884        45
         zxx     0.4268    0.8974    0.5785        39

    accuracy                         0.4162       185
   macro avg     0.3653    0.3307    0.3118       185
weighted avg     0.3969    0.4162    0.3722       185

micro f-score: 0.41621621621621624

========== Train Epoch 4 ==========
Loss: 1.466	Accuracy: 39.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.4583    0.4889    0.4731        45
         zxx     0.3793    0.8462    0.5238        39

    accuracy                         0.3946       185
   macro avg     0.3594    0.3146    0.3001       185
weighted avg     0.3839    0.3946    0.3513       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.429	Accuracy: 40.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     0.5385    0.4667    0.5000        45
         zxx     0.3953    0.8718    0.5440        39

    accuracy                         0.4054       185
   macro avg     0.3210    0.3205    0.2990       185
weighted avg     0.3677    0.4054    0.3606       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.410	Accuracy: 40.54%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2222    0.1667    0.1905        12
         qtx     0.4889    0.4889    0.4889        45
         zxx     0.3810    0.8205    0.5203        39

    accuracy                         0.4054       185
   macro avg     0.3786    0.3231    0.3157       185
weighted avg     0.4046    0.4054    0.3708       185

micro f-score: 0.40540540540540543

========== Train Epoch 7 ==========
Loss: 1.392	Accuracy: 41.08%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5946    0.4889    0.5366        45
         zxx     0.3723    0.8974    0.5263        39

    accuracy                         0.4108       185
   macro avg     0.3788    0.3230    0.3132       185
weighted avg     0.4145    0.4108    0.3729       185

micro f-score: 0.4108108108108109

========== Train Epoch 8 ==========
Loss: 1.372	Accuracy: 45.41%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5946    0.4889    0.5366        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4541       185
   macro avg     0.4275    0.3738    0.3676       185
weighted avg     0.4579    0.4541    0.4238       185

micro f-score: 0.4540540540540541

========== Train Epoch 9 ==========
Loss: 1.357	Accuracy: 45.41%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5714    0.4444    0.5000        45
         zxx     0.4648    0.8462    0.6000        39

    accuracy                         0.4541       185
   macro avg     0.4050    0.3868    0.3766       185
weighted avg     0.4422    0.4541    0.4274       185

micro f-score: 0.4540540540540541

========== Train Epoch 10 ==========
Loss: 1.306	Accuracy: 42.70%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.3976    0.8462    0.5410        39

    accuracy                         0.4270       185
   macro avg     0.3992    0.3503    0.3464       185
weighted avg     0.4236    0.4270    0.3956       185

micro f-score: 0.427027027027027

========== Train Epoch 11 ==========
Loss: 1.298	Accuracy: 46.49%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5946    0.4889    0.5366        45
         zxx     0.4648    0.8462    0.6000        39

    accuracy                         0.4649       185
   macro avg     0.4144    0.3915    0.3878       185
weighted avg     0.4514    0.4649    0.4410       185

micro f-score: 0.4648648648648649

========== Train Epoch 12 ==========
Loss: 1.273	Accuracy: 47.03%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.4521    0.8462    0.5893        39

    accuracy                         0.4703       185
   macro avg     0.4426    0.4112    0.4032       185
weighted avg     0.4676    0.4703    0.4447       185

micro f-score: 0.4702702702702703

========== Train Epoch 13 ==========
Loss: 1.241	Accuracy: 47.57%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6111    0.4889    0.5432        45
         zxx     0.4459    0.8462    0.5841        39

    accuracy                         0.4757       185
   macro avg     0.4398    0.4134    0.4088       185
weighted avg     0.4704    0.4757    0.4528       185

micro f-score: 0.4756756756756757

========== Train Epoch 14 ==========
Loss: 1.237	Accuracy: 48.65%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.4789    0.8718    0.6182        39

    accuracy                         0.4865       185
   macro avg     0.4487    0.4290    0.4184       185
weighted avg     0.4745    0.4865    0.4597       185

micro f-score: 0.4864864864864865

========== Train Epoch 15 ==========
Loss: 1.197	Accuracy: 50.81%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5081       185
   macro avg     0.4653    0.4566    0.4415       185
weighted avg     0.4958    0.5081    0.4841       185

micro f-score: 0.5081081081081081

========== Train Epoch 16 ==========
Loss: 1.189	Accuracy: 48.65%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.4865       185
   macro avg     0.4335    0.4212    0.4156       185
weighted avg     0.4617    0.4865    0.4621       185

micro f-score: 0.4864864864864865

========== Train Epoch 17 ==========
Loss: 1.162	Accuracy: 49.19%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6667    0.4889    0.5641        45
         zxx     0.4658    0.8718    0.6071        39

    accuracy                         0.4919       185
   macro avg     0.4603    0.4355    0.4289       185
weighted avg     0.4897    0.4919    0.4687       185

micro f-score: 0.4918918918918919

========== Train Epoch 18 ==========
Loss: 1.146	Accuracy: 50.27%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5000    0.5556    0.5263        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5027       185
   macro avg     0.4547    0.4385    0.4303       185
weighted avg     0.4771    0.5027    0.4741       185

micro f-score: 0.5027027027027027

========== Train Epoch 19 ==========
Loss: 1.106	Accuracy: 51.89%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.4458    0.9487    0.6066        39

    accuracy                         0.5189       185
   macro avg     0.5175    0.4621    0.4533       185
weighted avg     0.5404    0.5189    0.4917       185

micro f-score: 0.518918918918919

========== Train Epoch 20 ==========
Loss: 1.092	Accuracy: 50.27%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5789    0.3548    0.4400        31
         cwx     0.3235    0.5000    0.3929        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6000    0.5333    0.5647        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5027       185
   macro avg     0.4545    0.4587    0.4441       185
weighted avg     0.5009    0.5027    0.4893       185

micro f-score: 0.5027027027027027

========== Train Epoch 21 ==========
Loss: 1.083	Accuracy: 51.35%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4706    0.5161    0.4923        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.5410    0.8462    0.6600        39

    accuracy                         0.5135       185
   macro avg     0.4730    0.4645    0.4514       185
weighted avg     0.4964    0.5135    0.4887       185

micro f-score: 0.5135135135135135

========== Train Epoch 22 ==========
Loss: 1.056	Accuracy: 50.27%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.5027       185
   macro avg     0.4850    0.4500    0.4438       185
weighted avg     0.5081    0.5027    0.4823       185

micro f-score: 0.5027027027027027

========== Train Epoch 23 ==========
Loss: 1.027	Accuracy: 51.89%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5189       185
   macro avg     0.4766    0.4831    0.4641       185
weighted avg     0.5036    0.5189    0.4951       185

micro f-score: 0.518918918918919

========== Train Epoch 24 ==========
Loss: 0.998	Accuracy: 50.81%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6316    0.5333    0.5783        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5081       185
   macro avg     0.4546    0.4519    0.4377       185
weighted avg     0.4879    0.5081    0.4823       185

micro f-score: 0.5081081081081081

========== Train Epoch 25 ==========
Loss: 0.981	Accuracy: 55.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.5568       185
   macro avg     0.5065    0.5096    0.4917       185
weighted avg     0.5413    0.5568    0.5329       185

micro f-score: 0.5567567567567567

========== Train Epoch 26 ==========
Loss: 0.963	Accuracy: 55.14%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5514       185
   macro avg     0.5123    0.5041    0.4924       185
weighted avg     0.5443    0.5514    0.5320       185

micro f-score: 0.5513513513513514

========== Train Epoch 27 ==========
Loss: 0.947	Accuracy: 51.35%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8000    0.4444    0.5714        45
         zxx     0.4557    0.9231    0.6102        39

    accuracy                         0.5135       185
   macro avg     0.5063    0.4704    0.4500       185
weighted avg     0.5381    0.5135    0.4830       185

micro f-score: 0.5135135135135135

========== Train Epoch 28 ==========
Loss: 0.933	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.6275    0.8205    0.7111        39

    accuracy                         0.5459       185
   macro avg     0.4939    0.5075    0.4866       185
weighted avg     0.5381    0.5459    0.5308       185

micro f-score: 0.5459459459459459

========== Train Epoch 29 ==========
Loss: 0.905	Accuracy: 56.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6500    0.5778    0.6118        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5622       185
   macro avg     0.5016    0.5196    0.5042       185
weighted avg     0.5515    0.5622    0.5523       185

micro f-score: 0.5621621621621622

========== Train Epoch 30 ==========
Loss: 0.885	Accuracy: 56.76%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5676       185
   macro avg     0.5060    0.5213    0.5078       185
weighted avg     0.5608    0.5676    0.5577       185

micro f-score: 0.5675675675675675

========== Train Epoch 31 ==========
Loss: 0.847	Accuracy: 55.14%	Cost 49s
              precision    recall  f1-score   support

         bzx     0.6522    0.4839    0.5556        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6667    0.6222    0.6437        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5514       185
   macro avg     0.5438    0.4998    0.4815       185
weighted avg     0.5695    0.5514    0.5268       185

micro f-score: 0.5513513513513514

========== Train Epoch 32 ==========
Loss: 0.812	Accuracy: 57.84%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5784       185
   macro avg     0.5180    0.5209    0.5015       185
weighted avg     0.5635    0.5784    0.5566       185

micro f-score: 0.5783783783783784

========== Train Epoch 33 ==========
Loss: 0.814	Accuracy: 55.14%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.5514       185
   macro avg     0.5072    0.5197    0.5002       185
weighted avg     0.5508    0.5514    0.5358       185

micro f-score: 0.5513513513513514

========== Train Epoch 34 ==========
Loss: 0.783	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7576    0.5556    0.6410        45
         zxx     0.5385    0.8974    0.6731        39

    accuracy                         0.5459       185
   macro avg     0.5137    0.5081    0.4939       185
weighted avg     0.5581    0.5459    0.5311       185

micro f-score: 0.5459459459459459

========== Train Epoch 35 ==========
Loss: 0.776	Accuracy: 60.00%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6000       185
   macro avg     0.5650    0.5577    0.5517       185
weighted avg     0.5887    0.6000    0.5858       185

micro f-score: 0.6

========== Train Epoch 36 ==========
Loss: 0.756	Accuracy: 56.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5622       185
   macro avg     0.5265    0.5254    0.5115       185
weighted avg     0.5663    0.5622    0.5496       185

micro f-score: 0.5621621621621622

========== Train Epoch 37 ==========
Loss: 0.714	Accuracy: 54.59%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3571    0.2941    0.3226        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.6383    0.7692    0.6977        39

    accuracy                         0.5459       185
   macro avg     0.4910    0.5121    0.4934       185
weighted avg     0.5381    0.5459    0.5364       185

micro f-score: 0.5459459459459459

========== Train Epoch 38 ==========
Loss: 0.694	Accuracy: 58.92%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.5892       185
   macro avg     0.5302    0.5476    0.5345       185
weighted avg     0.5833    0.5892    0.5822       185

micro f-score: 0.5891891891891892

========== Train Epoch 39 ==========
Loss: 0.661	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5676       185
   macro avg     0.5325    0.5194    0.5177       185
weighted avg     0.5676    0.5676    0.5563       185

micro f-score: 0.5675675675675675

========== Train Epoch 40 ==========
Loss: 0.642	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.5838       185
   macro avg     0.5281    0.5444    0.5319       185
weighted avg     0.5760    0.5838    0.5762       185

micro f-score: 0.5837837837837838

========== Train Epoch 41 ==========
Loss: 0.630	Accuracy: 58.38%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.8108    0.7692    0.7895        39

    accuracy                         0.5838       185
   macro avg     0.5378    0.5607    0.5354       185
weighted avg     0.5943    0.5838    0.5816       185

micro f-score: 0.5837837837837838

========== Train Epoch 42 ==========
Loss: 0.604	Accuracy: 58.38%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.5838       185
   macro avg     0.5390    0.5457    0.5336       185
weighted avg     0.5710    0.5838    0.5689       185

micro f-score: 0.5837837837837838

========== Train Epoch 43 ==========
Loss: 0.586	Accuracy: 59.46%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.5946       185
   macro avg     0.5480    0.5549    0.5439       185
weighted avg     0.5849    0.5946    0.5842       185

micro f-score: 0.5945945945945946

========== Train Epoch 44 ==========
Loss: 0.581	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5263    0.4545    0.4878        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6531    0.7111    0.6809        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5730       185
   macro avg     0.5200    0.5331    0.5184       185
weighted avg     0.5525    0.5730    0.5565       185

micro f-score: 0.572972972972973

========== Train Epoch 45 ==========
Loss: 0.537	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.6471    0.8462    0.7333        39

    accuracy                         0.5730       185
   macro avg     0.5237    0.5307    0.5190       185
weighted avg     0.5685    0.5730    0.5633       185

micro f-score: 0.572972972972973

========== Train Epoch 46 ==========
Loss: 0.534	Accuracy: 56.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5676       185
   macro avg     0.5239    0.5439    0.5234       185
weighted avg     0.5600    0.5676    0.5545       185

micro f-score: 0.5675675675675675

========== Train Epoch 47 ==========
Loss: 0.503	Accuracy: 58.38%	Cost 44s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.5838       185
   macro avg     0.5292    0.5577    0.5348       185
weighted avg     0.5728    0.5838    0.5729       185

micro f-score: 0.5837837837837838

========== Train Epoch 48 ==========
Loss: 0.501	Accuracy: 57.84%	Cost 48s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5784       185
   macro avg     0.5394    0.5451    0.5242       185
weighted avg     0.5727    0.5784    0.5622       185

micro f-score: 0.5783783783783784

========== Train Epoch 49 ==========
Loss: 0.452	Accuracy: 56.76%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5714    0.3871    0.4615        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5676       185
   macro avg     0.5388    0.5393    0.5222       185
weighted avg     0.5700    0.5676    0.5547       185

micro f-score: 0.5675675675675675

========== Train Epoch 50 ==========
Loss: 0.454	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     0.6875    0.8462    0.7586        39

    accuracy                         0.6000       185
   macro avg     0.5466    0.5678    0.5470       185
weighted avg     0.5916    0.6000    0.5882       185

micro f-score: 0.6

========== Train Epoch 51 ==========
Loss: 0.445	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6000       185
   macro avg     0.5568    0.5580    0.5505       185
weighted avg     0.5938    0.6000    0.5887       185

micro f-score: 0.6

========== Train Epoch 52 ==========
Loss: 0.414	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2941    0.2632    0.2778        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.6226    0.8462    0.7174        39

    accuracy                         0.5676       185
   macro avg     0.5270    0.5193    0.5184       185
weighted avg     0.5569    0.5676    0.5562       185

micro f-score: 0.5675675675675675

========== Train Epoch 53 ==========
Loss: 0.404	Accuracy: 56.76%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6829    0.6222    0.6512        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.5676       185
   macro avg     0.5398    0.5367    0.5311       185
weighted avg     0.5671    0.5676    0.5590       185

micro f-score: 0.5675675675675675

========== Train Epoch 54 ==========
Loss: 0.394	Accuracy: 58.38%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.8182    0.2903    0.4286        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5838       185
   macro avg     0.5629    0.5587    0.5333       185
weighted avg     0.6089    0.5838    0.5686       185

micro f-score: 0.5837837837837838

========== Train Epoch 55 ==========
Loss: 0.385	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4375    0.3684    0.4000        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.7838    0.7436    0.7632        39

    accuracy                         0.5946       185
   macro avg     0.5593    0.5738    0.5590       185
weighted avg     0.6002    0.5946    0.5930       185

micro f-score: 0.5945945945945946

========== Train Epoch 56 ==========
Loss: 0.357	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5892       185
   macro avg     0.5461    0.5304    0.5337       185
weighted avg     0.5831    0.5892    0.5821       185

micro f-score: 0.5891891891891892

========== Train Epoch 57 ==========
Loss: 0.353	Accuracy: 57.30%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.5893    0.8462    0.6947        39

    accuracy                         0.5730       185
   macro avg     0.5460    0.5307    0.5280       185
weighted avg     0.5709    0.5730    0.5614       185

micro f-score: 0.572972972972973

========== Train Epoch 58 ==========
Loss: 0.322	Accuracy: 60.00%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6667    0.8718    0.7556        39

    accuracy                         0.6000       185
   macro avg     0.5566    0.5663    0.5518       185
weighted avg     0.5979    0.6000    0.5897       185

micro f-score: 0.6

========== Train Epoch 59 ==========
Loss: 0.324	Accuracy: 59.46%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7556    0.8718    0.8095        39

    accuracy                         0.5946       185
   macro avg     0.5480    0.5471    0.5440       185
weighted avg     0.5911    0.5946    0.5898       185

micro f-score: 0.5945945945945946

========== Train Epoch 60 ==========
Loss: 0.306	Accuracy: 60.00%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.4167    0.2632    0.3226        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.7174    0.8462    0.7765        39

    accuracy                         0.6000       185
   macro avg     0.5502    0.5605    0.5488       185
weighted avg     0.5876    0.6000    0.5885       185

micro f-score: 0.6

========== Train Epoch 61 ==========
Loss: 0.285	Accuracy: 61.08%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.4091    0.5294    0.4615        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6939    0.7556    0.7234        45
         zxx     0.7234    0.8718    0.7907        39

    accuracy                         0.6108       185
   macro avg     0.5578    0.5648    0.5529       185
weighted avg     0.6014    0.6108    0.5978       185

micro f-score: 0.6108108108108108

========== Train Epoch 62 ==========
Loss: 0.271	Accuracy: 58.92%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6111    0.5000    0.5500        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.4545    0.2632    0.3333        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5892       185
   macro avg     0.5522    0.5561    0.5421       185
weighted avg     0.5901    0.5892    0.5801       185

micro f-score: 0.5891891891891892

========== Train Epoch 63 ==========
Loss: 0.276	Accuracy: 57.30%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.5730       185
   macro avg     0.5225    0.5359    0.5242       185
weighted avg     0.5698    0.5730    0.5682       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Loss: 0.255	Accuracy: 59.46%	Cost 43s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.6034    0.8974    0.7216        39

    accuracy                         0.5946       185
   macro avg     0.5739    0.5490    0.5498       185
weighted avg     0.6000    0.5946    0.5833       185

micro f-score: 0.5945945945945946

Finished training!!!

Min Loss = 0.255 in epoch 63;
Max Accuracy = 61.08% in epoch 60;
Total Cost 49 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          3,476
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          3,476
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         6,804
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         6,804
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         13,460
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         13,460
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         51,396
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         51,396
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,330,375
Trainable params: 11,330,375
Non-trainable params: 0
Total mult-adds (G): 3.72
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 77.34
Params size (MB): 43.22
Estimated Total Size (MB): 121.74
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    ca_cbam_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_cbam_resnet.py", line 329, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_cbam_resnet.py", line 312, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
