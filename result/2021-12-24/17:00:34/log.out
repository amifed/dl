dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: spp_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.838	Accuracy: 27.03%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3023    0.4194    0.3514        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.1818    0.0889    0.1194        45
         zxx     0.2743    0.7949    0.4079        39

    accuracy                         0.2703       185
   macro avg     0.1492    0.1991    0.1452       185
weighted avg     0.1867    0.2703    0.1903       185

micro f-score: 0.2702702702702703

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.687	Accuracy: 39.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.1333    0.0909    0.1081        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     1.0000    0.1053    0.1905        19
         nqx     0.2500    0.3333    0.2857        12
         qtx     0.5000    0.6000    0.5455        45
         zxx     0.3976    0.8462    0.5410        39

    accuracy                         0.3946       185
   macro avg     0.4135    0.3091    0.2795       185
weighted avg     0.4241    0.3946    0.3383       185

micro f-score: 0.3945945945945946

========== Train Epoch 3 ==========
Loss: 1.501	Accuracy: 43.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4091    0.2903    0.3396        31
         cwx     0.3000    0.2727    0.2857        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.5179    0.6444    0.5743        45
         zxx     0.4225    0.7692    0.5455        39

    accuracy                         0.4324       185
   macro avg     0.4193    0.3380    0.3316       185
weighted avg     0.4315    0.4324    0.3942       185

micro f-score: 0.43243243243243246

========== Train Epoch 4 ==========
Loss: 1.438	Accuracy: 45.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5283    0.6222    0.5714        45
         zxx     0.4211    0.8205    0.5565        39

    accuracy                         0.4595       185
   macro avg     0.4598    0.3883    0.3835       185
weighted avg     0.4699    0.4595    0.4260       185

micro f-score: 0.4594594594594595

========== Train Epoch 5 ==========
Loss: 1.405	Accuracy: 44.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.4247    0.7949    0.5536        39

    accuracy                         0.4486       185
   macro avg     0.4181    0.3858    0.3769       185
weighted avg     0.4364    0.4486    0.4187       185

micro f-score: 0.4486486486486486

========== Train Epoch 6 ==========
Loss: 1.364	Accuracy: 47.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4783    0.3548    0.4074        31
         cwx     0.3750    0.2727    0.3158        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.2857    0.5000    0.3636        12
         qtx     0.6222    0.6222    0.6222        45
         zxx     0.4559    0.7949    0.5794        39

    accuracy                         0.4757       185
   macro avg     0.4596    0.4104    0.3975       185
weighted avg     0.4898    0.4757    0.4518       185

micro f-score: 0.4756756756756757

========== Train Epoch 7 ==========
Loss: 1.326	Accuracy: 45.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.6047    0.5778    0.5909        45
         zxx     0.4133    0.7949    0.5439        39

    accuracy                         0.4541       185
   macro avg     0.4084    0.3826    0.3754       185
weighted avg     0.4373    0.4541    0.4248       185

micro f-score: 0.4540540540540541

========== Train Epoch 8 ==========
Loss: 1.293	Accuracy: 45.41%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3158    0.5000    0.3871        12
         qtx     0.6429    0.6000    0.6207        45
         zxx     0.4133    0.7949    0.5439        39

    accuracy                         0.4541       185
   macro avg     0.3567    0.3836    0.3472       185
weighted avg     0.4153    0.4541    0.4117       185

micro f-score: 0.4540540540540541

========== Train Epoch 9 ==========
Loss: 1.237	Accuracy: 48.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3871    0.3871    0.3871        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6512    0.6222    0.6364        45
         zxx     0.4576    0.6923    0.5510        39

    accuracy                         0.4865       185
   macro avg     0.4339    0.4308    0.4174       185
weighted avg     0.4675    0.4865    0.4641       185

micro f-score: 0.4864864864864865

========== Train Epoch 10 ==========
Loss: 1.208	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4634    0.6129    0.5278        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.6000    0.5000    0.5455        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.5510    0.6923    0.6136        39

    accuracy                         0.5189       185
   macro avg     0.4667    0.4466    0.4431       185
weighted avg     0.4928    0.5189    0.4948       185

micro f-score: 0.518918918918919

========== Train Epoch 11 ==========
Loss: 1.193	Accuracy: 48.65%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.3333    0.6364    0.4375        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.6327    0.6889    0.6596        45
         zxx     0.7000    0.5385    0.6087        39

    accuracy                         0.4865       185
   macro avg     0.4512    0.4451    0.4255       185
weighted avg     0.5002    0.4865    0.4763       185

micro f-score: 0.4864864864864865

========== Train Epoch 12 ==========
Loss: 1.125	Accuracy: 50.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5556    0.4167    0.4762        12
         qtx     0.6591    0.6444    0.6517        45
         zxx     0.4156    0.8205    0.5517        39

    accuracy                         0.5081       185
   macro avg     0.4503    0.4243    0.4166       185
weighted avg     0.4806    0.5081    0.4726       185

micro f-score: 0.5081081081081081

========== Train Epoch 13 ==========
Loss: 1.102	Accuracy: 53.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5152    0.5484    0.5312        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6522    0.6667    0.6593        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.5351       185
   macro avg     0.5043    0.4653    0.4483       185
weighted avg     0.5277    0.5351    0.5012       185

micro f-score: 0.5351351351351351

========== Train Epoch 14 ==========
Loss: 1.066	Accuracy: 54.59%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4444    0.6667    0.5333        12
         qtx     0.6444    0.6444    0.6444        45
         zxx     0.5345    0.7949    0.6392        39

    accuracy                         0.5459       185
   macro avg     0.5339    0.4996    0.4923       185
weighted avg     0.5543    0.5459    0.5306       185

micro f-score: 0.5459459459459459

========== Train Epoch 15 ==========
Loss: 1.049	Accuracy: 54.59%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4872    0.6129    0.5429        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6200    0.6889    0.6526        45
         zxx     0.5439    0.7949    0.6458        39

    accuracy                         0.5459       185
   macro avg     0.5287    0.4698    0.4706       185
weighted avg     0.5445    0.5459    0.5211       185

micro f-score: 0.5459459459459459

========== Train Epoch 16 ==========
Loss: 0.998	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.6154    0.3636    0.4571        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.5147    0.8974    0.6542        39

    accuracy                         0.5676       185
   macro avg     0.5481    0.4845    0.4693       185
weighted avg     0.5728    0.5676    0.5306       185

micro f-score: 0.5675675675675675

========== Train Epoch 17 ==========
Loss: 0.982	Accuracy: 55.14%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.7419    0.5974        31
         cwx     0.4286    0.5455    0.4800        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.6596    0.6889    0.6739        45
         zxx     0.8750    0.5385    0.6667        39

    accuracy                         0.5514       185
   macro avg     0.5292    0.5142    0.4842       185
weighted avg     0.5896    0.5514    0.5397       185

micro f-score: 0.5513513513513514

========== Train Epoch 18 ==========
Loss: 0.946	Accuracy: 56.22%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5252    0.5178    0.5027       185
weighted avg     0.5565    0.5622    0.5440       185

micro f-score: 0.5621621621621622

========== Train Epoch 19 ==========
Loss: 0.927	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.6863    0.7778    0.7292        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5892       185
   macro avg     0.5491    0.5240    0.5212       185
weighted avg     0.5696    0.5892    0.5660       185

micro f-score: 0.5891891891891892

========== Train Epoch 20 ==========
Loss: 0.884	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4651    0.6452    0.5405        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.5730       185
   macro avg     0.5608    0.5169    0.4973       185
weighted avg     0.5936    0.5730    0.5487       185

micro f-score: 0.572972972972973

========== Train Epoch 21 ==========
Loss: 0.900	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7143    0.4839    0.5769        31
         cwx     0.5000    0.4091    0.4500        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.3182    0.3684    0.3415        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5784       185
   macro avg     0.5272    0.5326    0.5207       185
weighted avg     0.5898    0.5784    0.5763       185

micro f-score: 0.5783783783783784

========== Train Epoch 22 ==========
Loss: 0.809	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.8333    0.2632    0.4000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.5469    0.8974    0.6796        39

    accuracy                         0.6054       185
   macro avg     0.5970    0.5455    0.5381       185
weighted avg     0.6298    0.6054    0.5892       185

micro f-score: 0.6054054054054054

========== Train Epoch 23 ==========
Loss: 0.787	Accuracy: 56.22%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.6452    0.5970        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.2667    0.2353    0.2500        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6034    0.7778    0.6796        45
         zxx     0.8462    0.5641    0.6769        39

    accuracy                         0.5622       185
   macro avg     0.5483    0.5196    0.5075       185
weighted avg     0.5896    0.5622    0.5527       185

micro f-score: 0.5621621621621622

========== Train Epoch 24 ==========
Loss: 0.755	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.3667    0.5000    0.4231        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6316    0.8000    0.7059        45
         zxx     0.8125    0.6667    0.7324        39

    accuracy                         0.5838       185
   macro avg     0.5594    0.5443    0.5366       185
weighted avg     0.6058    0.5838    0.5810       185

micro f-score: 0.5837837837837838

========== Train Epoch 25 ==========
Loss: 0.761	Accuracy: 56.76%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4423    0.7419    0.5542        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.3571    0.8333    0.5000        12
         qtx     0.8158    0.6889    0.7470        45
         zxx     0.8750    0.5385    0.6667        39

    accuracy                         0.5676       185
   macro avg     0.5467    0.5421    0.5118       185
weighted avg     0.6215    0.5676    0.5676       185

micro f-score: 0.5675675675675675

========== Train Epoch 26 ==========
Loss: 0.703	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.4324    0.7273    0.5424        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.7778    0.3684    0.5000        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.7568    0.7179    0.7368        39

    accuracy                         0.5838       185
   macro avg     0.5675    0.5620    0.5386       185
weighted avg     0.6203    0.5838    0.5836       185

micro f-score: 0.5837837837837838

========== Train Epoch 27 ==========
Loss: 0.684	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7500    0.6667    0.7059        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5568       185
   macro avg     0.5374    0.5086    0.5048       185
weighted avg     0.5844    0.5568    0.5483       185

micro f-score: 0.5567567567567567

========== Train Epoch 28 ==========
Loss: 0.674	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5106    0.7742    0.6154        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.7000    0.7179    0.7089        39

    accuracy                         0.6000       185
   macro avg     0.5356    0.5553    0.5215       185
weighted avg     0.5905    0.6000    0.5776       185

micro f-score: 0.6

========== Train Epoch 29 ==========
Loss: 0.658	Accuracy: 57.30%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4792    0.7419    0.5823        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.2308    0.1765    0.2000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.6667    0.7179    0.6914        39

    accuracy                         0.5730       185
   macro avg     0.5187    0.5215    0.5031       185
weighted avg     0.5752    0.5730    0.5596       185

micro f-score: 0.572972972972973

========== Train Epoch 30 ==========
Loss: 0.614	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.9032    0.6222    0.7368        45
         zxx     0.6415    0.8718    0.7391        39

    accuracy                         0.6324       185
   macro avg     0.6022    0.6084    0.5937       185
weighted avg     0.6493    0.6324    0.6277       185

micro f-score: 0.6324324324324324

========== Train Epoch 31 ==========
Loss: 0.583	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6250    0.6452    0.6349        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6667    0.3158    0.4286        19
         nqx     0.3750    0.7500    0.5000        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.7742    0.6154    0.6857        39

    accuracy                         0.5838       185
   macro avg     0.5571    0.5505    0.5340       185
weighted avg     0.6056    0.5838    0.5815       185

micro f-score: 0.5837837837837838

========== Train Epoch 32 ==========
Loss: 0.572	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.6108       185
   macro avg     0.6034    0.5780    0.5615       185
weighted avg     0.6349    0.6108    0.5989       185

micro f-score: 0.6108108108108108

========== Train Epoch 33 ==========
Loss: 0.526	Accuracy: 60.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7273    0.5161    0.6038        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.2727    0.3529    0.3077        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.7111    0.8205    0.7619        39

    accuracy                         0.6000       185
   macro avg     0.5675    0.5591    0.5418       185
weighted avg     0.6239    0.6000    0.5968       185

micro f-score: 0.6

========== Train Epoch 34 ==========
Loss: 0.531	Accuracy: 61.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6207    0.5806    0.6000        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.6889    0.6889    0.6889        45
         zxx     0.5781    0.9487    0.7184        39

    accuracy                         0.6108       185
   macro avg     0.6060    0.5525    0.5415       185
weighted avg     0.6140    0.6108    0.5804       185

micro f-score: 0.6108108108108108

========== Train Epoch 35 ==========
Loss: 0.511	Accuracy: 63.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5227    0.7419    0.6133        31
         cwx     0.5278    0.8636    0.6552        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.6324       185
   macro avg     0.6297    0.6144    0.5803       185
weighted avg     0.6879    0.6324    0.6275       185

micro f-score: 0.6324324324324324

========== Train Epoch 36 ==========
Loss: 0.487	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4615    0.7742    0.5783        31
         cwx     0.5161    0.7273    0.6038        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.6270       185
   macro avg     0.6390    0.5910    0.5737       185
weighted avg     0.6781    0.6270    0.6194       185

micro f-score: 0.6270270270270271

========== Train Epoch 37 ==========
Loss: 0.464	Accuracy: 58.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8000    0.3871    0.5217        31
         cwx     0.6364    0.3182    0.4242        22
         hdx     0.3103    0.5294    0.3913        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.7083    0.7556    0.7312        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.5838       185
   macro avg     0.5838    0.5128    0.5153       185
weighted avg     0.6243    0.5838    0.5752       185

micro f-score: 0.5837837837837838

========== Train Epoch 38 ==========
Loss: 0.429	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4510    0.7419    0.5610        31
         cwx     1.0000    0.1364    0.2400        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5965    0.8718    0.7083        39

    accuracy                         0.5730       185
   macro avg     0.6161    0.5172    0.5075       185
weighted avg     0.6370    0.5730    0.5498       185

micro f-score: 0.572972972972973

========== Train Epoch 39 ==========
Loss: 0.443	Accuracy: 62.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.5517    0.7273    0.6275        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.5625    0.4737    0.5143        19
         nqx     0.3600    0.7500    0.4865        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.8571    0.7692    0.8108        39

    accuracy                         0.6270       185
   macro avg     0.5916    0.6132    0.5884       185
weighted avg     0.6605    0.6270    0.6344       185

micro f-score: 0.6270270270270271

========== Train Epoch 40 ==========
Loss: 0.393	Accuracy: 63.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5385    0.6774    0.6000        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.8750    0.3684    0.5185        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.6324       185
   macro avg     0.6250    0.5916    0.5868       185
weighted avg     0.6465    0.6324    0.6241       185

micro f-score: 0.6324324324324324

========== Train Epoch 41 ==========
Loss: 0.371	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5588    0.6129    0.5846        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3125    0.2941    0.3030        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.7391    0.8718    0.8000        39

    accuracy                         0.6162       185
   macro avg     0.5750    0.5371    0.5397       185
weighted avg     0.6018    0.6162    0.5961       185

micro f-score: 0.6162162162162163

========== Train Epoch 42 ==========
Loss: 0.368	Accuracy: 60.54%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5476    0.7419    0.6301        31
         cwx     0.4318    0.8636    0.5758        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.8846    0.5897    0.7077        39

    accuracy                         0.6054       185
   macro avg     0.6326    0.5701    0.5320       185
weighted avg     0.6820    0.6054    0.5900       185

micro f-score: 0.6054054054054054

========== Train Epoch 43 ==========
Loss: 0.347	Accuracy: 62.70%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7500    0.5806    0.6545        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.6154    0.4211    0.5000        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.5738    0.8974    0.7000        39

    accuracy                         0.6270       185
   macro avg     0.6185    0.6042    0.5903       185
weighted avg     0.6689    0.6270    0.6251       185

micro f-score: 0.6270270270270271

========== Train Epoch 44 ==========
Loss: 0.321	Accuracy: 63.78%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5102    0.8065    0.6250        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.7174    0.7333    0.7253        45
         zxx     0.8286    0.7436    0.7838        39

    accuracy                         0.6378       185
   macro avg     0.6322    0.5888    0.5754       185
weighted avg     0.6583    0.6378    0.6206       185

micro f-score: 0.6378378378378379

========== Train Epoch 45 ==========
Loss: 0.337	Accuracy: 62.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5500    0.7097    0.6197        31
         cwx     0.5600    0.6364    0.5957        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.9600    0.5333    0.6857        45
         zxx     0.7021    0.8462    0.7674        39

    accuracy                         0.6270       185
   macro avg     0.6166    0.6132    0.5880       185
weighted avg     0.6739    0.6270    0.6223       185

micro f-score: 0.6270270270270271

========== Train Epoch 46 ==========
Loss: 0.305	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5610    0.7419    0.6389        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.7143    0.2632    0.3846        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.7805    0.8205    0.8000        39

    accuracy                         0.6378       185
   macro avg     0.6073    0.5947    0.5778       185
weighted avg     0.6559    0.6378    0.6302       185

micro f-score: 0.6378378378378379

========== Train Epoch 47 ==========
Loss: 0.297	Accuracy: 61.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.6154    0.4211    0.5000        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.7111    0.7111    0.7111        45
         zxx     0.9000    0.6923    0.7826        39

    accuracy                         0.6162       185
   macro avg     0.5894    0.5959    0.5806       185
weighted avg     0.6441    0.6162    0.6220       185

micro f-score: 0.6162162162162163

========== Train Epoch 48 ==========
Loss: 0.290	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4894    0.7419    0.5897        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     1.0000    0.2632    0.4167        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.8889    0.7111    0.7901        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6432       185
   macro avg     0.6549    0.6023    0.5825       185
weighted avg     0.6929    0.6432    0.6337       185

micro f-score: 0.6432432432432432

========== Train Epoch 49 ==========
Loss: 0.250	Accuracy: 64.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.3684    0.4118    0.3889        17
         mtx     0.6667    0.4211    0.5161        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.8710    0.6923    0.7714        39

    accuracy                         0.6432       185
   macro avg     0.6140    0.6223    0.6018       185
weighted avg     0.6695    0.6432    0.6447       185

micro f-score: 0.6432432432432432

========== Train Epoch 50 ==========
Loss: 0.235	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5854    0.7742    0.6667        31
         cwx     0.5357    0.6818    0.6000        22
         hdx     0.5333    0.4706    0.5000        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.6486       185
   macro avg     0.6168    0.6282    0.6075       185
weighted avg     0.6866    0.6486    0.6539       185

micro f-score: 0.6486486486486487

========== Train Epoch 51 ==========
Loss: 0.251	Accuracy: 64.86%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6452    0.6452    0.6452        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.4167    0.5263    0.4651        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.9000    0.6923    0.7826        39

    accuracy                         0.6486       185
   macro avg     0.6114    0.6230    0.6126       185
weighted avg     0.6718    0.6486    0.6559       185

micro f-score: 0.6486486486486487

========== Train Epoch 52 ==========
Loss: 0.236	Accuracy: 63.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.5000    0.8636    0.6333        22
         hdx     0.4706    0.4706    0.4706        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.6324       185
   macro avg     0.6092    0.6141    0.5910       185
weighted avg     0.6586    0.6324    0.6279       185

micro f-score: 0.6324324324324324

========== Train Epoch 53 ==========
Loss: 0.230	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6296    0.5484    0.5862        31
         cwx     0.5172    0.6818    0.5882        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.8000    0.4211    0.5517        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.7609    0.7778    0.7692        45
         zxx     0.9259    0.6410    0.7576        39

    accuracy                         0.6378       185
   macro avg     0.6306    0.6249    0.6027       185
weighted avg     0.6899    0.6378    0.6454       185

micro f-score: 0.6378378378378379

========== Train Epoch 54 ==========
Loss: 0.208	Accuracy: 55.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6875    0.3548    0.4681        31
         cwx     0.5500    0.5000    0.5238        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.2449    0.6316    0.3529        19
         nqx     0.6250    0.4167    0.5000        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.5568       185
   macro avg     0.5828    0.5234    0.5263       185
weighted avg     0.6442    0.5568    0.5759       185

micro f-score: 0.5567567567567567

========== Train Epoch 55 ==========
Loss: 0.205	Accuracy: 61.08%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5098    0.8387    0.6341        31
         cwx     0.4750    0.8636    0.6129        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     1.0000    0.2105    0.3478        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.9130    0.5385    0.6774        39

    accuracy                         0.6108       185
   macro avg     0.6348    0.5845    0.5385       185
weighted avg     0.6977    0.6108    0.5956       185

micro f-score: 0.6108108108108108

========== Train Epoch 56 ==========
Loss: 0.177	Accuracy: 63.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.6500    0.5909    0.6190        22
         hdx     0.4762    0.5882    0.5263        17
         mtx     0.4167    0.5263    0.4651        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.6296    0.8718    0.7312        39

    accuracy                         0.6378       185
   macro avg     0.6308    0.5982    0.5964       185
weighted avg     0.6638    0.6378    0.6308       185

micro f-score: 0.6378378378378379

========== Train Epoch 57 ==========
Loss: 0.183	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6432       185
   macro avg     0.6671    0.6100    0.5939       185
weighted avg     0.6989    0.6432    0.6378       185

micro f-score: 0.6432432432432432

========== Train Epoch 58 ==========
Loss: 0.184	Accuracy: 68.11%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.6452    0.6557        31
         cwx     0.7143    0.6818    0.6977        22
         hdx     0.5000    0.5294    0.5143        17
         mtx     0.6429    0.4737    0.5455        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.7692    0.7692    0.7692        39

    accuracy                         0.6811       185
   macro avg     0.6508    0.6666    0.6462       185
weighted avg     0.7036    0.6811    0.6854       185

micro f-score: 0.6810810810810811

========== Train Epoch 59 ==========
Loss: 0.165	Accuracy: 64.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5714    0.6452    0.6061        31
         cwx     0.6364    0.6364    0.6364        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8857    0.6889    0.7750        45
         zxx     0.6604    0.8974    0.7609        39

    accuracy                         0.6432       185
   macro avg     0.6617    0.6017    0.5724       185
weighted avg     0.6982    0.6432    0.6269       185

micro f-score: 0.6432432432432432

========== Train Epoch 60 ==========
Loss: 0.141	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.6250    0.6818    0.6522        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.9286    0.5778    0.7123        45
         zxx     0.5000    0.8974    0.6422        39

    accuracy                         0.5946       185
   macro avg     0.6208    0.5725    0.5613       185
weighted avg     0.6529    0.5946    0.5855       185

micro f-score: 0.5945945945945946

========== Train Epoch 61 ==========
Loss: 0.161	Accuracy: 63.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6129    0.6129    0.6129        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6378       185
   macro avg     0.5797    0.5903    0.5749       185
weighted avg     0.6279    0.6378    0.6262       185

micro f-score: 0.6378378378378379

========== Train Epoch 62 ==========
Loss: 0.144	Accuracy: 61.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6500    0.4194    0.5098        31
         cwx     0.6818    0.6818    0.6818        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7143    0.7778    0.7447        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6162       185
   macro avg     0.6532    0.5712    0.5416       185
weighted avg     0.6628    0.6162    0.5853       185

micro f-score: 0.6162162162162163

========== Train Epoch 63 ==========
Loss: 0.139	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5476    0.7419    0.6301        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7907    0.7556    0.7727        45
         zxx     0.7045    0.7949    0.7470        39

    accuracy                         0.6432       185
   macro avg     0.6097    0.5922    0.5803       185
weighted avg     0.6465    0.6432    0.6300       185

micro f-score: 0.6432432432432432

========== Train Epoch 64 ==========
Loss: 0.126	Accuracy: 64.32%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.5385    0.4118    0.4667        17
         mtx     1.0000    0.3158    0.4800        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.6939    0.7556    0.7234        45
         zxx     0.7619    0.8205    0.7901        39

    accuracy                         0.6432       185
   macro avg     0.6521    0.6036    0.5944       185
weighted avg     0.6743    0.6432    0.6362       185

micro f-score: 0.6432432432432432

Finished training!!!

Min Loss = 0.126 in epoch 63;
Max Accuracy = 68.11% in epoch 57;
Total Cost 32 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPP: 1-4                               [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-5                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-22                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-23            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-24                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-25                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-26            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-27             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-28                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-29                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-30            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-31                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-32                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-33            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-35                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-36            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-37                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-40             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-41                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-8                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-42                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-43            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-44                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-45                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-46            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-47                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-9                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-49            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-50                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-51                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-52            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-53             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-54                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-10                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-55                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-56            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-57                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-58                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-59            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-60                   [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,190,535
Trainable params: 11,190,535
Non-trainable params: 0
Total mult-adds (G): 14.37
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 271.88
Params size (MB): 42.69
Estimated Total Size (MB): 315.74
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    dspp_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/dspp_resnet.py", line 353, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/dspp_resnet.py", line 330, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
