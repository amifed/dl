dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: cbam_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.830	Accuracy: 31.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2368    0.2903    0.2609        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.4524    0.4222    0.4368        45
         zxx     0.2838    0.5385    0.3717        39

    accuracy                         0.3135       185
   macro avg     0.2535    0.2490    0.2366       185
weighted avg     0.2862    0.3135    0.2853       185

micro f-score: 0.31351351351351353

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.634	Accuracy: 36.22%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5385    0.4667    0.5000        45
         zxx     0.3208    0.8718    0.4690        39

    accuracy                         0.3622       185
   macro avg     0.3222    0.2774    0.2511       185
weighted avg     0.3722    0.3622    0.3091       185

micro f-score: 0.3621621621621622

========== Train Epoch 3 ==========
Loss: 1.515	Accuracy: 37.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3750    0.0968    0.1538        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.1000    0.0833    0.0909        12
         qtx     0.5333    0.5333    0.5333        45
         zxx     0.3404    0.8205    0.4812        39

    accuracy                         0.3730       185
   macro avg     0.3673    0.2845    0.2702       185
weighted avg     0.3956    0.3730    0.3290       185

micro f-score: 0.37297297297297294

========== Train Epoch 4 ==========
Loss: 1.486	Accuracy: 39.46%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.1818    0.1667    0.1739        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.3500    0.8974    0.5036        39

    accuracy                         0.3946       185
   macro avg     0.4135    0.3059    0.2909       185
weighted avg     0.4385    0.3946    0.3501       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.451	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5000    0.5556    0.5263        45
         zxx     0.3765    0.8205    0.5161        39

    accuracy                         0.4054       185
   macro avg     0.3898    0.3180    0.3104       185
weighted avg     0.4142    0.4054    0.3674       185

micro f-score: 0.40540540540540543

========== Train Epoch 6 ==========
Loss: 1.427	Accuracy: 43.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4177    0.8462    0.5593        39

    accuracy                         0.4324       185
   macro avg     0.4117    0.3578    0.3546       185
weighted avg     0.4354    0.4324    0.4041       185

micro f-score: 0.43243243243243246

========== Train Epoch 7 ==========
Loss: 1.409	Accuracy: 42.70%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3462    0.2903    0.3158        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.4146    0.8718    0.5620        39

    accuracy                         0.4270       185
   macro avg     0.4094    0.3494    0.3431       185
weighted avg     0.4305    0.4270    0.3941       185

micro f-score: 0.427027027027027

========== Train Epoch 8 ==========
Loss: 1.383	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3846    0.3226    0.3509        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.5714    0.2353    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4324       185
   macro avg     0.4113    0.3540    0.3478       185
weighted avg     0.4349    0.4324    0.4006       185

micro f-score: 0.43243243243243246

========== Train Epoch 9 ==========
Loss: 1.349	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.2000    0.1667    0.1818        12
         qtx     0.5652    0.5778    0.5714        45
         zxx     0.4769    0.7949    0.5962        39

    accuracy                         0.4486       185
   macro avg     0.3899    0.3628    0.3563       185
weighted avg     0.4319    0.4486    0.4217       185

micro f-score: 0.4486486486486486

========== Train Epoch 10 ==========
Loss: 1.322	Accuracy: 42.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3571    0.3226    0.3390        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.4487    0.8974    0.5983        39

    accuracy                         0.4270       185
   macro avg     0.3660    0.3450    0.3293       185
weighted avg     0.4045    0.4270    0.3887       185

micro f-score: 0.427027027027027

========== Train Epoch 11 ==========
Loss: 1.297	Accuracy: 45.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3750    0.3871    0.3810        31
         cwx     0.2381    0.2273    0.2326        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.5000    0.9231    0.6486        39

    accuracy                         0.4541       185
   macro avg     0.3939    0.3695    0.3559       185
weighted avg     0.4371    0.4541    0.4199       185

micro f-score: 0.4540540540540541

========== Train Epoch 12 ==========
Loss: 1.277	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.2778    0.2273    0.2500        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5306    0.5778    0.5532        45
         zxx     0.5246    0.8205    0.6400        39

    accuracy                         0.4649       185
   macro avg     0.3973    0.3893    0.3774       185
weighted avg     0.4334    0.4649    0.4341       185

micro f-score: 0.4648648648648649

========== Train Epoch 13 ==========
Loss: 1.248	Accuracy: 46.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.2632    0.2273    0.2439        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.4649       185
   macro avg     0.4133    0.3898    0.3815       185
weighted avg     0.4499    0.4649    0.4389       185

micro f-score: 0.4648648648648649

========== Train Epoch 14 ==========
Loss: 1.206	Accuracy: 49.19%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.6098    0.5556    0.5814        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.4919       185
   macro avg     0.4301    0.4147    0.4046       185
weighted avg     0.4719    0.4919    0.4643       185

micro f-score: 0.4918918918918919

========== Train Epoch 15 ==========
Loss: 1.183	Accuracy: 48.65%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3939    0.4194    0.4062        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.5000    0.2353    0.3200        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6486    0.5333    0.5854        45
         zxx     0.5000    0.9231    0.6486        39

    accuracy                         0.4865       185
   macro avg     0.4543    0.4151    0.4049       185
weighted avg     0.4831    0.4865    0.4563       185

micro f-score: 0.4864864864864865

========== Train Epoch 16 ==========
Loss: 1.154	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4839    0.4839    0.4839        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.4919       185
   macro avg     0.4335    0.4167    0.4092       185
weighted avg     0.4699    0.4919    0.4653       185

micro f-score: 0.4918918918918919

========== Train Epoch 17 ==========
Loss: 1.115	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5909    0.5778    0.5843        45
         zxx     0.5484    0.8718    0.6733        39

    accuracy                         0.5081       185
   macro avg     0.4428    0.4290    0.4190       185
weighted avg     0.4841    0.5081    0.4803       185

micro f-score: 0.5081081081081081

========== Train Epoch 18 ==========
Loss: 1.091	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.3333    0.3636    0.3478        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6279    0.6000    0.6136        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5189       185
   macro avg     0.4562    0.4397    0.4352       185
weighted avg     0.4954    0.5189    0.4948       185

micro f-score: 0.518918918918919

========== Train Epoch 19 ==========
Loss: 1.060	Accuracy: 53.51%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6279    0.6000    0.6136        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5351       185
   macro avg     0.4995    0.4776    0.4702       185
weighted avg     0.5326    0.5351    0.5185       185

micro f-score: 0.5351351351351351

========== Train Epoch 20 ==========
Loss: 1.024	Accuracy: 52.43%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.3750    0.4091    0.3913        22
         hdx     0.2000    0.1176    0.1481        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5243       185
   macro avg     0.4457    0.4745    0.4460       185
weighted avg     0.5012    0.5243    0.5023       185

micro f-score: 0.5243243243243243

========== Train Epoch 21 ==========
Loss: 1.001	Accuracy: 52.97%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5385    0.4516    0.4912        31
         cwx     0.3125    0.4545    0.3704        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5297       185
   macro avg     0.4850    0.4759    0.4610       185
weighted avg     0.5293    0.5297    0.5131       185

micro f-score: 0.5297297297297298

========== Train Epoch 22 ==========
Loss: 0.974	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5455    0.9231    0.6857        39

    accuracy                         0.5568       185
   macro avg     0.5372    0.5085    0.4894       185
weighted avg     0.5685    0.5568    0.5329       185

micro f-score: 0.5567567567567567

========== Train Epoch 23 ==========
Loss: 0.939	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.3846    0.4545    0.4167        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.6207    0.9231    0.7423        39

    accuracy                         0.5730       185
   macro avg     0.5262    0.5265    0.5055       185
weighted avg     0.5707    0.5730    0.5534       185

micro f-score: 0.572972972972973

========== Train Epoch 24 ==========
Loss: 0.891	Accuracy: 53.51%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.5636    0.6889    0.6200        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5351       185
   macro avg     0.5104    0.4862    0.4681       185
weighted avg     0.5264    0.5351    0.5072       185

micro f-score: 0.5351351351351351

========== Train Epoch 25 ==========
Loss: 0.872	Accuracy: 55.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.5385    0.8974    0.6731        39

    accuracy                         0.5568       185
   macro avg     0.5113    0.5007    0.4798       185
weighted avg     0.5371    0.5568    0.5237       185

micro f-score: 0.5567567567567567

========== Train Epoch 26 ==========
Loss: 0.825	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4571    0.5161    0.4848        31
         cwx     0.5000    0.3182    0.3889        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.5224    0.8974    0.6604        39

    accuracy                         0.5514       185
   macro avg     0.5436    0.5048    0.4880       185
weighted avg     0.5697    0.5514    0.5283       185

micro f-score: 0.5513513513513514

========== Train Epoch 27 ==========
Loss: 0.790	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.5484    0.5231        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7045    0.6889    0.6966        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.5730       185
   macro avg     0.5190    0.5327    0.5233       185
weighted avg     0.5617    0.5730    0.5656       185

micro f-score: 0.572972972972973

========== Train Epoch 28 ==========
Loss: 0.756	Accuracy: 55.14%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.3448    0.4545    0.3922        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6364    0.7179    0.6747        39

    accuracy                         0.5514       185
   macro avg     0.5140    0.5171    0.5067       185
weighted avg     0.5502    0.5514    0.5442       185

micro f-score: 0.5513513513513514

========== Train Epoch 29 ==========
Loss: 0.732	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.6471    0.7333    0.6875        45
         zxx     0.6000    0.7692    0.6742        39

    accuracy                         0.5730       185
   macro avg     0.5596    0.5337    0.5232       185
weighted avg     0.5752    0.5730    0.5562       185

micro f-score: 0.572972972972973

========== Train Epoch 30 ==========
Loss: 0.693	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.5625    0.4091    0.4737        22
         hdx     0.4000    0.3529    0.3750        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5892       185
   macro avg     0.5525    0.5427    0.5380       185
weighted avg     0.5846    0.5892    0.5778       185

micro f-score: 0.5891891891891892

========== Train Epoch 31 ==========
Loss: 0.656	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3333    0.4118    0.3684        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.5769    0.7692    0.6593        39

    accuracy                         0.5946       185
   macro avg     0.5845    0.5577    0.5487       185
weighted avg     0.6114    0.5946    0.5857       185

micro f-score: 0.5945945945945946

========== Train Epoch 32 ==========
Loss: 0.629	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.8182    0.4091    0.5455        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.5147    0.8974    0.6542        39

    accuracy                         0.5730       185
   macro avg     0.5562    0.5120    0.5098       185
weighted avg     0.5779    0.5730    0.5507       185

micro f-score: 0.572972972972973

========== Train Epoch 33 ==========
Loss: 0.600	Accuracy: 60.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.6591    0.7436    0.6988        39

    accuracy                         0.6000       185
   macro avg     0.5876    0.5657    0.5563       185
weighted avg     0.6117    0.6000    0.5913       185

micro f-score: 0.6

========== Train Epoch 34 ==========
Loss: 0.564	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4737    0.5806    0.5217        31
         cwx     0.7059    0.5455    0.6154        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.5946       185
   macro avg     0.5596    0.5537    0.5480       185
weighted avg     0.5966    0.5946    0.5884       185

micro f-score: 0.5945945945945946

========== Train Epoch 35 ==========
Loss: 0.529	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4828    0.4516    0.4667        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3500    0.4118    0.3784        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.5849    0.7949    0.6739        39

    accuracy                         0.5946       185
   macro avg     0.5979    0.5558    0.5449       185
weighted avg     0.6121    0.5946    0.5789       185

micro f-score: 0.5945945945945946

========== Train Epoch 36 ==========
Loss: 0.509	Accuracy: 58.38%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4468    0.6774    0.5385        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.4375    0.4118    0.4242        17
         mtx     0.2353    0.2105    0.2222        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5838       185
   macro avg     0.5592    0.5436    0.5449       185
weighted avg     0.6049    0.5838    0.5863       185

micro f-score: 0.5837837837837838

========== Train Epoch 37 ==========
Loss: 0.477	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4474    0.5484    0.4928        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6304    0.7436    0.6824        39

    accuracy                         0.5892       185
   macro avg     0.5652    0.5564    0.5437       185
weighted avg     0.6001    0.5892    0.5813       185

micro f-score: 0.5891891891891892

========== Train Epoch 38 ==========
Loss: 0.441	Accuracy: 60.54%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4286    0.5806    0.4932        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8049    0.7333    0.7674        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.6054       185
   macro avg     0.5776    0.5747    0.5673       185
weighted avg     0.6244    0.6054    0.6078       185

micro f-score: 0.6054054054054054

========== Train Epoch 39 ==========
Loss: 0.421	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5838       185
   macro avg     0.5541    0.5402    0.5382       185
weighted avg     0.5912    0.5838    0.5785       185

micro f-score: 0.5837837837837838

========== Train Epoch 40 ==========
Loss: 0.386	Accuracy: 57.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4412    0.4839    0.4615        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7805    0.7111    0.7442        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5784       185
   macro avg     0.5515    0.5418    0.5294       185
weighted avg     0.5906    0.5784    0.5714       185

micro f-score: 0.5783783783783784

========== Train Epoch 41 ==========
Loss: 0.376	Accuracy: 58.38%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5838       185
   macro avg     0.5324    0.5272    0.5225       185
weighted avg     0.5728    0.5838    0.5714       185

micro f-score: 0.5837837837837838

========== Train Epoch 42 ==========
Loss: 0.336	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5217    0.3871    0.4444        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7442    0.7111    0.7273        45
         zxx     0.6038    0.8205    0.6957        39

    accuracy                         0.5892       185
   macro avg     0.5822    0.5617    0.5304       185
weighted avg     0.6094    0.5892    0.5684       185

micro f-score: 0.5891891891891892

========== Train Epoch 43 ==========
Loss: 0.327	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6458    0.7949    0.7126        39

    accuracy                         0.5892       185
   macro avg     0.5497    0.5545    0.5409       185
weighted avg     0.5940    0.5892    0.5823       185

micro f-score: 0.5891891891891892

========== Train Epoch 44 ==========
Loss: 0.304	Accuracy: 59.46%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4651    0.6452    0.5405        31
         cwx     0.6250    0.4545    0.5263        22
         hdx     0.3333    0.4706    0.3902        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.8421    0.7111    0.7711        45
         zxx     0.7000    0.7179    0.7089        39

    accuracy                         0.5946       185
   macro avg     0.5665    0.5538    0.5517       185
weighted avg     0.6128    0.5946    0.5958       185

micro f-score: 0.5945945945945946

========== Train Epoch 45 ==========
Loss: 0.282	Accuracy: 56.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4091    0.5806    0.4800        31
         cwx     0.7778    0.3182    0.4516        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.5622       185
   macro avg     0.5527    0.5128    0.5133       185
weighted avg     0.5781    0.5622    0.5526       185

micro f-score: 0.5621621621621622

========== Train Epoch 46 ==========
Loss: 0.274	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5892       185
   macro avg     0.5570    0.5594    0.5378       185
weighted avg     0.5917    0.5892    0.5750       185

micro f-score: 0.5891891891891892

========== Train Epoch 47 ==========
Loss: 0.252	Accuracy: 58.92%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4483    0.4194    0.4333        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5926    0.8205    0.6882        39

    accuracy                         0.5892       185
   macro avg     0.5751    0.5565    0.5454       185
weighted avg     0.6006    0.5892    0.5781       185

micro f-score: 0.5891891891891892

========== Train Epoch 48 ==========
Loss: 0.226	Accuracy: 57.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4375    0.4516    0.4444        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7619    0.7111    0.7356        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5784       185
   macro avg     0.5607    0.5405    0.5252       185
weighted avg     0.5851    0.5784    0.5616       185

micro f-score: 0.5783783783783784

========== Train Epoch 49 ==========
Loss: 0.211	Accuracy: 56.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3333    0.5294    0.4091        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5622       185
   macro avg     0.5288    0.5324    0.5136       185
weighted avg     0.5687    0.5622    0.5519       185

micro f-score: 0.5621621621621622

========== Train Epoch 50 ==========
Loss: 0.210	Accuracy: 60.00%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6818    0.7692    0.7229        39

    accuracy                         0.6000       185
   macro avg     0.5896    0.5778    0.5617       185
weighted avg     0.6351    0.6000    0.5995       185

micro f-score: 0.6

========== Train Epoch 51 ==========
Loss: 0.184	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4054    0.4839    0.4412        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3846    0.5882    0.4651        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5892       185
   macro avg     0.5701    0.5669    0.5541       185
weighted avg     0.6108    0.5892    0.5876       185

micro f-score: 0.5891891891891892

========== Train Epoch 52 ==========
Loss: 0.183	Accuracy: 60.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.6054       185
   macro avg     0.5682    0.5790    0.5578       185
weighted avg     0.6183    0.6054    0.5994       185

micro f-score: 0.6054054054054054

========== Train Epoch 53 ==========
Loss: 0.177	Accuracy: 58.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4565    0.6774    0.5455        31
         cwx     0.7500    0.4091    0.5294        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5892       185
   macro avg     0.5800    0.5541    0.5419       185
weighted avg     0.6230    0.5892    0.5837       185

micro f-score: 0.5891891891891892

========== Train Epoch 54 ==========
Loss: 0.170	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5455    0.5806    0.5625        31
         cwx     0.7333    0.5000    0.5946        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.6216       185
   macro avg     0.5936    0.5946    0.5833       185
weighted avg     0.6400    0.6216    0.6226       185

micro f-score: 0.6216216216216216

========== Train Epoch 55 ==========
Loss: 0.151	Accuracy: 58.92%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.6471    0.5000    0.5641        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.5892       185
   macro avg     0.5642    0.5647    0.5468       185
weighted avg     0.5992    0.5892    0.5787       185

micro f-score: 0.5891891891891892

========== Train Epoch 56 ==========
Loss: 0.142	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3548    0.6471    0.4583        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5556    0.8333    0.6667        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5946       185
   macro avg     0.5758    0.5769    0.5491       185
weighted avg     0.6142    0.5946    0.5844       185

micro f-score: 0.5945945945945946

========== Train Epoch 57 ==========
Loss: 0.143	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4500    0.5806    0.5070        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8529    0.6444    0.7342        45
         zxx     0.6667    0.7692    0.7143        39

    accuracy                         0.5946       185
   macro avg     0.5906    0.5702    0.5669       185
weighted avg     0.6283    0.5946    0.5984       185

micro f-score: 0.5945945945945946

========== Train Epoch 58 ==========
Loss: 0.142	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4848    0.5161    0.5000        31
         cwx     0.6667    0.5455    0.6000        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5892       185
   macro avg     0.5531    0.5626    0.5452       185
weighted avg     0.6068    0.5892    0.5859       185

micro f-score: 0.5891891891891892

========== Train Epoch 59 ==========
Loss: 0.122	Accuracy: 59.46%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5000    0.6774    0.5753        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3913    0.5294    0.4500        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.7273    0.6667    0.6957        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5946       185
   macro avg     0.5803    0.5648    0.5629       185
weighted avg     0.6145    0.5946    0.5938       185

micro f-score: 0.5945945945945946

========== Train Epoch 60 ==========
Loss: 0.123	Accuracy: 58.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4211    0.5161    0.4638        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8108    0.6667    0.7317        45
         zxx     0.6444    0.7436    0.6905        39

    accuracy                         0.5838       185
   macro avg     0.5649    0.5649    0.5516       185
weighted avg     0.6009    0.5838    0.5814       185

micro f-score: 0.5837837837837838

========== Train Epoch 61 ==========
Loss: 0.125	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4688    0.4839    0.4762        31
         cwx     0.6875    0.5000    0.5789        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6596    0.7949    0.7209        39

    accuracy                         0.5946       185
   macro avg     0.5598    0.5663    0.5477       185
weighted avg     0.6017    0.5946    0.5864       185

micro f-score: 0.5945945945945946

========== Train Epoch 62 ==========
Loss: 0.112	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.8333    0.4545    0.5882        22
         hdx     0.4348    0.5882    0.5000        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6154    0.8205    0.7033        39

    accuracy                         0.6162       185
   macro avg     0.6240    0.5877    0.5727       185
weighted avg     0.6425    0.6162    0.6031       185

micro f-score: 0.6162162162162163

========== Train Epoch 63 ==========
Loss: 0.104	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.7692    0.4545    0.5714        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.6250    0.8333    0.7143        12
         qtx     0.7561    0.6889    0.7209        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5730       185
   macro avg     0.5607    0.5522    0.5301       185
weighted avg     0.5888    0.5730    0.5614       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Loss: 0.097	Accuracy: 60.00%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4324    0.5161    0.4706        31
         cwx     0.7143    0.4545    0.5556        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.6000       185
   macro avg     0.5764    0.5576    0.5456       185
weighted avg     0.6080    0.6000    0.5871       185

micro f-score: 0.6

Finished training!!!

Min Loss = 0.097 in epoch 63;
Max Accuracy = 62.16% in epoch 53;
Total Cost 30 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-6                    [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-7                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12            [-1, 64, 80, 80]          128
|    |    └─CBAM: 3-13                   [-1, 64, 80, 80]          680
|    |    └─ReLU: 3-14                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-20                   [-1, 128, 40, 40]         2,284
|    |    └─Sequential: 3-21             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─CBAM: 3-28                   [-1, 128, 40, 40]         2,284
|    |    └─ReLU: 3-29                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-35                   [-1, 256, 20, 20]         8,564
|    |    └─Sequential: 3-36             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42            [-1, 256, 20, 20]         512
|    |    └─CBAM: 3-43                   [-1, 256, 20, 20]         8,564
|    |    └─ReLU: 3-44                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-50                   [-1, 512, 10, 10]         33,412
|    |    └─Sequential: 3-51             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57            [-1, 512, 10, 10]         1,024
|    |    └─CBAM: 3-58                   [-1, 512, 10, 10]         33,412
|    |    └─ReLU: 3-59                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 11,269,983
Trainable params: 11,269,983
Non-trainable params: 0
Total mult-adds (G): 3.72
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 77.34
Params size (MB): 42.99
Estimated Total Size (MB): 121.51
==========================================================================================



Traceback (most recent call last):
  File "train.py", line 258, in <module>
    cbam_resnet.resnet18, **args)
  File "train.py", line 188, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/cbam_resnet.py", line 357, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/cbam_resnet.py", line 339, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
