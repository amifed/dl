dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: ca_spp_resnet18
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.848	Accuracy: 28.11%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3636    0.3871    0.3750        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2800    0.1556    0.2000        45
         zxx     0.2583    0.7949    0.3899        39

    accuracy                         0.2811       185
   macro avg     0.1697    0.2041    0.1576       185
weighted avg     0.2175    0.2811    0.2101       185

micro f-score: 0.2810810810810811

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.670	Accuracy: 32.43%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.4444    0.1778    0.2540        45
         zxx     0.2762    0.7436    0.4028        39

    accuracy                         0.3243       185
   macro avg     0.3073    0.2739    0.2546       185
weighted avg     0.3297    0.3243    0.2812       185

micro f-score: 0.32432432432432434

========== Train Epoch 3 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.583	Accuracy: 38.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5000    0.4667    0.4828        45
         zxx     0.3448    0.7692    0.4762        39

    accuracy                         0.3892       185
   macro avg     0.4724    0.3134    0.3058       185
weighted avg     0.4529    0.3892    0.3537       185

micro f-score: 0.3891891891891892

========== Train Epoch 4 ==========
Loss: 1.556	Accuracy: 39.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.5000    0.4889    0.4944        45
         zxx     0.3516    0.8205    0.4923        39

    accuracy                         0.3946       185
   macro avg     0.4668    0.3093    0.3009       185
weighted avg     0.4535    0.3946    0.3554       185

micro f-score: 0.3945945945945946

========== Train Epoch 5 ==========
Loss: 1.547	Accuracy: 39.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3704    0.3226    0.3448        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.3529    0.7692    0.4839        39

    accuracy                         0.3946       185
   macro avg     0.4014    0.3185    0.3130       185
weighted avg     0.4096    0.3946    0.3615       185

micro f-score: 0.3945945945945946

========== Train Epoch 6 ==========
Loss: 1.531	Accuracy: 38.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4000    0.3226    0.3571        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.5250    0.4667    0.4941        45
         zxx     0.3483    0.7949    0.4844        39

    accuracy                         0.3892       185
   macro avg     0.4549    0.3070    0.2987       185
weighted avg     0.4488    0.3892    0.3546       185

micro f-score: 0.3891891891891892

========== Train Epoch 7 ==========
Loss: 1.505	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.4167    0.2273    0.2941        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3483    0.7949    0.4844        39

    accuracy                         0.4000       185
   macro avg     0.4776    0.3240    0.3184       185
weighted avg     0.4641    0.4000    0.3671       185

micro f-score: 0.4000000000000001

========== Train Epoch 8 ==========
Loss: 1.497	Accuracy: 40.00%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3750    0.3871    0.3810        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.2500    0.0588    0.0952        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5405    0.4444    0.4878        45
         zxx     0.3735    0.7949    0.5082        39

    accuracy                         0.4000       185
   macro avg     0.3632    0.3240    0.3139       185
weighted avg     0.3927    0.4000    0.3667       185

micro f-score: 0.4000000000000001

========== Train Epoch 9 ==========
Loss: 1.487	Accuracy: 41.62%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4074    0.3548    0.3793        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.5106    0.5333    0.5217        45
         zxx     0.4079    0.7949    0.5391        39

    accuracy                         0.4162       185
   macro avg     0.3568    0.3266    0.3164       185
weighted avg     0.3898    0.4162    0.3793       185

micro f-score: 0.41621621621621624

========== Train Epoch 10 ==========
Loss: 1.469	Accuracy: 39.46%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3750    0.2903    0.3273        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4583    0.4889    0.4731        45
         zxx     0.4079    0.7949    0.5391        39

    accuracy                         0.3946       185
   macro avg     0.3297    0.3155    0.2999       185
weighted avg     0.3605    0.3946    0.3547       185

micro f-score: 0.3945945945945946

========== Train Epoch 11 ==========
Loss: 1.448	Accuracy: 40.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3678    0.8205    0.5079        39

    accuracy                         0.4054       185
   macro avg     0.3720    0.3266    0.3183       185
weighted avg     0.3981    0.4054    0.3702       185

micro f-score: 0.40540540540540543

========== Train Epoch 12 ==========
Loss: 1.437	Accuracy: 42.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.4773    0.4667    0.4719        45
         zxx     0.4667    0.7179    0.5657        39

    accuracy                         0.4270       185
   macro avg     0.3928    0.3583    0.3597       185
weighted avg     0.4146    0.4270    0.4077       185

micro f-score: 0.427027027027027

========== Train Epoch 13 ==========
Loss: 1.422	Accuracy: 41.62%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.5000    0.4667    0.4828        45
         zxx     0.4026    0.7949    0.5345        39

    accuracy                         0.4162       185
   macro avg     0.3603    0.3353    0.3237       185
weighted avg     0.3884    0.4162    0.3790       185

micro f-score: 0.41621621621621624

========== Train Epoch 14 ==========
Loss: 1.415	Accuracy: 43.24%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4138    0.3871    0.4000        31
         cwx     0.4000    0.2727    0.3243        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.4583    0.4889    0.4731        45
         zxx     0.4429    0.7949    0.5688        39

    accuracy                         0.4324       185
   macro avg     0.4105    0.3655    0.3644       185
weighted avg     0.4193    0.4324    0.4041       185

micro f-score: 0.43243243243243246

========== Train Epoch 15 ==========
Loss: 1.389	Accuracy: 43.24%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4242    0.4516    0.4375        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.4889    0.4889    0.4889        45
         zxx     0.4493    0.7949    0.5741        39

    accuracy                         0.4324       185
   macro avg     0.3837    0.3553    0.3491       185
weighted avg     0.4061    0.4324    0.4006       185

micro f-score: 0.43243243243243246

========== Train Epoch 16 ==========
Loss: 1.387	Accuracy: 44.32%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.4889    0.4889    0.4889        45
         zxx     0.4324    0.8205    0.5664        39

    accuracy                         0.4432       185
   macro avg     0.4047    0.3646    0.3607       185
weighted avg     0.4262    0.4432    0.4121       185

micro f-score: 0.44324324324324327

========== Train Epoch 17 ==========
Loss: 1.376	Accuracy: 43.78%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.4681    0.4889    0.4783        45
         zxx     0.4844    0.7949    0.6019        39

    accuracy                         0.4378       185
   macro avg     0.3861    0.3593    0.3552       185
weighted avg     0.4136    0.4378    0.4102       185

micro f-score: 0.43783783783783786

========== Train Epoch 18 ==========
Loss: 1.350	Accuracy: 44.86%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.3600    0.4091    0.3830        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.4412    0.7692    0.5607        39

    accuracy                         0.4486       185
   macro avg     0.4122    0.3787    0.3758       185
weighted avg     0.4379    0.4486    0.4252       185

micro f-score: 0.4486486486486486

========== Train Epoch 19 ==========
Loss: 1.342	Accuracy: 46.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5172    0.4839    0.5000        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.4177    0.8462    0.5593        39

    accuracy                         0.4649       185
   macro avg     0.4383    0.3913    0.3885       185
weighted avg     0.4612    0.4649    0.4365       185

micro f-score: 0.4648648648648649

========== Train Epoch 20 ==========
Loss: 1.332	Accuracy: 46.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4815    0.4194    0.4483        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.4714    0.8462    0.6055        39

    accuracy                         0.4649       185
   macro avg     0.4285    0.3969    0.3929       185
weighted avg     0.4495    0.4649    0.4377       185

micro f-score: 0.4648648648648649

========== Train Epoch 21 ==========
Loss: 1.338	Accuracy: 47.03%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5161    0.5161    0.5161        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.3333    0.4000        12
         qtx     0.5000    0.5111    0.5055        45
         zxx     0.4627    0.7949    0.5849        39

    accuracy                         0.4703       185
   macro avg     0.4354    0.3982    0.3945       185
weighted avg     0.4521    0.4703    0.4414       185

micro f-score: 0.4702702702702703

========== Train Epoch 22 ==========
Loss: 1.307	Accuracy: 48.11%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.4811       185
   macro avg     0.4408    0.4065    0.4007       185
weighted avg     0.4684    0.4811    0.4524       185

micro f-score: 0.4810810810810811

========== Train Epoch 23 ==========
Loss: 1.297	Accuracy: 47.57%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5185    0.4516    0.4828        31
         cwx     0.3200    0.3636    0.3404        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.4727    0.5778    0.5200        45
         zxx     0.5882    0.7692    0.6667        39

    accuracy                         0.4757       185
   macro avg     0.4301    0.4052    0.4038       185
weighted avg     0.4576    0.4757    0.4549       185

micro f-score: 0.4756756756756757

========== Train Epoch 24 ==========
Loss: 1.285	Accuracy: 47.57%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.5000    0.7436    0.5979        39

    accuracy                         0.4757       185
   macro avg     0.4358    0.4196    0.4134       185
weighted avg     0.4598    0.4757    0.4549       185

micro f-score: 0.4756756756756757

========== Train Epoch 25 ==========
Loss: 1.263	Accuracy: 49.73%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.4839    0.5357        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.4973       185
   macro avg     0.4677    0.4342    0.4261       185
weighted avg     0.4917    0.4973    0.4715       185

micro f-score: 0.4972972972972973

========== Train Epoch 26 ==========
Loss: 1.243	Accuracy: 50.27%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4444    0.3636    0.4000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.6571    0.5111    0.5750        45
         zxx     0.4487    0.8974    0.5983        39

    accuracy                         0.5027       185
   macro avg     0.5119    0.4386    0.4301       185
weighted avg     0.5282    0.5027    0.4738       185

micro f-score: 0.5027027027027027

========== Train Epoch 27 ==========
Loss: 1.240	Accuracy: 48.65%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.4667    0.4516    0.4590        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.6111    0.4889    0.5432        45
         zxx     0.5000    0.7436    0.5979        39

    accuracy                         0.4865       185
   macro avg     0.4603    0.4505    0.4397       185
weighted avg     0.4808    0.4865    0.4688       185

micro f-score: 0.4864864864864865

========== Train Epoch 28 ==========
Loss: 1.229	Accuracy: 50.27%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4615    0.5000    0.4800        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.5027       185
   macro avg     0.4821    0.4485    0.4384       185
weighted avg     0.5040    0.5027    0.4779       185

micro f-score: 0.5027027027027027

========== Train Epoch 29 ==========
Loss: 1.220	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.5189       185
   macro avg     0.5304    0.4611    0.4527       185
weighted avg     0.5346    0.5189    0.4901       185

micro f-score: 0.518918918918919

========== Train Epoch 30 ==========
Loss: 1.193	Accuracy: 50.81%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.5789    0.4889    0.5301        45
         zxx     0.5156    0.8462    0.6408        39

    accuracy                         0.5081       185
   macro avg     0.4748    0.4633    0.4482       185
weighted avg     0.4991    0.5081    0.4838       185

micro f-score: 0.5081081081081081

========== Train Epoch 31 ==========
Loss: 1.196	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.5167    0.7949    0.6263        39

    accuracy                         0.5135       185
   macro avg     0.4802    0.4756    0.4579       185
weighted avg     0.5061    0.5135    0.4918       185

micro f-score: 0.5135135135135135

========== Train Epoch 32 ==========
Loss: 1.188	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.6571    0.5111    0.5750        45
         zxx     0.4776    0.8205    0.6038        39

    accuracy                         0.5081       185
   macro avg     0.4697    0.4644    0.4455       185
weighted avg     0.5020    0.5081    0.4841       185

micro f-score: 0.5081081081081081

========== Train Epoch 33 ==========
Loss: 1.176	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5556    0.4839    0.5172        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.5952    0.5556    0.5747        45
         zxx     0.5224    0.8974    0.6604        39

    accuracy                         0.5351       185
   macro avg     0.5346    0.4801    0.4686       185
weighted avg     0.5443    0.5351    0.5064       185

micro f-score: 0.5351351351351351

========== Train Epoch 34 ==========
Loss: 1.160	Accuracy: 52.97%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.5000    0.5000    0.5000        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.4930    0.8974    0.6364        39

    accuracy                         0.5297       185
   macro avg     0.5138    0.4833    0.4719       185
weighted avg     0.5299    0.5297    0.5037       185

micro f-score: 0.5297297297297298

========== Train Epoch 35 ==========
Loss: 1.144	Accuracy: 50.27%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4857    0.5484    0.5152        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.2857    0.2353    0.2581        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6154    0.5333    0.5714        45
         zxx     0.5745    0.6923    0.6279        39

    accuracy                         0.5027       185
   macro avg     0.4600    0.4633    0.4493       185
weighted avg     0.4936    0.5027    0.4880       185

micro f-score: 0.5027027027027027

========== Train Epoch 36 ==========
Loss: 1.125	Accuracy: 52.43%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.4583    0.5000    0.4783        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.5909    0.5778    0.5843        45
         zxx     0.5254    0.7949    0.6327        39

    accuracy                         0.5243       185
   macro avg     0.5082    0.4761    0.4707       185
weighted avg     0.5199    0.5243    0.5040       185

micro f-score: 0.5243243243243243

========== Train Epoch 37 ==========
Loss: 1.114	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.5161    0.5424        31
         cwx     0.4783    0.5000    0.4889        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6389    0.5111    0.5679        45
         zxx     0.5000    0.8718    0.6355        39

    accuracy                         0.5351       185
   macro avg     0.5479    0.4941    0.4820       185
weighted avg     0.5585    0.5351    0.5126       185

micro f-score: 0.5351351351351351

========== Train Epoch 38 ==========
Loss: 1.119	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5357    0.4839    0.5085        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.5189       185
   macro avg     0.5139    0.4725    0.4617       185
weighted avg     0.5414    0.5189    0.4973       185

micro f-score: 0.518918918918919

========== Train Epoch 39 ==========
Loss: 1.108	Accuracy: 53.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5667    0.5484    0.5574        31
         cwx     0.5238    0.5000    0.5116        22
         hdx     0.5000    0.1176    0.1905        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7742    0.5333    0.6316        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.5351       185
   macro avg     0.5429    0.4851    0.4741       185
weighted avg     0.5645    0.5351    0.5115       185

micro f-score: 0.5351351351351351

========== Train Epoch 40 ==========
Loss: 1.091	Accuracy: 52.43%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.5870    0.6000    0.5934        45
         zxx     0.5686    0.7436    0.6444        39

    accuracy                         0.5243       185
   macro avg     0.4869    0.4693    0.4664       185
weighted avg     0.5117    0.5243    0.5083       185

micro f-score: 0.5243243243243243

========== Train Epoch 41 ==========
Loss: 1.077	Accuracy: 55.14%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5143    0.5806    0.5455        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6410    0.5556    0.5952        45
         zxx     0.5962    0.7949    0.6813        39

    accuracy                         0.5514       185
   macro avg     0.5285    0.5117    0.4959       185
weighted avg     0.5519    0.5514    0.5324       185

micro f-score: 0.5513513513513514

========== Train Epoch 42 ==========
Loss: 1.077	Accuracy: 54.59%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7273    0.5333    0.6154        45
         zxx     0.5323    0.8462    0.6535        39

    accuracy                         0.5459       185
   macro avg     0.5110    0.5037    0.4853       185
weighted avg     0.5442    0.5459    0.5234       185

micro f-score: 0.5459459459459459

========== Train Epoch 43 ==========
Loss: 1.061	Accuracy: 55.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5862    0.5484    0.5667        31
         cwx     0.4444    0.5455    0.4898        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6122    0.6667    0.6383        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.5568       185
   macro avg     0.5000    0.5009    0.4930       185
weighted avg     0.5373    0.5568    0.5410       185

micro f-score: 0.5567567567567567

========== Train Epoch 44 ==========
Loss: 1.049	Accuracy: 54.05%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.5660    0.7692    0.6522        39

    accuracy                         0.5405       185
   macro avg     0.5049    0.4961    0.4840       185
weighted avg     0.5336    0.5405    0.5230       185

micro f-score: 0.5405405405405406

========== Train Epoch 45 ==========
Loss: 1.046	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6400    0.5161    0.5714        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5833    0.8974    0.7071        39

    accuracy                         0.5892       185
   macro avg     0.5673    0.5382    0.5347       185
weighted avg     0.5944    0.5892    0.5745       185

micro f-score: 0.5891891891891892

========== Train Epoch 46 ==========
Loss: 1.023	Accuracy: 54.05%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5926    0.5161    0.5517        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7667    0.5111    0.6133        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.5405       185
   macro avg     0.5437    0.5006    0.4924       185
weighted avg     0.5686    0.5405    0.5226       185

micro f-score: 0.5405405405405406

========== Train Epoch 47 ==========
Loss: 1.035	Accuracy: 51.89%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.8077    0.4667    0.5915        45
         zxx     0.4783    0.8462    0.6111        39

    accuracy                         0.5189       185
   macro avg     0.5035    0.4787    0.4684       185
weighted avg     0.5428    0.5189    0.5027       185

micro f-score: 0.518918918918919

========== Train Epoch 48 ==========
Loss: 1.017	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.5161    0.5818        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.5333    0.8205    0.6465        39

    accuracy                         0.5784       185
   macro avg     0.5486    0.5383    0.5283       185
weighted avg     0.5745    0.5784    0.5620       185

micro f-score: 0.5783783783783784

========== Train Epoch 49 ==========
Loss: 1.007	Accuracy: 56.76%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5806    0.5806    0.5806        31
         cwx     0.4839    0.6818    0.5660        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6327    0.7949    0.7045        39

    accuracy                         0.5676       185
   macro avg     0.5151    0.5244    0.5099       185
weighted avg     0.5651    0.5676    0.5566       185

micro f-score: 0.5675675675675675

========== Train Epoch 50 ==========
Loss: 0.996	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5625    0.5806    0.5714        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6750    0.6000    0.6353        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5838       185
   macro avg     0.5560    0.5509    0.5476       185
weighted avg     0.5808    0.5838    0.5766       185

micro f-score: 0.5837837837837838

========== Train Epoch 51 ==========
Loss: 0.998	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5429    0.6129    0.5758        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.6383    0.6667    0.6522        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5784       185
   macro avg     0.5321    0.5343    0.5269       185
weighted avg     0.5659    0.5784    0.5676       185

micro f-score: 0.5783783783783784

========== Train Epoch 52 ==========
Loss: 0.988	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5405    0.6452    0.5882        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6304    0.6444    0.6374        45
         zxx     0.6429    0.6923    0.6667        39

    accuracy                         0.5676       185
   macro avg     0.5288    0.5230    0.5178       185
weighted avg     0.5572    0.5676    0.5562       185

micro f-score: 0.5675675675675675

========== Train Epoch 53 ==========
Loss: 0.960	Accuracy: 57.30%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6429    0.5806    0.6102        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.6667    0.6222    0.6437        45
         zxx     0.5238    0.8462    0.6471        39

    accuracy                         0.5730       185
   macro avg     0.5618    0.5220    0.5121       185
weighted avg     0.5794    0.5730    0.5510       185

micro f-score: 0.572972972972973

========== Train Epoch 54 ==========
Loss: 0.965	Accuracy: 57.84%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5231    0.8718    0.6538        39

    accuracy                         0.5784       185
   macro avg     0.5703    0.5343    0.5256       185
weighted avg     0.5878    0.5784    0.5586       185

micro f-score: 0.5783783783783784

========== Train Epoch 55 ==========
Loss: 0.960	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.4878    0.6452    0.5556        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5838       185
   macro avg     0.5454    0.5363    0.5274       185
weighted avg     0.5803    0.5838    0.5690       185

micro f-score: 0.5837837837837838

========== Train Epoch 56 ==========
Loss: 0.933	Accuracy: 60.54%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.5758    0.6129    0.5938        31
         cwx     0.5652    0.5909    0.5778        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5714    0.2105    0.3077        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.6000    0.8462    0.7021        39

    accuracy                         0.6054       185
   macro avg     0.5844    0.5606    0.5550       185
weighted avg     0.6039    0.6054    0.5898       185

micro f-score: 0.6054054054054054

========== Train Epoch 57 ==========
Loss: 0.927	Accuracy: 58.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5278    0.6129    0.5672        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.4167    0.2941    0.3448        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.6000    0.7500    0.6667        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.5690    0.8462    0.6804        39

    accuracy                         0.5838       185
   macro avg     0.5609    0.5471    0.5331       185
weighted avg     0.5829    0.5838    0.5645       185

micro f-score: 0.5837837837837838

========== Train Epoch 58 ==========
Loss: 0.921	Accuracy: 55.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6250    0.2632    0.3704        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.4545    0.8974    0.6034        39

    accuracy                         0.5568       185
   macro avg     0.5741    0.5176    0.5104       185
weighted avg     0.6073    0.5568    0.5448       185

micro f-score: 0.5567567567567567

========== Train Epoch 59 ==========
Loss: 0.915	Accuracy: 58.38%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.7778    0.4516    0.5714        31
         cwx     0.5714    0.5455    0.5581        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.5556    0.2632    0.3571        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7000    0.6222    0.6588        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5838       185
   macro avg     0.5788    0.5510    0.5431       185
weighted avg     0.6065    0.5838    0.5724       185

micro f-score: 0.5837837837837838

========== Train Epoch 60 ==========
Loss: 0.871	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4762    0.6452    0.5479        31
         cwx     0.5789    0.5000    0.5366        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7027    0.5778    0.6341        45
         zxx     0.6078    0.7949    0.6889        39

    accuracy                         0.5730       185
   macro avg     0.5510    0.5398    0.5254       185
weighted avg     0.5749    0.5730    0.5570       185

micro f-score: 0.572972972972973

========== Train Epoch 61 ==========
Loss: 0.883	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5833    0.6364    0.6087        22
         hdx     0.7143    0.2941    0.4167        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.5312    0.8718    0.6602        39

    accuracy                         0.5946       185
   macro avg     0.5964    0.5384    0.5357       185
weighted avg     0.6059    0.5946    0.5738       185

micro f-score: 0.5945945945945946

========== Train Epoch 62 ==========
Loss: 0.877	Accuracy: 58.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6957    0.5161    0.5926        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.6818    0.6667    0.6742        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.5892       185
   macro avg     0.5636    0.5491    0.5401       185
weighted avg     0.5952    0.5892    0.5778       185

micro f-score: 0.5891891891891892

========== Train Epoch 63 ==========
Loss: 0.862	Accuracy: 59.46%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.3529    0.3529    0.3529        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5000    0.7500    0.6000        12
         qtx     0.7073    0.6444    0.6744        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5946       185
   macro avg     0.5506    0.5721    0.5546       185
weighted avg     0.5957    0.5946    0.5909       185

micro f-score: 0.5945945945945946

========== Train Epoch 64 ==========
Loss: 0.858	Accuracy: 58.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6818    0.4839    0.5660        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.6905    0.6444    0.6667        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5892       185
   macro avg     0.5466    0.5508    0.5403       185
weighted avg     0.5899    0.5892    0.5813       185

micro f-score: 0.5891891891891892

Finished training!!!

Min Loss = 0.858 in epoch 63;
Max Accuracy = 60.54% in epoch 55;
Total Cost 32 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─SPP: 1-4                                    [-1, 64, 160, 160]        --
|    └─Conv: 2-1                              [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                       [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2                  [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                         [-1, 32, 160, 160]        --
|    └─ModuleList: 2                          []                        --
|    |    └─MaxPool2d: 3-4                    [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5                    [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6                    [-1, 32, 160, 160]        --
|    └─Conv: 2-2                              [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                       [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8                  [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                         [-1, 64, 160, 160]        --
├─Sequential: 1-5                             [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11                 [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14                 [-1, 64, 160, 160]        128
|    |    └─CoordAtt: 3-15                    [-1, 64, 160, 160]        1,688
|    |    └─ReLU: 3-16                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-17                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-18                 [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-19                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-20                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-21                 [-1, 64, 160, 160]        128
|    |    └─CoordAtt: 3-22                    [-1, 64, 160, 160]        1,688
|    |    └─ReLU: 3-23                        [-1, 64, 160, 160]        --
├─Sequential: 1-6                             [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-5                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-24                      [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-25                 [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-26                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-27                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-28                 [-1, 128, 80, 80]         256
|    |    └─CoordAtt: 3-29                    [-1, 128, 80, 80]         3,352
|    |    └─Sequential: 3-30                  [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-31                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-32                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-33                 [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-34                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36                 [-1, 128, 80, 80]         256
|    |    └─CoordAtt: 3-37                    [-1, 128, 80, 80]         3,352
|    |    └─ReLU: 3-38                        [-1, 128, 80, 80]         --
├─Sequential: 1-7                             [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-7                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-39                      [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-40                 [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-41                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-42                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-43                 [-1, 256, 40, 40]         512
|    |    └─CoordAtt: 3-44                    [-1, 256, 40, 40]         6,680
|    |    └─Sequential: 3-45                  [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-46                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-8                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-47                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-48                 [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-49                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-50                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-51                 [-1, 256, 40, 40]         512
|    |    └─CoordAtt: 3-52                    [-1, 256, 40, 40]         6,680
|    |    └─ReLU: 3-53                        [-1, 256, 40, 40]         --
├─Sequential: 1-8                             [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-9                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-54                      [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-55                 [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-56                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-57                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-58                 [-1, 512, 20, 20]         1,024
|    |    └─CoordAtt: 3-59                    [-1, 512, 20, 20]         25,648
|    |    └─Sequential: 3-60                  [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-61                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-10                       [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-62                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-63                 [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-64                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-65                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-66                 [-1, 512, 20, 20]         1,024
|    |    └─CoordAtt: 3-67                    [-1, 512, 20, 20]         25,648
|    |    └─ReLU: 3-68                        [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,265,271
Trainable params: 11,265,271
Non-trainable params: 0
Total mult-adds (G): 14.37
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 273.28
Params size (MB): 42.97
Estimated Total Size (MB): 317.43
===============================================================================================



Traceback (most recent call last):
  File "train.py", line 259, in <module>
    ca_spp_resnet.resnet18, **args)
  File "train.py", line 189, in train
    stat(net, (3, 320, 320))
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 71, in stat
    ms.show_report()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 64, in show_report
    collected_nodes = self._analyze_model()
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/statistics.py", line 57, in _analyze_model
    model_hook = ModelHook(self._model, self._input_size)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 24, in __init__
    self._model(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/dl/models/ca_spp_resnet.py", line 349, in forward
    return self._forward_impl(x, y)
  File "/home/djy/dl/models/ca_spp_resnet.py", line 332, in _forward_impl
    x = self.conv1(x)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchstat/model_hook.py", line 50, in wrap_call
    output = self._origin_call[module.__class__](module, *input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
