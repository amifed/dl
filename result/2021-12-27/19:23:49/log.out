dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: hcam_resnet18_max1
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.816	Accuracy: 21.62%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2857    0.0909    0.1379        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.1053    0.1212        19
         nqx     0.3333    0.1667    0.2222        12
         qtx     0.1818    0.0889    0.1194        45
         zxx     0.2222    0.7692    0.3448        39

    accuracy                         0.2162       185
   macro avg     0.1666    0.1744    0.1351       185
weighted avg     0.1613    0.2162    0.1450       185

micro f-score: 0.21621621621621623

========== Train Epoch 2 ==========
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.579	Accuracy: 32.43%	Cost 45s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.2000    0.1364    0.1622        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.5143    0.4000    0.4500        45
         zxx     0.3009    0.8718    0.4474        39

    accuracy                         0.3243       185
   macro avg     0.3522    0.2490    0.2079       185
weighted avg     0.4166    0.3243    0.2583       185

micro f-score: 0.32432432432432434

========== Train Epoch 3 ==========
Loss: 1.531	Accuracy: 35.68%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5429    0.4222    0.4750        45
         zxx     0.3148    0.8718    0.4626        39

    accuracy                         0.3568       185
   macro avg     0.3712    0.2949    0.2669       185
weighted avg     0.3987    0.3568    0.3021       185

micro f-score: 0.3567567567567568

========== Train Epoch 4 ==========
Loss: 1.518	Accuracy: 36.22%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5556    0.4444    0.4938        45
         zxx     0.3208    0.8718    0.4690        39

    accuracy                         0.3622       185
   macro avg     0.3719    0.2943    0.2659       185
weighted avg     0.4139    0.3622    0.3093       185

micro f-score: 0.3621621621621622

========== Train Epoch 5 ==========
Loss: 1.517	Accuracy: 34.59%	Cost 45s
              precision    recall  f1-score   support

         bzx     0.6667    0.0645    0.1176        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.5556    0.4444    0.4938        45
         zxx     0.3148    0.8718    0.4626        39

    accuracy                         0.3459       185
   macro avg     0.3181    0.2665    0.2322       185
weighted avg     0.3778    0.3459    0.2875       185

micro f-score: 0.34594594594594597

========== Train Epoch 6 ==========
Loss: 1.507	Accuracy: 36.76%	Cost 46s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5526    0.4667    0.5060        45
         zxx     0.3267    0.8462    0.4714        39

    accuracy                         0.3676       185
   macro avg     0.3408    0.3003    0.2738       185
weighted avg     0.3752    0.3676    0.3173       185

micro f-score: 0.3675675675675676

========== Train Epoch 7 ==========
Loss: 1.503	Accuracy: 36.22%	Cost 47s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5526    0.4667    0.5060        45
         zxx     0.3235    0.8462    0.4681        39

    accuracy                         0.3622       185
   macro avg     0.3328    0.2928    0.2626       185
weighted avg     0.3760    0.3622    0.3092       185

micro f-score: 0.3621621621621622

========== Train Epoch 8 ==========
Loss: 1.495	Accuracy: 35.68%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.5526    0.4667    0.5060        45
         zxx     0.3235    0.8462    0.4681        39

    accuracy                         0.3568       185
   macro avg     0.2947    0.2844    0.2498       185
weighted avg     0.3439    0.3568    0.3007       185

micro f-score: 0.3567567567567568

========== Train Epoch 9 ==========
Loss: 1.481	Accuracy: 36.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2000    0.0645    0.0976        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.3465    0.8974    0.5000        39

    accuracy                         0.3676       185
   macro avg     0.2848    0.2917    0.2595       185
weighted avg     0.3248    0.3676    0.3094       185

micro f-score: 0.3675675675675676

========== Train Epoch 10 ==========
Loss: 1.484	Accuracy: 35.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2222    0.0645    0.1000        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5250    0.4667    0.4941        45
         zxx     0.3333    0.8205    0.4741        39

    accuracy                         0.3568       185
   macro avg     0.2952    0.2891    0.2632       185
weighted avg     0.3262    0.3568    0.3066       185

micro f-score: 0.3567567567567568

========== Train Epoch 11 ==========
Loss: 1.484	Accuracy: 38.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3000    0.0968    0.1463        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.3548    0.8462    0.5000        39

    accuracy                         0.3892       185
   macro avg     0.3585    0.3230    0.3069       185
weighted avg     0.3800    0.3892    0.3462       185

micro f-score: 0.3891891891891892

========== Train Epoch 12 ==========
Loss: 1.478	Accuracy: 36.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.2000    0.0968    0.1304        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5250    0.4667    0.4941        45
         zxx     0.3444    0.7949    0.4806        39

    accuracy                         0.3622       185
   macro avg     0.3141    0.2985    0.2817       185
weighted avg     0.3370    0.3622    0.3212       185

micro f-score: 0.3621621621621622

========== Train Epoch 13 ==========
Loss: 1.461	Accuracy: 38.92%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3000    0.0968    0.1463        31
         cwx     0.3333    0.2273    0.2703        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3579    0.8718    0.5075        39

    accuracy                         0.3892       185
   macro avg     0.3412    0.3245    0.3007       185
weighted avg     0.3697    0.3892    0.3410       185

micro f-score: 0.3891891891891892

========== Train Epoch 14 ==========
Loss: 1.469	Accuracy: 35.68%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2308    0.0968    0.1364        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5250    0.4667    0.4941        45
         zxx     0.3478    0.8205    0.4885        39

    accuracy                         0.3568       185
   macro avg     0.2895    0.2872    0.2630       185
weighted avg     0.3233    0.3568    0.3095       185

micro f-score: 0.3567567567567568

========== Train Epoch 15 ==========
Loss: 1.461	Accuracy: 35.68%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2000    0.0968    0.1304        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.3523    0.7949    0.4882        39

    accuracy                         0.3568       185
   macro avg     0.2856    0.2867    0.2637       185
weighted avg     0.3188    0.3568    0.3113       185

micro f-score: 0.3567567567567568

========== Train Epoch 16 ==========
Loss: 1.445	Accuracy: 36.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2143    0.0968    0.1333        31
         cwx     0.2778    0.2273    0.2500        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5385    0.4667    0.5000        45
         zxx     0.3587    0.8462    0.5038        39

    accuracy                         0.3622       185
   macro avg     0.2818    0.2864    0.2618       185
weighted avg     0.3201    0.3622    0.3131       185

micro f-score: 0.3621621621621622

========== Train Epoch 17 ==========
Loss: 1.439	Accuracy: 37.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2308    0.0968    0.1364        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3617    0.8718    0.5113        39

    accuracy                         0.3784       185
   macro avg     0.2932    0.3032    0.2752       185
weighted avg     0.3332    0.3784    0.3259       185

micro f-score: 0.37837837837837834

========== Train Epoch 18 ==========
Loss: 1.433	Accuracy: 36.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2143    0.0968    0.1333        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3596    0.8205    0.5000        39

    accuracy                         0.3676       185
   macro avg     0.3058    0.2979    0.2769       185
weighted avg     0.3365    0.3676    0.3230       185

micro f-score: 0.3675675675675676

========== Train Epoch 19 ==========
Loss: 1.429	Accuracy: 37.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2500    0.1290    0.1702        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3636    0.8205    0.5039        39

    accuracy                         0.3784       185
   macro avg     0.3281    0.3090    0.2924       185
weighted avg     0.3547    0.3784    0.3371       185

micro f-score: 0.37837837837837834

========== Train Epoch 20 ==========
Loss: 1.421	Accuracy: 38.38%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2500    0.1290    0.1702        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.3765    0.8205    0.5161        39

    accuracy                         0.3838       185
   macro avg     0.3286    0.3164    0.2994       185
weighted avg     0.3543    0.3838    0.3425       185

micro f-score: 0.3837837837837838

========== Train Epoch 21 ==========
Loss: 1.419	Accuracy: 38.38%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.2353    0.1290    0.1667        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.3678    0.8205    0.5079        39

    accuracy                         0.3838       185
   macro avg     0.3440    0.3228    0.3065       185
weighted avg     0.3651    0.3838    0.3448       185

micro f-score: 0.3837837837837838

========== Train Epoch 22 ==========
Loss: 1.422	Accuracy: 37.84%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2353    0.1290    0.1667        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.3810    0.8205    0.5203        39

    accuracy                         0.3784       185
   macro avg     0.3304    0.3109    0.2951       185
weighted avg     0.3531    0.3784    0.3380       185

micro f-score: 0.37837837837837834

========== Train Epoch 23 ==========
Loss: 1.418	Accuracy: 38.38%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2143    0.0968    0.1333        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.3837    0.8462    0.5280        39

    accuracy                         0.3838       185
   macro avg     0.3308    0.3165    0.2980       185
weighted avg     0.3547    0.3838    0.3403       185

micro f-score: 0.3837837837837838

========== Train Epoch 24 ==========
Loss: 1.407	Accuracy: 38.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2500    0.1290    0.1702        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3793    0.8462    0.5238        39

    accuracy                         0.3838       185
   macro avg     0.3359    0.3146    0.2978       185
weighted avg     0.3613    0.3838    0.3421       185

micro f-score: 0.3837837837837838

========== Train Epoch 25 ==========
Loss: 1.403	Accuracy: 39.46%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.2778    0.1613    0.2041        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.3946       185
   macro avg     0.3493    0.3257    0.3112       185
weighted avg     0.3763    0.3946    0.3565       185

micro f-score: 0.3945945945945946

========== Train Epoch 26 ==========
Loss: 1.396	Accuracy: 38.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3333    0.1935    0.2449        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.3892       185
   macro avg     0.3249    0.3163    0.2981       185
weighted avg     0.3623    0.3892    0.3491       185

micro f-score: 0.3891891891891892

========== Train Epoch 27 ==========
Loss: 1.389	Accuracy: 40.00%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2941    0.1613    0.2083        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.3882    0.8462    0.5323        39

    accuracy                         0.4000       185
   macro avg     0.3655    0.3322    0.3197       185
weighted avg     0.3841    0.4000    0.3612       185

micro f-score: 0.4000000000000001

========== Train Epoch 28 ==========
Loss: 1.388	Accuracy: 38.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2941    0.1613    0.2083        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.3976    0.8462    0.5410        39

    accuracy                         0.3892       185
   macro avg     0.3361    0.3192    0.3031       185
weighted avg     0.3632    0.3892    0.3487       185

micro f-score: 0.3891891891891892

========== Train Epoch 29 ==========
Loss: 1.376	Accuracy: 40.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2941    0.1613    0.2083        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3750    0.8462    0.5197        39

    accuracy                         0.4000       185
   macro avg     0.3688    0.3376    0.3228       185
weighted avg     0.3897    0.4000    0.3620       185

micro f-score: 0.4000000000000001

========== Train Epoch 30 ==========
Loss: 1.371	Accuracy: 39.46%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.3855    0.8205    0.5246        39

    accuracy                         0.3946       185
   macro avg     0.3510    0.3248    0.3128       185
weighted avg     0.3794    0.3946    0.3598       185

micro f-score: 0.3945945945945946

========== Train Epoch 31 ==========
Loss: 1.362	Accuracy: 38.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3125    0.1613    0.2128        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.1667    0.0526    0.0800        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.3929    0.8462    0.5366        39

    accuracy                         0.3838       185
   macro avg     0.3171    0.3117    0.2916       185
weighted avg     0.3505    0.3838    0.3403       185

micro f-score: 0.3837837837837838

========== Train Epoch 32 ==========
Loss: 1.360	Accuracy: 41.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5116    0.4889    0.5000        45
         zxx     0.4074    0.8462    0.5500        39

    accuracy                         0.4108       185
   macro avg     0.3700    0.3468    0.3345       185
weighted avg     0.3910    0.4108    0.3745       185

micro f-score: 0.4108108108108109

========== Train Epoch 33 ==========
Loss: 1.369	Accuracy: 41.62%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.4125    0.8462    0.5546        39

    accuracy                         0.4162       185
   macro avg     0.3703    0.3446    0.3338       185
weighted avg     0.3961    0.4162    0.3802       185

micro f-score: 0.41621621621621624

========== Train Epoch 34 ==========
Loss: 1.352	Accuracy: 40.54%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.2500    0.1818    0.2105        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3636    0.3333    0.3478        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.4048    0.8718    0.5528        39

    accuracy                         0.4054       185
   macro avg     0.3564    0.3321    0.3176       185
weighted avg     0.3865    0.4054    0.3666       185

micro f-score: 0.40540540540540543

========== Train Epoch 35 ==========
Loss: 1.356	Accuracy: 41.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5641    0.4889    0.5238        45
         zxx     0.3908    0.8718    0.5397        39

    accuracy                         0.4108       185
   macro avg     0.3710    0.3440    0.3290       185
weighted avg     0.3979    0.4108    0.3727       185

micro f-score: 0.4108108108108109

========== Train Epoch 36 ==========
Loss: 1.354	Accuracy: 40.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3000    0.1935    0.2353        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5238    0.4889    0.5057        45
         zxx     0.4026    0.7949    0.5345        39

    accuracy                         0.4000       185
   macro avg     0.3587    0.3433    0.3327       185
weighted avg     0.3802    0.4000    0.3693       185

micro f-score: 0.4000000000000001

========== Train Epoch 37 ==========
Loss: 1.337	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3000    0.1935    0.2353        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.4156    0.8205    0.5517        39

    accuracy                         0.4108       185
   macro avg     0.3599    0.3468    0.3341       185
weighted avg     0.3850    0.4108    0.3763       185

micro f-score: 0.4108108108108109

========== Train Epoch 38 ==========
Loss: 1.334	Accuracy: 42.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3529    0.1935    0.2500        31
         cwx     0.2857    0.1818    0.2222        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.4146    0.8718    0.5620        39

    accuracy                         0.4270       185
   macro avg     0.3819    0.3573    0.3448       185
weighted avg     0.4055    0.4270    0.3884       185

micro f-score: 0.427027027027027

========== Train Epoch 39 ==========
Loss: 1.339	Accuracy: 42.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3529    0.1935    0.2500        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4146    0.8718    0.5620        39

    accuracy                         0.4216       185
   macro avg     0.3773    0.3574    0.3437       185
weighted avg     0.4035    0.4216    0.3852       185

micro f-score: 0.42162162162162165

========== Train Epoch 40 ==========
Loss: 1.316	Accuracy: 42.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.4177    0.8462    0.5593        39

    accuracy                         0.4270       185
   macro avg     0.3918    0.3649    0.3545       185
weighted avg     0.4132    0.4270    0.3946       185

micro f-score: 0.427027027027027

========== Train Epoch 41 ==========
Loss: 1.322	Accuracy: 41.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3846    0.1613    0.2273        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5227    0.5111    0.5169        45
         zxx     0.3929    0.8462    0.5366        39

    accuracy                         0.4162       185
   macro avg     0.3853    0.3538    0.3418       185
weighted avg     0.4029    0.4162    0.3780       185

micro f-score: 0.41621621621621624

========== Train Epoch 42 ==========
Loss: 1.323	Accuracy: 43.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3571    0.2273    0.2778        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.4198    0.8718    0.5667        39

    accuracy                         0.4324       185
   macro avg     0.3914    0.3652    0.3536       185
weighted avg     0.4158    0.4324    0.3970       185

micro f-score: 0.43243243243243246

========== Train Epoch 43 ==========
Loss: 1.316	Accuracy: 42.70%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3333    0.1613    0.2174        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4342    0.8462    0.5739        39

    accuracy                         0.4270       185
   macro avg     0.3732    0.3653    0.3496       185
weighted avg     0.4031    0.4270    0.3920       185

micro f-score: 0.427027027027027

========== Train Epoch 44 ==========
Loss: 1.316	Accuracy: 42.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5366    0.4889    0.5116        45
         zxx     0.4359    0.8718    0.5812        39

    accuracy                         0.4270       185
   macro avg     0.3830    0.3673    0.3528       185
weighted avg     0.4082    0.4270    0.3919       185

micro f-score: 0.427027027027027

========== Train Epoch 45 ==========
Loss: 1.300	Accuracy: 43.24%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.4375    0.8974    0.5882        39

    accuracy                         0.4324       185
   macro avg     0.3886    0.3724    0.3562       185
weighted avg     0.4208    0.4324    0.3984       185

micro f-score: 0.43243243243243246

========== Train Epoch 46 ==========
Loss: 1.302	Accuracy: 43.78%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3500    0.2258    0.2745        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4378       185
   macro avg     0.3990    0.3717    0.3621       185
weighted avg     0.4222    0.4378    0.4043       185

micro f-score: 0.43783783783783786

========== Train Epoch 47 ==========
Loss: 1.298	Accuracy: 43.24%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3684    0.2258    0.2800        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5455    0.5333    0.5393        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.4324       185
   macro avg     0.3928    0.3652    0.3513       185
weighted avg     0.4159    0.4324    0.3953       185

micro f-score: 0.43243243243243246

========== Train Epoch 48 ==========
Loss: 1.298	Accuracy: 42.70%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.1613    0.2174        31
         cwx     0.2941    0.2273    0.2564        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5435    0.5556    0.5495        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4270       185
   macro avg     0.3669    0.3592    0.3428       185
weighted avg     0.3955    0.4270    0.3876       185

micro f-score: 0.427027027027027

========== Train Epoch 49 ==========
Loss: 1.287	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5581    0.5333    0.5455        45
         zxx     0.4198    0.8718    0.5667        39

    accuracy                         0.4432       185
   macro avg     0.4141    0.3782    0.3698       185
weighted avg     0.4356    0.4432    0.4094       185

micro f-score: 0.44324324324324327

========== Train Epoch 50 ==========
Loss: 1.287	Accuracy: 44.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3333    0.1053    0.1600        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.4217    0.8974    0.5738        39

    accuracy                         0.4432       185
   macro avg     0.4117    0.3787    0.3657       185
weighted avg     0.4396    0.4432    0.4081       185

micro f-score: 0.44324324324324327

========== Train Epoch 51 ==========
Loss: 1.290	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6216    0.5111    0.5610        45
         zxx     0.4146    0.8718    0.5620        39

    accuracy                         0.4432       185
   macro avg     0.4070    0.3869    0.3722       185
weighted avg     0.4380    0.4432    0.4118       185

micro f-score: 0.44324324324324327

========== Train Epoch 52 ==========
Loss: 1.283	Accuracy: 43.24%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.3529    0.2727    0.3077        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5714    0.5333    0.5517        45
         zxx     0.4177    0.8462    0.5593        39

    accuracy                         0.4324       185
   macro avg     0.3933    0.3681    0.3606       185
weighted avg     0.4170    0.4324    0.4012       185

micro f-score: 0.43243243243243246

========== Train Epoch 53 ==========
Loss: 1.271	Accuracy: 43.78%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.3000    0.2727    0.2857        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5532    0.5778    0.5652        45
         zxx     0.4533    0.8718    0.5965        39

    accuracy                         0.4378       185
   macro avg     0.3825    0.3689    0.3536       185
weighted avg     0.4132    0.4378    0.3990       185

micro f-score: 0.43783783783783786

========== Train Epoch 54 ==========
Loss: 1.251	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4500    0.2903    0.3529        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.4486       185
   macro avg     0.4021    0.3843    0.3722       185
weighted avg     0.4386    0.4486    0.4195       185

micro f-score: 0.4486486486486486

========== Train Epoch 55 ==========
Loss: 1.255	Accuracy: 43.78%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3846    0.1613    0.2273        31
         cwx     0.3158    0.2727    0.2927        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5556    0.5556    0.5556        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.4378       185
   macro avg     0.3911    0.3741    0.3607       185
weighted avg     0.4159    0.4378    0.4007       185

micro f-score: 0.43783783783783786

========== Train Epoch 56 ==========
Loss: 1.262	Accuracy: 44.86%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4706    0.2581    0.3333        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5000    0.4167    0.4545        12
         qtx     0.5682    0.5556    0.5618        45
         zxx     0.4231    0.8462    0.5641        39

    accuracy                         0.4486       185
   macro avg     0.4162    0.3823    0.3763       185
weighted avg     0.4388    0.4486    0.4179       185

micro f-score: 0.4486486486486486

========== Train Epoch 57 ==========
Loss: 1.256	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4545    0.4167    0.4348        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4304    0.8718    0.5763        39

    accuracy                         0.4432       185
   macro avg     0.4009    0.3782    0.3680       185
weighted avg     0.4289    0.4432    0.4108       185

micro f-score: 0.44324324324324327

========== Train Epoch 58 ==========
Loss: 1.248	Accuracy: 44.32%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3333    0.1613    0.2174        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.5897    0.5111    0.5476        45
         zxx     0.4416    0.8718    0.5862        39

    accuracy                         0.4432       185
   macro avg     0.3997    0.3917    0.3735       185
weighted avg     0.4273    0.4432    0.4098       185

micro f-score: 0.44324324324324327

========== Train Epoch 59 ==========
Loss: 1.246	Accuracy: 47.57%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.5870    0.6000    0.5934        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.4757       185
   macro avg     0.4303    0.4130    0.4021       185
weighted avg     0.4624    0.4757    0.4471       185

micro f-score: 0.4756756756756757

========== Train Epoch 60 ==========
Loss: 1.236	Accuracy: 48.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.4348    0.4545    0.4444        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.6000    0.6000    0.6000        45
         zxx     0.5000    0.8462    0.6286        39

    accuracy                         0.4865       185
   macro avg     0.4371    0.4241    0.4155       185
weighted avg     0.4688    0.4865    0.4606       185

micro f-score: 0.4864864864864865

========== Train Epoch 61 ==========
Loss: 1.228	Accuracy: 45.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.3684    0.3182    0.3415        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.4167    0.4167    0.4167        12
         qtx     0.5814    0.5556    0.5682        45
         zxx     0.4521    0.8462    0.5893        39

    accuracy                         0.4541       185
   macro avg     0.4070    0.3907    0.3815       185
weighted avg     0.4383    0.4541    0.4257       185

micro f-score: 0.4540540540540541

========== Train Epoch 62 ==========
Loss: 1.244	Accuracy: 48.11%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4118    0.2258    0.2917        31
         cwx     0.4091    0.4091    0.4091        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6341    0.5778    0.6047        45
         zxx     0.4857    0.8718    0.6239        39

    accuracy                         0.4811       185
   macro avg     0.4302    0.4289    0.4096       185
weighted avg     0.4641    0.4811    0.4510       185

micro f-score: 0.4810810810810811

========== Train Epoch 63 ==========
Loss: 1.215	Accuracy: 45.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4737    0.2903    0.3600        31
         cwx     0.3889    0.3182    0.3500        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6053    0.5111    0.5542        45
         zxx     0.4474    0.8718    0.5913        39

    accuracy                         0.4541       185
   macro avg     0.4112    0.3918    0.3812       185
weighted avg     0.4496    0.4541    0.4281       185

micro f-score: 0.4540540540540541

========== Train Epoch 64 ==========
Loss: 1.239	Accuracy: 47.03%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4375    0.2258    0.2979        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.4583    0.8462    0.5946        39

    accuracy                         0.4703       185
   macro avg     0.4296    0.4143    0.4031       185
weighted avg     0.4608    0.4703    0.4437       185

micro f-score: 0.4702702702702703

Finished training!!!

Min Loss = 1.215 in epoch 62;
Max Accuracy = 48.65% in epoch 59;
Total Cost 33 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                              [-1, 64, 80, 80]          --
├─Sequential: 1-5                             [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                         [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5                  [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-6                    [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-7                         [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-8                       [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-9                  [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-10                        [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-11                      [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-12                 [-1, 64, 80, 80]          128
|    |    └─CoordAtt1: 3-13                   [-1, 64, 80, 80]          3,376
|    |    └─ReLU: 3-14                        [-1, 64, 80, 80]          --
├─Sequential: 1-6                             [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-3                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-15                      [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-16                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-17                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-18                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-19                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-20                   [-1, 128, 40, 40]         6,704
|    |    └─Sequential: 3-21                  [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-22                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-23                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-24                 [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-25                        [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                      [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27                 [-1, 128, 40, 40]         256
|    |    └─CoordAtt1: 3-28                   [-1, 128, 40, 40]         6,704
|    |    └─ReLU: 3-29                        [-1, 128, 40, 40]         --
├─Sequential: 1-7                             [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-5                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-30                      [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-31                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-32                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-33                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-34                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-35                   [-1, 256, 20, 20]         13,360
|    |    └─Sequential: 3-36                  [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-37                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-6                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-38                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-39                 [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-40                        [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-41                      [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-42                 [-1, 256, 20, 20]         512
|    |    └─CoordAtt1: 3-43                   [-1, 256, 20, 20]         13,360
|    |    └─ReLU: 3-44                        [-1, 256, 20, 20]         --
├─Sequential: 1-8                             [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-7                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-45                      [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-46                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-47                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-48                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-49                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-50                   [-1, 512, 10, 10]         51,296
|    |    └─Sequential: 3-51                  [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-52                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-8                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-53                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-54                 [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-55                        [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-56                      [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-57                 [-1, 512, 10, 10]         1,024
|    |    └─CoordAtt1: 3-58                   [-1, 512, 10, 10]         51,296
|    |    └─ReLU: 3-59                        [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,329,575
Trainable params: 11,329,575
Non-trainable params: 0
Total mult-adds (G): 3.73
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 78.75
Params size (MB): 43.22
Estimated Total Size (MB): 123.14
===============================================================================================



