dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

msg: sppb_resnet.resnet34
9
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Learning Rate: [0.001]
Loss: 2.015	Accuracy: 24.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        25
         cwx     0.0000    0.0000    0.0000        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.0000    0.0000    0.0000        15
         qtx     1.0000    0.0323    0.0625        31
         zxx     0.2431    1.0000    0.3911        44

    accuracy                         0.2432       185
   macro avg     0.1776    0.1475    0.0648       185
weighted avg     0.2254    0.2432    0.1035       185

micro f-score: 0.24324324324324326

========== Train Epoch 2 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.834	Accuracy: 19.46%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        25
         cwx     0.0000    0.0000    0.0000        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.0833    0.2000    0.1176        15
         qtx     0.1154    0.0968    0.1053        31
         zxx     0.2500    0.6818    0.3659        44

    accuracy                         0.1946       185
   macro avg     0.0641    0.1398    0.0841       185
weighted avg     0.0856    0.1946    0.1142       185

micro f-score: 0.1945945945945946

========== Train Epoch 3 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.795	Accuracy: 21.62%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.1818    0.9600    0.3057        25
         cwx     0.0000    0.0000    0.0000        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2727    0.2000    0.2308        15
         qtx     0.4286    0.1935    0.2667        31
         zxx     0.2500    0.1591    0.1944        44

    accuracy                         0.2162       185
   macro avg     0.1619    0.2161    0.1425       185
weighted avg     0.1780    0.2162    0.1510       185

micro f-score: 0.21621621621621623

========== Train Epoch 4 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.767	Accuracy: 29.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2247    0.8000    0.3509        25
         cwx     0.4815    0.5000    0.4906        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2083    0.3333    0.2564        15
         qtx     0.3256    0.4516    0.3784        31
         zxx     1.0000    0.0455    0.0870        44

    accuracy                         0.2919       185
   macro avg     0.3200    0.3043    0.2233       185
weighted avg     0.4073    0.2919    0.2212       185

micro f-score: 0.2918918918918919

========== Train Epoch 5 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.717	Accuracy: 27.03%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        25
         cwx     0.5556    0.3846    0.4545        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.1452    0.6000    0.2338        15
         qtx     0.1489    0.2258    0.1795        31
         zxx     0.4138    0.5455    0.4706        44

    accuracy                         0.2703       185
   macro avg     0.1805    0.2508    0.1912       185
weighted avg     0.2132    0.2703    0.2248       185

micro f-score: 0.2702702702702703

========== Train Epoch 6 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.701	Accuracy: 21.62%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        25
         cwx     0.1667    0.3846    0.2326        26
         hdx     0.3333    0.0435    0.0769        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3333    0.4000    0.3636        15
         qtx     0.2093    0.5806    0.3077        31
         zxx     0.3125    0.1136    0.1667        44

    accuracy                         0.2162       185
   macro avg     0.1936    0.2175    0.1639       185
weighted avg     0.2013    0.2162    0.1629       185

micro f-score: 0.21621621621621623

========== Train Epoch 7 ==========
Learning Rate: [0.001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.696	Accuracy: 32.97%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2174    0.2000    0.2083        25
         cwx     0.2273    0.3846    0.2857        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.5000    0.0952    0.1600        21
         nqx     0.3077    0.2667    0.2857        15
         qtx     0.3182    0.6774    0.4330        31
         zxx     0.5429    0.4318    0.4810        44

    accuracy                         0.3297       185
   macro avg     0.3019    0.2937    0.2648       185
weighted avg     0.3255    0.3297    0.2966       185

micro f-score: 0.32972972972972975

========== Train Epoch 8 ==========
Learning Rate: [0.0001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.546	Accuracy: 40.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2000    0.2800    0.2333        25
         cwx     0.3611    0.5000    0.4194        26
         hdx     0.5000    0.0870    0.1481        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3333    0.2667    0.2963        15
         qtx     0.4222    0.6129    0.5000        31
         zxx     0.5577    0.6591    0.6042        44

    accuracy                         0.4000       185
   macro avg     0.3392    0.3437    0.3145       185
weighted avg     0.3704    0.4000    0.3604       185

micro f-score: 0.4000000000000001

========== Train Epoch 9 ==========
Learning Rate: [0.0001]
Loss: 1.515	Accuracy: 38.92%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.1860    0.3200    0.2353        25
         cwx     0.3750    0.4615    0.4138        26
         hdx     0.5000    0.0870    0.1481        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2500    0.2667    0.2581        15
         qtx     0.4318    0.6129    0.5067        31
         zxx     0.6000    0.6136    0.6067        44

    accuracy                         0.3892       185
   macro avg     0.3347    0.3374    0.3098       185
weighted avg     0.3753    0.3892    0.3585       185

micro f-score: 0.3891891891891892

========== Train Epoch 10 ==========
Learning Rate: [0.0001]
Loss: 1.502	Accuracy: 38.92%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1667    0.2400    0.1967        25
         cwx     0.3714    0.5000    0.4262        26
         hdx     0.3333    0.0435    0.0769        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2667    0.2667    0.2667        15
         qtx     0.4359    0.5484    0.4857        31
         zxx     0.5636    0.7045    0.6263        44

    accuracy                         0.3892       185
   macro avg     0.3054    0.3290    0.2969       185
weighted avg     0.3449    0.3892    0.3480       185

micro f-score: 0.3891891891891892

========== Train Epoch 11 ==========
Learning Rate: [0.0001]
Loss: 1.455	Accuracy: 40.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2381    0.4000    0.2985        25
         cwx     0.4194    0.5000    0.4561        26
         hdx     0.2000    0.0435    0.0714        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2727    0.2000    0.2308        15
         qtx     0.4000    0.6452    0.4938        31
         zxx     0.5870    0.6136    0.6000        44

    accuracy                         0.4000       185
   macro avg     0.3024    0.3432    0.3072       185
weighted avg     0.3447    0.4000    0.3575       185

micro f-score: 0.4000000000000001

========== Train Epoch 12 ==========
Learning Rate: [0.0001]
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/djy/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loss: 1.456	Accuracy: 43.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2333    0.2800    0.2545        25
         cwx     0.3611    0.5000    0.4194        26
         hdx     0.6000    0.1304    0.2143        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.4848    0.5161    0.5000        31
         zxx     0.5538    0.8182    0.6606        44

    accuracy                         0.4324       185
   macro avg     0.3700    0.3683    0.3419       185
weighted avg     0.3988    0.4324    0.3888       185

micro f-score: 0.43243243243243246

========== Train Epoch 13 ==========
Learning Rate: [0.0001]
Loss: 1.466	Accuracy: 40.00%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.1750    0.2800    0.2154        25
         cwx     0.3171    0.5000    0.3881        26
         hdx     0.4286    0.1304    0.2000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.2778    0.3333    0.3030        15
         qtx     0.5000    0.5161    0.5079        31
         zxx     0.6522    0.6818    0.6667        44

    accuracy                         0.4000       185
   macro avg     0.3358    0.3488    0.3259       185
weighted avg     0.3829    0.4000    0.3768       185

micro f-score: 0.4000000000000001

========== Train Epoch 14 ==========
Learning Rate: [0.0001]
Loss: 1.425	Accuracy: 42.16%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2273    0.4000    0.2899        25
         cwx     0.4667    0.5385    0.5000        26
         hdx     0.6000    0.1304    0.2143        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.4722    0.5484    0.5075        31
         zxx     0.5577    0.6591    0.6042        44

    accuracy                         0.4216       185
   macro avg     0.3830    0.3728    0.3515       185
weighted avg     0.4116    0.4216    0.3928       185

micro f-score: 0.42162162162162165

========== Train Epoch 15 ==========
Learning Rate: [0.0001]
Loss: 1.394	Accuracy: 40.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.1765    0.2400    0.2034        25
         cwx     0.4000    0.6154    0.4848        26
         hdx     0.2857    0.0870    0.1333        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3750    0.4000    0.3871        15
         qtx     0.5769    0.4839    0.5263        31
         zxx     0.5179    0.6591    0.5800        44

    accuracy                         0.4000       185
   macro avg     0.3331    0.3550    0.3307       185
weighted avg     0.3658    0.4000    0.3697       185

micro f-score: 0.4000000000000001

========== Train Epoch 16 ==========
Learning Rate: [0.0001]
Loss: 1.395	Accuracy: 41.62%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2059    0.2800    0.2373        25
         cwx     0.4000    0.6154    0.4848        26
         hdx     0.3636    0.1739    0.2353        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3000    0.4000    0.3429        15
         qtx     0.5152    0.5484    0.5312        31
         zxx     0.6136    0.6136    0.6136        44

    accuracy                         0.4162       185
   macro avg     0.3426    0.3759    0.3493       185
weighted avg     0.3858    0.4162    0.3922       185

micro f-score: 0.41621621621621624

========== Train Epoch 17 ==========
Learning Rate: [0.0001]
Loss: 1.360	Accuracy: 43.78%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2500    0.3200    0.2807        25
         cwx     0.3261    0.5769    0.4167        26
         hdx     0.6667    0.1739    0.2759        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3077    0.2667    0.2857        15
         qtx     0.5517    0.5161    0.5333        31
         zxx     0.6071    0.7727    0.6800        44

    accuracy                         0.4378       185
   macro avg     0.3870    0.3752    0.3532       185
weighted avg     0.4243    0.4378    0.4051       185

micro f-score: 0.43783783783783786

========== Train Epoch 18 ==========
Learning Rate: [0.0001]
Loss: 1.335	Accuracy: 42.70%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2941    0.4000    0.3390        25
         cwx     0.4000    0.5385    0.4590        26
         hdx     1.0000    0.0435    0.0833        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3529    0.4000    0.3750        15
         qtx     0.4762    0.6452    0.5479        31
         zxx     0.5957    0.6364    0.6154        44

    accuracy                         0.4270       185
   macro avg     0.4456    0.3805    0.3457       185
weighted avg     0.4704    0.4270    0.3893       185

micro f-score: 0.427027027027027

========== Train Epoch 19 ==========
Learning Rate: [0.0001]
Loss: 1.305	Accuracy: 43.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2424    0.3200    0.2759        25
         cwx     0.4595    0.6538    0.5397        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3750    0.4000    0.3871        15
         qtx     0.5926    0.5161    0.5517        31
         zxx     0.5156    0.7500    0.6111        44

    accuracy                         0.4324       185
   macro avg     0.3122    0.3771    0.3379       185
weighted avg     0.3497    0.4324    0.3823       185

micro f-score: 0.43243243243243246

========== Train Epoch 20 ==========
Learning Rate: [0.0001]
Loss: 1.292	Accuracy: 47.03%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3500    0.2800    0.3111        25
         cwx     0.3778    0.6538    0.4789        26
         hdx     0.7500    0.1304    0.2222        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.5000    0.2667    0.3478        15
         qtx     0.5000    0.6774    0.5753        31
         zxx     0.5932    0.7955    0.6796        44

    accuracy                         0.4703       185
   macro avg     0.4387    0.4005    0.3736       185
weighted avg     0.4590    0.4703    0.4232       185

micro f-score: 0.4702702702702703

========== Train Epoch 21 ==========
Learning Rate: [0.0001]
Loss: 1.293	Accuracy: 39.46%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2889    0.5200    0.3714        25
         cwx     0.3864    0.6538    0.4857        26
         hdx     0.3333    0.0870    0.1379        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.4167    0.3333    0.3704        15
         qtx     0.4074    0.7097    0.5176        31
         zxx     0.7000    0.3182    0.4375        44

    accuracy                         0.3946       185
   macro avg     0.3618    0.3746    0.3315       185
weighted avg     0.4033    0.3946    0.3564       185

micro f-score: 0.3945945945945946

========== Train Epoch 22 ==========
Learning Rate: [0.0001]
Loss: 1.273	Accuracy: 47.03%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3750    0.2400    0.2927        25
         cwx     0.3333    0.7308    0.4578        26
         hdx     0.6667    0.0870    0.1538        23
         mtx     0.2727    0.1429    0.1875        21
         nqx     0.2500    0.1333    0.1739        15
         qtx     0.6538    0.5484    0.5965        31
         zxx     0.5938    0.8636    0.7037        44

    accuracy                         0.4703       185
   macro avg     0.4493    0.3923    0.3666       185
weighted avg     0.4824    0.4703    0.4257       185

micro f-score: 0.4702702702702703

========== Train Epoch 23 ==========
Learning Rate: [0.0001]
Loss: 1.269	Accuracy: 43.24%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3793    0.4400    0.4074        25
         cwx     0.4333    0.5000    0.4643        26
         hdx     0.3333    0.0435    0.0769        23
         mtx     0.1111    0.0476    0.0667        21
         nqx     0.2308    0.4000    0.2927        15
         qtx     0.4286    0.6774    0.5250        31
         zxx     0.6923    0.6136    0.6506        44

    accuracy                         0.4324       185
   macro avg     0.3727    0.3889    0.3548       185
weighted avg     0.4214    0.4324    0.4039       185

micro f-score: 0.43243243243243246

========== Train Epoch 24 ==========
Learning Rate: [0.0001]
Loss: 1.218	Accuracy: 45.41%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2979    0.5600    0.3889        25
         cwx     0.5152    0.6538    0.5763        26
         hdx     1.0000    0.0870    0.1600        23
         mtx     0.2000    0.0476    0.0769        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.4082    0.6452    0.5000        31
         zxx     0.7143    0.5682    0.6329        44

    accuracy                         0.4541       185
   macro avg     0.4989    0.4136    0.3828       185
weighted avg     0.5269    0.4541    0.4244       185

micro f-score: 0.4540540540540541

========== Train Epoch 25 ==========
Learning Rate: [0.0001]
Loss: 1.206	Accuracy: 47.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2000    0.2000    0.2000        25
         cwx     0.3585    0.7308    0.4810        26
         hdx     0.3333    0.1739    0.2286        23
         mtx     0.3333    0.0952    0.1481        21
         nqx     0.4545    0.3333    0.3846        15
         qtx     0.6875    0.7097    0.6984        31
         zxx     0.6739    0.7045    0.6889        44

    accuracy                         0.4757       185
   macro avg     0.4344    0.4211    0.4042       185
weighted avg     0.4690    0.4757    0.4519       185

micro f-score: 0.4756756756756757

========== Train Epoch 26 ==========
Learning Rate: [0.0001]
Loss: 1.179	Accuracy: 47.03%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3448    0.4000    0.3704        25
         cwx     0.4828    0.5385    0.5091        26
         hdx     0.5000    0.0870    0.1481        23
         mtx     0.1667    0.0476    0.0741        21
         nqx     0.3333    0.1333    0.1905        15
         qtx     0.5556    0.6452    0.5970        31
         zxx     0.5067    0.8636    0.6387        44

    accuracy                         0.4703       185
   macro avg     0.4128    0.3879    0.3611       185
weighted avg     0.4362    0.4703    0.4158       185

micro f-score: 0.4702702702702703

========== Train Epoch 27 ==========
Learning Rate: [0.0001]
Loss: 1.127	Accuracy: 45.95%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2955    0.5200    0.3768        25
         cwx     0.5000    0.5385    0.5185        26
         hdx     0.3333    0.0870    0.1379        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.6250    0.6452    0.6349        31
         zxx     0.5962    0.7045    0.6458        44

    accuracy                         0.4595       185
   macro avg     0.3867    0.4041    0.3798       185
weighted avg     0.4271    0.4595    0.4289       185

micro f-score: 0.4594594594594595

========== Train Epoch 28 ==========
Learning Rate: [0.0001]
Loss: 1.177	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3235    0.4400    0.3729        25
         cwx     0.4286    0.6923    0.5294        26
         hdx     1.0000    0.0870    0.1600        23
         mtx     0.1000    0.0476    0.0645        21
         nqx     0.3333    0.3333    0.3333        15
         qtx     0.6471    0.7097    0.6769        31
         zxx     0.6250    0.6818    0.6522        44

    accuracy                         0.4811       185
   macro avg     0.4939    0.4274    0.3985       185
weighted avg     0.5237    0.4811    0.4476       185

micro f-score: 0.4810810810810811

========== Train Epoch 29 ==========
Learning Rate: [0.0001]
Loss: 1.099	Accuracy: 40.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2955    0.5200    0.3768        25
         cwx     0.3273    0.6923    0.4444        26
         hdx     0.3333    0.0870    0.1379        23
         mtx     0.0000    0.0000    0.0000        21
         nqx     0.3636    0.2667    0.3077        15
         qtx     0.5484    0.5484    0.5484        31
         zxx     0.6452    0.4545    0.5333        44

    accuracy                         0.4000       185
   macro avg     0.3590    0.3670    0.3355       185
weighted avg     0.4022    0.4000    0.3742       185

micro f-score: 0.4000000000000001

========== Train Epoch 30 ==========
Learning Rate: [0.0001]
Loss: 1.077	Accuracy: 37.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2667    0.1600    0.2000        25
         cwx     0.3077    0.3077    0.3077        26
         hdx     0.0000    0.0000    0.0000        23
         mtx     0.2222    0.0952    0.1333        21
         nqx     0.3750    0.2000    0.2609        15
         qtx     0.6111    0.3548    0.4490        31
         zxx     0.3925    0.9545    0.5563        44

    accuracy                         0.3784       185
   macro avg     0.3107    0.2960    0.2725       185
weighted avg     0.3307    0.3784    0.3141       185

micro f-score: 0.37837837837837834

========== Train Epoch 31 ==========
Learning Rate: [0.0001]
Loss: 1.090	Accuracy: 45.95%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2603    0.7600    0.3878        25
         cwx     0.5833    0.5385    0.5600        26
         hdx     0.2500    0.0435    0.0741        23
         mtx     0.6000    0.1429    0.2308        21
         nqx     0.4286    0.2000    0.2727        15
         qtx     0.5758    0.6129    0.5938        31
         zxx     0.6667    0.5909    0.6265        44

    accuracy                         0.4595       185
   macro avg     0.4807    0.4127    0.3922       185
weighted avg     0.5061    0.4595    0.4371       185

micro f-score: 0.4594594594594595

========== Train Epoch 32 ==========
Learning Rate: [0.0001]
Loss: 1.022	Accuracy: 45.41%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3273    0.7200    0.4500        25
         cwx     0.7222    0.5000    0.5909        26
         hdx     0.1000    0.0435    0.0606        23
         mtx     0.2000    0.0476    0.0769        21
         nqx     0.4000    0.4000    0.4000        15
         qtx     0.4138    0.7742    0.5393        31
         zxx     0.8750    0.4773    0.6176        44

    accuracy                         0.4541       185
   macro avg     0.4340    0.4232    0.3908       185
weighted avg     0.4907    0.4541    0.4298       185

micro f-score: 0.4540540540540541

========== Train Epoch 33 ==========
Learning Rate: [0.0001]
Loss: 0.982	Accuracy: 48.65%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5263    0.4000    0.4545        25
         cwx     0.6000    0.5769    0.5882        26
         hdx     0.1875    0.1304    0.1538        23
         mtx     0.1667    0.1429    0.1538        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.6957    0.5161    0.5926        31
         zxx     0.5429    0.8636    0.6667        44

    accuracy                         0.4865       185
   macro avg     0.4394    0.4233    0.4221       185
weighted avg     0.4723    0.4865    0.4665       185

micro f-score: 0.4864864864864865

========== Train Epoch 34 ==========
Learning Rate: [0.0001]
Loss: 1.014	Accuracy: 50.27%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3019    0.6400    0.4103        25
         cwx     0.4651    0.7692    0.5797        26
         hdx     0.4615    0.2609    0.3333        23
         mtx     0.3636    0.1905    0.2500        21
         nqx     0.6000    0.2000    0.3000        15
         qtx     0.6970    0.7419    0.7188        31
         zxx     0.7778    0.4773    0.5915        44

    accuracy                         0.5027       185
   macro avg     0.5238    0.4685    0.4548       185
weighted avg     0.5552    0.5027    0.4922       185

micro f-score: 0.5027027027027027

========== Train Epoch 35 ==========
Learning Rate: [0.0001]
Loss: 0.993	Accuracy: 51.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3415    0.5600    0.4242        25
         cwx     0.6400    0.6154    0.6275        26
         hdx     0.3636    0.1739    0.2353        23
         mtx     0.3750    0.1429    0.2069        21
         nqx     0.5000    0.0667    0.1176        15
         qtx     0.5789    0.7097    0.6377        31
         zxx     0.6000    0.8182    0.6923        44

    accuracy                         0.5189       185
   macro avg     0.4856    0.4410    0.4202       185
weighted avg     0.5041    0.5189    0.4793       185

micro f-score: 0.518918918918919

========== Train Epoch 36 ==========
Learning Rate: [0.0001]
Loss: 0.950	Accuracy: 53.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4444    0.3200    0.3721        25
         cwx     0.5455    0.6923    0.6102        26
         hdx     0.3913    0.3913    0.3913        23
         mtx     0.5000    0.0952    0.1600        21
         nqx     0.4615    0.4000    0.4286        15
         qtx     0.4808    0.8065    0.6024        31
         zxx     0.7381    0.7045    0.7209        44

    accuracy                         0.5351       185
   macro avg     0.5088    0.4871    0.4694       185
weighted avg     0.5357    0.5351    0.5100       185

micro f-score: 0.5351351351351351

========== Train Epoch 37 ==========
Learning Rate: [0.0001]
Loss: 0.915	Accuracy: 41.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2857    0.1600    0.2051        25
         cwx     0.4762    0.3846    0.4255        26
         hdx     0.2000    0.0435    0.0714        23
         mtx     0.5000    0.0952    0.1600        21
         nqx     0.3636    0.2667    0.3077        15
         qtx     0.5000    0.4516    0.4746        31
         zxx     0.4118    0.9545    0.5753        44

    accuracy                         0.4162       185
   macro avg     0.3910    0.3366    0.3171       185
weighted avg     0.3984    0.4162    0.3559       185

micro f-score: 0.41621621621621624

========== Train Epoch 38 ==========
Learning Rate: [0.0001]
Loss: 0.966	Accuracy: 51.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3846    0.4000    0.3922        25
         cwx     0.6071    0.6538    0.6296        26
         hdx     0.3333    0.3478    0.3404        23
         mtx     0.1364    0.1429    0.1395        21
         nqx     0.3333    0.0667    0.1111        15
         qtx     0.5435    0.8065    0.6494        31
         zxx     0.8889    0.7273    0.8000        44

    accuracy                         0.5189       185
   macro avg     0.4610    0.4493    0.4375       185
weighted avg     0.5237    0.5189    0.5077       185

micro f-score: 0.518918918918919

========== Train Epoch 39 ==========
Learning Rate: [0.0001]
Loss: 0.854	Accuracy: 50.81%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3600    0.3600    0.3600        25
         cwx     0.4634    0.7308    0.5672        26
         hdx     0.2727    0.1304    0.1765        23
         mtx     0.2500    0.0952    0.1379        21
         nqx     0.5714    0.2667    0.3636        15
         qtx     0.5833    0.6774    0.6269        31
         zxx     0.6316    0.8182    0.7129        44

    accuracy                         0.5081       185
   macro avg     0.4475    0.4398    0.4207       185
weighted avg     0.4704    0.5081    0.4700       185

micro f-score: 0.5081081081081081

========== Train Epoch 40 ==========
Learning Rate: [0.0001]
Loss: 0.810	Accuracy: 45.41%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3226    0.8000    0.4598        25
         cwx     0.5405    0.7692    0.6349        26
         hdx     0.2143    0.1304    0.1622        23
         mtx     0.4444    0.1905    0.2667        21
         nqx     0.4286    0.4000    0.4138        15
         qtx     0.6129    0.6129    0.6129        31
         zxx     0.6667    0.2727    0.3871        44

    accuracy                         0.4541       185
   macro avg     0.4614    0.4537    0.4196       185
weighted avg     0.4927    0.4541    0.4301       185

micro f-score: 0.4540540540540541

========== Train Epoch 41 ==========
Learning Rate: [0.0001]
Loss: 0.826	Accuracy: 47.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3333    0.5200    0.4063        25
         cwx     0.6667    0.4615    0.5455        26
         hdx     0.2000    0.0870    0.1212        23
         mtx     0.3333    0.1905    0.2424        21
         nqx     0.2381    0.3333    0.2778        15
         qtx     0.4878    0.6452    0.5556        31
         zxx     0.7273    0.7273    0.7273        44

    accuracy                         0.4757       185
   macro avg     0.4266    0.4235    0.4108       185
weighted avg     0.4755    0.4757    0.4627       185

micro f-score: 0.4756756756756757

========== Train Epoch 42 ==========
Learning Rate: [0.0001]
Loss: 0.837	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3750    0.4800    0.4211        25
         cwx     0.7333    0.4231    0.5366        26
         hdx     0.2857    0.1739    0.2162        23
         mtx     0.1875    0.1429    0.1622        21
         nqx     0.3571    0.3333    0.3448        15
         qtx     0.4314    0.7097    0.5366        31
         zxx     0.7209    0.7045    0.7126        44

    accuracy                         0.4757       185
   macro avg     0.4416    0.4239    0.4186       185
weighted avg     0.4832    0.4757    0.4650       185

micro f-score: 0.4756756756756757

========== Train Epoch 43 ==========
Learning Rate: [0.0001]
Loss: 0.782	Accuracy: 49.73%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3889    0.5600    0.4590        25
         cwx     0.6522    0.5769    0.6122        26
         hdx     0.2857    0.0870    0.1333        23
         mtx     0.2381    0.2381    0.2381        21
         nqx     0.2812    0.6000    0.3830        15
         qtx     0.6522    0.4839    0.5556        31
         zxx     0.7442    0.7273    0.7356        44

    accuracy                         0.4973       185
   macro avg     0.4632    0.4676    0.4453       185
weighted avg     0.5158    0.4973    0.4908       185

micro f-score: 0.4972972972972973

========== Train Epoch 44 ==========
Learning Rate: [0.0001]
Loss: 0.698	Accuracy: 51.89%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4167    0.4000    0.4082        25
         cwx     0.5135    0.7308    0.6032        26
         hdx     0.2727    0.2609    0.2667        23
         mtx     0.2353    0.1905    0.2105        21
         nqx     0.5455    0.4000    0.4615        15
         qtx     0.5758    0.6129    0.5938        31
         zxx     0.7805    0.7273    0.7529        44

    accuracy                         0.5189       185
   macro avg     0.4771    0.4746    0.4710       185
weighted avg     0.5154    0.5189    0.5130       185

micro f-score: 0.518918918918919

========== Train Epoch 45 ==========
Learning Rate: [0.0001]
Loss: 0.715	Accuracy: 51.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3684    0.5600    0.4444        25
         cwx     0.6207    0.6923    0.6545        26
         hdx     0.3684    0.3043    0.3333        23
         mtx     0.1818    0.1905    0.1860        21
         nqx     0.4000    0.2667    0.3200        15
         qtx     0.6552    0.6129    0.6333        31
         zxx     0.7895    0.6818    0.7317        44

    accuracy                         0.5189       185
   macro avg     0.4834    0.4726    0.4719       185
weighted avg     0.5334    0.5189    0.5207       185

micro f-score: 0.518918918918919

========== Train Epoch 46 ==========
Learning Rate: [0.0001]
Loss: 0.665	Accuracy: 51.89%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4286    0.2400    0.3077        25
         cwx     0.4250    0.6538    0.5152        26
         hdx     0.3333    0.1304    0.1875        23
         mtx     0.4000    0.2857    0.3333        21
         nqx     0.4615    0.4000    0.4286        15
         qtx     0.6333    0.6129    0.6230        31
         zxx     0.6094    0.8864    0.7222        44

    accuracy                         0.5189       185
   macro avg     0.4702    0.4585    0.4453       185
weighted avg     0.4930    0.5189    0.4860       185

micro f-score: 0.518918918918919

========== Train Epoch 47 ==========
Learning Rate: [0.0001]
Loss: 0.662	Accuracy: 48.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3478    0.3200    0.3333        25
         cwx     0.4286    0.8077    0.5600        26
         hdx     0.3000    0.1304    0.1818        23
         mtx     0.4167    0.2381    0.3030        21
         nqx     0.3750    0.4000    0.3871        15
         qtx     0.5385    0.6774    0.6000        31
         zxx     0.7222    0.5909    0.6500        44

    accuracy                         0.4865       185
   macro avg     0.4470    0.4521    0.4308       185
weighted avg     0.4842    0.4865    0.4673       185

micro f-score: 0.4864864864864865

========== Train Epoch 48 ==========
Learning Rate: [0.0001]
Loss: 0.696	Accuracy: 52.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4667    0.5600    0.5091        25
         cwx     0.5200    0.5000    0.5098        26
         hdx     0.3636    0.3478    0.3556        23
         mtx     0.3333    0.2381    0.2778        21
         nqx     0.3846    0.3333    0.3571        15
         qtx     0.5111    0.7419    0.6053        31
         zxx     0.8571    0.6818    0.7595        44

    accuracy                         0.5297       185
   macro avg     0.4909    0.4861    0.4820       185
weighted avg     0.5399    0.5297    0.5272       185

micro f-score: 0.5297297297297298

========== Train Epoch 49 ==========
Learning Rate: [0.0001]
Loss: 0.634	Accuracy: 53.51%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3462    0.7200    0.4675        25
         cwx     0.5556    0.7692    0.6452        26
         hdx     0.3750    0.2609    0.3077        23
         mtx     0.4000    0.1905    0.2581        21
         nqx     0.5000    0.3333    0.4000        15
         qtx     0.7273    0.5161    0.6038        31
         zxx     0.7692    0.6818    0.7229        44

    accuracy                         0.5351       185
   macro avg     0.5247    0.4960    0.4864       185
weighted avg     0.5622    0.5351    0.5269       185

micro f-score: 0.5351351351351351

========== Train Epoch 50 ==========
Learning Rate: [0.0001]
Loss: 0.644	Accuracy: 48.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.1538    0.0800    0.1053        25
         cwx     0.4848    0.6154    0.5424        26
         hdx     0.3125    0.2174    0.2564        23
         mtx     0.2800    0.3333    0.3043        21
         nqx     0.5714    0.2667    0.3636        15
         qtx     0.7273    0.5161    0.6038        31
         zxx     0.5652    0.8864    0.6903        44

    accuracy                         0.4811       185
   macro avg     0.4422    0.4165    0.4094       185
weighted avg     0.4622    0.4811    0.4517       185

micro f-score: 0.4810810810810811

========== Train Epoch 51 ==========
Learning Rate: [0.0001]
Loss: 0.602	Accuracy: 48.11%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2857    0.2400    0.2609        25
         cwx     0.4000    0.6154    0.4848        26
         hdx     0.4375    0.3043    0.3590        23
         mtx     0.2727    0.1429    0.1875        21
         nqx     0.4375    0.4667    0.4516        15
         qtx     0.6250    0.6452    0.6349        31
         zxx     0.6122    0.6818    0.6452        44

    accuracy                         0.4811       185
   macro avg     0.4387    0.4423    0.4320       185
weighted avg     0.4660    0.4811    0.4658       185

micro f-score: 0.4810810810810811

========== Train Epoch 52 ==========
Learning Rate: [0.0001]
Loss: 0.594	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4138    0.4800    0.4444        25
         cwx     0.5000    0.7692    0.6061        26
         hdx     0.4167    0.2174    0.2857        23
         mtx     0.5556    0.2381    0.3333        21
         nqx     0.6000    0.4000    0.4800        15
         qtx     0.7391    0.5484    0.6296        31
         zxx     0.5645    0.7955    0.6604        44

    accuracy                         0.5405       185
   macro avg     0.5414    0.4927    0.4914       185
weighted avg     0.5478    0.5405    0.5201       185

micro f-score: 0.5405405405405406

========== Train Epoch 53 ==========
Learning Rate: [0.0001]
Loss: 0.541	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4667    0.5600    0.5091        25
         cwx     0.7647    0.5000    0.6047        26
         hdx     0.3030    0.4348    0.3571        23
         mtx     0.4000    0.2857    0.3333        21
         nqx     0.5833    0.4667    0.5185        15
         qtx     0.5854    0.7742    0.6667        31
         zxx     0.7568    0.6364    0.6914        44

    accuracy                         0.5514       185
   macro avg     0.5514    0.5225    0.5258       185
weighted avg     0.5790    0.5514    0.5542       185

micro f-score: 0.5513513513513514

========== Train Epoch 54 ==========
Learning Rate: [0.0001]
Loss: 0.513	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4211    0.3200    0.3636        25
         cwx     0.6667    0.6923    0.6792        26
         hdx     0.2667    0.1739    0.2105        23
         mtx     0.3333    0.4286    0.3750        21
         nqx     0.6667    0.5333    0.5926        15
         qtx     0.6667    0.6452    0.6557        31
         zxx     0.6727    0.8409    0.7475        44

    accuracy                         0.5622       185
   macro avg     0.5277    0.5192    0.5177       185
weighted avg     0.5473    0.5622    0.5490       185

micro f-score: 0.5621621621621622

========== Train Epoch 55 ==========
Learning Rate: [0.0001]
Loss: 0.522	Accuracy: 50.81%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4167    0.6000    0.4918        25
         cwx     0.6667    0.5385    0.5957        26
         hdx     0.3000    0.1304    0.1818        23
         mtx     0.2188    0.3333    0.2642        21
         nqx     0.3750    0.4000    0.3871        15
         qtx     0.6000    0.6774    0.6364        31
         zxx     0.8000    0.6364    0.7089        44

    accuracy                         0.5081       185
   macro avg     0.4824    0.4737    0.4665       185
weighted avg     0.5333    0.5081    0.5094       185

micro f-score: 0.5081081081081081

========== Train Epoch 56 ==========
Learning Rate: [0.0001]
Loss: 0.508	Accuracy: 47.03%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4375    0.2800    0.3415        25
         cwx     0.6667    0.5385    0.5957        26
         hdx     0.3077    0.3478    0.3265        23
         mtx     0.1818    0.2857    0.2222        21
         nqx     0.3333    0.4667    0.3889        15
         qtx     0.5135    0.6129    0.5588        31
         zxx     0.8387    0.5909    0.6933        44

    accuracy                         0.4703       185
   macro avg     0.4685    0.4461    0.4467       185
weighted avg     0.5243    0.4703    0.4858       185

micro f-score: 0.4702702702702703

========== Train Epoch 57 ==========
Learning Rate: [0.0001]
Loss: 0.443	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3929    0.4400    0.4151        25
         cwx     0.6552    0.7308    0.6909        26
         hdx     0.3200    0.3478    0.3333        23
         mtx     0.3077    0.1905    0.2353        21
         nqx     0.6364    0.4667    0.5385        15
         qtx     0.6176    0.6774    0.6462        31
         zxx     0.7556    0.7727    0.7640        44

    accuracy                         0.5622       185
   macro avg     0.5265    0.5180    0.5176       185
weighted avg     0.5547    0.5622    0.5550       185

micro f-score: 0.5621621621621622

========== Train Epoch 58 ==========
Learning Rate: [0.0001]
Loss: 0.412	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4000    0.3200    0.3556        25
         cwx     0.7500    0.5769    0.6522        26
         hdx     0.4000    0.3478    0.3721        23
         mtx     0.4118    0.3333    0.3684        21
         nqx     0.6154    0.5333    0.5714        15
         qtx     0.6000    0.7742    0.6761        31
         zxx     0.6182    0.7727    0.6869        44

    accuracy                         0.5622       185
   macro avg     0.5422    0.5226    0.5261       185
weighted avg     0.5534    0.5622    0.5508       185

micro f-score: 0.5621621621621622

========== Train Epoch 59 ==========
Learning Rate: [0.0001]
Loss: 0.416	Accuracy: 51.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3636    0.3200    0.3404        25
         cwx     0.4750    0.7308    0.5758        26
         hdx     0.2857    0.1739    0.2162        23
         mtx     0.3600    0.4286    0.3913        21
         nqx     0.5000    0.4000    0.4444        15
         qtx     0.6333    0.6129    0.6230        31
         zxx     0.7143    0.6818    0.6977        44

    accuracy                         0.5135       185
   macro avg     0.4760    0.4783    0.4698       185
weighted avg     0.5088    0.5135    0.5046       185

micro f-score: 0.5135135135135135

========== Train Epoch 60 ==========
Learning Rate: [0.0001]
Loss: 0.411	Accuracy: 53.51%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3793    0.4400    0.4074        25
         cwx     0.8125    0.5000    0.6190        26
         hdx     0.4583    0.4783    0.4681        23
         mtx     0.2667    0.3810    0.3137        21
         nqx     0.5385    0.4667    0.5000        15
         qtx     0.6333    0.6129    0.6230        31
         zxx     0.6977    0.6818    0.6897        44

    accuracy                         0.5351       185
   macro avg     0.5409    0.5087    0.5173       185
weighted avg     0.5684    0.5351    0.5448       185

micro f-score: 0.5351351351351351

========== Train Epoch 61 ==========
Learning Rate: [0.0001]
Loss: 0.372	Accuracy: 50.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3889    0.2800    0.3256        25
         cwx     0.5000    0.7692    0.6061        26
         hdx     0.3600    0.3913    0.3750        23
         mtx     0.2381    0.2381    0.2381        21
         nqx     0.4500    0.6000    0.5143        15
         qtx     0.6818    0.4839    0.5660        31
         zxx     0.7436    0.6591    0.6988        44

    accuracy                         0.5081       185
   macro avg     0.4803    0.4888    0.4748       185
weighted avg     0.5222    0.5081    0.5056       185

micro f-score: 0.5081081081081081

========== Train Epoch 62 ==========
Learning Rate: [0.0001]
Loss: 0.365	Accuracy: 56.76%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4000    0.5600    0.4667        25
         cwx     0.6667    0.6923    0.6792        26
         hdx     0.5000    0.2609    0.3429        23
         mtx     0.5000    0.3333    0.4000        21
         nqx     0.5000    0.4000    0.4444        15
         qtx     0.6286    0.7097    0.6667        31
         zxx     0.6400    0.7273    0.6809        44

    accuracy                         0.5676       185
   macro avg     0.5479    0.5262    0.5258       185
weighted avg     0.5648    0.5676    0.5562       185

micro f-score: 0.5675675675675675

========== Train Epoch 63 ==========
Learning Rate: [0.0001]
Loss: 0.350	Accuracy: 57.30%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3684    0.2800    0.3182        25
         cwx     0.7273    0.6154    0.6667        26
         hdx     0.4286    0.5217    0.4706        23
         mtx     0.3333    0.4762    0.3922        21
         nqx     0.5000    0.4667    0.4828        15
         qtx     0.6571    0.7419    0.6970        31
         zxx     0.8378    0.7045    0.7654        44

    accuracy                         0.5730       185
   macro avg     0.5504    0.5438    0.5418       185
weighted avg     0.5930    0.5730    0.5777       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Learning Rate: [0.0001]
Loss: 0.369	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4000    0.3200    0.3556        25
         cwx     0.6667    0.6923    0.6792        26
         hdx     0.4074    0.4783    0.4400        23
         mtx     0.2333    0.3333    0.2745        21
         nqx     0.6667    0.4000    0.5000        15
         qtx     0.6364    0.6774    0.6562        31
         zxx     0.8205    0.7273    0.7711        44

    accuracy                         0.5568       185
   macro avg     0.5473    0.5184    0.5252       185
weighted avg     0.5807    0.5568    0.5633       185

micro f-score: 0.5567567567567567

Finished training!!!

Min Loss = 0.350 in epoch 62;
Max Accuracy = 57.30% in epoch 62;
Total Cost 37 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
ReLU: 1-3                              [-1, 64, 160, 160]        --
SPPB: 1-4                              [-1, 64, 160, 160]        --
|    Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    ReLU: 3-3                    [-1, 32, 160, 160]        --
|    ModuleList: 2                     []                        --
|    |    MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    ReLU: 3-9                    [-1, 64, 160, 160]        --
Sequential: 1-5                        [-1, 64, 160, 160]        --
|    BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    ReLU: 3-15                   [-1, 64, 160, 160]        --
|    BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    ReLU: 3-21                   [-1, 64, 160, 160]        --
|    BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    ReLU: 3-27                   [-1, 64, 160, 160]        --
Sequential: 1-6                        [-1, 128, 80, 80]         --
|    BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    ReLU: 3-34                   [-1, 128, 80, 80]         --
|    BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    ReLU: 3-40                   [-1, 128, 80, 80]         --
|    BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    ReLU: 3-46                   [-1, 128, 80, 80]         --
|    BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    ReLU: 3-52                   [-1, 128, 80, 80]         --
Sequential: 1-7                        [-1, 256, 40, 40]         --
|    BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    ReLU: 3-59                   [-1, 256, 40, 40]         --
|    BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    ReLU: 3-65                   [-1, 256, 40, 40]         --
|    BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    ReLU: 3-71                   [-1, 256, 40, 40]         --
|    BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    ReLU: 3-77                   [-1, 256, 40, 40]         --
|    BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    ReLU: 3-83                   [-1, 256, 40, 40]         --
|    BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    ReLU: 3-89                   [-1, 256, 40, 40]         --
Sequential: 1-8                        [-1, 512, 20, 20]         --
|    BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    ReLU: 3-96                   [-1, 512, 20, 20]         --
|    BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    ReLU: 3-102                  [-1, 512, 20, 20]         --
|    BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    ReLU: 3-108                  [-1, 512, 20, 20]         --
AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



