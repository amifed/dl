dataset_path: /home/djy/dataset/dataset2_aug
pretrained : True 
parallel: True

parallel segment dataset : /home/djy/dataset/ycrcb_hsv_dataset2_aug
net: hcam_sppb_resnet_alexnet.resnet18
msg: continue to train from /home/djy/dl/result/2022-01-04/22:14:07/model.pth
using model: ResNet, resnet18
using device cuda:0
batch_size = 20
epochs = 32
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 0.045	Accuracy: 93.82%	Cost 260s
              precision    recall  f1-score   support

         bzx     0.9113    0.8898    0.9004       127
         cwx     0.9535    0.9609    0.9572       128
         hdx     0.8830    0.9222    0.9022        90
         mtx     0.9479    0.9579    0.9529        95
         nqx     0.9855    0.9189    0.9510        74
         qtx     0.9578    0.9636    0.9607       165
         zxx     0.9347    0.9385    0.9366       244

    accuracy                         0.9382       923
   macro avg     0.9391    0.9360    0.9373       923
weighted avg     0.9386    0.9382    0.9383       923

micro f-score: 0.9382448537378115

========== Train Epoch 2 ==========
Loss: 0.040	Accuracy: 93.39%	Cost 256s
              precision    recall  f1-score   support

         bzx     0.8915    0.9055    0.8984       127
         cwx     0.9248    0.9609    0.9425       128
         hdx     0.9011    0.9111    0.9061        90
         mtx     0.9667    0.9158    0.9405        95
         nqx     0.9444    0.9189    0.9315        74
         qtx     0.9461    0.9576    0.9518       165
         zxx     0.9502    0.9385    0.9443       244

    accuracy                         0.9339       923
   macro avg     0.9321    0.9298    0.9307       923
weighted avg     0.9343    0.9339    0.9340       923

micro f-score: 0.933911159263272

========== Train Epoch 3 ==========
Loss: 0.049	Accuracy: 93.50%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.8898    0.8898    0.8898       127
         cwx     0.9462    0.9609    0.9535       128
         hdx     0.8469    0.9222    0.8830        90
         mtx     0.9780    0.9368    0.9570        95
         nqx     0.9324    0.9324    0.9324        74
         qtx     0.9573    0.9515    0.9544       165
         zxx     0.9582    0.9385    0.9482       244

    accuracy                         0.9350       923
   macro avg     0.9298    0.9332    0.9312       923
weighted avg     0.9361    0.9350    0.9353       923

micro f-score: 0.9349945828819068

========== Train Epoch 4 ==========
Loss: 0.047	Accuracy: 93.72%	Cost 255s
              precision    recall  f1-score   support

         bzx     0.8939    0.9291    0.9112       127
         cwx     0.9394    0.9688    0.9538       128
         hdx     0.8710    0.9000    0.8852        90
         mtx     0.9560    0.9158    0.9355        95
         nqx     0.9714    0.9189    0.9444        74
         qtx     0.9515    0.9515    0.9515       165
         zxx     0.9583    0.9426    0.9504       244

    accuracy                         0.9372       923
   macro avg     0.9345    0.9324    0.9332       923
weighted avg     0.9379    0.9372    0.9373       923

micro f-score: 0.9371614301191766

========== Train Epoch 5 ==========
Loss: 0.046	Accuracy: 93.07%	Cost 256s
              precision    recall  f1-score   support

         bzx     0.8561    0.8898    0.8726       127
         cwx     0.9318    0.9609    0.9462       128
         hdx     0.9111    0.9111    0.9111        90
         mtx     0.9167    0.9263    0.9215        95
         nqx     0.9714    0.9189    0.9444        74
         qtx     0.9576    0.9576    0.9576       165
         zxx     0.9538    0.9303    0.9419       244

    accuracy                         0.9307       923
   macro avg     0.9283    0.9279    0.9279       923
weighted avg     0.9314    0.9307    0.9309       923

micro f-score: 0.9306608884073673

========== Train Epoch 6 ==========
Loss: 0.043	Accuracy: 92.85%	Cost 263s
              precision    recall  f1-score   support

         bzx     0.8712    0.9055    0.8880       127
         cwx     0.9242    0.9531    0.9385       128
         hdx     0.9205    0.9000    0.9101        90
         mtx     0.9263    0.9263    0.9263        95
         nqx     0.9565    0.8919    0.9231        74
         qtx     0.9398    0.9455    0.9426       165
         zxx     0.9502    0.9385    0.9443       244

    accuracy                         0.9285       923
   macro avg     0.9270    0.9230    0.9247       923
weighted avg     0.9290    0.9285    0.9286       923

micro f-score: 0.9284940411700975

========== Train Epoch 7 ==========
Loss: 0.043	Accuracy: 93.07%	Cost 266s
              precision    recall  f1-score   support

         bzx     0.8682    0.8819    0.8750       127
         cwx     0.9403    0.9844    0.9618       128
         hdx     0.9011    0.9111    0.9061        90
         mtx     0.9468    0.9368    0.9418        95
         nqx     0.9306    0.9054    0.9178        74
         qtx     0.9630    0.9455    0.9541       165
         zxx     0.9419    0.9303    0.9361       244

    accuracy                         0.9307       923
   macro avg     0.9274    0.9279    0.9275       923
weighted avg     0.9309    0.9307    0.9307       923

micro f-score: 0.9306608884073673

========== Train Epoch 8 ==========
Epoch     8: reducing learning rate of group 0 to 1.0000e-06.
Loss: 0.044	Accuracy: 93.50%	Cost 262s
              precision    recall  f1-score   support

         bzx     0.8992    0.9134    0.9063       127
         cwx     0.9104    0.9531    0.9313       128
         hdx     0.8876    0.8778    0.8827        90
         mtx     0.9368    0.9368    0.9368        95
         nqx     0.9459    0.9459    0.9459        74
         qtx     0.9521    0.9636    0.9578       165
         zxx     0.9702    0.9344    0.9520       244

    accuracy                         0.9350       923
   macro avg     0.9289    0.9322    0.9304       923
weighted avg     0.9355    0.9350    0.9351       923

micro f-score: 0.9349945828819068

========== Train Epoch 9 ==========
Loss: 0.045	Accuracy: 93.61%	Cost 256s
              precision    recall  f1-score   support

         bzx     0.8984    0.9055    0.9020       127
         cwx     0.9167    0.9453    0.9308       128
         hdx     0.9000    0.9000    0.9000        90
         mtx     0.9293    0.9684    0.9485        95
         nqx     0.9718    0.9324    0.9517        74
         qtx     0.9689    0.9455    0.9571       165
         zxx     0.9504    0.9426    0.9465       244

    accuracy                         0.9361       923
   macro avg     0.9337    0.9343    0.9338       923
weighted avg     0.9365    0.9361    0.9362       923

micro f-score: 0.9360780065005417

========== Train Epoch 10 ==========
Loss: 0.045	Accuracy: 94.37%	Cost 268s
              precision    recall  f1-score   support

         bzx     0.9141    0.9213    0.9176       127
         cwx     0.9389    0.9609    0.9498       128
         hdx     0.8925    0.9222    0.9071        90
         mtx     0.9674    0.9368    0.9519        95
         nqx     0.9589    0.9459    0.9524        74
         qtx     0.9568    0.9394    0.9480       165
         zxx     0.9590    0.9590    0.9590       244

    accuracy                         0.9437       923
   macro avg     0.9411    0.9408    0.9408       923
weighted avg     0.9440    0.9437    0.9438       923

micro f-score: 0.9436619718309859

========== Train Epoch 11 ==========
Loss: 0.048	Accuracy: 93.61%	Cost 262s
              precision    recall  f1-score   support

         bzx     0.8750    0.9370    0.9049       127
         cwx     0.9179    0.9609    0.9389       128
         hdx     0.9286    0.8667    0.8966        90
         mtx     0.9462    0.9263    0.9362        95
         nqx     0.9859    0.9459    0.9655        74
         qtx     0.9634    0.9576    0.9605       165
         zxx     0.9461    0.9344    0.9402       244

    accuracy                         0.9361       923
   macro avg     0.9376    0.9327    0.9347       923
weighted avg     0.9370    0.9361    0.9362       923

micro f-score: 0.9360780065005417

========== Train Epoch 12 ==========
Loss: 0.042	Accuracy: 92.31%	Cost 260s
              precision    recall  f1-score   support

         bzx     0.9204    0.8189    0.8667       127
         cwx     0.9104    0.9531    0.9313       128
         hdx     0.8438    0.9000    0.8710        90
         mtx     0.9175    0.9368    0.9271        95
         nqx     0.9452    0.9324    0.9388        74
         qtx     0.9568    0.9394    0.9480       165
         zxx     0.9355    0.9508    0.9431       244

    accuracy                         0.9231       923
   macro avg     0.9185    0.9188    0.9180       923
weighted avg     0.9237    0.9231    0.9228       923

micro f-score: 0.9230769230769231

========== Train Epoch 13 ==========
Loss: 0.046	Accuracy: 92.96%	Cost 260s
              precision    recall  f1-score   support

         bzx     0.9016    0.8661    0.8835       127
         cwx     0.9457    0.9531    0.9494       128
         hdx     0.9000    0.9000    0.9000        90
         mtx     0.9355    0.9158    0.9255        95
         nqx     0.9315    0.9189    0.9252        74
         qtx     0.9398    0.9455    0.9426       165
         zxx     0.9360    0.9590    0.9474       244

    accuracy                         0.9296       923
   macro avg     0.9272    0.9226    0.9248       923
weighted avg     0.9294    0.9296    0.9294       923

micro f-score: 0.9295774647887324

========== Train Epoch 14 ==========
Epoch    14: reducing learning rate of group 0 to 1.0000e-07.
Loss: 0.047	Accuracy: 92.85%	Cost 255s
              precision    recall  f1-score   support

         bzx     0.8862    0.8583    0.8720       127
         cwx     0.9389    0.9609    0.9498       128
         hdx     0.8804    0.9000    0.8901        90
         mtx     0.9263    0.9263    0.9263        95
         nqx     0.9714    0.9189    0.9444        74
         qtx     0.9458    0.9515    0.9486       165
         zxx     0.9390    0.9467    0.9429       244

    accuracy                         0.9285       923
   macro avg     0.9269    0.9232    0.9249       923
weighted avg     0.9285    0.9285    0.9284       923

micro f-score: 0.9284940411700975

========== Train Epoch 15 ==========
Loss: 0.047	Accuracy: 93.82%	Cost 258s
              precision    recall  f1-score   support

         bzx     0.8712    0.9055    0.8880       127
         cwx     0.9462    0.9609    0.9535       128
         hdx     0.8913    0.9111    0.9011        90
         mtx     0.9462    0.9263    0.9362        95
         nqx     0.9855    0.9189    0.9510        74
         qtx     0.9581    0.9697    0.9639       165
         zxx     0.9583    0.9426    0.9504       244

    accuracy                         0.9382       923
   macro avg     0.9367    0.9336    0.9349       923
weighted avg     0.9390    0.9382    0.9384       923

micro f-score: 0.9382448537378115

========== Train Epoch 16 ==========
Loss: 0.045	Accuracy: 92.63%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.8828    0.8898    0.8863       127
         cwx     0.9318    0.9609    0.9462       128
         hdx     0.8681    0.8778    0.8729        90
         mtx     0.9462    0.9263    0.9362        95
         nqx     0.9189    0.9189    0.9189        74
         qtx     0.9281    0.9394    0.9337       165
         zxx     0.9622    0.9385    0.9502       244

    accuracy                         0.9263       923
   macro avg     0.9197    0.9217    0.9206       923
weighted avg     0.9267    0.9263    0.9264       923

micro f-score: 0.9263271939328277

========== Train Epoch 17 ==========
Loss: 0.050	Accuracy: 93.50%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.8992    0.9134    0.9063       127
         cwx     0.9308    0.9453    0.9380       128
         hdx     0.9011    0.9111    0.9061        90
         mtx     0.9570    0.9368    0.9468        95
         nqx     0.9583    0.9324    0.9452        74
         qtx     0.9235    0.9515    0.9373       165
         zxx     0.9622    0.9385    0.9502       244

    accuracy                         0.9350       923
   macro avg     0.9332    0.9327    0.9328       923
weighted avg     0.9355    0.9350    0.9351       923

micro f-score: 0.9349945828819068

========== Train Epoch 18 ==========
Loss: 0.047	Accuracy: 93.28%	Cost 258s
              precision    recall  f1-score   support

         bzx     0.8797    0.9213    0.9000       127
         cwx     0.9104    0.9531    0.9313       128
         hdx     0.8526    0.9000    0.8757        90
         mtx     0.9659    0.8947    0.9290        95
         nqx     0.9710    0.9054    0.9371        74
         qtx     0.9521    0.9636    0.9578       165
         zxx     0.9705    0.9426    0.9563       244

    accuracy                         0.9328       923
   macro avg     0.9289    0.9258    0.9267       923
weighted avg     0.9345    0.9328    0.9332       923

micro f-score: 0.9328277356446371

========== Train Epoch 19 ==========
Loss: 0.045	Accuracy: 93.07%	Cost 261s
              precision    recall  f1-score   support

         bzx     0.8915    0.9055    0.8984       127
         cwx     0.9231    0.9375    0.9302       128
         hdx     0.8646    0.9222    0.8925        90
         mtx     0.9457    0.9158    0.9305        95
         nqx     0.9429    0.8919    0.9167        74
         qtx     0.9576    0.9576    0.9576       165
         zxx     0.9544    0.9426    0.9485       244

    accuracy                         0.9307       923
   macro avg     0.9257    0.9247    0.9249       923
weighted avg     0.9314    0.9307    0.9308       923

micro f-score: 0.9306608884073673

========== Train Epoch 20 ==========
Epoch    20: reducing learning rate of group 0 to 1.0000e-08.
Loss: 0.043	Accuracy: 93.17%	Cost 261s
              precision    recall  f1-score   support

         bzx     0.8800    0.8661    0.8730       127
         cwx     0.9313    0.9531    0.9421       128
         hdx     0.9195    0.8889    0.9040        90
         mtx     0.9278    0.9474    0.9375        95
         nqx     0.9444    0.9189    0.9315        74
         qtx     0.9461    0.9576    0.9518       165
         zxx     0.9508    0.9508    0.9508       244

    accuracy                         0.9317       923
   macro avg     0.9286    0.9261    0.9272       923
weighted avg     0.9316    0.9317    0.9316       923

micro f-score: 0.9317443120260022

========== Train Epoch 21 ==========
Loss: 0.042	Accuracy: 93.39%	Cost 259s
              precision    recall  f1-score   support

         bzx     0.8947    0.9370    0.9154       127
         cwx     0.9242    0.9531    0.9385       128
         hdx     0.8723    0.9111    0.8913        90
         mtx     0.9263    0.9263    0.9263        95
         nqx     0.9324    0.9324    0.9324        74
         qtx     0.9684    0.9273    0.9474       165
         zxx     0.9662    0.9385    0.9522       244

    accuracy                         0.9339       923
   macro avg     0.9264    0.9323    0.9291       923
weighted avg     0.9350    0.9339    0.9342       923

micro f-score: 0.933911159263272

========== Train Epoch 22 ==========
Loss: 0.040	Accuracy: 93.17%	Cost 255s
              precision    recall  f1-score   support

         bzx     0.8702    0.8976    0.8837       127
         cwx     0.9313    0.9531    0.9421       128
         hdx     0.8602    0.8889    0.8743        90
         mtx     0.9674    0.9368    0.9519        95
         nqx     1.0000    0.9189    0.9577        74
         qtx     0.9345    0.9515    0.9429       165
         zxx     0.9583    0.9426    0.9504       244

    accuracy                         0.9317       923
   macro avg     0.9317    0.9271    0.9290       923
weighted avg     0.9329    0.9317    0.9321       923

micro f-score: 0.9317443120260022

========== Train Epoch 23 ==========
Loss: 0.043	Accuracy: 94.47%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.9070    0.9213    0.9141       127
         cwx     0.9318    0.9609    0.9462       128
         hdx     0.9022    0.9222    0.9121        90
         mtx     1.0000    0.9263    0.9617        95
         nqx     0.9589    0.9459    0.9524        74
         qtx     0.9576    0.9576    0.9576       165
         zxx     0.9549    0.9549    0.9549       244

    accuracy                         0.9447       923
   macro avg     0.9446    0.9413    0.9427       923
weighted avg     0.9454    0.9447    0.9449       923

micro f-score: 0.9447453954496208

========== Train Epoch 24 ==========
Loss: 0.038	Accuracy: 93.61%	Cost 263s
              precision    recall  f1-score   support

         bzx     0.8750    0.8819    0.8784       127
         cwx     0.9318    0.9609    0.9462       128
         hdx     0.9022    0.9222    0.9121        90
         mtx     0.9468    0.9368    0.9418        95
         nqx     1.0000    0.8919    0.9429        74
         qtx     0.9518    0.9576    0.9547       165
         zxx     0.9510    0.9549    0.9530       244

    accuracy                         0.9361       923
   macro avg     0.9369    0.9295    0.9327       923
weighted avg     0.9368    0.9361    0.9361       923

micro f-score: 0.9360780065005417

========== Train Epoch 25 ==========
Loss: 0.042	Accuracy: 92.52%	Cost 259s
              precision    recall  f1-score   support

         bzx     0.8672    0.8740    0.8706       127
         cwx     0.9242    0.9531    0.9385       128
         hdx     0.8316    0.8778    0.8541        90
         mtx     0.9560    0.9158    0.9355        95
         nqx     0.9577    0.9189    0.9379        74
         qtx     0.9576    0.9576    0.9576       165
         zxx     0.9502    0.9385    0.9443       244

    accuracy                         0.9252       923
   macro avg     0.9207    0.9194    0.9198       923
weighted avg     0.9261    0.9252    0.9255       923

micro f-score: 0.9252437703141928

========== Train Epoch 26 ==========
Loss: 0.044	Accuracy: 93.39%	Cost 260s
              precision    recall  f1-score   support

         bzx     0.9113    0.8898    0.9004       127
         cwx     0.9179    0.9609    0.9389       128
         hdx     0.8966    0.8667    0.8814        90
         mtx     0.9457    0.9158    0.9305        95
         nqx     0.9583    0.9324    0.9452        74
         qtx     0.9576    0.9576    0.9576       165
         zxx     0.9398    0.9590    0.9493       244

    accuracy                         0.9339       923
   macro avg     0.9324    0.9260    0.9290       923
weighted avg     0.9339    0.9339    0.9337       923

micro f-score: 0.933911159263272

========== Train Epoch 27 ==========
Loss: 0.044	Accuracy: 93.50%	Cost 264s
              precision    recall  f1-score   support

         bzx     0.8871    0.8661    0.8765       127
         cwx     0.9318    0.9609    0.9462       128
         hdx     0.9011    0.9111    0.9061        90
         mtx     0.9667    0.9158    0.9405        95
         nqx     0.9853    0.9054    0.9437        74
         qtx     0.9415    0.9758    0.9583       165
         zxx     0.9433    0.9549    0.9491       244

    accuracy                         0.9350       923
   macro avg     0.9367    0.9272    0.9315       923
weighted avg     0.9353    0.9350    0.9348       923

micro f-score: 0.9349945828819068

========== Train Epoch 28 ==========
Loss: 0.041	Accuracy: 93.72%	Cost 258s
              precision    recall  f1-score   support

         bzx     0.8992    0.9134    0.9063       127
         cwx     0.9231    0.9375    0.9302       128
         hdx     0.9101    0.9000    0.9050        90
         mtx     0.9278    0.9474    0.9375        95
         nqx     0.9583    0.9324    0.9452        74
         qtx     0.9515    0.9515    0.9515       165
         zxx     0.9627    0.9508    0.9567       244

    accuracy                         0.9372       923
   macro avg     0.9333    0.9333    0.9332       923
weighted avg     0.9374    0.9372    0.9372       923

micro f-score: 0.9371614301191766

========== Train Epoch 29 ==========
Loss: 0.051	Accuracy: 94.58%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.9055    0.9055    0.9055       127
         cwx     0.9389    0.9609    0.9498       128
         hdx     0.9432    0.9222    0.9326        90
         mtx     0.9000    0.9474    0.9231        95
         nqx     1.0000    0.9459    0.9722        74
         qtx     0.9753    0.9576    0.9664       165
         zxx     0.9551    0.9590    0.9571       244

    accuracy                         0.9458       923
   macro avg     0.9454    0.9427    0.9438       923
weighted avg     0.9464    0.9458    0.9460       923

micro f-score: 0.9458288190682557

========== Train Epoch 30 ==========
Loss: 0.051	Accuracy: 94.37%	Cost 257s
              precision    recall  f1-score   support

         bzx     0.9023    0.9449    0.9231       127
         cwx     0.9528    0.9453    0.9490       128
         hdx     0.8977    0.8778    0.8876        90
         mtx     0.9479    0.9579    0.9529        95
         nqx     0.9452    0.9324    0.9388        74
         qtx     0.9634    0.9576    0.9605       165
         zxx     0.9628    0.9549    0.9588       244

    accuracy                         0.9437       923
   macro avg     0.9389    0.9387    0.9387       923
weighted avg     0.9439    0.9437    0.9437       923

micro f-score: 0.9436619718309859

========== Train Epoch 31 ==========
Loss: 0.042	Accuracy: 94.15%	Cost 258s
              precision    recall  f1-score   support

         bzx     0.9344    0.8976    0.9157       127
         cwx     0.9394    0.9688    0.9538       128
         hdx     0.8723    0.9111    0.8913        90
         mtx     0.9579    0.9579    0.9579        95
         nqx     0.9714    0.9189    0.9444        74
         qtx     0.9401    0.9515    0.9458       165
         zxx     0.9588    0.9549    0.9569       244

    accuracy                         0.9415       923
   macro avg     0.9392    0.9372    0.9380       923
weighted avg     0.9419    0.9415    0.9415       923

micro f-score: 0.9414951245937161

========== Train Epoch 32 ==========
Loss: 0.036	Accuracy: 93.61%	Cost 259s
              precision    recall  f1-score   support

         bzx     0.8797    0.9213    0.9000       127
         cwx     0.9179    0.9609    0.9389       128
         hdx     0.9176    0.8667    0.8914        90
         mtx     0.9468    0.9368    0.9418        95
         nqx     0.9857    0.9324    0.9583        74
         qtx     0.9515    0.9515    0.9515       165
         zxx     0.9545    0.9467    0.9506       244

    accuracy                         0.9361       923
   macro avg     0.9363    0.9309    0.9332       923
weighted avg     0.9367    0.9361    0.9361       923

micro f-score: 0.9360780065005417

Finished training!!!

Min Loss = 0.036 in epoch 31;
Max Accuracy = 94.58% in epoch 28;
Total Cost 138 minutes

===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─Conv2d: 1-1                                 [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                            [-1, 64, 160, 160]        128
├─ReLU: 1-3                                   [-1, 64, 160, 160]        --
├─SPP: 1-4                                    [-1, 64, 160, 160]        --
|    └─Conv: 2-1                              [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                       [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2                  [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                         [-1, 32, 160, 160]        --
|    └─ModuleList: 2                          []                        --
|    |    └─MaxPool2d: 3-4                    [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5                    [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6                    [-1, 32, 160, 160]        --
|    └─Conv: 2-2                              [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                       [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8                  [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                         [-1, 64, 160, 160]        --
├─Sequential: 1-5                             [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11                 [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14                 [-1, 64, 160, 160]        128
|    |    └─HCAM1: 3-15                       [-1, 64, 160, 160]        3,376
|    |    └─ReLU: 3-16                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-17                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-18                 [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-19                        [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-20                      [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-21                 [-1, 64, 160, 160]        128
|    |    └─HCAM1: 3-22                       [-1, 64, 160, 160]        3,376
|    |    └─ReLU: 3-23                        [-1, 64, 160, 160]        --
├─Sequential: 1-6                             [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-5                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-24                      [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-25                 [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-26                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-27                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-28                 [-1, 128, 80, 80]         256
|    |    └─HCAM1: 3-29                       [-1, 128, 80, 80]         6,704
|    |    └─Sequential: 3-30                  [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-31                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-32                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-33                 [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-34                        [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                      [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36                 [-1, 128, 80, 80]         256
|    |    └─HCAM1: 3-37                       [-1, 128, 80, 80]         6,704
|    |    └─ReLU: 3-38                        [-1, 128, 80, 80]         --
├─Sequential: 1-7                             [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-7                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-39                      [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-40                 [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-41                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-42                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-43                 [-1, 256, 40, 40]         512
|    |    └─HCAM1: 3-44                       [-1, 256, 40, 40]         13,360
|    |    └─Sequential: 3-45                  [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-46                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-8                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-47                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-48                 [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-49                        [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-50                      [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-51                 [-1, 256, 40, 40]         512
|    |    └─HCAM1: 3-52                       [-1, 256, 40, 40]         13,360
|    |    └─ReLU: 3-53                        [-1, 256, 40, 40]         --
├─Sequential: 1-8                             [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-9                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-54                      [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-55                 [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-56                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-57                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-58                 [-1, 512, 20, 20]         1,024
|    |    └─HCAM1: 3-59                       [-1, 512, 20, 20]         51,296
|    |    └─Sequential: 3-60                  [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-61                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-10                       [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-62                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-63                 [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-64                        [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-65                      [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-66                 [-1, 512, 20, 20]         1,024
|    |    └─HCAM1: 3-67                       [-1, 512, 20, 20]         51,296
|    |    └─ReLU: 3-68                        [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                      [-1, 512, 1, 1]           --
├─Linear: 1-10                                [-1, 7]                   3,591
===============================================================================================
Total params: 11,340,007
Trainable params: 11,340,007
Non-trainable params: 0
Total mult-adds (G): 14.37
===============================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 274.69
Params size (MB): 43.26
Estimated Total Size (MB): 319.12
===============================================================================================



