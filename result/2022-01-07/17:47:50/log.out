dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 2.073	Accuracy: 21.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.1250    0.0222    0.0377        45
         zxx     0.2134    0.8974    0.3448        39

    accuracy                         0.2108       185
   macro avg     0.0841    0.1671    0.0904       185
weighted avg     0.0916    0.2108    0.0981       185

micro f-score: 0.21081081081081082

========== Train Epoch 2 ==========
Loss: 1.824	Accuracy: 24.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.2917    0.3182    0.3043        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.2500    0.1778    0.2078        45
         zxx     0.2339    0.7436    0.3558        39

    accuracy                         0.2486       185
   macro avg     0.2894    0.1936    0.1508       185
weighted avg     0.3286    0.2486    0.1803       185

micro f-score: 0.24864864864864866

========== Train Epoch 3 ==========
Loss: 1.820	Accuracy: 22.16%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2391    0.7097    0.3577        31
         cwx     0.1250    0.1364    0.1304        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0769    0.0526    0.0625        19
         nqx     0.1613    0.4167    0.2326        12
         qtx     0.4000    0.2222    0.2857        45
         zxx     0.0000    0.0000    0.0000        39

    accuracy                         0.2216       185
   macro avg     0.1432    0.2197    0.1527       185
weighted avg     0.1706    0.2216    0.1665       185

micro f-score: 0.22162162162162163

========== Train Epoch 4 ==========
Loss: 1.801	Accuracy: 32.97%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3750    0.2500    0.3000        12
         qtx     0.6667    0.1778    0.2807        45
         zxx     0.2537    0.8718    0.3931        39

    accuracy                         0.3297       185
   macro avg     0.3395    0.2764    0.2534       185
weighted avg     0.3875    0.3297    0.2796       185

micro f-score: 0.32972972972972975

========== Train Epoch 5 ==========
Loss: 1.786	Accuracy: 27.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2500    0.0968    0.1395        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2333    0.5833    0.3333        12
         qtx     0.3077    0.2667    0.2857        45
         zxx     0.2907    0.6410    0.4000        39

    accuracy                         0.2757       185
   macro avg     0.1863    0.2528    0.1941       185
weighted avg     0.2196    0.2757    0.2226       185

micro f-score: 0.2756756756756757

========== Train Epoch 6 ==========
Loss: 1.736	Accuracy: 26.49%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.2373    0.4516    0.3111        31
         cwx     0.2609    0.5455    0.3529        22
         hdx     0.1765    0.1765    0.1765        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3793    0.2444    0.2973        45
         zxx     0.2692    0.1795    0.2154        39

    accuracy                         0.2649       185
   macro avg     0.2298    0.2432    0.2153       185
weighted avg     0.2654    0.2649    0.2438       185

micro f-score: 0.2648648648648649

========== Train Epoch 7 ==========
Loss: 1.677	Accuracy: 20.00%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.0714    0.0323    0.0444        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.1111    0.0222    0.0370        45
         zxx     0.2174    0.8974    0.3500        39

    accuracy                         0.2000       185
   macro avg     0.0571    0.1360    0.0616       185
weighted avg     0.0848    0.2000    0.0902       185

micro f-score: 0.20000000000000004

========== Train Epoch 8 ==========
Loss: 1.762	Accuracy: 28.65%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2581    0.5161    0.3441        31
         cwx     0.2000    0.2273    0.2128        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1250    0.3333    0.1818        12
         qtx     0.4524    0.4222    0.4368        45
         zxx     0.3750    0.2308    0.2857        39

    accuracy                         0.2865       185
   macro avg     0.2015    0.2471    0.2087       185
weighted avg     0.2642    0.2865    0.2612       185

micro f-score: 0.2864864864864865

========== Train Epoch 9 ==========
Loss: 1.699	Accuracy: 29.19%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2667    0.1290    0.1739        31
         cwx     0.1569    0.3636    0.2192        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.2381    0.4167    0.3030        12
         qtx     0.3929    0.2444    0.3014        45
         zxx     0.4259    0.5897    0.4946        39

    accuracy                         0.2919       185
   macro avg     0.2421    0.2716    0.2391       185
weighted avg     0.2861    0.2919    0.2711       185

micro f-score: 0.2918918918918919

========== Train Epoch 10 ==========
Loss: 1.671	Accuracy: 33.51%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1750    0.6364    0.2745        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2083    0.2632    0.2326        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.7692    0.4444    0.5634        45
         zxx     0.4231    0.5641    0.4835        39

    accuracy                         0.3351       185
   macro avg     0.2965    0.2845    0.2424       185
weighted avg     0.3509    0.3351    0.3048       185

micro f-score: 0.33513513513513515

========== Train Epoch 11 ==========
Loss: 1.630	Accuracy: 38.92%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2286    0.5161    0.3168        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.2000    0.5833    0.2979        12
         qtx     0.7500    0.4667    0.5753        45
         zxx     0.5897    0.5897    0.5897        39

    accuracy                         0.3892       185
   macro avg     0.3717    0.3435    0.3068       185
weighted avg     0.4517    0.3892    0.3770       185

micro f-score: 0.3891891891891892

========== Train Epoch 12 ==========
Loss: 1.520	Accuracy: 36.22%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3333    0.4839    0.3947        31
         cwx     0.2273    0.2273    0.2273        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1071    0.1579    0.1277        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.5806    0.4000    0.4737        45
         zxx     0.4444    0.6154    0.5161        39

    accuracy                         0.3622       185
   macro avg     0.2990    0.2930    0.2821       185
weighted avg     0.3548    0.3622    0.3456       185

micro f-score: 0.3621621621621622

========== Train Epoch 13 ==========
Loss: 1.527	Accuracy: 38.92%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.3750    0.1935    0.2553        31
         cwx     0.2727    0.1364    0.1818        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2308    0.3158    0.2667        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.3827    0.6889    0.4921        45
         zxx     0.6486    0.6154    0.6316        39

    accuracy                         0.3892       185
   macro avg     0.3300    0.3024    0.2947       185
weighted avg     0.3748    0.3892    0.3599       185

micro f-score: 0.3891891891891892

========== Train Epoch 14 ==========
Loss: 1.492	Accuracy: 35.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3333    0.0968    0.1500        31
         cwx     0.2500    0.0909    0.1333        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.5833    0.3500        12
         qtx     0.4259    0.5111    0.4646        45
         zxx     0.3718    0.7436    0.4957        39

    accuracy                         0.3568       185
   macro avg     0.2687    0.3062    0.2505       185
weighted avg     0.3068    0.3568    0.2959       185

micro f-score: 0.3567567567567568

========== Train Epoch 15 ==========
Loss: 1.487	Accuracy: 38.38%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.2917    0.3182    0.3043        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2778    0.4167    0.3333        12
         qtx     0.4098    0.5556    0.4717        45
         zxx     0.4189    0.7949    0.5487        39

    accuracy                         0.3838       185
   macro avg     0.3188    0.3193    0.2704       185
weighted avg     0.3551    0.3838    0.3144       185

micro f-score: 0.3837837837837838

========== Train Epoch 16 ==========
Loss: 1.475	Accuracy: 34.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1463    0.2727    0.1905        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1667    0.4211    0.2388        19
         nqx     0.2500    0.7500    0.3750        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.9333    0.3590    0.5185        39

    accuracy                         0.3405       185
   macro avg     0.3022    0.3401    0.2744       185
weighted avg     0.3981    0.3405    0.3262       185

micro f-score: 0.34054054054054056

========== Train Epoch 17 ==========
Loss: 1.439	Accuracy: 32.97%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2500    0.0909    0.1333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.3729    0.4889    0.4231        45
         zxx     0.3168    0.8205    0.4571        39

    accuracy                         0.3297       185
   macro avg     0.1853    0.2596    0.1997       185
weighted avg     0.2104    0.3297    0.2401       185

micro f-score: 0.32972972972972975

========== Train Epoch 18 ==========
Loss: 1.385	Accuracy: 44.86%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3478    0.2581    0.2963        31
         cwx     0.3214    0.4091    0.3600        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2326    0.5263    0.3226        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.4486       185
   macro avg     0.3705    0.3814    0.3534       185
weighted avg     0.4690    0.4486    0.4320       185

micro f-score: 0.4486486486486486

========== Train Epoch 19 ==========
Loss: 1.355	Accuracy: 37.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.2368    0.4091    0.3000        22
         hdx     0.2857    0.1176    0.1667        17
         mtx     0.2222    0.1053    0.1429        19
         nqx     0.2000    0.0833    0.1176        12
         qtx     0.3200    0.5333    0.4000        45
         zxx     0.5918    0.7436    0.6591        39

    accuracy                         0.3730       185
   macro avg     0.4081    0.2938    0.2725       185
weighted avg     0.4604    0.3730    0.3298       185

micro f-score: 0.37297297297297294

========== Train Epoch 20 ==========
Loss: 1.386	Accuracy: 47.03%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3571    0.1613    0.2222        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.4286    0.3158    0.3636        19
         nqx     0.3214    0.7500    0.4500        12
         qtx     0.4432    0.8667    0.5865        45
         zxx     0.8077    0.5385    0.6462        39

    accuracy                         0.4703       185
   macro avg     0.4035    0.4215    0.3781       185
weighted avg     0.4583    0.4703    0.4276       185

micro f-score: 0.4702702702702703

========== Train Epoch 21 ==========
Loss: 1.256	Accuracy: 47.03%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.3871    0.3582        31
         cwx     0.6667    0.2727    0.3871        22
         hdx     0.1579    0.1765    0.1667        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.6383    0.6667    0.6522        45
         zxx     0.5600    0.7179    0.6292        39

    accuracy                         0.4703       185
   macro avg     0.4599    0.3906    0.4014       185
weighted avg     0.4889    0.4703    0.4626       185

micro f-score: 0.4702702702702703

========== Train Epoch 22 ==========
Loss: 1.252	Accuracy: 47.57%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.3333    0.5806    0.4235        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.6667    0.3333    0.4444        12
         qtx     0.5455    0.6667    0.6000        45
         zxx     0.6154    0.6154    0.6154        39

    accuracy                         0.4757       185
   macro avg     0.4720    0.3966    0.3980       185
weighted avg     0.4815    0.4757    0.4526       185

micro f-score: 0.4756756756756757

========== Train Epoch 23 ==========
Loss: 1.202	Accuracy: 47.03%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4000    0.0645    0.1111        31
         cwx     0.3421    0.5909    0.4333        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.2093    0.4737    0.2903        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.6977    0.6667    0.6818        45
         zxx     0.7179    0.7179    0.7179        39

    accuracy                         0.4703       185
   macro avg     0.4310    0.4081    0.3824       185
weighted avg     0.4992    0.4703    0.4514       185

micro f-score: 0.4702702702702703

========== Train Epoch 24 ==========
Loss: 1.134	Accuracy: 50.27%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3333    0.1935    0.2449        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.2105    0.2353    0.2222        17
         mtx     0.3077    0.4211    0.3556        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.7143    0.6667    0.6897        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5027       185
   macro avg     0.4518    0.4430    0.4347       185
weighted avg     0.5069    0.5027    0.4956       185

micro f-score: 0.5027027027027027

========== Train Epoch 25 ==========
Loss: 1.133	Accuracy: 49.19%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3514    0.4194    0.3824        31
         cwx     0.4706    0.3636    0.4103        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7297    0.6000    0.6585        45
         zxx     0.5909    0.6667    0.6265        39

    accuracy                         0.4919       185
   macro avg     0.4473    0.4610    0.4444       185
weighted avg     0.4999    0.4919    0.4887       185

micro f-score: 0.4918918918918919

========== Train Epoch 26 ==========
Loss: 1.050	Accuracy: 49.73%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.4935    0.8444    0.6230        45
         zxx     0.6571    0.5897    0.6216        39

    accuracy                         0.4973       185
   macro avg     0.5248    0.4698    0.4166       185
weighted avg     0.5506    0.4973    0.4523       185

micro f-score: 0.4972972972972973

========== Train Epoch 27 ==========
Loss: 1.057	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6000    0.0968    0.1667        31
         cwx     0.3333    0.3182    0.3256        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.5263    0.3704        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.4302    0.8222    0.5649        45
         zxx     0.7059    0.3077    0.4286        39

    accuracy                         0.4054       185
   macro avg     0.3793    0.3673    0.3187       185
weighted avg     0.4424    0.4054    0.3568       185

micro f-score: 0.40540540540540543

========== Train Epoch 28 ==========
Loss: 1.014	Accuracy: 47.57%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2500    0.3548    0.2933        31
         cwx     0.3571    0.4545    0.4000        22
         hdx     0.0714    0.0588    0.0645        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.8387    0.5778    0.6842        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.4757       185
   macro avg     0.5261    0.4146    0.4009       185
weighted avg     0.5581    0.4757    0.4607       185

micro f-score: 0.4756756756756757

========== Train Epoch 29 ==========
Loss: 0.861	Accuracy: 49.19%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.2955    0.5909    0.3939        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.4286    0.4737    0.4500        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.7647    0.5778    0.6582        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.4919       185
   macro avg     0.5090    0.4361    0.4181       185
weighted avg     0.5455    0.4919    0.4704       185

micro f-score: 0.4918918918918919

========== Train Epoch 30 ==========
Loss: 0.808	Accuracy: 49.73%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3387    0.6774    0.4516        31
         cwx     0.4231    0.5000    0.4583        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.5385    0.5833    0.5600        12
         qtx     0.6667    0.5333    0.5926        45
         zxx     0.7931    0.5897    0.6765        39

    accuracy                         0.4973       185
   macro avg     0.4447    0.4571    0.4389       185
weighted avg     0.5076    0.4973    0.4875       185

micro f-score: 0.4972972972972973

========== Train Epoch 31 ==========
Loss: 0.806	Accuracy: 48.11%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4000    0.2581    0.3137        31
         cwx     0.3019    0.7273    0.4267        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.7105    0.6000    0.6506        45
         zxx     0.5455    0.6154    0.5783        39

    accuracy                         0.4811       185
   macro avg     0.5297    0.4434    0.4426       185
weighted avg     0.5283    0.4811    0.4752       185

micro f-score: 0.4810810810810811

========== Train Epoch 32 ==========
Loss: 0.708	Accuracy: 51.35%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.4767    0.9111    0.6260        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.5135       185
   macro avg     0.6388    0.4113    0.4066       185
weighted avg     0.6024    0.5135    0.4684       185

micro f-score: 0.5135135135135135

========== Train Epoch 33 ==========
Loss: 0.706	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3667    0.3548    0.3607        31
         cwx     0.5000    0.5909    0.5417        22
         hdx     0.2903    0.5294    0.3750        17
         mtx     0.5000    0.3158    0.3871        19
         nqx     0.5833    0.5833    0.5833        12
         qtx     0.7727    0.7556    0.7640        45
         zxx     0.7667    0.5897    0.6667        39

    accuracy                         0.5568       185
   macro avg     0.5400    0.5314    0.5255       185
weighted avg     0.5864    0.5568    0.5633       185

micro f-score: 0.5567567567567567

========== Train Epoch 34 ==========
Loss: 0.659	Accuracy: 57.30%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.2941    0.2941    0.2941        17
         mtx     0.5263    0.5263    0.5263        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.5942    0.9111    0.7193        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5730       185
   macro avg     0.5711    0.5156    0.5189       185
weighted avg     0.5632    0.5730    0.5418       185

micro f-score: 0.572972972972973

========== Train Epoch 35 ==========
Loss: 0.567	Accuracy: 51.89%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.3636    0.7273    0.4848        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3333    0.5263    0.4082        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.8846    0.5111    0.6479        45
         zxx     0.7073    0.7436    0.7250        39

    accuracy                         0.5189       185
   macro avg     0.5069    0.5148    0.4732       185
weighted avg     0.5885    0.5189    0.5147       185

micro f-score: 0.518918918918919

========== Train Epoch 36 ==========
Loss: 0.501	Accuracy: 51.89%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.3939    0.4194    0.4062        31
         cwx     0.5000    0.5455    0.5217        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.4211    0.4211    0.4211        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.5800    0.7436    0.6517        39

    accuracy                         0.5189       185
   macro avg     0.5026    0.5081    0.4924       185
weighted avg     0.5599    0.5189    0.5208       185

micro f-score: 0.518918918918919

========== Train Epoch 37 ==========
Loss: 0.469	Accuracy: 51.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4250    0.5484    0.4789        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3214    0.5294    0.4000        17
         mtx     0.3030    0.5263    0.3846        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.9565    0.4889    0.6471        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5189       185
   macro avg     0.5397    0.4884    0.4836       185
weighted avg     0.6092    0.5189    0.5339       185

micro f-score: 0.518918918918919

========== Train Epoch 38 ==========
Loss: 0.473	Accuracy: 54.05%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3226    0.5263    0.4000        19
         nqx     0.3333    0.5833    0.4242        12
         qtx     0.7447    0.7778    0.7609        45
         zxx     0.5614    0.8205    0.6667        39

    accuracy                         0.5405       185
   macro avg     0.5175    0.4870    0.4571       185
weighted avg     0.5763    0.5405    0.5132       185

micro f-score: 0.5405405405405406

========== Train Epoch 39 ==========
Loss: 0.378	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4545    0.1613    0.2381        31
         cwx     0.4667    0.3182    0.3784        22
         hdx     0.2188    0.8235    0.3457        17
         mtx     0.7273    0.4211    0.5333        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.8462    0.4889    0.6197        45
         zxx     0.6111    0.8462    0.7097        39

    accuracy                         0.5027       185
   macro avg     0.6178    0.4846    0.4750       185
weighted avg     0.6260    0.5027    0.5042       185

micro f-score: 0.5027027027027027

========== Train Epoch 40 ==========
Loss: 0.225	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.1613    0.2778        31
         cwx     0.3016    0.8636    0.4471        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.2812    0.7500    0.4091        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.6923    0.6923    0.6923        39

    accuracy                         0.5081       185
   macro avg     0.5984    0.4935    0.4412       185
weighted avg     0.6745    0.5081    0.4964       185

micro f-score: 0.5081081081081081

========== Train Epoch 41 ==========
Loss: 0.233	Accuracy: 50.81%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5000    0.1290    0.2051        31
         cwx     0.6923    0.4091    0.5143        22
         hdx     0.7500    0.3529    0.4800        17
         mtx     0.2750    0.5789    0.3729        19
         nqx     0.2500    0.7500    0.3750        12
         qtx     0.6600    0.7333    0.6947        45
         zxx     0.7333    0.5641    0.6377        39

    accuracy                         0.5081       185
   macro avg     0.5515    0.5025    0.4685       185
weighted avg     0.5946    0.5081    0.5057       185

micro f-score: 0.5081081081081081

========== Train Epoch 42 ==========
Loss: 0.304	Accuracy: 55.14%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.4667    0.4118    0.4375        17
         mtx     0.3667    0.5789    0.4490        19
         nqx     0.5714    0.3333    0.4211        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5514       185
   macro avg     0.5351    0.4930    0.4888       185
weighted avg     0.5680    0.5514    0.5340       185

micro f-score: 0.5513513513513514

========== Train Epoch 43 ==========
Loss: 0.292	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     1.0000    0.2273    0.3704        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.2778    0.8333    0.4167        12
         qtx     0.5405    0.8889    0.6723        45
         zxx     0.8636    0.4872    0.6230        39

    accuracy                         0.5135       185
   macro avg     0.5667    0.4813    0.4515       185
weighted avg     0.6107    0.5135    0.4985       185

micro f-score: 0.5135135135135135

========== Train Epoch 44 ==========
Loss: 0.289	Accuracy: 52.97%	Cost 31s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.5000    0.4545    0.4762        22
         hdx     0.5000    0.3529    0.4138        17
         mtx     0.5714    0.4211    0.4848        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.7429    0.5778    0.6500        45
         zxx     0.4235    0.9231    0.5806        39

    accuracy                         0.5297       185
   macro avg     0.5721    0.4890    0.4957       185
weighted avg     0.5779    0.5297    0.5111       185

micro f-score: 0.5297297297297298

========== Train Epoch 45 ==========
Loss: 0.229	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5294    0.2903    0.3750        31
         cwx     0.4737    0.4091    0.4390        22
         hdx     0.2821    0.6471    0.3929        17
         mtx     0.5833    0.3684    0.4516        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.6923    0.8000    0.7423        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.5514       185
   macro avg     0.5522    0.5516    0.5168       185
weighted avg     0.6108    0.5514    0.5512       185

micro f-score: 0.5513513513513514

========== Train Epoch 46 ==========
Loss: 0.232	Accuracy: 53.51%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4118    0.4516    0.4308        31
         cwx     0.4500    0.4091    0.4286        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.6111    0.5789    0.5946        19
         nqx     1.0000    0.3333    0.5000        12
         qtx     0.9500    0.4222    0.5846        45
         zxx     0.4932    0.9231    0.6429        39

    accuracy                         0.5351       185
   macro avg     0.6130    0.4959    0.5064       185
weighted avg     0.6196    0.5351    0.5278       185

micro f-score: 0.5351351351351351

========== Train Epoch 47 ==========
Loss: 0.149	Accuracy: 54.59%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5556    0.3226    0.4082        31
         cwx     0.4545    0.6818    0.5455        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.4615    0.3158    0.3750        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.6000    0.7333    0.6600        45
         zxx     0.7500    0.5385    0.6269        39

    accuracy                         0.5459       185
   macro avg     0.5289    0.5362    0.5168       185
weighted avg     0.5643    0.5459    0.5391       185

micro f-score: 0.5459459459459459

========== Train Epoch 48 ==========
Loss: 0.110	Accuracy: 56.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.4286    0.4091    0.4186        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.7500    0.3158    0.4444        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.8333    0.5556    0.6667        45
         zxx     0.5397    0.8718    0.6667        39

    accuracy                         0.5622       185
   macro avg     0.5646    0.5379    0.5219       185
weighted avg     0.6039    0.5622    0.5551       185

micro f-score: 0.5621621621621622

========== Train Epoch 49 ==========
Loss: 0.155	Accuracy: 53.51%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5455    0.3871    0.4528        31
         cwx     0.3500    0.6364    0.4516        22
         hdx     0.3182    0.4118    0.3590        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8276    0.5333    0.6486        45
         zxx     0.7027    0.6667    0.6842        39

    accuracy                         0.5351       185
   macro avg     0.5232    0.5362    0.5136       185
weighted avg     0.5860    0.5351    0.5437       185

micro f-score: 0.5351351351351351

========== Train Epoch 50 ==========
Loss: 0.207	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.3514    0.5909    0.4407        22
         hdx     0.5455    0.3529    0.4286        17
         mtx     0.4444    0.6316    0.5217        19
         nqx     0.7143    0.4167    0.5263        12
         qtx     0.6604    0.7778    0.7143        45
         zxx     0.8077    0.5385    0.6462        39

    accuracy                         0.5622       185
   macro avg     0.5748    0.5279    0.5306       185
weighted avg     0.5986    0.5622    0.5626       185

micro f-score: 0.5621621621621622

========== Train Epoch 51 ==========
Loss: 0.162	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3548    0.4151        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.3913    0.4737    0.4286        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.8205    0.7111    0.7619        45
         zxx     0.5741    0.7949    0.6667        39

    accuracy                         0.5676       185
   macro avg     0.5629    0.5457    0.5127       185
weighted avg     0.6060    0.5676    0.5526       185

micro f-score: 0.5675675675675675

========== Train Epoch 52 ==========
Loss: 0.121	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3913    0.5806    0.4675        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.3889    0.4118    0.4000        17
         mtx     0.5625    0.4737    0.5143        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7941    0.6000    0.6835        45
         zxx     0.7353    0.6410    0.6849        39

    accuracy                         0.5676       185
   macro avg     0.5684    0.5534    0.5550       185
weighted avg     0.6028    0.5676    0.5775       185

micro f-score: 0.5675675675675675

========== Train Epoch 53 ==========
Loss: 0.068	Accuracy: 60.00%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3548    0.6471    0.4583        17
         mtx     0.6667    0.5263    0.5882        19
         nqx     0.6667    0.6667    0.6667        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.7105    0.6923    0.7013        39

    accuracy                         0.6000       185
   macro avg     0.5960    0.5967    0.5877       185
weighted avg     0.6203    0.6000    0.6037       185

micro f-score: 0.6

========== Train Epoch 54 ==========
Loss: 0.077	Accuracy: 60.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.4333    0.5909    0.5000        22
         hdx     0.5556    0.2941    0.3846        17
         mtx     0.5789    0.5789    0.5789        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.8462    0.7333    0.7857        45
         zxx     0.5789    0.8462    0.6875        39

    accuracy                         0.6054       185
   macro avg     0.5847    0.5715    0.5571       185
weighted avg     0.6229    0.6054    0.5929       185

micro f-score: 0.6054054054054054

========== Train Epoch 55 ==========
Loss: 0.064	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     1.0000    0.0968    0.1765        31
         cwx     0.4762    0.4545    0.4651        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.6000    0.6316    0.6154        19
         nqx     1.0000    0.4167    0.5882        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.5676       185
   macro avg     0.6639    0.5345    0.5195       185
weighted avg     0.6671    0.5676    0.5384       185

micro f-score: 0.5675675675675675

========== Train Epoch 56 ==========
Loss: 0.105	Accuracy: 51.35%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4615    0.3871    0.4211        31
         cwx     0.4167    0.4545    0.4348        22
         hdx     0.2759    0.4706    0.3478        17
         mtx     0.3750    0.3158    0.3429        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.6000    0.7333    0.6600        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.5135       185
   macro avg     0.5497    0.4573    0.4649       185
weighted avg     0.5531    0.5135    0.5125       185

micro f-score: 0.5135135135135135

========== Train Epoch 57 ==========
Loss: 0.123	Accuracy: 52.43%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.3750    0.5455    0.4444        22
         hdx     0.2778    0.2941    0.2857        17
         mtx     0.4762    0.5263    0.5000        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.8519    0.5111    0.6389        45
         zxx     0.5577    0.7436    0.6374        39

    accuracy                         0.5243       185
   macro avg     0.5120    0.5011    0.4949       185
weighted avg     0.5630    0.5243    0.5272       185

micro f-score: 0.5243243243243243

========== Train Epoch 58 ==========
Loss: 0.098	Accuracy: 57.84%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.5000    0.6818    0.5769        22
         hdx     0.4000    0.2353    0.2963        17
         mtx     0.5000    0.6842    0.5778        19
         nqx     0.4583    0.9167    0.6111        12
         qtx     0.8519    0.5111    0.6389        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5784       185
   macro avg     0.5550    0.5933    0.5460       185
weighted avg     0.6084    0.5784    0.5679       185

micro f-score: 0.5783783783783784

========== Train Epoch 59 ==========
Loss: 0.089	Accuracy: 58.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.3871    0.4364        31
         cwx     0.4400    0.5000    0.4681        22
         hdx     0.4286    0.3529    0.3871        17
         mtx     0.4828    0.7368    0.5833        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8571    0.6667    0.7500        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5892       185
   macro avg     0.5696    0.5590    0.5540       185
weighted avg     0.6059    0.5892    0.5875       185

micro f-score: 0.5891891891891892

========== Train Epoch 60 ==========
Loss: 0.033	Accuracy: 62.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5833    0.2258    0.3256        31
         cwx     0.4848    0.7273    0.5818        22
         hdx     0.6000    0.3529    0.4444        17
         mtx     0.6087    0.7368    0.6667        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.6216       185
   macro avg     0.6038    0.6141    0.5841       185
weighted avg     0.6327    0.6216    0.6033       185

micro f-score: 0.6216216216216216

========== Train Epoch 61 ==========
Loss: 0.059	Accuracy: 54.59%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4375    0.6774    0.5316        31
         cwx     0.5000    0.3636    0.4211        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3871    0.6316    0.4800        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.6875    0.7333    0.7097        45
         zxx     0.9444    0.4359    0.5965        39

    accuracy                         0.5459       185
   macro avg     0.5818    0.5040    0.5061       185
weighted avg     0.6198    0.5459    0.5480       185

micro f-score: 0.5459459459459459

========== Train Epoch 62 ==========
Loss: 0.068	Accuracy: 61.08%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3947    0.4839    0.4348        31
         cwx     0.4800    0.5455    0.5106        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.8571    0.3158    0.4615        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7347    0.8000    0.7660        45
         zxx     0.7368    0.7179    0.7273        39

    accuracy                         0.6108       185
   macro avg     0.6217    0.5715    0.5752       185
weighted avg     0.6364    0.6108    0.6081       185

micro f-score: 0.6108108108108108

========== Train Epoch 63 ==========
Loss: 0.084	Accuracy: 56.76%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.3929    0.5000    0.4400        22
         hdx     0.3200    0.4706    0.3810        17
         mtx     0.5000    0.6316    0.5581        19
         nqx     0.8000    0.3333    0.4706        12
         qtx     0.6800    0.7556    0.7158        45
         zxx     0.6739    0.7949    0.7294        39

    accuracy                         0.5676       185
   macro avg     0.5830    0.5210    0.5083       185
weighted avg     0.6065    0.5676    0.5472       185

micro f-score: 0.5675675675675675

========== Train Epoch 64 ==========
Loss: 0.113	Accuracy: 60.00%	Cost 26s
              precision    recall  f1-score   support

         bzx     0.7143    0.3226    0.4444        31
         cwx     0.5714    0.3636    0.4444        22
         hdx     0.5714    0.4706    0.5161        17
         mtx     0.3939    0.6842    0.5000        19
         nqx     0.4167    0.8333    0.5556        12
         qtx     0.8250    0.7333    0.7765        45
         zxx     0.6304    0.7436    0.6824        39

    accuracy                         0.6000       185
   macro avg     0.5890    0.5930    0.5599       185
weighted avg     0.6412    0.6000    0.5949       185

micro f-score: 0.6

Finished training!!!

Min Loss = 0.033 in epoch 59;
Max Accuracy = 62.16% in epoch 59;
Total Cost 31 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-6                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-7                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-8             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-9                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-10                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-12                   [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-3                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-13                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-15                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-16                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-18                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-19                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-20            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-21                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-22                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    └─Sequential: 3-24             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-5                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-28                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-29                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-30            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-31                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-6                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-32                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-33            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-34                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-37                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-40                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-43                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-8                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-44                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-45            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-46                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-47                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-48            [-1, 256, 20, 20]         512
|    |    └─Sequential: 3-49             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-50                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-9                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-51                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-56                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-10                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-57                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-58            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-59                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-62                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-65                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-68                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-71                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-74                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-77                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-80                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-14                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-81                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-82            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-83                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-84                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-85            [-1, 512, 10, 10]         1,024
|    |    └─Sequential: 3-86             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-87                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-15                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-88                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-89            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-90                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-91                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-92            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-93                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-16                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-94                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,288,263
Trainable params: 21,288,263
Non-trainable params: 0
Total mult-adds (G): 7.52
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 116.41
Params size (MB): 81.21
Estimated Total Size (MB): 198.79
==========================================================================================



