dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: sppb_resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 2.146	Accuracy: 16.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1429    0.0645    0.0889        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.1014    0.4118    0.1628        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2500    0.0444    0.0755        45
         zxx     0.1978    0.4615    0.2769        39

    accuracy                         0.1622       185
   macro avg     0.1703    0.1468    0.0982       185
weighted avg     0.1952    0.1622    0.1165       185

micro f-score: 0.16216216216216217

========== Train Epoch 2 ==========
Loss: 1.891	Accuracy: 27.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.4000    0.5333    0.4571        45
         zxx     0.2143    0.6154    0.3179        39

    accuracy                         0.2757       185
   macro avg     0.1235    0.1998    0.1464       185
weighted avg     0.1587    0.2757    0.1944       185

micro f-score: 0.2756756756756757

========== Train Epoch 3 ==========
Loss: 1.837	Accuracy: 28.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.2778    0.4167    0.3333        12
         qtx     0.3444    0.6889    0.4593        45
         zxx     0.1974    0.3846    0.2609        39

    accuracy                         0.2811       185
   macro avg     0.2599    0.2204    0.1648       185
weighted avg     0.2461    0.2811    0.1986       185

micro f-score: 0.2810810810810811

========== Train Epoch 4 ==========
Loss: 1.818	Accuracy: 24.86%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3684    0.4516    0.4058        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.2000    0.3333    0.2500        12
         qtx     0.2778    0.1111    0.1587        45
         zxx     0.2125    0.4359    0.2857        39

    accuracy                         0.2486       185
   macro avg     0.2087    0.2389    0.2092       185
weighted avg     0.2258    0.2486    0.2179       185

micro f-score: 0.24864864864864866

========== Train Epoch 5 ==========
Loss: 1.826	Accuracy: 28.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1250    0.0455    0.0667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5000    0.4444    0.4706        45
         zxx     0.2540    0.8205    0.3879        39

    accuracy                         0.2865       185
   macro avg     0.1256    0.1872    0.1322       185
weighted avg     0.1900    0.2865    0.2042       185

micro f-score: 0.2864864864864865

========== Train Epoch 6 ==========
Loss: 1.753	Accuracy: 22.70%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.0645    0.1143        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1442    0.7895    0.2439        19
         nqx     0.1667    0.0833    0.1111        12
         qtx     0.5263    0.2222    0.3125        45
         zxx     0.2745    0.3590    0.3111        39

    accuracy                         0.2270       185
   macro avg     0.2302    0.2169    0.1561       185
weighted avg     0.2953    0.2270    0.1930       185

micro f-score: 0.22702702702702704

========== Train Epoch 7 ==========
Loss: 1.715	Accuracy: 37.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3611    0.4194    0.3881        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.1562    0.2941    0.2041        17
         mtx     0.1724    0.2632    0.2083        19
         nqx     1.0000    0.0833    0.1538        12
         qtx     0.5854    0.5333    0.5581        45
         zxx     0.4667    0.5385    0.5000        39

    accuracy                         0.3730       185
   macro avg     0.3917    0.3045    0.2875       185
weighted avg     0.3982    0.3730    0.3563       185

micro f-score: 0.37297297297297294

========== Train Epoch 8 ==========
Loss: 1.665	Accuracy: 30.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4000    0.1935    0.2609        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1500    0.1579    0.1538        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.5000    0.2667    0.3478        45
         zxx     0.2869    0.8974    0.4348        39

    accuracy                         0.3027       185
   macro avg     0.1910    0.2165    0.1710       185
weighted avg     0.2645    0.3027    0.2358       185

micro f-score: 0.3027027027027027

========== Train Epoch 9 ==========
Loss: 1.617	Accuracy: 27.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.1818    0.1290    0.1509        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.1250    0.1053    0.1143        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4400    0.2444    0.3143        45
         zxx     0.2783    0.8205    0.4156        39

    accuracy                         0.2757       185
   macro avg     0.2417    0.2024    0.1707       185
weighted avg     0.2703    0.2757    0.2195       185

micro f-score: 0.2756756756756757

========== Train Epoch 10 ==========
Loss: 1.594	Accuracy: 34.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2619    0.3548    0.3014        31
         cwx     0.1212    0.1818    0.1455        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.2105    0.3333    0.2581        12
         qtx     0.4769    0.6889    0.5636        45
         zxx     0.7857    0.2821    0.4151        39

    accuracy                         0.3405       185
   macro avg     0.3009    0.2780    0.2617       185
weighted avg     0.3793    0.3405    0.3244       185

micro f-score: 0.34054054054054056

========== Train Epoch 11 ==========
Loss: 1.682	Accuracy: 29.73%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2429    0.5484    0.3366        31
         cwx     0.1429    0.1364    0.1395        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2727    0.2500    0.2609        12
         qtx     0.4464    0.5556    0.4950        45
         zxx     0.2593    0.1795    0.2121        39

    accuracy                         0.2973       185
   macro avg     0.1949    0.2385    0.2063       185
weighted avg     0.2386    0.2973    0.2551       185

micro f-score: 0.2972972972972973

========== Train Epoch 12 ==========
Loss: 1.606	Accuracy: 38.38%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3182    0.2258    0.2642        31
         cwx     0.2222    0.1818    0.2000        22
         hdx     0.1765    0.1765    0.1765        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.5500    0.4889    0.5176        45
         zxx     0.4143    0.7436    0.5321        39

    accuracy                         0.3838       185
   macro avg     0.3354    0.3266    0.3074       185
weighted avg     0.3729    0.3838    0.3557       185

micro f-score: 0.3837837837837838

========== Train Epoch 13 ==========
Loss: 1.521	Accuracy: 40.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.1250    0.1818    0.1481        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.4915    0.6444    0.5577        45
         zxx     0.4754    0.7436    0.5800        39

    accuracy                         0.4000       185
   macro avg     0.3425    0.3073    0.2862       185
weighted avg     0.3845    0.4000    0.3583       185

micro f-score: 0.4000000000000001

========== Train Epoch 14 ==========
Loss: 1.580	Accuracy: 36.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2750    0.3548    0.3099        31
         cwx     0.3077    0.1818    0.2286        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.8095    0.3778    0.5152        45
         zxx     0.3294    0.7179    0.4516        39

    accuracy                         0.3622       185
   macro avg     0.3265    0.3034    0.2894       185
weighted avg     0.3943    0.3622    0.3405       185

micro f-score: 0.3621621621621622

========== Train Epoch 15 ==========
Loss: 1.513	Accuracy: 46.49%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3111    0.4516    0.3684        31
         cwx     0.4444    0.1818    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.5962    0.6889    0.6392        45
         zxx     0.4648    0.8462    0.6000        39

    accuracy                         0.4649       185
   macro avg     0.3928    0.3530    0.3299       185
weighted avg     0.4211    0.4649    0.4066       185

micro f-score: 0.4648648648648649

========== Train Epoch 16 ==========
Loss: 1.555	Accuracy: 34.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     0.3708    0.7333    0.4925        45
         zxx     0.3457    0.7179    0.4667        39

    accuracy                         0.3459       185
   macro avg     0.1857    0.2376    0.1770       185
weighted avg     0.2189    0.3459    0.2407       185

micro f-score: 0.34594594594594597

========== Train Epoch 17 ==========
Loss: 1.499	Accuracy: 43.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2745    0.4516    0.3415        31
         cwx     0.3000    0.1364    0.1875        22
         hdx     0.1429    0.1765    0.1579        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3500    0.5833    0.4375        12
         qtx     0.7179    0.6222    0.6667        45
         zxx     0.5750    0.5897    0.5823        39

    accuracy                         0.4324       185
   macro avg     0.4086    0.3807    0.3639       185
weighted avg     0.4647    0.4324    0.4252       185

micro f-score: 0.43243243243243246

========== Train Epoch 18 ==========
Loss: 1.456	Accuracy: 38.38%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2632    0.1613    0.2000        31
         cwx     0.2258    0.3182    0.2642        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.2381    0.2632    0.2500        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.6667    0.4444    0.5333        45
         zxx     0.4912    0.7179    0.5833        39

    accuracy                         0.3838       185
   macro avg     0.3022    0.3226    0.3014       185
weighted avg     0.3823    0.3838    0.3689       185

micro f-score: 0.3837837837837838

========== Train Epoch 19 ==========
Loss: 1.474	Accuracy: 49.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.3500    0.3182    0.3333        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.3158    0.5000    0.3871        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.4848    0.8205    0.6095        39

    accuracy                         0.4973       185
   macro avg     0.5317    0.4304    0.4064       185
weighted avg     0.5513    0.4973    0.4687       185

micro f-score: 0.4972972972972973

========== Train Epoch 20 ==========
Loss: 1.441	Accuracy: 40.54%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3571    0.1613    0.2222        31
         cwx     1.0000    0.0909    0.1667        22
         hdx     0.1803    0.6471    0.2821        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.5385    0.6222    0.5773        45
         zxx     0.5714    0.6154    0.5926        39

    accuracy                         0.4054       185
   macro avg     0.4292    0.3648    0.3179       185
weighted avg     0.4699    0.4054    0.3733       185

micro f-score: 0.40540540540540543

========== Train Epoch 21 ==========
Loss: 1.417	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3478    0.5161    0.4156        31
         cwx     0.5556    0.2273    0.3226        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2857    0.6667    0.4000        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.5714    0.7179    0.6364        39

    accuracy                         0.4757       185
   macro avg     0.3383    0.4024    0.3458       185
weighted avg     0.4112    0.4757    0.4252       185

micro f-score: 0.4756756756756757

========== Train Epoch 22 ==========
Loss: 1.379	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.2857    0.4545    0.3509        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.6458    0.6889    0.6667        45
         zxx     0.9474    0.4615    0.6207        39

    accuracy                         0.4811       185
   macro avg     0.4683    0.4501    0.4412       185
weighted avg     0.5434    0.4811    0.4902       185

micro f-score: 0.4810810810810811

========== Train Epoch 23 ==========
Loss: 1.380	Accuracy: 45.95%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6471    0.3548    0.4583        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2059    0.5833    0.3043        12
         qtx     0.4217    0.7778    0.5469        45
         zxx     0.7143    0.6410    0.6757        39

    accuracy                         0.4595       185
   macro avg     0.4343    0.3842    0.3504       185
weighted avg     0.4891    0.4595    0.4247       185

micro f-score: 0.4594594594594595

========== Train Epoch 24 ==========
Loss: 1.352	Accuracy: 41.08%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4286    0.2903    0.3462        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.8000    0.2105    0.3333        19
         nqx     0.2424    0.6667    0.3556        12
         qtx     0.7917    0.4222    0.5507        45
         zxx     0.3626    0.8462    0.5077        39

    accuracy                         0.4108       185
   macro avg     0.4227    0.3675    0.3267       185
weighted avg     0.4784    0.4108    0.3793       185

micro f-score: 0.4108108108108109

========== Train Epoch 25 ==========
Loss: 1.378	Accuracy: 36.76%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3750    0.5806    0.4557        31
         cwx     0.1500    0.2727    0.1935        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.7500    0.3750        12
         qtx     0.5833    0.3111    0.4058        45
         zxx     0.6000    0.5385    0.5676        39

    accuracy                         0.3676       185
   macro avg     0.2798    0.3504    0.2854       185
weighted avg     0.3653    0.3676    0.3421       185

micro f-score: 0.3675675675675676

========== Train Epoch 26 ==========
Loss: 1.372	Accuracy: 42.70%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3333    0.7419    0.4600        31
         cwx     0.5000    0.2273    0.3125        22
         hdx     0.0909    0.1176    0.1026        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.3478    0.6667    0.4571        12
         qtx     0.8696    0.4444    0.5882        45
         zxx     0.5882    0.5128    0.5479        39

    accuracy                         0.4270       185
   macro avg     0.4257    0.3948    0.3650       185
weighted avg     0.5074    0.4270    0.4208       185

micro f-score: 0.427027027027027

========== Train Epoch 27 ==========
Loss: 1.362	Accuracy: 35.14%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3871    0.3871    0.3871        31
         cwx     0.2500    0.3182    0.2800        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2162    0.6667    0.3265        12
         qtx     0.8000    0.1778    0.2909        45
         zxx     0.4110    0.7692    0.5357        39

    accuracy                         0.3514       185
   macro avg     0.2949    0.3313    0.2600       185
weighted avg     0.3898    0.3514    0.3030       185

micro f-score: 0.35135135135135137

========== Train Epoch 28 ==========
Loss: 1.292	Accuracy: 43.78%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4062    0.4194    0.4127        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3704    0.8889    0.5229        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.4378       185
   macro avg     0.3502    0.2923    0.2437       185
weighted avg     0.4194    0.4378    0.3508       185

micro f-score: 0.43783783783783786

========== Train Epoch 29 ==========
Loss: 1.247	Accuracy: 45.41%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5333    0.2581    0.3478        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.3158    0.3529    0.3333        17
         mtx     0.3750    0.1579    0.2222        19
         nqx     0.4000    0.5000    0.4444        12
         qtx     0.6757    0.5556    0.6098        45
         zxx     0.3933    0.8974    0.5469        39

    accuracy                         0.4541       185
   macro avg     0.4562    0.3953    0.3697       185
weighted avg     0.4896    0.4541    0.4141       185

micro f-score: 0.4540540540540541

========== Train Epoch 30 ==========
Loss: 1.314	Accuracy: 44.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.0968    0.1667        31
         cwx     0.3000    0.5455    0.3871        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.6190    0.5778    0.5977        45
         zxx     0.4853    0.8462    0.6168        39

    accuracy                         0.4432       185
   macro avg     0.3771    0.3764    0.3382       185
weighted avg     0.4367    0.4432    0.3946       185

micro f-score: 0.44324324324324327

========== Train Epoch 31 ==========
Loss: 1.290	Accuracy: 44.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4167    0.3226    0.3636        31
         cwx     0.2500    0.5000    0.3333        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.1923    0.2632    0.2222        19
         nqx     0.4211    0.6667    0.5161        12
         qtx     0.7500    0.5333    0.6234        45
         zxx     0.7188    0.5897    0.6479        39

    accuracy                         0.4486       185
   macro avg     0.4284    0.4276    0.4095       185
weighted avg     0.5035    0.4486    0.4598       185

micro f-score: 0.4486486486486486

========== Train Epoch 32 ==========
Loss: 1.223	Accuracy: 46.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.2667    0.1818    0.2162        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.4222    0.8444    0.5630        45
         zxx     0.7857    0.5641    0.6567        39

    accuracy                         0.4649       185
   macro avg     0.4049    0.3986    0.3838       185
weighted avg     0.4513    0.4649    0.4318       185

micro f-score: 0.4648648648648649

========== Train Epoch 33 ==========
Loss: 1.186	Accuracy: 45.95%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4444    0.3871    0.4138        31
         cwx     0.3333    0.4545    0.3846        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.2500    0.7500    0.3750        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.4595       185
   macro avg     0.4226    0.4462    0.4070       185
weighted avg     0.5076    0.4595    0.4650       185

micro f-score: 0.4594594594594595

========== Train Epoch 34 ==========
Loss: 1.235	Accuracy: 44.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     1.0000    0.0455    0.0870        22
         hdx     0.3750    0.3529    0.3636        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.5738    0.7778    0.6604        45
         zxx     0.3684    0.8974    0.5224        39

    accuracy                         0.4486       185
   macro avg     0.4882    0.3458    0.3069       185
weighted avg     0.4933    0.4486    0.3646       185

micro f-score: 0.4486486486486486

========== Train Epoch 35 ==========
Loss: 1.194	Accuracy: 51.89%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4390    0.5806    0.5000        31
         cwx     0.3548    0.5000    0.4151        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2143    0.3158    0.2553        19
         nqx     0.4118    0.5833    0.4828        12
         qtx     0.8919    0.7333    0.8049        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.5189       185
   macro avg     0.4986    0.4787    0.4685       185
weighted avg     0.5789    0.5189    0.5299       185

micro f-score: 0.518918918918919

========== Train Epoch 36 ==========
Loss: 1.209	Accuracy: 50.27%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.5806    0.5373        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.4545    0.2941    0.3571        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.3636    0.6667    0.4706        12
         qtx     0.6250    0.6667    0.6452        45
         zxx     0.5500    0.5641    0.5570        39

    accuracy                         0.5027       185
   macro avg     0.4490    0.4630    0.4423       185
weighted avg     0.4904    0.5027    0.4882       185

micro f-score: 0.5027027027027027

========== Train Epoch 37 ==========
Loss: 1.163	Accuracy: 32.97%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.1975    0.7273    0.3107        22
         hdx     0.1579    0.1765    0.1667        17
         mtx     0.2143    0.1579    0.1818        19
         nqx     0.2571    0.7500    0.3830        12
         qtx     0.7895    0.3333    0.4688        45
         zxx     1.0000    0.2821    0.4400        39

    accuracy                         0.3297       185
   macro avg     0.4690    0.3652    0.3096       185
weighted avg     0.5912    0.3297    0.3388       185

micro f-score: 0.32972972972972975

========== Train Epoch 38 ==========
Loss: 1.162	Accuracy: 44.86%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4545    0.3226    0.3774        31
         cwx     0.2128    0.4545    0.2899        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.3333    0.6667    0.4444        12
         qtx     0.7692    0.4444    0.5634        45
         zxx     0.5714    0.8205    0.6737        39

    accuracy                         0.4486       185
   macro avg     0.4297    0.4104    0.3728       185
weighted avg     0.4973    0.4486    0.4314       185

micro f-score: 0.4486486486486486

========== Train Epoch 39 ==========
Loss: 1.087	Accuracy: 34.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3011    0.9032    0.4516        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.1875    0.1765    0.1818        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2727    0.7500    0.4000        12
         qtx     0.7778    0.1556    0.2593        45
         zxx     0.7778    0.1795    0.2917        39

    accuracy                         0.3405       185
   macro avg     0.4211    0.3687    0.2919       185
weighted avg     0.5095    0.3405    0.2961       185

micro f-score: 0.34054054054054056

========== Train Epoch 40 ==========
Loss: 1.095	Accuracy: 30.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3600    0.2903    0.3214        31
         cwx     0.2500    0.0909    0.1333        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.7500    0.0667    0.1224        45
         zxx     0.2721    0.9487    0.4229        39

    accuracy                         0.3081       185
   macro avg     0.3801    0.2604    0.2290       185
weighted avg     0.4081    0.3081    0.2345       185

micro f-score: 0.3081081081081081

========== Train Epoch 41 ==========
Loss: 1.090	Accuracy: 51.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5652    0.4194    0.4815        31
         cwx     0.3913    0.4091    0.4000        22
         hdx     0.4444    0.4706    0.4571        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.2727    0.7500    0.4000        12
         qtx     0.8077    0.4667    0.5915        45
         zxx     0.5957    0.7179    0.6512        39

    accuracy                         0.5135       185
   macro avg     0.5063    0.5146    0.4847       185
weighted avg     0.5698    0.5135    0.5197       185

micro f-score: 0.5135135135135135

========== Train Epoch 42 ==========
Loss: 1.102	Accuracy: 52.43%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7273    0.2581    0.3810        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.2500    0.2353    0.2424        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.5263    0.8889    0.6612        45
         zxx     0.6042    0.7436    0.6667        39

    accuracy                         0.5243       185
   macro avg     0.5051    0.4583    0.4298       185
weighted avg     0.5364    0.5243    0.4790       185

micro f-score: 0.5243243243243243

========== Train Epoch 43 ==========
Loss: 1.052	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.3871    0.4898        31
         cwx     0.3902    0.7273    0.5079        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8000    0.7111    0.7529        45
         zxx     0.7250    0.7436    0.7342        39

    accuracy                         0.5730       185
   macro avg     0.5278    0.5405    0.4990       185
weighted avg     0.6003    0.5730    0.5615       185

micro f-score: 0.572972972972973

========== Train Epoch 44 ==========
Loss: 1.067	Accuracy: 45.41%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3889    0.4516    0.4179        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.4250    0.8718    0.5714        39

    accuracy                         0.4541       185
   macro avg     0.3759    0.3969    0.3615       185
weighted avg     0.4299    0.4541    0.4125       185

micro f-score: 0.4540540540540541

========== Train Epoch 45 ==========
Loss: 0.965	Accuracy: 52.97%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.8000    0.1818    0.2963        22
         hdx     0.3000    0.1765    0.2222        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.6441    0.8444    0.7308        45
         zxx     0.4667    0.8974    0.6140        39

    accuracy                         0.5297       185
   macro avg     0.5552    0.4574    0.4204       185
weighted avg     0.5776    0.5297    0.4731       185

micro f-score: 0.5297297297297298

========== Train Epoch 46 ==========
Loss: 0.990	Accuracy: 52.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4722    0.5484    0.5075        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.1875    0.1579    0.1714        19
         nqx     0.5000    0.6667    0.5714        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.5556    0.6410    0.5952        39

    accuracy                         0.5243       185
   macro avg     0.4673    0.4829    0.4704       185
weighted avg     0.5236    0.5243    0.5197       185

micro f-score: 0.5243243243243243

========== Train Epoch 47 ==========
Loss: 0.955	Accuracy: 54.59%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.5556    0.6452    0.5970        31
         cwx     0.5385    0.3182    0.4000        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.7143    0.5556    0.6250        45
         zxx     0.6531    0.8205    0.7273        39

    accuracy                         0.5459       185
   macro avg     0.4947    0.5015    0.4827       185
weighted avg     0.5537    0.5459    0.5370       185

micro f-score: 0.5459459459459459

========== Train Epoch 48 ==========
Loss: 0.978	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4286    0.2903    0.3462        31
         cwx     0.5455    0.5455    0.5455        22
         hdx     0.3846    0.2941    0.3333        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.2222    1.0000    0.3636        12
         qtx     0.8065    0.5556    0.6579        45
         zxx     0.5588    0.4872    0.5205        39

    accuracy                         0.4757       185
   macro avg     0.5066    0.4983    0.4544       185
weighted avg     0.5620    0.4757    0.4894       185

micro f-score: 0.4756756756756757

========== Train Epoch 49 ==========
Loss: 0.942	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6071    0.5484    0.5763        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3030    0.8333    0.4444        12
         qtx     0.6481    0.7778    0.7071        45
         zxx     0.6905    0.7436    0.7160        39

    accuracy                         0.5405       185
   macro avg     0.3707    0.4732    0.4027       185
weighted avg     0.4658    0.5405    0.4929       185

micro f-score: 0.5405405405405406

========== Train Epoch 50 ==========
Loss: 0.921	Accuracy: 53.51%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.3056    0.5000    0.3793        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.4375    0.5833    0.5000        12
         qtx     0.6944    0.5556    0.6173        45
         zxx     0.6727    0.9487    0.7872        39

    accuracy                         0.5351       185
   macro avg     0.4706    0.4785    0.4567       185
weighted avg     0.5415    0.5351    0.5190       185

micro f-score: 0.5351351351351351

========== Train Epoch 51 ==========
Loss: 1.000	Accuracy: 37.84%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3433    0.7419    0.4694        31
         cwx     0.3636    0.3636    0.3636        22
         hdx     1.0000    0.0588    0.1111        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.4737    0.7500    0.5806        12
         qtx     0.0000    0.0000    0.0000        45
         zxx     0.4127    0.6667    0.5098        39

    accuracy                         0.3784       185
   macro avg     0.4094    0.3913    0.3192       185
weighted avg     0.3384    0.3784    0.2978       185

micro f-score: 0.37837837837837834

========== Train Epoch 52 ==========
Loss: 0.902	Accuracy: 55.14%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7333    0.3548    0.4783        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2812    0.5294    0.3673        17
         mtx     0.1250    0.1579    0.1395        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.6667    0.8000    0.7273        45
         zxx     0.8485    0.7179    0.7778        39

    accuracy                         0.5514       185
   macro avg     0.5609    0.4794    0.4855       185
weighted avg     0.6133    0.5514    0.5568       185

micro f-score: 0.5513513513513514

========== Train Epoch 53 ==========
Loss: 0.847	Accuracy: 57.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.5161    0.5079        31
         cwx     0.5200    0.5909    0.5532        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3846    0.8333    0.5263        12
         qtx     0.9062    0.6444    0.7532        45
         zxx     0.5862    0.8718    0.7010        39

    accuracy                         0.5784       185
   macro avg     0.6087    0.5349    0.4896       185
weighted avg     0.6507    0.5784    0.5526       185

micro f-score: 0.5783783783783784

========== Train Epoch 54 ==========
Loss: 0.797	Accuracy: 47.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3400    0.5484    0.4198        31
         cwx     0.3182    0.6364    0.4242        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2917    0.5833    0.3889        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.8182    0.4615    0.5902        39

    accuracy                         0.4757       185
   macro avg     0.4080    0.4244    0.3809       185
weighted avg     0.5157    0.4757    0.4633       185

micro f-score: 0.4756756756756757

========== Train Epoch 55 ==========
Loss: 0.860	Accuracy: 49.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6154    0.2581    0.3636        31
         cwx     0.4545    0.4545    0.4545        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.2075    0.9167    0.3385        12
         qtx     0.6667    0.7556    0.7083        45
         zxx     0.9091    0.5128    0.6557        39

    accuracy                         0.4973       185
   macro avg     0.5005    0.4887    0.4343       185
weighted avg     0.5869    0.4973    0.4961       185

micro f-score: 0.4972972972972973

========== Train Epoch 56 ==========
Loss: 0.846	Accuracy: 52.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4545    0.4839    0.4687        31
         cwx     0.7500    0.1364    0.2308        22
         hdx     0.4000    0.1176    0.1818        17
         mtx     0.2500    0.0526    0.0870        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.4773    0.9333    0.6316        45
         zxx     0.7647    0.6667    0.7123        39

    accuracy                         0.5243       185
   macro avg     0.5096    0.4367    0.4091       185
weighted avg     0.5356    0.5243    0.4712       185

micro f-score: 0.5243243243243243

========== Train Epoch 57 ==========
Loss: 0.837	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3953    0.5484    0.4595        31
         cwx     0.3871    0.5455    0.4528        22
         hdx     0.4444    0.2353    0.3077        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.7500    0.8667    0.8041        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.5730       185
   macro avg     0.5346    0.5119    0.5010       185
weighted avg     0.5747    0.5730    0.5559       185

micro f-score: 0.572972972972973

========== Train Epoch 58 ==========
Loss: 0.738	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.3611    0.5909    0.4483        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.3636    0.4211    0.3902        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7826    0.8000    0.7912        45
         zxx     0.6071    0.8718    0.7158        39

    accuracy                         0.5514       185
   macro avg     0.5481    0.4928    0.4513       185
weighted avg     0.6191    0.5514    0.5061       185

micro f-score: 0.5513513513513514

========== Train Epoch 59 ==========
Loss: 0.740	Accuracy: 51.35%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.2903    0.3913        31
         cwx     0.3810    0.3636    0.3721        22
         hdx     0.2381    0.2941    0.2632        17
         mtx     0.4000    0.1053    0.1667        19
         nqx     0.4286    0.5000    0.4615        12
         qtx     0.5000    0.9111    0.6457        45
         zxx     0.8889    0.6154    0.7273        39

    accuracy                         0.5135       185
   macro avg     0.4909    0.4400    0.4325       185
weighted avg     0.5456    0.5135    0.4914       185

micro f-score: 0.5135135135135135

========== Train Epoch 60 ==========
Loss: 0.832	Accuracy: 54.59%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5200    0.4194    0.4643        31
         cwx     0.5217    0.5455    0.5333        22
         hdx     0.2857    0.4706    0.3556        17
         mtx     0.3462    0.4737    0.4000        19
         nqx     0.4706    0.6667    0.5517        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.7333    0.5641    0.6377        39

    accuracy                         0.5459       185
   macro avg     0.5262    0.5406    0.5227       185
weighted avg     0.5921    0.5459    0.5594       185

micro f-score: 0.5459459459459459

========== Train Epoch 61 ==========
Loss: 0.729	Accuracy: 65.41%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6552    0.6129    0.6333        31
         cwx     0.5909    0.5909    0.5909        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.6667    0.2105    0.3200        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.6724    0.8667    0.7573        45
         zxx     0.7674    0.8462    0.8049        39

    accuracy                         0.6541       185
   macro avg     0.6296    0.5910    0.5668       185
weighted avg     0.6585    0.6541    0.6264       185

micro f-score: 0.654054054054054

========== Train Epoch 62 ==========
Loss: 0.666	Accuracy: 60.00%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.5417    0.5909    0.5652        22
         hdx     0.3600    0.5294    0.4286        17
         mtx     0.5000    0.2632    0.3448        19
         nqx     0.5882    0.8333    0.6897        12
         qtx     0.8966    0.5778    0.7027        45
         zxx     0.7500    0.8462    0.7952        39

    accuracy                         0.6000       185
   macro avg     0.5790    0.5892    0.5677       185
weighted avg     0.6330    0.6000    0.6003       185

micro f-score: 0.6

========== Train Epoch 63 ==========
Loss: 0.624	Accuracy: 57.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5517    0.5161    0.5333        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.3636    0.2353    0.2857        17
         mtx     0.5000    0.2105    0.2963        19
         nqx     0.7000    0.5833    0.6364        12
         qtx     0.8649    0.7111    0.7805        45
         zxx     0.4744    0.9487    0.6325        39

    accuracy                         0.5730       185
   macro avg     0.5649    0.4968    0.5025       185
weighted avg     0.5925    0.5730    0.5525       185

micro f-score: 0.572972972972973

========== Train Epoch 64 ==========
Loss: 0.671	Accuracy: 60.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.4516    0.4746        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.2449    0.7059    0.3636        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.8750    0.5833    0.7000        12
         qtx     0.9211    0.7778    0.8434        45
         zxx     0.7333    0.8462    0.7857        39

    accuracy                         0.6000       185
   macro avg     0.5630    0.5456    0.5297       185
weighted avg     0.6210    0.6000    0.5934       185

micro f-score: 0.6

Finished training!!!

Min Loss = 0.624 in epoch 62;
Max Accuracy = 65.41% in epoch 60;
Total Cost 36 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPPB: 1-4                              [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-27                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-40                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-46                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-52                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-59                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-65                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-71                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-77                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-83                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-89                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-96                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-102                  [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-108                  [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



