dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 2.151	Accuracy: 18.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.2500    0.0455    0.0769        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1447    0.5789    0.2316        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2281    0.2889    0.2549        45
         zxx     0.1389    0.1282    0.1333        39

    accuracy                         0.1892       185
   macro avg     0.1683    0.1718    0.1328       185
weighted avg     0.1992    0.1892    0.1620       185

micro f-score: 0.18918918918918917

========== Train Epoch 2 ==========
Loss: 1.895	Accuracy: 25.41%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.2391    0.3548    0.2857        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.2222    0.3529    0.2727        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4138    0.2667    0.3243        45
         zxx     0.1948    0.3846    0.2586        39

    accuracy                         0.2541       185
   macro avg     0.2243    0.2167    0.1973       185
weighted avg     0.2536    0.2541    0.2310       185

micro f-score: 0.25405405405405407

========== Train Epoch 3 ==========
Loss: 1.828	Accuracy: 20.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3462    0.5806    0.4337        31
         cwx     0.1127    0.3636    0.1720        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.1053    0.1053    0.1053        19
         nqx     0.1667    0.2500    0.2000        12
         qtx     0.4545    0.1111    0.1786        45
         zxx     0.0909    0.0256    0.0400        39

    accuracy                         0.2054       185
   macro avg     0.2299    0.2136    0.1757       185
weighted avg     0.2534    0.2054    0.1780       185

micro f-score: 0.20540540540540544

========== Train Epoch 4 ==========
Loss: 1.808	Accuracy: 25.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2892    0.5333    0.3750        45
         zxx     0.2255    0.5897    0.3262        39

    accuracy                         0.2541       185
   macro avg     0.0735    0.1604    0.1002       185
weighted avg     0.1179    0.2541    0.1600       185

micro f-score: 0.25405405405405407

========== Train Epoch 5 ==========
Loss: 1.781	Accuracy: 25.95%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.2667    0.1290    0.1739        31
         cwx     0.1923    0.2273    0.2083        22
         hdx     0.3077    0.2353    0.2667        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.2000    0.2500    0.2222        12
         qtx     0.2174    0.1111    0.1471        45
         zxx     0.2973    0.5641    0.3894        39

    accuracy                         0.2595       185
   macro avg     0.2492    0.2543    0.2387       185
weighted avg     0.2514    0.2595    0.2377       185

micro f-score: 0.2594594594594595

========== Train Epoch 6 ==========
Loss: 1.735	Accuracy: 21.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7500    0.0968    0.1714        31
         cwx     0.1385    0.4091    0.2069        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1739    0.4211    0.2462        19
         nqx     0.0400    0.0833    0.0541        12
         qtx     0.4444    0.0889    0.1481        45
         zxx     0.3889    0.3590    0.3733        39

    accuracy                         0.2108       185
   macro avg     0.2765    0.2083    0.1714       185
weighted avg     0.3527    0.2108    0.1969       185

micro f-score: 0.21081081081081082

========== Train Epoch 7 ==========
Loss: 1.671	Accuracy: 15.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.1667    0.1364    0.1500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1185    0.8421    0.2078        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3478    0.1778    0.2353        45
         zxx     0.4000    0.0513    0.0909        39

    accuracy                         0.1568       185
   macro avg     0.1476    0.1725    0.0977       185
weighted avg     0.2009    0.1568    0.1156       185

micro f-score: 0.15675675675675677

========== Train Epoch 8 ==========
Loss: 1.672	Accuracy: 36.22%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.2258    0.3111        31
         cwx     0.4000    0.0909    0.1481        22
         hdx     0.1111    0.1176    0.1143        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.0833    0.1333        12
         qtx     0.5000    0.6000    0.5455        45
         zxx     0.3077    0.7179    0.4308        39

    accuracy                         0.3622       185
   macro avg     0.3074    0.2622    0.2404       185
weighted avg     0.3497    0.3622    0.3124       185

micro f-score: 0.3621621621621622

========== Train Epoch 9 ==========
Loss: 1.601	Accuracy: 30.81%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.1667    0.0323    0.0541        31
         cwx     0.2353    0.1818    0.2051        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4167    0.5556    0.4762        45
         zxx     0.2903    0.6923    0.4091        39

    accuracy                         0.3081       185
   macro avg     0.1584    0.2088    0.1635       185
weighted avg     0.2185    0.3081    0.2355       185

micro f-score: 0.3081081081081081

========== Train Epoch 10 ==========
Loss: 1.681	Accuracy: 22.16%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3000    0.2903    0.2951        31
         cwx     0.1667    0.1364    0.1500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.1739    0.6667    0.2759        12
         qtx     0.3333    0.0222    0.0417        45
         zxx     0.2209    0.4872    0.3040        39

    accuracy                         0.2216       185
   macro avg     0.2421    0.2365    0.1660       185
weighted avg     0.2604    0.2216    0.1692       185

micro f-score: 0.22162162162162163

========== Train Epoch 11 ==========
Loss: 1.567	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3889    0.2258    0.2857        31
         cwx     0.3333    0.1364    0.1935        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.2857    0.1053    0.1538        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.4697    0.6889    0.5586        45
         zxx     0.3671    0.7436    0.4915        39

    accuracy                         0.4054       185
   macro avg     0.4064    0.3036    0.2928       185
weighted avg     0.3997    0.4054    0.3527       185

micro f-score: 0.40540540540540543

========== Train Epoch 12 ==========
Loss: 1.544	Accuracy: 25.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4130    0.6129    0.4935        31
         cwx     0.1875    0.4091    0.2571        22
         hdx     0.0702    0.2353    0.1081        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4667    0.1556    0.2333        45
         zxx     0.7500    0.1538    0.2553        39

    accuracy                         0.2541       185
   macro avg     0.2982    0.2389    0.2122       185
weighted avg     0.3901    0.2541    0.2480       185

micro f-score: 0.25405405405405407

========== Train Epoch 13 ==========
Loss: 1.524	Accuracy: 41.08%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.2273    0.2273    0.2273        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.5610    0.5111    0.5349        45
         zxx     0.3676    0.6410    0.4673        39

    accuracy                         0.4108       185
   macro avg     0.3318    0.3836    0.3393       185
weighted avg     0.3781    0.4108    0.3781       185

micro f-score: 0.4108108108108109

========== Train Epoch 14 ==========
Loss: 1.455	Accuracy: 46.49%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.5250    0.6774    0.5915        31
         cwx     0.2500    0.2273    0.2381        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.2105    0.6667    0.3200        12
         qtx     0.5161    0.7111    0.5981        45
         zxx     0.7727    0.4359    0.5574        39

    accuracy                         0.4649       185
   macro avg     0.4678    0.4109    0.3683       185
weighted avg     0.5225    0.4649    0.4392       185

micro f-score: 0.4648648648648649

========== Train Epoch 15 ==========
Loss: 1.420	Accuracy: 37.84%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.2692    0.3182    0.2917        22
         hdx     0.1392    0.6471    0.2292        17
         mtx     0.1875    0.1579    0.1714        19
         nqx     1.0000    0.1667    0.2857        12
         qtx     0.7097    0.4889    0.5789        45
         zxx     0.8400    0.5385    0.6562        39

    accuracy                         0.3784       185
   macro avg     0.5446    0.3495    0.3471       185
weighted avg     0.5904    0.3784    0.4073       185

micro f-score: 0.37837837837837834

========== Train Epoch 16 ==========
Loss: 1.412	Accuracy: 45.95%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6087    0.4516    0.5185        31
         cwx     0.2083    0.4545    0.2857        22
         hdx     0.2222    0.1176    0.1538        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.3333    0.3333    0.3333        12
         qtx     0.5091    0.6222    0.5600        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.4595       185
   macro avg     0.4434    0.3855    0.3771       185
weighted avg     0.4963    0.4595    0.4488       185

micro f-score: 0.4594594594594595

========== Train Epoch 17 ==========
Loss: 1.335	Accuracy: 40.54%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3571    0.6452    0.4598        31
         cwx     0.3415    0.6364    0.4444        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1250    0.1579    0.1395        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.6957    0.3556    0.4706        45
         zxx     0.7368    0.3590    0.4828        39

    accuracy                         0.4054       185
   macro avg     0.3767    0.4029    0.3546       185
weighted avg     0.4625    0.4054    0.3919       185

micro f-score: 0.40540540540540543

========== Train Epoch 18 ==========
Loss: 1.408	Accuracy: 41.08%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.2800    0.3182    0.2979        22
         hdx     0.1818    0.2353    0.2051        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.3333    0.3636        12
         qtx     0.4306    0.6889    0.5299        45
         zxx     0.5682    0.6410    0.6024        39

    accuracy                         0.4108       185
   macro avg     0.3551    0.3397    0.3222       185
weighted avg     0.4052    0.4108    0.3767       185

micro f-score: 0.4108108108108109

========== Train Epoch 19 ==========
Loss: 1.351	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0645    0.1212        31
         cwx     0.2903    0.4091    0.3396        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.1923    0.4167    0.2632        12
         qtx     0.4630    0.5556    0.5051        45
         zxx     0.5085    0.7692    0.6122        39

    accuracy                         0.4054       185
   macro avg     0.3945    0.3465    0.2988       185
weighted avg     0.4660    0.4054    0.3554       185

micro f-score: 0.40540540540540543

========== Train Epoch 20 ==========
Loss: 1.244	Accuracy: 29.73%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3571    0.1613    0.2222        31
         cwx     0.1429    0.1364    0.1395        22
         hdx     0.1250    0.1176    0.1212        17
         mtx     0.6000    0.1579    0.2500        19
         nqx     0.5000    0.0833    0.1429        12
         qtx     0.3824    0.5778    0.4602        45
         zxx     0.2542    0.3846    0.3061        39

    accuracy                         0.2973       185
   macro avg     0.3374    0.2313    0.2346       185
weighted avg     0.3290    0.2973    0.2764       185

micro f-score: 0.2972972972972973

========== Train Epoch 21 ==========
Loss: 1.422	Accuracy: 36.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.2778    0.2273    0.2500        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.5349    0.5111    0.5227        45
         zxx     0.3153    0.8974    0.4667        39

    accuracy                         0.3622       185
   macro avg     0.2802    0.2740    0.2265       185
weighted avg     0.3350    0.3622    0.2839       185

micro f-score: 0.3621621621621622

========== Train Epoch 22 ==========
Loss: 1.282	Accuracy: 50.81%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7222    0.4194    0.5306        31
         cwx     0.3182    0.6364    0.4242        22
         hdx     0.3333    0.3529    0.3429        17
         mtx     0.3529    0.3158    0.3333        19
         nqx     0.7500    0.2500    0.3750        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.5167    0.7949    0.6263        39

    accuracy                         0.5081       185
   macro avg     0.5526    0.4623    0.4630       185
weighted avg     0.5961    0.5081    0.5095       185

micro f-score: 0.5081081081081081

========== Train Epoch 23 ==========
Loss: 1.215	Accuracy: 37.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.2000    0.2727    0.2308        22
         hdx     0.2500    0.1765    0.2069        17
         mtx     0.1667    0.1579    0.1622        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.4308    0.6222    0.5091        45
         zxx     0.6111    0.5641    0.5867        39

    accuracy                         0.3730       185
   macro avg     0.2846    0.2885    0.2807       185
weighted avg     0.3533    0.3730    0.3557       185

micro f-score: 0.37297297297297294

========== Train Epoch 24 ==========
Loss: 1.172	Accuracy: 40.54%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.3019    0.5161    0.3810        31
         cwx     0.2979    0.6364    0.4058        22
         hdx     0.1250    0.0588    0.0800        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.6774    0.4667    0.5526        45
         zxx     0.5556    0.3846    0.4545        39

    accuracy                         0.4054       185
   macro avg     0.3933    0.3811    0.3634       185
weighted avg     0.4404    0.4054    0.3987       185

micro f-score: 0.40540540540540543

========== Train Epoch 25 ==========
Loss: 1.088	Accuracy: 41.08%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.2581    0.3404        31
         cwx     0.3125    0.2273    0.2632        22
         hdx     0.2105    0.4706    0.2909        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.2857    0.6667    0.4000        12
         qtx     0.7826    0.4000    0.5294        45
         zxx     0.5000    0.6923    0.5806        39

    accuracy                         0.4108       185
   macro avg     0.3988    0.4029    0.3632       185
weighted avg     0.4751    0.4108    0.4064       185

micro f-score: 0.4108108108108109

========== Train Epoch 26 ==========
Loss: 1.087	Accuracy: 31.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2222    0.0645    0.1000        31
         cwx     0.2000    0.9091    0.3279        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1923    0.2632    0.2222        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.8000    0.3556    0.4923        45
         zxx     0.9167    0.2821    0.4314        39

    accuracy                         0.3189       185
   macro avg     0.3840    0.3273    0.2798       185
weighted avg     0.4918    0.3189    0.3142       185

micro f-score: 0.31891891891891894

========== Train Epoch 27 ==========
Loss: 1.065	Accuracy: 37.84%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4286    0.3871    0.4068        31
         cwx     0.3000    0.1364    0.1875        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1875    0.4737    0.2687        19
         nqx     0.1579    0.5000    0.2400        12
         qtx     0.6579    0.5556    0.6024        45
         zxx     0.6522    0.3846    0.4839        39

    accuracy                         0.3784       185
   macro avg     0.3406    0.3482    0.3127       185
weighted avg     0.4345    0.3784    0.3822       185

micro f-score: 0.37837837837837834

========== Train Epoch 28 ==========
Loss: 0.975	Accuracy: 49.19%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4167    0.4839    0.4478        31
         cwx     0.4074    0.5000    0.4490        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.2000    0.2632    0.2273        19
         nqx     0.5000    0.5833    0.5385        12
         qtx     0.7931    0.5111    0.6216        45
         zxx     0.6875    0.5641    0.6197        39

    accuracy                         0.4919       185
   macro avg     0.4812    0.4823    0.4734       185
weighted avg     0.5425    0.4919    0.5062       185

micro f-score: 0.4918918918918919

========== Train Epoch 29 ==========
Loss: 0.895	Accuracy: 47.57%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.8571    0.1935    0.3158        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.2069    0.3529    0.2609        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.3889    0.5833    0.4667        12
         qtx     0.8148    0.4889    0.6111        45
         zxx     0.5424    0.8205    0.6531        39

    accuracy                         0.4757       185
   macro avg     0.4815    0.4479    0.4163       185
weighted avg     0.5645    0.4757    0.4636       185

micro f-score: 0.4756756756756757

========== Train Epoch 30 ==========
Loss: 0.885	Accuracy: 52.43%	Cost 30s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     0.3243    0.5455    0.4068        22
         hdx     0.3478    0.4706    0.4000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3913    0.7500    0.5143        12
         qtx     0.6667    0.6667    0.6667        45
         zxx     0.6977    0.7692    0.7317        39

    accuracy                         0.5243       185
   macro avg     0.4421    0.4943    0.4416       185
weighted avg     0.5169    0.5243    0.4973       185

micro f-score: 0.5243243243243243

========== Train Epoch 31 ==========
Loss: 0.961	Accuracy: 38.92%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4194    0.4561        31
         cwx     0.5833    0.3182    0.4118        22
         hdx     0.1212    0.2353    0.1600        17
         mtx     0.2581    0.4211    0.3200        19
         nqx     0.1875    0.2500    0.2143        12
         qtx     0.7000    0.3111    0.4308        45
         zxx     0.4894    0.5897    0.5349        39

    accuracy                         0.3892       185
   macro avg     0.4056    0.3635    0.3611       185
weighted avg     0.4764    0.3892    0.4044       185

micro f-score: 0.3891891891891892

========== Train Epoch 32 ==========
Loss: 0.825	Accuracy: 56.22%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.7083    0.5484    0.6182        31
         cwx     0.3542    0.7727    0.4857        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6122    0.6667    0.6383        45
         zxx     0.7381    0.7949    0.7654        39

    accuracy                         0.5622       185
   macro avg     0.5998    0.4898    0.4632       185
weighted avg     0.6306    0.5622    0.5362       185

micro f-score: 0.5621621621621622

========== Train Epoch 33 ==========
Loss: 0.776	Accuracy: 52.97%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5769    0.4839    0.5263        31
         cwx     0.3214    0.8182    0.4615        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7812    0.5556    0.6494        45
         zxx     0.8846    0.5897    0.7077        39

    accuracy                         0.5297       185
   macro avg     0.5424    0.5126    0.5042       185
weighted avg     0.6104    0.5297    0.5454       185

micro f-score: 0.5297297297297298

========== Train Epoch 34 ==========
Loss: 0.833	Accuracy: 45.95%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.3889    0.6364    0.4828        22
         hdx     0.2857    0.3529    0.3158        17
         mtx     0.1200    0.1579    0.1364        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.5741    0.6889    0.6263        45
         zxx     0.6667    0.4103    0.5079        39

    accuracy                         0.4595       185
   macro avg     0.4605    0.4557    0.4353       185
weighted avg     0.4981    0.4595    0.4526       185

micro f-score: 0.4594594594594595

========== Train Epoch 35 ==========
Loss: 0.625	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.4643    0.4194    0.4407        31
         cwx     0.6429    0.4091    0.5000        22
         hdx     0.3333    0.2941    0.3125        17
         mtx     0.4118    0.3684    0.3889        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.8000    0.5333    0.6400        45
         zxx     0.5152    0.8718    0.6476        39

    accuracy                         0.5514       185
   macro avg     0.5477    0.5328    0.5243       185
weighted avg     0.5736    0.5514    0.5422       185

micro f-score: 0.5513513513513514

========== Train Epoch 36 ==========
Loss: 0.578	Accuracy: 38.92%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5455    0.1935    0.2857        31
         cwx     0.4375    0.3182    0.3684        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.1512    0.6842    0.2476        19
         nqx     0.5000    0.2500    0.3333        12
         qtx     0.9444    0.3778    0.5397        45
         zxx     0.6111    0.5641    0.5867        39

    accuracy                         0.3892       185
   macro avg     0.5033    0.3747    0.3768       185
weighted avg     0.5806    0.3892    0.4190       185

micro f-score: 0.3891891891891892

========== Train Epoch 37 ==========
Loss: 0.510	Accuracy: 45.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3333    0.0968    0.1500        31
         cwx     1.0000    0.1818    0.3077        22
         hdx     0.2222    0.3529    0.2727        17
         mtx     0.2105    0.4211    0.2807        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.5429    0.8444    0.6609        45
         zxx     0.6786    0.4872    0.5672        39

    accuracy                         0.4541       185
   macro avg     0.5220    0.4120    0.4015       185
weighted avg     0.5352    0.4541    0.4330       185

micro f-score: 0.4540540540540541

========== Train Epoch 38 ==========
Loss: 0.509	Accuracy: 47.57%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.3462    0.4091    0.3750        22
         hdx     0.2800    0.4118    0.3333        17
         mtx     0.3333    0.2632    0.2941        19
         nqx     0.4667    0.5833    0.5185        12
         qtx     0.8261    0.4222    0.5588        45
         zxx     0.4776    0.8205    0.6038        39

    accuracy                         0.4757       185
   macro avg     0.4818    0.4572    0.4405       185
weighted avg     0.5407    0.4757    0.4693       185

micro f-score: 0.4756756756756757

========== Train Epoch 39 ==========
Loss: 0.514	Accuracy: 51.89%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     0.4419    0.8636    0.5846        22
         hdx     0.4000    0.4706    0.4324        17
         mtx     0.2222    0.2105    0.2162        19
         nqx     0.3810    0.6667    0.4848        12
         qtx     0.7353    0.5556    0.6329        45
         zxx     0.7143    0.7692    0.7407        39

    accuracy                         0.5189       185
   macro avg     0.4543    0.5144    0.4567       185
weighted avg     0.5141    0.5189    0.4907       185

micro f-score: 0.518918918918919

========== Train Epoch 40 ==========
Loss: 0.403	Accuracy: 53.51%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5500    0.3548    0.4314        31
         cwx     0.7500    0.2727    0.4000        22
         hdx     0.2857    0.5882    0.3846        17
         mtx     0.1429    0.1053    0.1212        19
         nqx     0.4545    0.8333    0.5882        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.6170    0.7436    0.6744        39

    accuracy                         0.5351       185
   macro avg     0.5136    0.5124    0.4768       185
weighted avg     0.5752    0.5351    0.5275       185

micro f-score: 0.5351351351351351

========== Train Epoch 41 ==========
Loss: 0.358	Accuracy: 50.27%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.4359    0.7727    0.5574        22
         hdx     0.2222    0.4706    0.3019        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4348    0.8333    0.5714        12
         qtx     0.7021    0.7333    0.7174        45
         zxx     0.9474    0.4615    0.6207        39

    accuracy                         0.5027       185
   macro avg     0.4892    0.5054    0.4494       185
weighted avg     0.5734    0.5027    0.4910       185

micro f-score: 0.5027027027027027

========== Train Epoch 42 ==========
Loss: 0.397	Accuracy: 53.51%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5333    0.5161    0.5246        31
         cwx     0.4062    0.5909    0.4815        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.5667    0.8718    0.6869        39

    accuracy                         0.5351       185
   macro avg     0.4990    0.4946    0.4788       185
weighted avg     0.5608    0.5351    0.5225       185

micro f-score: 0.5351351351351351

========== Train Epoch 43 ==========
Loss: 0.413	Accuracy: 51.35%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6000    0.3871    0.4706        31
         cwx     0.6000    0.4091    0.4865        22
         hdx     0.2571    0.5294    0.3462        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.6154    0.6667    0.6400        12
         qtx     0.8000    0.4444    0.5714        45
         zxx     0.5000    0.8205    0.6214        39

    accuracy                         0.5135       185
   macro avg     0.5367    0.5029    0.4926       185
weighted avg     0.5749    0.5135    0.5121       185

micro f-score: 0.5135135135135135

========== Train Epoch 44 ==========
Loss: 0.297	Accuracy: 61.62%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5600    0.4516    0.5000        31
         cwx     0.5938    0.8636    0.7037        22
         hdx     0.4615    0.3529    0.4000        17
         mtx     0.3333    0.1579    0.2143        19
         nqx     0.4762    0.8333    0.6061        12
         qtx     0.7750    0.6889    0.7294        45
         zxx     0.6889    0.7949    0.7381        39

    accuracy                         0.6162       185
   macro avg     0.5555    0.5919    0.5559       185
weighted avg     0.6057    0.6162    0.5986       185

micro f-score: 0.6162162162162163

========== Train Epoch 45 ==========
Loss: 0.198	Accuracy: 54.59%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.4595    0.5484    0.5000        31
         cwx     0.6842    0.5909    0.6341        22
         hdx     0.3810    0.4706    0.4211        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.3548    0.9167    0.5116        12
         qtx     0.7436    0.6444    0.6905        45
         zxx     0.7600    0.4872    0.5938        39

    accuracy                         0.5459       185
   macro avg     0.5272    0.5527    0.5144       185
weighted avg     0.5891    0.5459    0.5499       185

micro f-score: 0.5459459459459459

========== Train Epoch 46 ==========
Loss: 0.177	Accuracy: 55.68%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.5263    0.3226    0.4000        31
         cwx     0.5294    0.4091    0.4615        22
         hdx     0.3125    0.5882    0.4082        17
         mtx     0.4000    0.2105    0.2759        19
         nqx     0.6923    0.7500    0.7200        12
         qtx     0.8182    0.6000    0.6923        45
         zxx     0.5574    0.8718    0.6800        39

    accuracy                         0.5568       185
   macro avg     0.5480    0.5360    0.5197       185
weighted avg     0.5824    0.5568    0.5462       185

micro f-score: 0.5567567567567567

========== Train Epoch 47 ==========
Loss: 0.218	Accuracy: 59.46%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7500    0.1935    0.3077        31
         cwx     0.4750    0.8636    0.6129        22
         hdx     0.3750    0.5294    0.4390        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7955    0.7778    0.7865        45
         zxx     0.6829    0.7179    0.7000        39

    accuracy                         0.5946       185
   macro avg     0.5677    0.5775    0.5353       185
weighted avg     0.6248    0.5946    0.5719       185

micro f-score: 0.5945945945945946

========== Train Epoch 48 ==========
Loss: 0.175	Accuracy: 61.62%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5484    0.5484    0.5484        31
         cwx     0.7000    0.6364    0.6667        22
         hdx     0.4400    0.6471    0.5238        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.6364    0.5833    0.6087        12
         qtx     0.7838    0.6444    0.7073        45
         zxx     0.7209    0.7949    0.7561        39

    accuracy                         0.6162       185
   macro avg     0.5867    0.5882    0.5830       185
weighted avg     0.6280    0.6162    0.6180       185

micro f-score: 0.6162162162162163

========== Train Epoch 49 ==========
Loss: 0.177	Accuracy: 50.27%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5000    0.4839    0.4918        31
         cwx     0.3276    0.8636    0.4750        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.1818    0.1053    0.1333        19
         nqx     0.4231    0.9167    0.5789        12
         qtx     0.8750    0.4667    0.6087        45
         zxx     0.7059    0.6154    0.6575        39

    accuracy                         0.5027       185
   macro avg     0.5019    0.5015    0.4358       185
weighted avg     0.5764    0.5027    0.4865       185

micro f-score: 0.5027027027027027

========== Train Epoch 50 ==========
Loss: 0.263	Accuracy: 57.84%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6667    0.2581    0.3721        31
         cwx     0.6000    0.5455    0.5714        22
         hdx     0.3704    0.5882    0.4545        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.4286    0.7500    0.5455        12
         qtx     0.5833    0.7778    0.6667        45
         zxx     0.7895    0.7692    0.7792        39

    accuracy                         0.5784       185
   macro avg     0.5524    0.5495    0.5172       185
weighted avg     0.5972    0.5784    0.5576       185

micro f-score: 0.5783783783783784

========== Train Epoch 51 ==========
Loss: 0.271	Accuracy: 45.41%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.3793    0.3548    0.3667        31
         cwx     0.3793    0.5000    0.4314        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.8947    0.3778    0.5312        45
         zxx     0.4861    0.8974    0.6306        39

    accuracy                         0.4541       185
   macro avg     0.4187    0.4076    0.3825       185
weighted avg     0.4932    0.4541    0.4307       185

micro f-score: 0.4540540540540541

========== Train Epoch 52 ==========
Loss: 0.213	Accuracy: 64.32%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5833    0.4516    0.5091        31
         cwx     0.5128    0.9091    0.6557        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.4667    0.3684    0.4118        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.7857    0.7333    0.7586        45
         zxx     0.7778    0.7179    0.7467        39

    accuracy                         0.6432       185
   macro avg     0.6149    0.6287    0.6083       185
weighted avg     0.6548    0.6432    0.6382       185

micro f-score: 0.6432432432432432

========== Train Epoch 53 ==========
Loss: 0.184	Accuracy: 53.51%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.7500    0.2903    0.4186        31
         cwx     0.6087    0.6364    0.6222        22
         hdx     0.3333    0.5882    0.4255        17
         mtx     0.1714    0.3158    0.2222        19
         nqx     0.5263    0.8333    0.6452        12
         qtx     0.7778    0.6222    0.6914        45
         zxx     0.7333    0.5641    0.6377        39

    accuracy                         0.5351       185
   macro avg     0.5573    0.5501    0.5233       185
weighted avg     0.6242    0.5351    0.5505       185

micro f-score: 0.5351351351351351

========== Train Epoch 54 ==========
Loss: 0.136	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6190    0.4194    0.5000        31
         cwx     0.6316    0.5455    0.5854        22
         hdx     0.3077    0.7059    0.4286        17
         mtx     0.3125    0.2632    0.2857        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.7000    0.7179    0.7089        39

    accuracy                         0.5676       185
   macro avg     0.5537    0.5598    0.5394       185
weighted avg     0.6090    0.5676    0.5742       185

micro f-score: 0.5675675675675675

========== Train Epoch 55 ==========
Loss: 0.192	Accuracy: 55.14%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5312    0.5484    0.5397        31
         cwx     0.6667    0.3636    0.4706        22
         hdx     0.4118    0.4118    0.4118        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.3846    0.8333    0.5263        12
         qtx     0.6735    0.7333    0.7021        45
         zxx     0.6410    0.6410    0.6410        39

    accuracy                         0.5514       185
   macro avg     0.5013    0.5195    0.4899       185
weighted avg     0.5506    0.5514    0.5385       185

micro f-score: 0.5513513513513514

========== Train Epoch 56 ==========
Loss: 0.228	Accuracy: 52.97%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.5909    0.4194    0.4906        31
         cwx     0.6667    0.1818    0.2857        22
         hdx     0.3462    0.5294    0.4186        17
         mtx     0.2222    0.4211    0.2909        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.8000    0.6222    0.7000        45
         zxx     0.7105    0.6923    0.7013        39

    accuracy                         0.5297       185
   macro avg     0.5351    0.5166    0.4881       185
weighted avg     0.6038    0.5297    0.5370       185

micro f-score: 0.5297297297297298

========== Train Epoch 57 ==========
Loss: 0.148	Accuracy: 54.05%	Cost 29s
              precision    recall  f1-score   support

         bzx     1.0000    0.0323    0.0625        31
         cwx     0.4571    0.7273    0.5614        22
         hdx     0.3636    0.4706    0.4103        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.4000    0.8333    0.5405        12
         qtx     0.8485    0.6222    0.7179        45
         zxx     0.5818    0.8205    0.6809        39

    accuracy                         0.5405       185
   macro avg     0.5726    0.5385    0.4681       185
weighted avg     0.6470    0.5405    0.4993       185

micro f-score: 0.5405405405405406

========== Train Epoch 58 ==========
Loss: 0.127	Accuracy: 56.76%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6842    0.4194    0.5200        31
         cwx     0.5556    0.4545    0.5000        22
         hdx     0.6154    0.4706    0.5333        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.2703    0.8333    0.4082        12
         qtx     0.7000    0.7778    0.7368        45
         zxx     0.7222    0.6667    0.6933        39

    accuracy                         0.5676       185
   macro avg     0.5425    0.5400    0.5122       185
weighted avg     0.6030    0.5676    0.5674       185

micro f-score: 0.5675675675675675

========== Train Epoch 59 ==========
Loss: 0.102	Accuracy: 57.30%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.3864    0.7727    0.5152        22
         hdx     0.3571    0.5882    0.4444        17
         mtx     0.3000    0.1579    0.2069        19
         nqx     0.5455    0.5000    0.5217        12
         qtx     0.8378    0.6889    0.7561        45
         zxx     0.7632    0.7436    0.7532        39

    accuracy                         0.5730       185
   macro avg     0.5397    0.5391    0.5163       185
weighted avg     0.6082    0.5730    0.5697       185

micro f-score: 0.572972972972973

========== Train Epoch 60 ==========
Loss: 0.115	Accuracy: 56.76%	Cost 28s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.5556    0.6818    0.6122        22
         hdx     0.2917    0.4118    0.3415        17
         mtx     0.3571    0.2632    0.3030        19
         nqx     0.6667    0.8333    0.7407        12
         qtx     0.6739    0.6889    0.6813        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5676       185
   macro avg     0.5474    0.5525    0.5251       185
weighted avg     0.5791    0.5676    0.5462       185

micro f-score: 0.5675675675675675

========== Train Epoch 61 ==========
Loss: 0.102	Accuracy: 59.46%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6316    0.3871    0.4800        31
         cwx     0.5806    0.8182    0.6792        22
         hdx     0.5000    0.4118    0.4516        17
         mtx     0.1667    0.1053    0.1290        19
         nqx     0.3448    0.8333    0.4878        12
         qtx     0.7391    0.7556    0.7473        45
         zxx     0.7941    0.6923    0.7397        39

    accuracy                         0.5946       185
   macro avg     0.5367    0.5719    0.5307       185
weighted avg     0.6075    0.5946    0.5853       185

micro f-score: 0.5945945945945946

========== Train Epoch 62 ==========
Loss: 0.077	Accuracy: 66.49%	Cost 29s
              precision    recall  f1-score   support

         bzx     0.6000    0.5806    0.5902        31
         cwx     0.5714    0.7273    0.6400        22
         hdx     0.4643    0.7647    0.5778        17
         mtx     0.3333    0.0526    0.0909        19
         nqx     0.5625    0.7500    0.6429        12
         qtx     0.8333    0.7778    0.8046        45
         zxx     0.8158    0.7949    0.8052        39

    accuracy                         0.6649       185
   macro avg     0.5972    0.6354    0.5931       185
weighted avg     0.6566    0.6649    0.6446       185

micro f-score: 0.6648648648648648

========== Train Epoch 63 ==========
Loss: 0.052	Accuracy: 61.08%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.6250    0.4839    0.5455        31
         cwx     0.6000    0.6818    0.6383        22
         hdx     0.4167    0.5882    0.4878        17
         mtx     0.3077    0.2105    0.2500        19
         nqx     0.5294    0.7500    0.6207        12
         qtx     0.8333    0.6667    0.7407        45
         zxx     0.6522    0.7692    0.7059        39

    accuracy                         0.6108       185
   macro avg     0.5663    0.5929    0.5698       185
weighted avg     0.6205    0.6108    0.6071       185

micro f-score: 0.6108108108108108

========== Train Epoch 64 ==========
Loss: 0.065	Accuracy: 57.30%	Cost 27s
              precision    recall  f1-score   support

         bzx     0.7857    0.3548    0.4889        31
         cwx     0.5882    0.4545    0.5128        22
         hdx     0.2553    0.7059    0.3750        17
         mtx     0.2727    0.1579    0.2000        19
         nqx     0.5714    0.6667    0.6154        12
         qtx     0.8788    0.6444    0.7436        45
         zxx     0.6735    0.8462    0.7500        39

    accuracy                         0.5730       185
   macro avg     0.5751    0.5472    0.5265       185
weighted avg     0.6459    0.5730    0.5768       185

micro f-score: 0.572972972972973

Finished training!!!

Min Loss = 0.052 in epoch 62;
Max Accuracy = 66.49% in epoch 61;
Total Cost 30 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─MaxPool2d: 1-4                         [-1, 64, 80, 80]          --
├─Sequential: 1-5                        [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-1                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-1                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-2             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-3                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-4                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-5             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-6                    [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-2                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-7                  [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-8             [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-9                    [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-10                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-12                   [-1, 64, 80, 80]          --
|    └─BasicBlock: 2-3                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-13                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-15                   [-1, 64, 80, 80]          --
|    |    └─Conv2d: 3-16                 [-1, 64, 80, 80]          36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 80, 80]          128
|    |    └─ReLU: 3-18                   [-1, 64, 80, 80]          --
├─Sequential: 1-6                        [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-4                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-19                 [-1, 128, 40, 40]         73,728
|    |    └─BatchNorm2d: 3-20            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-21                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-22                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-23            [-1, 128, 40, 40]         256
|    |    └─Sequential: 3-24             [-1, 128, 40, 40]         8,448
|    |    └─ReLU: 3-25                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-5                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-26                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-27            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-28                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-29                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-30            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-31                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-6                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-32                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-33            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-34                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-37                   [-1, 128, 40, 40]         --
|    └─BasicBlock: 2-7                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-40                   [-1, 128, 40, 40]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 40, 40]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 40, 40]         256
|    |    └─ReLU: 3-43                   [-1, 128, 40, 40]         --
├─Sequential: 1-7                        [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-8                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-44                 [-1, 256, 20, 20]         294,912
|    |    └─BatchNorm2d: 3-45            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-46                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-47                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-48            [-1, 256, 20, 20]         512
|    |    └─Sequential: 3-49             [-1, 256, 20, 20]         33,280
|    |    └─ReLU: 3-50                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-9                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-51                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-52            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-53                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-54                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-55            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-56                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-10                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-57                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-58            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-59                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-62                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-11                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-65                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-68                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-12                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-71                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-74                   [-1, 256, 20, 20]         --
|    └─BasicBlock: 2-13                  [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-77                   [-1, 256, 20, 20]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 20, 20]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 20, 20]         512
|    |    └─ReLU: 3-80                   [-1, 256, 20, 20]         --
├─Sequential: 1-8                        [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-14                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-81                 [-1, 512, 10, 10]         1,179,648
|    |    └─BatchNorm2d: 3-82            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-83                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-84                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-85            [-1, 512, 10, 10]         1,024
|    |    └─Sequential: 3-86             [-1, 512, 10, 10]         132,096
|    |    └─ReLU: 3-87                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-15                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-88                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-89            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-90                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-91                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-92            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-93                   [-1, 512, 10, 10]         --
|    └─BasicBlock: 2-16                  [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-94                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-95            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-96                   [-1, 512, 10, 10]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 10, 10]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 10, 10]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 10, 10]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,288,263
Trainable params: 21,288,263
Non-trainable params: 0
Total mult-adds (G): 7.52
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 116.41
Params size (MB): 81.21
Estimated Total Size (MB): 198.79
==========================================================================================



