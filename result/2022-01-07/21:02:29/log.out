dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: sppb_resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 2.066	Accuracy: 24.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.0323    0.0606        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.2457    0.9556    0.3909        45
         zxx     0.5000    0.0513    0.0930        39

    accuracy                         0.2486       185
   macro avg     0.1780    0.1484    0.0778       185
weighted avg     0.2490    0.2486    0.1249       185

micro f-score: 0.24864864864864866

========== Train Epoch 2 ==========
Loss: 1.863	Accuracy: 28.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2000    0.5000    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.4000    0.1667    0.2353        12
         qtx     0.3774    0.4444    0.4082        45
         zxx     0.2639    0.4872    0.3423        39

    accuracy                         0.2811       185
   macro avg     0.1773    0.2283    0.1816       185
weighted avg     0.1972    0.2811    0.2207       185

micro f-score: 0.2810810810810811

========== Train Epoch 3 ==========
Loss: 1.811	Accuracy: 30.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2000    0.0645    0.0976        31
         cwx     0.1915    0.4091    0.2609        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3797    0.6667    0.4839        45
         zxx     0.3265    0.4103    0.3636        39

    accuracy                         0.3081       185
   macro avg     0.1568    0.2215    0.1723       185
weighted avg     0.2175    0.3081    0.2417       185

micro f-score: 0.3081081081081081

========== Train Epoch 4 ==========
Loss: 1.774	Accuracy: 28.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2105    0.3636    0.2667        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1429    0.0526    0.0769        19
         nqx     0.0000    0.0000    0.0000        12
         qtx     0.3382    0.5111    0.4071        45
         zxx     0.3088    0.5385    0.3925        39

    accuracy                         0.2865       185
   macro avg     0.1429    0.2094    0.1633       185
weighted avg     0.1871    0.2865    0.2214       185

micro f-score: 0.2864864864864865

========== Train Epoch 5 ==========
Loss: 1.704	Accuracy: 28.11%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.2857    0.1935    0.2308        31
         cwx     0.1522    0.3182    0.2059        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.2105    0.2051        19
         nqx     0.1429    0.1667    0.1538        12
         qtx     0.3913    0.2000    0.2647        45
         zxx     0.3934    0.6154    0.4800        39

    accuracy                         0.2811       185
   macro avg     0.2236    0.2435    0.2200       185
weighted avg     0.2739    0.2811    0.2598       185

micro f-score: 0.2810810810810811

========== Train Epoch 6 ==========
Loss: 1.701	Accuracy: 28.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2000    0.0323    0.0556        31
         cwx     0.2500    0.0909    0.1333        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1452    0.4737    0.2222        19
         nqx     0.1905    0.3333    0.2424        12
         qtx     0.4194    0.5778    0.4860        45
         zxx     0.4074    0.2821    0.3333        39

    accuracy                         0.2865       185
   macro avg     0.2303    0.2557    0.2104       185
weighted avg     0.2784    0.2865    0.2522       185

micro f-score: 0.2864864864864865

========== Train Epoch 7 ==========
Loss: 1.652	Accuracy: 34.05%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3214    0.2903    0.3051        31
         cwx     0.1667    0.2727    0.2069        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.1250    0.0526    0.0741        19
         nqx     0.1250    0.0833    0.1000        12
         qtx     0.5000    0.3778    0.4304        45
         zxx     0.4085    0.7436    0.5273        39

    accuracy                         0.3405       185
   macro avg     0.2352    0.2601    0.2348       185
weighted avg     0.3024    0.3405    0.3057       185

micro f-score: 0.34054054054054056

========== Train Epoch 8 ==========
Loss: 1.653	Accuracy: 33.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.0968    0.1667        31
         cwx     0.1690    0.5455    0.2581        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2500    0.1579    0.1935        19
         nqx     0.3333    0.2500    0.2857        12
         qtx     0.4750    0.4222    0.4471        45
         zxx     0.4583    0.5641    0.5057        39

    accuracy                         0.3351       185
   macro avg     0.3265    0.2909    0.2653       185
weighted avg     0.3801    0.3351    0.3124       185

micro f-score: 0.33513513513513515

========== Train Epoch 9 ==========
Loss: 1.608	Accuracy: 31.35%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1667    0.2903    0.2118        31
         cwx     0.1154    0.1364    0.1250        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1176    0.1667    0.1379        12
         qtx     0.5278    0.4222    0.4691        45
         zxx     0.4902    0.6410    0.5556        39

    accuracy                         0.3135       185
   macro avg     0.2025    0.2367    0.2142       185
weighted avg     0.2810    0.3135    0.2905       185

micro f-score: 0.31351351351351353

========== Train Epoch 10 ==========
Loss: 1.580	Accuracy: 34.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7143    0.1613    0.2632        31
         cwx     0.1746    0.5000    0.2588        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2069    0.3158    0.2500        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.4286    0.6000    0.5000        45
         zxx     0.8125    0.3333    0.4727        39

    accuracy                         0.3459       185
   macro avg     0.3747    0.2967    0.2793       185
weighted avg     0.4558    0.3459    0.3355       185

micro f-score: 0.34594594594594597

========== Train Epoch 11 ==========
Loss: 1.564	Accuracy: 23.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0714    0.0323    0.0444        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.4545    0.1111    0.1786        45
         zxx     0.2323    0.9231    0.3711        39

    accuracy                         0.2324       185
   macro avg     0.1440    0.1643    0.1027       185
weighted avg     0.1877    0.2324    0.1372       185

micro f-score: 0.23243243243243245

========== Train Epoch 12 ==========
Loss: 1.539	Accuracy: 26.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.1905    0.1290    0.1538        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.0526    0.0833        19
         nqx     0.1667    0.0833    0.1111        12
         qtx     0.6000    0.1333    0.2182        45
         zxx     0.2500    0.8974    0.3911        39

    accuracy                         0.2649       185
   macro avg     0.2963    0.1981    0.1596       185
weighted avg     0.3412    0.2649    0.1961       185

micro f-score: 0.2648648648648649

========== Train Epoch 13 ==========
Loss: 1.540	Accuracy: 31.35%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2500    0.2581    0.2540        31
         cwx     0.2000    0.0455    0.0741        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.2941    0.4167    0.3448        12
         qtx     0.5625    0.2000    0.2951        45
         zxx     0.3173    0.8462    0.4615        39

    accuracy                         0.3135       185
   macro avg     0.2606    0.2674    0.2239       185
weighted avg     0.3090    0.3135    0.2570       185

micro f-score: 0.31351351351351353

========== Train Epoch 14 ==========
Loss: 1.558	Accuracy: 29.73%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.3333    0.2727    0.3000        22
         hdx     0.1212    0.2353    0.1600        17
         mtx     0.2500    0.1053    0.1481        19
         nqx     0.2500    0.2500    0.2500        12
         qtx     0.3229    0.6889    0.4397        45
         zxx     0.5000    0.2308    0.3158        39

    accuracy                         0.2973       185
   macro avg     0.2539    0.2547    0.2305       185
weighted avg     0.2766    0.2973    0.2553       185

micro f-score: 0.2972972972972973

========== Train Epoch 15 ==========
Loss: 1.519	Accuracy: 34.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2500    0.1613    0.1961        31
         cwx     0.1818    0.4545    0.2597        22
         hdx     0.1818    0.1176    0.1429        17
         mtx     0.5000    0.0526    0.0952        19
         nqx     0.1333    0.3333    0.1905        12
         qtx     0.5750    0.5111    0.5412        45
         zxx     0.6667    0.4615    0.5455        39

    accuracy                         0.3405       185
   macro avg     0.3555    0.2989    0.2816       185
weighted avg     0.4206    0.3405    0.3456       185

micro f-score: 0.34054054054054056

========== Train Epoch 16 ==========
Loss: 1.490	Accuracy: 27.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2449    0.3871    0.3000        31
         cwx     0.6250    0.2273    0.3333        22
         hdx     0.2000    0.0588    0.0909        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.1364    1.0000    0.2400        12
         qtx     0.5625    0.2000    0.2951        45
         zxx     0.6923    0.2308    0.3462        39

    accuracy                         0.2757       185
   macro avg     0.4230    0.3231    0.2636       185
weighted avg     0.4767    0.2757    0.2832       185

micro f-score: 0.2756756756756757

========== Train Epoch 17 ==========
Loss: 1.481	Accuracy: 34.05%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.4286    0.0968    0.1579        31
         cwx     0.2000    0.2727    0.2308        22
         hdx     0.1842    0.4118    0.2545        17
         mtx     0.2000    0.1053    0.1379        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.4253    0.8222    0.5606        45
         zxx     0.7778    0.1795    0.2917        39

    accuracy                         0.3405       185
   macro avg     0.3523    0.2817    0.2512       185
weighted avg     0.4167    0.3405    0.2974       185

micro f-score: 0.34054054054054056

========== Train Epoch 18 ==========
Loss: 1.427	Accuracy: 31.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3636    0.1290    0.1905        31
         cwx     0.2500    0.0455    0.0769        22
         hdx     0.1091    0.3529    0.1667        17
         mtx     0.1667    0.1579    0.1622        19
         nqx     0.2857    0.1667    0.2105        12
         qtx     0.4118    0.3111    0.3544        45
         zxx     0.5179    0.7436    0.6105        39

    accuracy                         0.3189       185
   macro avg     0.3007    0.2724    0.2531       185
weighted avg     0.3457    0.3189    0.3016       185

micro f-score: 0.31891891891891894

========== Train Epoch 19 ==========
Loss: 1.431	Accuracy: 33.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3208    0.5484    0.4048        31
         cwx     0.1429    0.0909    0.1111        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2857    0.2105    0.2424        19
         nqx     0.1667    0.5000    0.2500        12
         qtx     0.7778    0.1556    0.2593        45
         zxx     0.4407    0.6667    0.5306        39

    accuracy                         0.3351       185
   macro avg     0.3049    0.3103    0.2569       185
weighted avg     0.3930    0.3351    0.2971       185

micro f-score: 0.33513513513513515

========== Train Epoch 20 ==========
Loss: 1.401	Accuracy: 37.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     0.2000    0.0909    0.1250        22
         hdx     0.1111    0.0588    0.0769        17
         mtx     0.2500    0.3684    0.2979        19
         nqx     0.2667    0.3333    0.2963        12
         qtx     0.4205    0.8222    0.5564        45
         zxx     0.5714    0.4103    0.4776        39

    accuracy                         0.3730       185
   macro avg     0.3008    0.3069    0.2765       185
weighted avg     0.3476    0.3730    0.3254       185

micro f-score: 0.37297297297297294

========== Train Epoch 21 ==========
Loss: 1.365	Accuracy: 32.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2667    0.1290    0.1739        31
         cwx     0.1618    0.5000    0.2444        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2143    0.3158    0.2553        19
         nqx     0.2632    0.4167    0.3226        12
         qtx     0.7647    0.2889    0.4194        45
         zxx     0.6286    0.5641    0.5946        39

    accuracy                         0.3297       185
   macro avg     0.3285    0.3164    0.2872       185
weighted avg     0.4215    0.3297    0.3327       185

micro f-score: 0.32972972972972975

========== Train Epoch 22 ==========
Loss: 1.394	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2889    0.4194    0.3421        31
         cwx     0.3846    0.2273    0.2857        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2400    0.3158    0.2727        19
         nqx     0.2857    0.3333    0.3077        12
         qtx     0.9412    0.3556    0.5161        45
         zxx     0.4769    0.7949    0.5962        39

    accuracy                         0.4054       185
   macro avg     0.3739    0.3495    0.3315       185
weighted avg     0.4668    0.4054    0.3905       185

micro f-score: 0.40540540540540543

========== Train Epoch 23 ==========
Loss: 1.352	Accuracy: 43.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5714    0.1290    0.2105        31
         cwx     0.4545    0.2273    0.3030        22
         hdx     0.1000    0.0588    0.0741        17
         mtx     0.2222    0.2105    0.2162        19
         nqx     0.6000    0.2500    0.3529        12
         qtx     0.7714    0.6000    0.6750        45
         zxx     0.3636    0.9231    0.5217        39

    accuracy                         0.4324       185
   macro avg     0.4405    0.3427    0.3362       185
weighted avg     0.4850    0.4324    0.3974       185

micro f-score: 0.43243243243243246

========== Train Epoch 24 ==========
Loss: 1.364	Accuracy: 45.41%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2941    0.1613    0.2083        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.5000    0.1053    0.1739        19
         nqx     0.2174    0.8333    0.3448        12
         qtx     0.6038    0.7111    0.6531        45
         zxx     0.5660    0.7692    0.6522        39

    accuracy                         0.4541       185
   macro avg     0.4366    0.4068    0.3466       185
weighted avg     0.4748    0.4541    0.4118       185

micro f-score: 0.4540540540540541

========== Train Epoch 25 ==========
Loss: 1.395	Accuracy: 41.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4667    0.2258    0.3043        31
         cwx     0.0000    0.0000    0.0000        22
         hdx     0.5000    0.2941    0.3704        17
         mtx     0.2308    0.1579    0.1875        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.7333    0.4889    0.5867        45
         zxx     0.3333    0.9231    0.4898        39

    accuracy                         0.4108       185
   macro avg     0.3847    0.3343    0.3221       185
weighted avg     0.4243    0.4108    0.3707       185

micro f-score: 0.4108108108108109

========== Train Epoch 26 ==========
Loss: 1.321	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3913    0.2903    0.3333        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.3363    0.9744    0.5000        39

    accuracy                         0.4054       185
   macro avg     0.3219    0.3165    0.2713       185
weighted avg     0.4104    0.4054    0.3468       185

micro f-score: 0.40540540540540543

========== Train Epoch 27 ==========
Loss: 1.305	Accuracy: 34.05%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2195    0.5806    0.3186        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.2632    0.2632    0.2632        19
         nqx     0.3214    0.7500    0.4500        12
         qtx     0.8182    0.2000    0.3214        45
         zxx     0.5000    0.5128    0.5063        39

    accuracy                         0.3405       185
   macro avg     0.3746    0.3425    0.2876       185
weighted avg     0.4485    0.3405    0.3128       185

micro f-score: 0.34054054054054056

========== Train Epoch 28 ==========
Loss: 1.352	Accuracy: 45.95%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2778    0.1613    0.2041        31
         cwx     0.4000    0.1818    0.2500        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     1.0000    0.0526    0.1000        19
         nqx     0.3043    0.5833    0.4000        12
         qtx     0.5373    0.8000    0.6429        45
         zxx     0.4921    0.7949    0.6078        39

    accuracy                         0.4595       185
   macro avg     0.4778    0.3761    0.3293       185
weighted avg     0.4816    0.4595    0.3938       185

micro f-score: 0.4594594594594595

========== Train Epoch 29 ==========
Loss: 1.300	Accuracy: 43.78%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6429    0.2903    0.4000        31
         cwx     0.2581    0.3636    0.3019        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.3684    0.3684    0.3684        19
         nqx     0.3750    0.5000    0.4286        12
         qtx     0.4868    0.8222    0.6116        45
         zxx     0.5909    0.3333    0.4262        39

    accuracy                         0.4378       185
   macro avg     0.4093    0.3910    0.3743       185
weighted avg     0.4567    0.4378    0.4148       185

micro f-score: 0.43783783783783786

========== Train Epoch 30 ==========
Loss: 1.280	Accuracy: 43.24%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3750    0.5806    0.4557        31
         cwx     0.2105    0.1818    0.1951        22
         hdx     0.1786    0.2941    0.2222        17
         mtx     0.2778    0.2632    0.2703        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.6585    0.6000    0.6279        45
         zxx     0.7500    0.4615    0.5714        39

    accuracy                         0.4324       185
   macro avg     0.4113    0.3759    0.3798       185
weighted avg     0.4789    0.4324    0.4414       185

micro f-score: 0.43243243243243246

========== Train Epoch 31 ==========
Loss: 1.268	Accuracy: 43.78%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2857    0.0645    0.1053        31
         cwx     0.2162    0.3636    0.2712        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.1538    0.1053    0.1250        19
         nqx     0.2432    0.7500    0.3673        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.6750    0.6923    0.6835        39

    accuracy                         0.4378       185
   macro avg     0.3677    0.3922    0.3344       185
weighted avg     0.4403    0.4378    0.4072       185

micro f-score: 0.43783783783783786

========== Train Epoch 32 ==========
Loss: 1.214	Accuracy: 31.35%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.5000    0.0455    0.0833        22
         hdx     0.1379    0.4706    0.2133        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.6667    0.1667    0.2667        12
         qtx     0.3694    0.9111    0.5256        45
         zxx     0.7500    0.1538    0.2553        39

    accuracy                         0.3135       185
   macro avg     0.3463    0.2497    0.1920       185
weighted avg     0.3633    0.3135    0.2285       185

micro f-score: 0.31351351351351353

========== Train Epoch 33 ==========
Loss: 1.287	Accuracy: 47.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3333    0.2258    0.2692        31
         cwx     0.5000    0.0909    0.1538        22
         hdx     0.5000    0.0588    0.1053        17
         mtx     0.3571    0.5263    0.4255        19
         nqx     0.2800    0.5833    0.3784        12
         qtx     0.7895    0.6667    0.7229        45
         zxx     0.4627    0.7949    0.5849        39

    accuracy                         0.4757       185
   macro avg     0.4604    0.4210    0.3771       185
weighted avg     0.5057    0.4757    0.4405       185

micro f-score: 0.4756756756756757

========== Train Epoch 34 ==========
Loss: 1.217	Accuracy: 41.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.1613    0.2564        31
         cwx     0.5000    0.2727    0.3529        22
         hdx     0.6000    0.1765    0.2727        17
         mtx     0.6667    0.1053    0.1818        19
         nqx     0.2500    0.0833    0.1250        12
         qtx     0.5676    0.4667    0.5122        45
         zxx     0.3276    0.9744    0.4903        39

    accuracy                         0.4108       185
   macro avg     0.5053    0.3200    0.3131       185
weighted avg     0.5111    0.4108    0.3647       185

micro f-score: 0.4108108108108109

========== Train Epoch 35 ==========
Loss: 1.208	Accuracy: 41.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3636    0.2581    0.3019        31
         cwx     0.1765    0.4091    0.2466        22
         hdx     0.3333    0.0588    0.1000        17
         mtx     0.7500    0.1579    0.2609        19
         nqx     0.2857    0.5000    0.3636        12
         qtx     0.8261    0.4222    0.5588        45
         zxx     0.4918    0.7692    0.6000        39

    accuracy                         0.4108       185
   macro avg     0.4610    0.3679    0.3474       185
weighted avg     0.5127    0.4108    0.4019       185

micro f-score: 0.4108108108108109

========== Train Epoch 36 ==========
Loss: 1.208	Accuracy: 50.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.7059    0.3871    0.5000        31
         cwx     0.2895    0.5000    0.3667        22
         hdx     0.1176    0.1176    0.1176        17
         mtx     0.4444    0.2105    0.2857        19
         nqx     0.4286    0.2500    0.3158        12
         qtx     0.6667    0.7111    0.6882        45
         zxx     0.6122    0.7692    0.6818        39

    accuracy                         0.5081       185
   macro avg     0.4664    0.4208    0.4223       185
weighted avg     0.5282    0.5081    0.4992       185

micro f-score: 0.5081081081081081

========== Train Epoch 37 ==========
Loss: 1.216	Accuracy: 35.14%	Cost 32s
              precision    recall  f1-score   support

         bzx     0.6667    0.1290    0.2162        31
         cwx     0.3333    0.0455    0.0800        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.0000    0.0000    0.0000        19
         nqx     0.1852    0.8333    0.3030        12
         qtx     0.3619    0.8444    0.5067        45
         zxx     0.9231    0.3077    0.4615        39

    accuracy                         0.3514       185
   macro avg     0.3529    0.3086    0.2239       185
weighted avg     0.4460    0.3514    0.2859       185

micro f-score: 0.35135135135135137

========== Train Epoch 38 ==========
Loss: 1.154	Accuracy: 36.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2500    0.0323    0.0571        31
         cwx     0.2391    0.5000    0.3235        22
         hdx     0.2143    0.1765    0.1935        17
         mtx     0.1818    0.5263    0.2703        19
         nqx     0.4000    0.6667    0.5000        12
         qtx     0.6667    0.4444    0.5333        45
         zxx     0.8750    0.3590    0.5091        39

    accuracy                         0.3622       185
   macro avg     0.4038    0.3864    0.3410       185
weighted avg     0.4813    0.3622    0.3631       185

micro f-score: 0.3621621621621622

========== Train Epoch 39 ==========
Loss: 1.126	Accuracy: 50.27%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.0968    0.1622        31
         cwx     0.2000    0.0455    0.0741        22
         hdx     0.3333    0.1765    0.2308        17
         mtx     0.6000    0.3158    0.4138        19
         nqx     0.3846    0.4167    0.4000        12
         qtx     0.4667    0.9333    0.6222        45
         zxx     0.6346    0.8462    0.7253        39

    accuracy                         0.5027       185
   macro avg     0.4456    0.4044    0.3755       185
weighted avg     0.4721    0.5027    0.4299       185

micro f-score: 0.5027027027027027

========== Train Epoch 40 ==========
Loss: 1.137	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.4286    0.1765    0.2500        17
         mtx     0.2609    0.6316    0.3692        19
         nqx     0.3333    0.4167    0.3704        12
         qtx     0.8056    0.6444    0.7160        45
         zxx     0.5079    0.8205    0.6275        39

    accuracy                         0.4919       185
   macro avg     0.5123    0.4397    0.4175       185
weighted avg     0.5597    0.4919    0.4728       185

micro f-score: 0.4918918918918919

========== Train Epoch 41 ==========
Loss: 1.169	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4167    0.1613    0.2326        31
         cwx     0.4118    0.3182    0.3590        22
         hdx     0.1111    0.0588    0.0769        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.3571    0.4167    0.3846        12
         qtx     0.6167    0.8222    0.7048        45
         zxx     0.6200    0.7949    0.6966        39

    accuracy                         0.5027       185
   macro avg     0.4054    0.4201    0.3983       185
weighted avg     0.4641    0.5027    0.4662       185

micro f-score: 0.5027027027027027

========== Train Epoch 42 ==========
Loss: 1.142	Accuracy: 44.86%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4444    0.1290    0.2000        31
         cwx     0.2549    0.5909    0.3562        22
         hdx     0.1739    0.2353    0.2000        17
         mtx     0.2500    0.4211    0.3137        19
         nqx     0.8333    0.4167    0.5556        12
         qtx     0.7632    0.6444    0.6988        45
         zxx     0.7692    0.5128    0.6154        39

    accuracy                         0.4486       185
   macro avg     0.4984    0.4215    0.4199       185
weighted avg     0.5483    0.4486    0.4622       185

micro f-score: 0.4486486486486486

========== Train Epoch 43 ==========
Loss: 1.117	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.1613    0.2439        31
         cwx     0.2800    0.3182    0.2979        22
         hdx     0.2250    0.5294    0.3158        17
         mtx     0.2105    0.2105    0.2105        19
         nqx     0.5000    0.8333    0.6250        12
         qtx     0.7317    0.6667    0.6977        45
         zxx     0.8667    0.6667    0.7536        39

    accuracy                         0.4919       185
   macro avg     0.4734    0.4837    0.4492       185
weighted avg     0.5525    0.4919    0.4960       185

micro f-score: 0.4918918918918919

========== Train Epoch 44 ==========
Loss: 1.050	Accuracy: 47.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2000    0.0323    0.0556        31
         cwx     0.3030    0.4545    0.3636        22
         hdx     0.3750    0.1765    0.2400        17
         mtx     0.3000    0.4737    0.3673        19
         nqx     0.2121    0.5833    0.3111        12
         qtx     0.6809    0.7111    0.6957        45
         zxx     0.8966    0.6667    0.7647        39

    accuracy                         0.4757       185
   macro avg     0.4239    0.4426    0.3997       185
weighted avg     0.5032    0.4757    0.4629       185

micro f-score: 0.4756756756756757

========== Train Epoch 45 ==========
Loss: 1.042	Accuracy: 50.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4400    0.3548    0.3929        31
         cwx     0.3636    0.1818    0.2424        22
         hdx     0.3333    0.2353    0.2759        17
         mtx     0.3846    0.2632    0.3125        19
         nqx     0.2727    0.7500    0.4000        12
         qtx     0.7209    0.6889    0.7045        45
         zxx     0.6250    0.7692    0.6897        39

    accuracy                         0.5081       185
   macro avg     0.4486    0.4633    0.4311       185
weighted avg     0.5119    0.5081    0.4948       185

micro f-score: 0.5081081081081081

========== Train Epoch 46 ==========
Loss: 1.088	Accuracy: 51.89%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5714    0.2581    0.3556        31
         cwx     0.4054    0.6818    0.5085        22
         hdx     0.6667    0.1176    0.2000        17
         mtx     0.3448    0.5263    0.4167        19
         nqx     0.2571    0.7500    0.3830        12
         qtx     0.7273    0.7111    0.7191        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.5189       185
   macro avg     0.5489    0.5083    0.4611       185
weighted avg     0.6175    0.5189    0.5170       185

micro f-score: 0.518918918918919

========== Train Epoch 47 ==========
Loss: 1.024	Accuracy: 46.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5882    0.3226    0.4167        31
         cwx     0.2571    0.4091    0.3158        22
         hdx     0.1111    0.0588    0.0769        17
         mtx     0.3500    0.3684    0.3590        19
         nqx     0.2439    0.8333    0.3774        12
         qtx     0.7222    0.5778    0.6420        45
         zxx     0.8519    0.5897    0.6970        39

    accuracy                         0.4649       185
   macro avg     0.4464    0.4514    0.4121       185
weighted avg     0.5464    0.4649    0.4789       185

micro f-score: 0.4648648648648649

========== Train Epoch 48 ==========
Loss: 0.947	Accuracy: 47.03%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3333    0.5806    0.4235        31
         cwx     0.6000    0.1364    0.2222        22
         hdx     0.1765    0.3529    0.2353        17
         mtx     0.3478    0.4211    0.3810        19
         nqx     0.5000    0.5000    0.5000        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.7500    0.6154    0.6761        39

    accuracy                         0.4703       185
   macro avg     0.5125    0.4422    0.4381       185
weighted avg     0.5837    0.4703    0.4860       185

micro f-score: 0.4702702702702703

========== Train Epoch 49 ==========
Loss: 0.882	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4444    0.2581    0.3265        31
         cwx     0.4000    0.4545    0.4255        22
         hdx     0.2353    0.2353    0.2353        17
         mtx     0.4000    0.3158    0.3529        19
         nqx     0.2553    1.0000    0.4068        12
         qtx     0.9091    0.6667    0.7692        45
         zxx     0.7667    0.5897    0.6667        39

    accuracy                         0.5027       185
   macro avg     0.4873    0.5029    0.4547       185
weighted avg     0.5841    0.5027    0.5172       185

micro f-score: 0.5027027027027027

========== Train Epoch 50 ==========
Loss: 0.978	Accuracy: 45.41%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3000    0.4839    0.3704        31
         cwx     0.6667    0.2727    0.3871        22
         hdx     0.3333    0.1176    0.1739        17
         mtx     0.4000    0.4211    0.4103        19
         nqx     0.3000    0.2500    0.2727        12
         qtx     1.0000    0.3556    0.5246        45
         zxx     0.4595    0.8718    0.6018        39

    accuracy                         0.4541       185
   macro avg     0.4942    0.3961    0.3915       185
weighted avg     0.5608    0.4541    0.4384       185

micro f-score: 0.4540540540540541

========== Train Epoch 51 ==========
Loss: 1.110	Accuracy: 45.95%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3261    0.4839    0.3896        31
         cwx     0.3235    0.5000    0.3929        22
         hdx     0.2500    0.1176    0.1600        17
         mtx     0.3429    0.6316    0.4444        19
         nqx     0.3125    0.4167    0.3571        12
         qtx     0.8800    0.4889    0.6286        45
         zxx     0.8571    0.4615    0.6000        39

    accuracy                         0.4595       185
   macro avg     0.4703    0.4429    0.4247       185
weighted avg     0.5663    0.4595    0.4749       185

micro f-score: 0.4594594594594595

========== Train Epoch 52 ==========
Loss: 0.963	Accuracy: 55.14%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.3226    0.3922        31
         cwx     0.5455    0.2727    0.3636        22
         hdx     0.5000    0.1765    0.2609        17
         mtx     0.3889    0.3684    0.3784        19
         nqx     0.2917    0.5833    0.3889        12
         qtx     0.8947    0.7556    0.8193        45
         zxx     0.5147    0.8974    0.6542        39

    accuracy                         0.5514       185
   macro avg     0.5194    0.4824    0.4653       185
weighted avg     0.5796    0.5514    0.5342       185

micro f-score: 0.5513513513513514

========== Train Epoch 53 ==========
Loss: 0.844	Accuracy: 51.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.1935    0.3000        31
         cwx     0.6667    0.2727    0.3871        22
         hdx     0.2727    0.1765    0.2143        17
         mtx     1.0000    0.1579    0.2727        19
         nqx     0.4444    0.3333    0.3810        12
         qtx     0.6491    0.8222    0.7255        45
         zxx     0.4253    0.9487    0.5873        39

    accuracy                         0.5189       185
   macro avg     0.5893    0.4150    0.4097       185
weighted avg     0.5951    0.5189    0.4690       185

micro f-score: 0.518918918918919

========== Train Epoch 54 ==========
Loss: 0.835	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6000    0.1935    0.2927        31
         cwx     0.4138    0.5455    0.4706        22
         hdx     0.1111    0.0588    0.0769        17
         mtx     0.2963    0.4211    0.3478        19
         nqx     0.5333    0.6667    0.5926        12
         qtx     0.7333    0.7333    0.7333        45
         zxx     0.6400    0.8205    0.7191        39

    accuracy                         0.5405       185
   macro avg     0.4754    0.4913    0.4619       185
weighted avg     0.5383    0.5405    0.5162       185

micro f-score: 0.5405405405405406

========== Train Epoch 55 ==========
Loss: 0.856	Accuracy: 37.30%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        31
         cwx     0.2500    0.3182    0.2800        22
         hdx     0.1667    0.2941    0.2128        17
         mtx     0.1935    0.6316    0.2963        19
         nqx     0.3077    0.3333    0.3200        12
         qtx     0.7381    0.6889    0.7126        45
         zxx     1.0000    0.2564    0.4082        39

    accuracy                         0.3730       185
   macro avg     0.3794    0.3604    0.3186       185
weighted avg     0.4752    0.3730    0.3634       185

micro f-score: 0.37297297297297294

========== Train Epoch 56 ==========
Loss: 0.905	Accuracy: 37.30%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2899    0.6452    0.4000        31
         cwx     0.6667    0.0909    0.1600        22
         hdx     0.1667    0.0588    0.0870        17
         mtx     0.4286    0.1579    0.2308        19
         nqx     0.2500    0.1667    0.2000        12
         qtx     1.0000    0.1111    0.2000        45
         zxx     0.4138    0.9231    0.5714        39

    accuracy                         0.3730       185
   macro avg     0.4594    0.3077    0.2642       185
weighted avg     0.5339    0.3730    0.2998       185

micro f-score: 0.37297297297297294

========== Train Epoch 57 ==========
Loss: 0.833	Accuracy: 49.19%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3333    0.4516    0.3836        31
         cwx     0.3704    0.4545    0.4082        22
         hdx     1.0000    0.1176    0.2105        17
         mtx     0.3333    0.2105    0.2581        19
         nqx     0.3000    0.5000    0.3750        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.5556    0.7692    0.6452        39

    accuracy                         0.4919       185
   macro avg     0.5408    0.4370    0.4236       185
weighted avg     0.5798    0.4919    0.4856       185

micro f-score: 0.4918918918918919

========== Train Epoch 58 ==========
Loss: 0.895	Accuracy: 50.81%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2653    0.4194    0.3250        31
         cwx     0.8333    0.2273    0.3571        22
         hdx     0.2308    0.3529    0.2791        17
         mtx     0.2692    0.3684    0.3111        19
         nqx     0.6429    0.7500    0.6923        12
         qtx     0.8611    0.6889    0.7654        45
         zxx     0.8214    0.5897    0.6866        39

    accuracy                         0.5081       185
   macro avg     0.5606    0.4852    0.4881       185
weighted avg     0.6167    0.5081    0.5304       185

micro f-score: 0.5081081081081081

========== Train Epoch 59 ==========
Loss: 0.769	Accuracy: 47.03%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4516    0.4516    0.4516        31
         cwx     0.4000    0.3636    0.3810        22
         hdx     0.0000    0.0000    0.0000        17
         mtx     0.5000    0.1579    0.2400        19
         nqx     0.2037    0.9167    0.3333        12
         qtx     0.6078    0.6889    0.6458        45
         zxx     0.8696    0.5128    0.6452        39

    accuracy                         0.4703       185
   macro avg     0.4332    0.4416    0.3853       185
weighted avg     0.5190    0.4703    0.4603       185

micro f-score: 0.4702702702702703

========== Train Epoch 60 ==========
Loss: 0.931	Accuracy: 46.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.8333    0.1613    0.2703        31
         cwx     0.3448    0.4545    0.3922        22
         hdx     0.1471    0.2941    0.1961        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.2667    0.6667    0.3810        12
         qtx     0.7949    0.6889    0.7381        45
         zxx     0.8333    0.5128    0.6349        39

    accuracy                         0.4649       185
   macro avg     0.5035    0.4495    0.4208       185
weighted avg     0.6117    0.4649    0.4823       185

micro f-score: 0.4648648648648649

========== Train Epoch 61 ==========
Loss: 0.747	Accuracy: 43.24%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.2857    0.7097    0.4074        31
         cwx     0.6667    0.2727    0.3871        22
         hdx     0.1429    0.0588    0.0833        17
         mtx     0.2500    0.5789    0.3492        19
         nqx     0.6667    0.5000    0.5714        12
         qtx     0.8929    0.5556    0.6849        45
         zxx     0.8182    0.2308    0.3600        39

    accuracy                         0.4324       185
   macro avg     0.5318    0.4152    0.4062       185
weighted avg     0.5989    0.4324    0.4374       185

micro f-score: 0.43243243243243246

========== Train Epoch 62 ==========
Loss: 0.640	Accuracy: 46.49%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4000    0.1290    0.1951        31
         cwx     0.4815    0.5909    0.5306        22
         hdx     0.1587    0.5882    0.2500        17
         mtx     0.2609    0.3158    0.2857        19
         nqx     1.0000    0.2500    0.4000        12
         qtx     0.7692    0.6667    0.7143        45
         zxx     1.0000    0.5128    0.6780        39

    accuracy                         0.4649       185
   macro avg     0.5815    0.4362    0.4362       185
weighted avg     0.6284    0.4649    0.4907       185

micro f-score: 0.4648648648648649

========== Train Epoch 63 ==========
Loss: 0.662	Accuracy: 51.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4091    0.5806    0.4800        31
         cwx     0.4615    0.5455    0.5000        22
         hdx     0.1875    0.3529    0.2449        17
         mtx     0.3636    0.2105    0.2667        19
         nqx     0.4091    0.7500    0.5294        12
         qtx     0.9333    0.6222    0.7467        45
         zxx     0.9500    0.4872    0.6441        39

    accuracy                         0.5189       185
   macro avg     0.5306    0.5070    0.4874       185
weighted avg     0.6318    0.5189    0.5415       185

micro f-score: 0.518918918918919

========== Train Epoch 64 ==========
Loss: 0.680	Accuracy: 52.43%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3600    0.5806    0.4444        31
         cwx     0.6667    0.4545    0.5405        22
         hdx     0.2500    0.3529    0.2927        17
         mtx     0.3043    0.3684    0.3333        19
         nqx     0.4500    0.7500    0.5625        12
         qtx     0.9565    0.4889    0.6471        45
         zxx     0.8333    0.6410    0.7246        39

    accuracy                         0.5243       185
   macro avg     0.5458    0.5195    0.5065       185
weighted avg     0.6314    0.5243    0.5465       185

micro f-score: 0.5243243243243243

Finished training!!!

Min Loss = 0.640 in epoch 61;
Max Accuracy = 55.14% in epoch 51;
Total Cost 36 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPPB: 1-4                              [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-27                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-40                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-46                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-52                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-59                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-65                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-71                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-77                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-83                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-89                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-96                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-102                  [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-108                  [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



