dataset_path: /home/djy/dataset/dataset2
pretrained : True 
parallel: False

net: sppb_resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.916	Accuracy: 24.32%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.0000    0.0000    0.0000        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.3750    0.4688    0.4167        32
         zxx     0.2113    0.7500    0.3297        40

    accuracy                         0.2432       185
   macro avg     0.0838    0.1741    0.1066       185
weighted avg     0.1105    0.2432    0.1434       185

micro f-score: 0.24324324324324326

========== Train Epoch 2 ==========
Loss: 1.721	Accuracy: 31.89%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3571    0.1562    0.2174        32
         cwx     0.4118    0.2188    0.2857        32
         hdx     0.1429    0.0769    0.1000        13
         mtx     0.1429    0.0455    0.0690        22
         nqx     0.1538    0.1429    0.1481        14
         qtx     0.4444    0.2500    0.3200        32
         zxx     0.3211    0.8750    0.4698        40

    accuracy                         0.3189       185
   macro avg     0.2820    0.2522    0.2300       185
weighted avg     0.3180    0.3189    0.2704       185

micro f-score: 0.31891891891891894

========== Train Epoch 3 ==========
Loss: 1.641	Accuracy: 17.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3333    0.1250    0.1818        32
         cwx     0.0750    0.0938    0.0833        32
         hdx     0.1087    0.3846    0.1695        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.0000    0.0000    0.0000        32
         zxx     0.2471    0.5250    0.3360        40

    accuracy                         0.1784       185
   macro avg     0.1092    0.1612    0.1101       185
weighted avg     0.1317    0.1784    0.1304       185

micro f-score: 0.1783783783783784

========== Train Epoch 4 ==========
Loss: 1.628	Accuracy: 32.43%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.5000    0.0312    0.0588        32
         cwx     0.5000    0.0625    0.1111        32
         hdx     0.0833    0.0769    0.0800        13
         mtx     0.3333    0.0455    0.0800        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.3333    0.6875    0.4490        32
         zxx     0.3367    0.8250    0.4783        40

    accuracy                         0.3243       185
   macro avg     0.2981    0.2469    0.1796       185
weighted avg     0.3489    0.3243    0.2256       185

micro f-score: 0.32432432432432434

========== Train Epoch 5 ==========
Loss: 1.537	Accuracy: 39.46%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3200    0.5000    0.3902        32
         cwx     0.2609    0.3750    0.3077        32
         hdx     0.6667    0.1538    0.2500        13
         mtx     0.2000    0.0455    0.0741        22
         nqx     0.2500    0.2857    0.2667        14
         qtx     0.8000    0.3750    0.5106        32
         zxx     0.5200    0.6500    0.5778        40

    accuracy                         0.3946       185
   macro avg     0.4311    0.3407    0.3396       185
weighted avg     0.4408    0.3946    0.3805       185

micro f-score: 0.3945945945945946

========== Train Epoch 6 ==========
Loss: 1.495	Accuracy: 29.19%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.1429    0.1562    0.1493        32
         cwx     0.3333    0.0625    0.1053        32
         hdx     0.2000    0.0769    0.1111        13
         mtx     0.2000    0.0909    0.1250        22
         nqx     0.1600    0.2857    0.2051        14
         qtx     0.3034    0.8438    0.4463        32
         zxx     0.8667    0.3250    0.4727        40

    accuracy                         0.2919       185
   macro avg     0.3152    0.2630    0.2307       185
weighted avg     0.3722    0.2919    0.2616       185

micro f-score: 0.2918918918918919

========== Train Epoch 7 ==========
Loss: 1.425	Accuracy: 42.16%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.2895    0.3438    0.3143        32
         cwx     0.5833    0.2188    0.3182        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2105    0.1818    0.1951        22
         nqx     0.5000    0.1429    0.2222        14
         qtx     0.6364    0.6562    0.6462        32
         zxx     0.4286    0.8250    0.5641        40

    accuracy                         0.4216       185
   macro avg     0.3783    0.3383    0.3229       185
weighted avg     0.4166    0.4216    0.3832       185

micro f-score: 0.42162162162162165

========== Train Epoch 8 ==========
Loss: 1.486	Accuracy: 44.86%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.4500    0.2812    0.3462        32
         cwx     0.3750    0.4688    0.4167        32
         hdx     0.2143    0.2308    0.2222        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.2778    0.3571    0.3125        14
         qtx     0.5094    0.8438    0.6353        32
         zxx     0.6857    0.6000    0.6400        40

    accuracy                         0.4486       185
   macro avg     0.3589    0.3974    0.3675       185
weighted avg     0.4152    0.4486    0.4195       185

micro f-score: 0.4486486486486486

========== Train Epoch 9 ==========
Loss: 1.365	Accuracy: 41.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2143    0.0938    0.1304        32
         cwx     0.3404    0.5000    0.4051        32
         hdx     0.1667    0.0769    0.1053        13
         mtx     0.2083    0.2273    0.2174        22
         nqx     0.3077    0.2857    0.2963        14
         qtx     0.5870    0.8438    0.6923        32
         zxx     0.6000    0.5250    0.5600        40

    accuracy                         0.4162       185
   macro avg     0.3463    0.3646    0.3438       185
weighted avg     0.3870    0.4162    0.3891       185

micro f-score: 0.41621621621621624

========== Train Epoch 10 ==========
Loss: 1.303	Accuracy: 43.78%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3235    0.3438    0.3333        32
         cwx     0.3400    0.5312    0.4146        32
         hdx     0.1429    0.1538    0.1481        13
         mtx     0.5000    0.0909    0.1538        22
         nqx     0.2500    0.3571    0.2941        14
         qtx     0.6579    0.7812    0.7143        32
         zxx     0.7600    0.4750    0.5846        40

    accuracy                         0.4378       185
   macro avg     0.4249    0.3904    0.3776       185
weighted avg     0.4813    0.4378    0.4303       185

micro f-score: 0.43783783783783786

========== Train Epoch 11 ==========
Loss: 1.254	Accuracy: 42.70%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2500    0.0312    0.0556        32
         cwx     0.4000    0.6250    0.4878        32
         hdx     0.1176    0.1538    0.1333        13
         mtx     0.3000    0.1364    0.1875        22
         nqx     0.5714    0.2857    0.3810        14
         qtx     0.7500    0.4688    0.5769        32
         zxx     0.4416    0.8500    0.5812        40

    accuracy                         0.4270       185
   macro avg     0.4044    0.3644    0.3433       185
weighted avg     0.4248    0.4270    0.3799       185

micro f-score: 0.427027027027027

========== Train Epoch 12 ==========
Loss: 1.192	Accuracy: 47.03%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.3200    0.5000    0.3902        32
         cwx     0.8235    0.4375    0.5714        32
         hdx     0.2000    0.0769    0.1111        13
         mtx     0.2500    0.1818    0.2105        22
         nqx     0.3333    0.1429    0.2000        14
         qtx     0.4839    0.9375    0.6383        32
         zxx     0.6897    0.5000    0.5797        40

    accuracy                         0.4703       185
   macro avg     0.4429    0.3967    0.3859       185
weighted avg     0.4996    0.4703    0.4501       185

micro f-score: 0.4702702702702703

========== Train Epoch 13 ==========
Loss: 1.201	Accuracy: 43.78%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.1667    0.0625    0.0909        32
         cwx     0.3623    0.7812    0.4950        32
         hdx     0.0909    0.0769    0.0833        13
         mtx     0.3000    0.1364    0.1875        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.7778    0.6562    0.7119        32
         zxx     0.5091    0.7000    0.5895        40

    accuracy                         0.4378       185
   macro avg     0.4581    0.3550    0.3274       185
weighted avg     0.4538    0.4378    0.3902       185

micro f-score: 0.43783783783783786

========== Train Epoch 14 ==========
Loss: 1.224	Accuracy: 45.41%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5714    0.1250    0.2051        32
         cwx     0.4255    0.6250    0.5063        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.4737    0.8438    0.6067        32
         zxx     0.4615    0.7500    0.5714        40

    accuracy                         0.4541       185
   macro avg     0.3617    0.3654    0.3151       185
weighted avg     0.3996    0.4541    0.3755       185

micro f-score: 0.4540540540540541

========== Train Epoch 15 ==========
Loss: 1.159	Accuracy: 45.41%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.4688    0.4688    0.4688        32
         cwx     0.4815    0.4062    0.4407        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.5000    0.0909    0.1538        22
         nqx     0.1154    0.2143    0.1500        14
         qtx     0.5192    0.8438    0.6429        32
         zxx     0.7500    0.6000    0.6667        40

    accuracy                         0.4541       185
   macro avg     0.4050    0.3748    0.3604       185
weighted avg     0.4845    0.4541    0.4423       185

micro f-score: 0.4540540540540541

========== Train Epoch 16 ==========
Loss: 1.073	Accuracy: 36.76%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.3750    0.0938    0.1500        32
         cwx     0.3333    0.8125    0.4727        32
         hdx     0.0816    0.3077    0.1290        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.2222    0.1429    0.1739        14
         qtx     0.6818    0.4688    0.5556        32
         zxx     0.9474    0.4500    0.6102        40

    accuracy                         0.3676       185
   macro avg     0.3773    0.3251    0.2988       185
weighted avg     0.4678    0.3676    0.3580       185

micro f-score: 0.3675675675675676

========== Train Epoch 17 ==========
Loss: 1.029	Accuracy: 49.73%	Cost 38s
              precision    recall  f1-score   support

         bzx     0.5000    0.2188    0.3043        32
         cwx     0.6000    0.4688    0.5263        32
         hdx     0.1739    0.3077    0.2222        13
         mtx     0.4118    0.3182    0.3590        22
         nqx     0.3333    0.3571    0.3448        14
         qtx     0.8000    0.7500    0.7742        32
         zxx     0.4918    0.7500    0.5941        40

    accuracy                         0.4973       185
   macro avg     0.4730    0.4529    0.4464       185
weighted avg     0.5214    0.4973    0.4904       185

micro f-score: 0.4972972972972973

========== Train Epoch 18 ==========
Loss: 0.942	Accuracy: 49.19%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3077    0.1250    0.1778        32
         cwx     0.4681    0.6875    0.5570        32
         hdx     0.2222    0.1538    0.1818        13
         mtx     0.4091    0.4091    0.4091        22
         nqx     0.3200    0.5714    0.4103        14
         qtx     0.5833    0.8750    0.7000        32
         zxx     0.8571    0.4500    0.5902        40

    accuracy                         0.4919       185
   macro avg     0.4525    0.4674    0.4323       185
weighted avg     0.5089    0.4919    0.4682       185

micro f-score: 0.4918918918918919

========== Train Epoch 19 ==========
Loss: 0.992	Accuracy: 49.19%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.4706    0.5000    0.4848        32
         cwx     0.5600    0.4375    0.4912        32
         hdx     0.1429    0.0769    0.1000        13
         mtx     0.2308    0.1364    0.1714        22
         nqx     0.2609    0.4286    0.3243        14
         qtx     0.7333    0.6875    0.7097        32
         zxx     0.5472    0.7250    0.6237        40

    accuracy                         0.4919       185
   macro avg     0.4208    0.4274    0.4150       185
weighted avg     0.4806    0.4919    0.4784       185

micro f-score: 0.4918918918918919

========== Train Epoch 20 ==========
Loss: 0.919	Accuracy: 45.95%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.1875    0.2727        32
         cwx     0.3333    0.7500    0.4615        32
         hdx     0.2188    0.5385    0.3111        13
         mtx     0.3750    0.2727    0.3158        22
         nqx     0.4444    0.2857    0.3478        14
         qtx     0.8750    0.4375    0.5833        32
         zxx     0.8571    0.6000    0.7059        40

    accuracy                         0.4595       185
   macro avg     0.5148    0.4388    0.4283       185
weighted avg     0.5744    0.4595    0.4663       185

micro f-score: 0.4594594594594595

========== Train Epoch 21 ==========
Loss: 0.839	Accuracy: 48.65%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4545    0.6250    0.5263        32
         cwx     0.8750    0.2188    0.3500        32
         hdx     0.1818    0.1538    0.1667        13
         mtx     0.4545    0.4545    0.4545        22
         nqx     0.1667    0.0714    0.1000        14
         qtx     0.4655    0.8438    0.6000        32
         zxx     0.6389    0.5750    0.6053        40

    accuracy                         0.4865       185
   macro avg     0.4624    0.4203    0.4004       185
weighted avg     0.5281    0.4865    0.4596       185

micro f-score: 0.4864864864864865

========== Train Epoch 22 ==========
Loss: 0.852	Accuracy: 34.59%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.4286    0.6562    0.5185        32
         hdx     0.1067    0.6154    0.1818        13
         mtx     0.2000    0.1364    0.1622        22
         nqx     0.3636    0.2857    0.3200        14
         qtx     0.8462    0.3438    0.4889        32
         zxx     1.0000    0.4250    0.5965        40

    accuracy                         0.3459       185
   macro avg     0.4207    0.3518    0.3240       185
weighted avg     0.4955    0.3459    0.3595       185

micro f-score: 0.34594594594594597

========== Train Epoch 23 ==========
Loss: 0.865	Accuracy: 43.78%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.5152    0.5312    0.5231        32
         hdx     0.1379    0.3077    0.1905        13
         mtx     0.5000    0.4091    0.4500        22
         nqx     0.2778    0.3571    0.3125        14
         qtx     0.4242    0.8750    0.5714        32
         zxx     0.9000    0.4500    0.6000        40

    accuracy                         0.4378       185
   macro avg     0.3936    0.4186    0.3782       185
weighted avg     0.4473    0.4378    0.4096       185

micro f-score: 0.43783783783783786

========== Train Epoch 24 ==========
Loss: 0.759	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4737    0.5625    0.5143        32
         cwx     0.6000    0.7500    0.6667        32
         hdx     0.1905    0.3077    0.2353        13
         mtx     0.5556    0.2273    0.3226        22
         nqx     0.5000    0.5000    0.5000        14
         qtx     0.9091    0.6250    0.7407        32
         zxx     0.6585    0.6750    0.6667        40

    accuracy                         0.5676       185
   macro avg     0.5553    0.5211    0.5209       185
weighted avg     0.6026    0.5676    0.5693       185

micro f-score: 0.5675675675675675

========== Train Epoch 25 ==========
Loss: 0.625	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4545    0.1562    0.2326        32
         cwx     0.5682    0.7812    0.6579        32
         hdx     0.1200    0.2308    0.1579        13
         mtx     0.2619    0.5000    0.3438        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.6585    0.8438    0.7397        32
         zxx     1.0000    0.4250    0.5965        40

    accuracy                         0.4919       185
   macro avg     0.5233    0.4502    0.4349       185
weighted avg     0.5920    0.4919    0.4868       185

micro f-score: 0.4918918918918919

========== Train Epoch 26 ==========
Loss: 0.675	Accuracy: 57.30%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5500    0.3438    0.4231        32
         cwx     0.6216    0.7188    0.6667        32
         hdx     0.2500    0.2308    0.2400        13
         mtx     0.5000    0.2727    0.3529        22
         nqx     0.3462    0.6429    0.4500        14
         qtx     0.6944    0.7812    0.7353        32
         zxx     0.6905    0.7250    0.7073        40

    accuracy                         0.5730       185
   macro avg     0.5218    0.5307    0.5108       185
weighted avg     0.5753    0.5730    0.5615       185

micro f-score: 0.572972972972973

========== Train Epoch 27 ==========
Loss: 0.637	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.4783    0.3438    0.4000        32
         cwx     0.7000    0.6562    0.6774        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.3077    0.7273    0.4324        22
         nqx     0.5833    0.5000    0.5385        14
         qtx     0.8696    0.6250    0.7273        32
         zxx     0.6444    0.7250    0.6824        40

    accuracy                         0.5622       185
   macro avg     0.5119    0.5110    0.4940       185
weighted avg     0.5743    0.5622    0.5519       185

micro f-score: 0.5621621621621622

========== Train Epoch 28 ==========
Loss: 0.624	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6522    0.4688    0.5455        32
         cwx     0.7500    0.3750    0.5000        32
         hdx     0.2857    0.3077    0.2963        13
         mtx     0.5714    0.1818    0.2759        22
         nqx     0.3500    0.5000    0.4118        14
         qtx     0.5472    0.9062    0.6824        32
         zxx     0.6346    0.8250    0.7174        40

    accuracy                         0.5622       185
   macro avg     0.5416    0.5092    0.4899       185
weighted avg     0.5889    0.5622    0.5388       185

micro f-score: 0.5621621621621622

========== Train Epoch 29 ==========
Loss: 0.538	Accuracy: 54.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4800    0.3750    0.4211        32
         cwx     0.5306    0.8125    0.6420        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.3043    0.6364    0.4118        22
         nqx     0.8333    0.3571    0.5000        14
         qtx     0.8000    0.5000    0.6154        32
         zxx     0.7568    0.7000    0.7273        40

    accuracy                         0.5459       185
   macro avg     0.5293    0.4830    0.4739       185
weighted avg     0.5761    0.5459    0.5344       185

micro f-score: 0.5459459459459459

========== Train Epoch 30 ==========
Loss: 0.524	Accuracy: 52.43%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4286    0.2812    0.3396        32
         cwx     0.6136    0.8438    0.7105        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.2708    0.5909    0.3714        22
         nqx     0.4286    0.4286    0.4286        14
         qtx     0.7083    0.5312    0.6071        32
         zxx     0.7742    0.6000    0.6761        40

    accuracy                         0.5243       185
   macro avg     0.5082    0.4790    0.4655       185
weighted avg     0.5583    0.5243    0.5182       185

micro f-score: 0.5243243243243243

========== Train Epoch 31 ==========
Loss: 0.536	Accuracy: 51.35%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5455    0.3750    0.4444        32
         cwx     0.4576    0.8438    0.5934        32
         hdx     0.2800    0.5385    0.3684        13
         mtx     0.5556    0.4545    0.5000        22
         nqx     0.2500    0.0714    0.1111        14
         qtx     0.5641    0.6875    0.6197        32
         zxx     0.8889    0.4000    0.5517        40

    accuracy                         0.5135       185
   macro avg     0.5059    0.4815    0.4555       185
weighted avg     0.5679    0.5135    0.4998       185

micro f-score: 0.5135135135135135

========== Train Epoch 32 ==========
Loss: 0.476	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4000    0.5000    0.4444        32
         cwx     0.5500    0.6875    0.6111        32
         hdx     0.2500    0.0769    0.1176        13
         mtx     0.3714    0.5909    0.4561        22
         nqx     0.6000    0.4286    0.5000        14
         qtx     0.9375    0.4688    0.6250        32
         zxx     0.7750    0.7750    0.7750        40

    accuracy                         0.5622       185
   macro avg     0.5548    0.5040    0.5042       185
weighted avg     0.6012    0.5622    0.5586       185

micro f-score: 0.5621621621621622

========== Train Epoch 33 ==========
Loss: 0.353	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4364    0.7500    0.5517        32
         cwx     0.7692    0.3125    0.4444        32
         hdx     0.2353    0.3077    0.2667        13
         mtx     0.5000    0.3636    0.4211        22
         nqx     0.4000    0.1429    0.2105        14
         qtx     0.5600    0.8750    0.6829        32
         zxx     0.8276    0.6000    0.6957        40

    accuracy                         0.5405       185
   macro avg     0.5326    0.4788    0.4676       185
weighted avg     0.5906    0.5405    0.5256       185

micro f-score: 0.5405405405405406

========== Train Epoch 34 ==========
Loss: 0.344	Accuracy: 51.89%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3939    0.4062    0.4000        32
         cwx     0.4655    0.8438    0.6000        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.3871    0.5455    0.4528        22
         nqx     0.5714    0.2857    0.3810        14
         qtx     0.6552    0.5938    0.6230        32
         zxx     0.8333    0.5000    0.6250        40

    accuracy                         0.5189       185
   macro avg     0.5200    0.4645    0.4581       185
weighted avg     0.5549    0.5189    0.5073       185

micro f-score: 0.518918918918919

========== Train Epoch 35 ==========
Loss: 0.365	Accuracy: 56.76%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5312    0.5312    0.5312        32
         cwx     0.6800    0.5312    0.5965        32
         hdx     0.2273    0.3846    0.2857        13
         mtx     0.3846    0.6818    0.4918        22
         nqx     0.6667    0.4286    0.5217        14
         qtx     0.7241    0.6562    0.6885        32
         zxx     0.8276    0.6000    0.6957        40

    accuracy                         0.5676       185
   macro avg     0.5774    0.5448    0.5445       185
weighted avg     0.6259    0.5676    0.5826       185

micro f-score: 0.5675675675675675

========== Train Epoch 36 ==========
Loss: 0.333	Accuracy: 61.08%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6250    0.3125    0.4167        32
         cwx     0.7742    0.7500    0.7619        32
         hdx     0.3333    0.5385    0.4118        13
         mtx     0.6250    0.4545    0.5263        22
         nqx     0.4091    0.6429    0.5000        14
         qtx     0.5385    0.8750    0.6667        32
         zxx     0.9259    0.6250    0.7463        40

    accuracy                         0.6108       185
   macro avg     0.6044    0.5998    0.5757       185
weighted avg     0.6641    0.6108    0.6099       185

micro f-score: 0.6108108108108108

========== Train Epoch 37 ==========
Loss: 0.286	Accuracy: 52.97%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4118    0.6562    0.5060        32
         cwx     0.9286    0.4062    0.5652        32
         hdx     0.4000    0.3077    0.3478        13
         mtx     0.2885    0.6818    0.4054        22
         nqx     0.6250    0.3571    0.4545        14
         qtx     0.7600    0.5938    0.6667        32
         zxx     0.8400    0.5250    0.6462        40

    accuracy                         0.5297       185
   macro avg     0.6077    0.5040    0.5131       185
weighted avg     0.6546    0.5297    0.5474       185

micro f-score: 0.5297297297297298

========== Train Epoch 38 ==========
Loss: 0.294	Accuracy: 54.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5417    0.4062    0.4643        32
         cwx     0.3913    0.8438    0.5347        32
         hdx     0.5000    0.1538    0.2353        13
         mtx     0.3636    0.3636    0.3636        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.8077    0.6562    0.7241        32
         zxx     0.7714    0.6750    0.7200        40

    accuracy                         0.5459       185
   macro avg     0.5680    0.4733    0.4797       185
weighted avg     0.5917    0.5459    0.5374       185

micro f-score: 0.5459459459459459

========== Train Epoch 39 ==========
Loss: 0.250	Accuracy: 55.14%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.6875    0.5789        32
         cwx     0.8421    0.5000    0.6275        32
         hdx     0.3846    0.3846    0.3846        13
         mtx     0.2917    0.6364    0.4000        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.7917    0.5938    0.6786        32
         zxx     0.7188    0.5750    0.6389        40

    accuracy                         0.5514       185
   macro avg     0.5898    0.5131    0.5178       185
weighted avg     0.6316    0.5514    0.5627       185

micro f-score: 0.5513513513513514

========== Train Epoch 40 ==========
Loss: 0.242	Accuracy: 57.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5128    0.6250    0.5634        32
         cwx     0.8750    0.4375    0.5833        32
         hdx     0.1944    0.5385    0.2857        13
         mtx     0.5556    0.2273    0.3226        22
         nqx     1.0000    0.2143    0.3529        14
         qtx     0.6970    0.7188    0.7077        32
         zxx     0.7143    0.8750    0.7865        40

    accuracy                         0.5784       185
   macro avg     0.6499    0.5195    0.5146       185
weighted avg     0.6705    0.5784    0.5760       185

micro f-score: 0.5783783783783784

========== Train Epoch 41 ==========
Loss: 0.284	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6250    0.3125    0.4167        32
         cwx     0.6970    0.7188    0.7077        32
         hdx     0.2083    0.3846    0.2703        13
         mtx     0.6667    0.1818    0.2857        22
         nqx     0.5385    0.5000    0.5185        14
         qtx     0.4590    0.8750    0.6022        32
         zxx     0.8125    0.6500    0.7222        40

    accuracy                         0.5568       185
   macro avg     0.5724    0.5175    0.5033       185
weighted avg     0.6184    0.5568    0.5470       185

micro f-score: 0.5567567567567567

========== Train Epoch 42 ==========
Loss: 0.222	Accuracy: 61.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4286    0.8438    0.5684        32
         cwx     0.8667    0.4062    0.5532        32
         hdx     0.3333    0.3077    0.3200        13
         mtx     0.6875    0.5000    0.5789        22
         nqx     0.5714    0.5714    0.5714        14
         qtx     1.0000    0.5000    0.6667        32
         zxx     0.6939    0.8500    0.7640        40

    accuracy                         0.6108       185
   macro avg     0.6545    0.5684    0.5747       185
weighted avg     0.6955    0.6108    0.6091       185

micro f-score: 0.6108108108108108

========== Train Epoch 43 ==========
Loss: 0.193	Accuracy: 58.92%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6000    0.0938    0.1622        32
         cwx     0.5088    0.9062    0.6517        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.4242    0.6364    0.5091        22
         nqx     0.4167    0.3571    0.3846        14
         qtx     0.7333    0.6875    0.7097        32
         zxx     0.8378    0.7750    0.8052        40

    accuracy                         0.5892       185
   macro avg     0.5679    0.5487    0.5199       185
weighted avg     0.6137    0.5892    0.5566       185

micro f-score: 0.5891891891891892

========== Train Epoch 44 ==========
Loss: 0.134	Accuracy: 67.03%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.7097    0.6875    0.6984        32
         cwx     0.9091    0.6250    0.7407        32
         hdx     0.5000    0.3077    0.3810        13
         mtx     0.5185    0.6364    0.5714        22
         nqx     0.5455    0.4286    0.4800        14
         qtx     0.6087    0.8750    0.7179        32
         zxx     0.7500    0.7500    0.7500        40

    accuracy                         0.6703       185
   macro avg     0.6488    0.6157    0.6199       185
weighted avg     0.6855    0.6703    0.6663       185

micro f-score: 0.6702702702702703

========== Train Epoch 45 ==========
Loss: 0.160	Accuracy: 55.68%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.4375    0.4667        32
         cwx     0.6897    0.6250    0.6557        32
         hdx     0.3000    0.4615    0.3636        13
         mtx     0.3488    0.6818    0.4615        22
         nqx     0.5000    0.2857    0.3636        14
         qtx     0.8261    0.5938    0.6909        32
         zxx     0.7353    0.6250    0.6757        40

    accuracy                         0.5568       185
   macro avg     0.5571    0.5300    0.5254       185
weighted avg     0.6081    0.5568    0.5677       185

micro f-score: 0.5567567567567567

========== Train Epoch 46 ==========
Loss: 0.193	Accuracy: 64.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5581    0.7500    0.6400        32
         cwx     0.6250    0.7812    0.6944        32
         hdx     0.2500    0.2308    0.2400        13
         mtx     1.0000    0.3182    0.4828        22
         nqx     0.4500    0.6429    0.5294        14
         qtx     0.7667    0.7188    0.7419        32
         zxx     0.8788    0.7250    0.7945        40

    accuracy                         0.6486       185
   macro avg     0.6469    0.5953    0.5890       185
weighted avg     0.6978    0.6486    0.6453       185

micro f-score: 0.6486486486486487

========== Train Epoch 47 ==========
Loss: 0.207	Accuracy: 60.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7000    0.2188    0.3333        32
         cwx     0.5625    0.8438    0.6750        32
         hdx     0.2222    0.1538    0.1818        13
         mtx     0.5000    0.5455    0.5217        22
         nqx     0.6250    0.3571    0.4545        14
         qtx     0.6250    0.7812    0.6944        32
         zxx     0.7174    0.8250    0.7674        40

    accuracy                         0.6000       185
   macro avg     0.5646    0.5322    0.5183       185
weighted avg     0.6040    0.6000    0.5697       185

micro f-score: 0.6

========== Train Epoch 48 ==========
Loss: 0.209	Accuracy: 63.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4828    0.4375    0.4590        32
         cwx     0.8667    0.8125    0.8387        32
         hdx     0.6000    0.2308    0.3333        13
         mtx     0.3947    0.6818    0.5000        22
         nqx     0.5000    0.2143    0.3000        14
         qtx     0.5909    0.8125    0.6842        32
         zxx     0.9091    0.7500    0.8219        40

    accuracy                         0.6324       185
   macro avg     0.6206    0.5628    0.5625       185
weighted avg     0.6591    0.6324    0.6261       185

micro f-score: 0.6324324324324324

========== Train Epoch 49 ==========
Loss: 0.136	Accuracy: 62.16%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5405    0.6250    0.5797        32
         cwx     0.7692    0.6250    0.6897        32
         hdx     0.3478    0.6154    0.4444        13
         mtx     0.8571    0.2727    0.4138        22
         nqx     0.5455    0.4286    0.4800        14
         qtx     0.8182    0.5625    0.6667        32
         zxx     0.6271    0.9250    0.7475        40

    accuracy                         0.6216       185
   macro avg     0.6436    0.5792    0.5745       185
weighted avg     0.6713    0.6216    0.6133       185

micro f-score: 0.6216216216216216

========== Train Epoch 50 ==========
Loss: 0.156	Accuracy: 64.86%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6250    0.4688    0.5357        32
         cwx     0.9130    0.6562    0.7636        32
         hdx     0.4286    0.4615    0.4444        13
         mtx     0.5909    0.5909    0.5909        22
         nqx     0.4000    0.2857    0.3333        14
         qtx     0.6585    0.8438    0.7397        32
         zxx     0.6667    0.8500    0.7473        40

    accuracy                         0.6486       185
   macro avg     0.6118    0.5938    0.5936       185
weighted avg     0.6547    0.6486    0.6410       185

micro f-score: 0.6486486486486487

========== Train Epoch 51 ==========
Loss: 0.233	Accuracy: 59.46%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5789    0.3438    0.4314        32
         cwx     0.7407    0.6250    0.6780        32
         hdx     0.8333    0.3846    0.5263        13
         mtx     0.3077    0.7273    0.4324        22
         nqx     0.4000    0.2857    0.3333        14
         qtx     0.6579    0.7812    0.7143        32
         zxx     0.8788    0.7250    0.7945        40

    accuracy                         0.5946       185
   macro avg     0.6282    0.5532    0.5586       185
weighted avg     0.6575    0.5946    0.6009       185

micro f-score: 0.5945945945945946

========== Train Epoch 52 ==========
Loss: 0.151	Accuracy: 63.78%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6842    0.4062    0.5098        32
         cwx     0.7586    0.6875    0.7213        32
         hdx     0.3333    0.4615    0.3871        13
         mtx     0.5312    0.7727    0.6296        22
         nqx     0.4000    0.2857    0.3333        14
         qtx     0.6486    0.7500    0.6957        32
         zxx     0.8000    0.8000    0.8000        40

    accuracy                         0.6378       185
   macro avg     0.5937    0.5948    0.5824       185
weighted avg     0.6516    0.6378    0.6336       185

micro f-score: 0.6378378378378379

========== Train Epoch 53 ==========
Loss: 0.093	Accuracy: 58.38%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6000    0.2812    0.3830        32
         cwx     0.6667    0.5625    0.6102        32
         hdx     0.4286    0.2308    0.3000        13
         mtx     0.3404    0.7273    0.4638        22
         nqx     0.5000    0.2857    0.3636        14
         qtx     0.6216    0.7188    0.6667        32
         zxx     0.7955    0.8750    0.8333        40

    accuracy                         0.5838       185
   macro avg     0.5647    0.5259    0.5172       185
weighted avg     0.6070    0.5838    0.5710       185

micro f-score: 0.5837837837837838

========== Train Epoch 54 ==========
Loss: 0.090	Accuracy: 68.65%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6970    0.7188    0.7077        32
         cwx     0.8710    0.8438    0.8571        32
         hdx     0.2174    0.3846    0.2778        13
         mtx     0.6000    0.5455    0.5714        22
         nqx     0.6000    0.4286    0.5000        14
         qtx     0.6667    0.6875    0.6769        32
         zxx     0.9143    0.8000    0.8533        40

    accuracy                         0.6865       185
   macro avg     0.6523    0.6298    0.6349       185
weighted avg     0.7162    0.6865    0.6976       185

micro f-score: 0.6864864864864865

========== Train Epoch 55 ==========
Loss: 0.194	Accuracy: 58.92%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5333    0.5000    0.5161        32
         cwx     0.8095    0.5312    0.6415        32
         hdx     0.3333    0.6154    0.4324        13
         mtx     0.6667    0.4545    0.5405        22
         nqx     0.7143    0.3571    0.4762        14
         qtx     0.5185    0.8750    0.6512        32
         zxx     0.7353    0.6250    0.6757        40

    accuracy                         0.5892       185
   macro avg     0.6159    0.5655    0.5619       185
weighted avg     0.6377    0.5892    0.5897       185

micro f-score: 0.5891891891891892

========== Train Epoch 56 ==========
Loss: 0.224	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5161    0.5000    0.5079        32
         cwx     0.5789    0.6875    0.6286        32
         hdx     0.3077    0.6154    0.4103        13
         mtx     0.5833    0.3182    0.4118        22
         nqx     0.4211    0.5714    0.4848        14
         qtx     0.8667    0.4062    0.5532        32
         zxx     0.5909    0.6500    0.6190        40

    accuracy                         0.5405       185
   macro avg     0.5521    0.5355    0.5165       185
weighted avg     0.5899    0.5405    0.5406       185

micro f-score: 0.5405405405405406

========== Train Epoch 57 ==========
Loss: 0.211	Accuracy: 68.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5532    0.8125    0.6582        32
         cwx     0.8276    0.7500    0.7869        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.5652    0.5909    0.5778        22
         nqx     0.5556    0.3571    0.4348        14
         qtx     0.7667    0.7188    0.7419        32
         zxx     0.8333    0.7500    0.7895        40

    accuracy                         0.6811       185
   macro avg     0.6509    0.6234    0.6294       185
weighted avg     0.6928    0.6811    0.6799       185

micro f-score: 0.6810810810810811

========== Train Epoch 58 ==========
Loss: 0.065	Accuracy: 69.73%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.7037    0.5938    0.6441        32
         cwx     0.7297    0.8438    0.7826        32
         hdx     0.4286    0.4615    0.4444        13
         mtx     0.7000    0.6364    0.6667        22
         nqx     0.4444    0.2857    0.3478        14
         qtx     0.6341    0.8125    0.7123        32
         zxx     0.8919    0.8250    0.8571        40

    accuracy                         0.6973       185
   macro avg     0.6475    0.6369    0.6364       185
weighted avg     0.6975    0.6973    0.6922       185

micro f-score: 0.6972972972972973

========== Train Epoch 59 ==========
Loss: 0.063	Accuracy: 67.03%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7241    0.6562    0.6885        32
         cwx     0.7419    0.7188    0.7302        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.5200    0.5909    0.5532        22
         nqx     0.5000    0.2143    0.3000        14
         qtx     0.5778    0.8125    0.6753        32
         zxx     0.8684    0.8250    0.8462        40

    accuracy                         0.6703       185
   macro avg     0.6267    0.6003    0.6014       185
weighted avg     0.6729    0.6703    0.6629       185

micro f-score: 0.6702702702702703

========== Train Epoch 60 ==========
Loss: 0.085	Accuracy: 67.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5385    0.6562    0.5915        32
         cwx     0.7027    0.8125    0.7536        32
         hdx     0.4444    0.3077    0.3636        13
         mtx     0.5357    0.6818    0.6000        22
         nqx     0.6667    0.2857    0.4000        14
         qtx     0.8750    0.6562    0.7500        32
         zxx     0.8095    0.8500    0.8293        40

    accuracy                         0.6757       185
   macro avg     0.6532    0.6072    0.6126       185
weighted avg     0.6865    0.6757    0.6689       185

micro f-score: 0.6756756756756757

========== Train Epoch 61 ==========
Loss: 0.104	Accuracy: 61.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6818    0.4688    0.5556        32
         cwx     0.7333    0.6875    0.7097        32
         hdx     0.4615    0.4615    0.4615        13
         mtx     0.6316    0.5455    0.5854        22
         nqx     0.2941    0.3571    0.3226        14
         qtx     0.5283    0.8750    0.6588        32
         zxx     0.8065    0.6250    0.7042        40

    accuracy                         0.6108       185
   macro avg     0.5910    0.5743    0.5711       185
weighted avg     0.6403    0.6108    0.6115       185

micro f-score: 0.6108108108108108

========== Train Epoch 62 ==========
Loss: 0.118	Accuracy: 64.86%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6111    0.3438    0.4400        32
         cwx     0.6667    0.8125    0.7324        32
         hdx     0.3500    0.5385    0.4242        13
         mtx     0.5000    0.6364    0.5600        22
         nqx     0.5714    0.2857    0.3810        14
         qtx     0.7188    0.7188    0.7188        32
         zxx     0.8537    0.8750    0.8642        40

    accuracy                         0.6486       185
   macro avg     0.6102    0.6015    0.5886       185
weighted avg     0.6572    0.6486    0.6392       185

micro f-score: 0.6486486486486487

========== Train Epoch 63 ==========
Loss: 0.087	Accuracy: 64.86%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.9167    0.3438    0.5000        32
         cwx     0.8000    0.7500    0.7742        32
         hdx     0.2727    0.4615    0.3429        13
         mtx     0.7692    0.4545    0.5714        22
         nqx     0.5000    0.2857    0.3636        14
         qtx     0.5455    0.9375    0.6897        32
         zxx     0.7778    0.8750    0.8235        40

    accuracy                         0.6486       185
   macro avg     0.6546    0.5869    0.5808       185
weighted avg     0.7079    0.6486    0.6373       185

micro f-score: 0.6486486486486487

========== Train Epoch 64 ==========
Loss: 0.093	Accuracy: 63.24%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5000    0.6875    0.5789        32
         cwx     0.7857    0.6875    0.7333        32
         hdx     0.5000    0.1538    0.2353        13
         mtx     0.6400    0.7273    0.6809        22
         nqx     0.5714    0.2857    0.3810        14
         qtx     0.5952    0.7812    0.6757        32
         zxx     0.7429    0.6500    0.6933        40

    accuracy                         0.6324       185
   macro avg     0.6193    0.5676    0.5683       185
weighted avg     0.6405    0.6324    0.6201       185

micro f-score: 0.6324324324324324

Finished training!!!

Min Loss = 0.063 in epoch 58;
Max Accuracy = 69.73% in epoch 57;
Total Cost 38 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPPB: 1-4                              [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-27                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-40                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-46                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-52                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-59                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-65                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-71                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-77                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-83                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-89                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-96                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-102                  [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-108                  [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



