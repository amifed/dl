dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: sppb_resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.887	Accuracy: 26.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3158    0.1875    0.2353        32
         cwx     0.2000    0.5000    0.2857        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.2791    0.3750    0.3200        32
         zxx     0.3571    0.3750    0.3659        40

    accuracy                         0.2649       185
   macro avg     0.1646    0.2054    0.1724       185
weighted avg     0.2147    0.2649    0.2246       185

micro f-score: 0.2648648648648649

========== Train Epoch 2 ==========
Loss: 1.690	Accuracy: 30.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3269    0.5312    0.4048        32
         cwx     0.3462    0.2812    0.3103        32
         hdx     0.0741    0.1538    0.1000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.1500    0.2143    0.1765        14
         qtx     0.3404    0.5000    0.4051        32
         zxx     0.8182    0.2250    0.3529        40

    accuracy                         0.3027       185
   macro avg     0.2937    0.2722    0.2499       185
weighted avg     0.3688    0.3027    0.2905       185

micro f-score: 0.3027027027027027

========== Train Epoch 3 ==========
Loss: 1.555	Accuracy: 27.57%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5000    0.1250    0.2000        32
         cwx     1.0000    0.0312    0.0606        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.7000    0.2188    0.3333        32
         zxx     0.2500    0.9750    0.3980        40

    accuracy                         0.2757       185
   macro avg     0.3500    0.1929    0.1417       185
weighted avg     0.4346    0.2757    0.1888       185

micro f-score: 0.2756756756756757

========== Train Epoch 4 ==========
Loss: 1.398	Accuracy: 26.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2328    0.8438    0.3649        32
         cwx     0.3158    0.3750    0.3429        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.2000    0.3571    0.2564        14
         qtx     0.0000    0.0000    0.0000        32
         zxx     0.8333    0.1250    0.2174        40

    accuracy                         0.2649       185
   macro avg     0.2260    0.2430    0.1688       185
weighted avg     0.2902    0.2649    0.1888       185

micro f-score: 0.2648648648648649

========== Train Epoch 5 ==========
Loss: 1.303	Accuracy: 41.62%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.1429    0.0312    0.0513        32
         cwx     0.3485    0.7188    0.4694        32
         hdx     0.1250    0.0769    0.0952        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.1818    0.1429    0.1600        14
         qtx     0.5667    0.5312    0.5484        32
         zxx     0.5238    0.8250    0.6408        40

    accuracy                         0.4162       185
   macro avg     0.2698    0.3323    0.2807       185
weighted avg     0.3188    0.4162    0.3423       185

micro f-score: 0.41621621621621624

========== Train Epoch 6 ==========
Loss: 1.269	Accuracy: 48.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5238    0.3438    0.4151        32
         cwx     0.3830    0.5625    0.4557        32
         hdx     0.1333    0.1538    0.1429        13
         mtx     0.3571    0.2273    0.2778        22
         nqx     0.3333    0.0714    0.1176        14
         qtx     0.5641    0.6875    0.6197        32
         zxx     0.6522    0.7500    0.6977        40

    accuracy                         0.4811       185
   macro avg     0.4210    0.3995    0.3895       185
weighted avg     0.4725    0.4811    0.4606       185

micro f-score: 0.4810810810810811

========== Train Epoch 7 ==========
Loss: 1.172	Accuracy: 42.70%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6000    0.0938    0.1622        32
         cwx     0.5556    0.3125    0.4000        32
         hdx     0.2143    0.2308    0.2222        13
         mtx     0.2000    0.0909    0.1250        22
         nqx     0.1053    0.1429    0.1212        14
         qtx     0.3784    0.8750    0.5283        32
         zxx     0.6889    0.7750    0.7294        40

    accuracy                         0.4270       185
   macro avg     0.3918    0.3601    0.3269       185
weighted avg     0.4611    0.4270    0.3860       185

micro f-score: 0.427027027027027

========== Train Epoch 8 ==========
Loss: 1.049	Accuracy: 48.65%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4615    0.3750    0.4138        32
         cwx     0.7273    0.2500    0.3721        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2000    0.0455    0.0741        22
         nqx     0.4118    0.5000    0.4516        14
         qtx     0.5556    0.7812    0.6494        32
         zxx     0.4625    0.9250    0.6167        40

    accuracy                         0.4865       185
   macro avg     0.4027    0.4110    0.3682       185
weighted avg     0.4567    0.4865    0.4246       185

micro f-score: 0.4864864864864865

========== Train Epoch 9 ==========
Loss: 0.975	Accuracy: 43.24%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3793    0.3438    0.3607        32
         cwx     0.6842    0.4062    0.5098        32
         hdx     0.0833    0.0769    0.0800        13
         mtx     0.1923    0.6818    0.3000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.7826    0.5625    0.6545        32
         zxx     0.9565    0.5500    0.6984        40

    accuracy                         0.4324       185
   macro avg     0.4398    0.3745    0.3719       185
weighted avg     0.5549    0.4324    0.4561       185

micro f-score: 0.43243243243243246

========== Train Epoch 10 ==========
Loss: 0.858	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3281    0.6562    0.4375        32
         cwx     0.6500    0.4062    0.5000        32
         hdx     0.2069    0.4615    0.2857        13
         mtx     0.4118    0.3182    0.3590        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.4694    0.7188    0.5679        32
         zxx     0.8333    0.1250    0.2174        40

    accuracy                         0.4054       185
   macro avg     0.4142    0.3837    0.3382       185
weighted avg     0.4941    0.4054    0.3702       185

micro f-score: 0.40540540540540543

========== Train Epoch 11 ==========
Loss: 0.827	Accuracy: 38.92%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.1875    0.2727        32
         cwx     0.3099    0.6875    0.4272        32
         hdx     0.1875    0.4615    0.2667        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.2222    0.4286    0.2927        14
         qtx     0.8333    0.1562    0.2632        32
         zxx     0.7297    0.6750    0.7013        40

    accuracy                         0.3892       185
   macro avg     0.3975    0.3709    0.3177       185
weighted avg     0.4720    0.3892    0.3591       185

micro f-score: 0.3891891891891892

========== Train Epoch 12 ==========
Loss: 0.763	Accuracy: 52.43%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5714    0.5000    0.5333        32
         cwx     0.5152    0.5312    0.5231        32
         hdx     0.1429    0.0769    0.1000        13
         mtx     0.4000    0.1818    0.2500        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.5610    0.7188    0.6301        32
         zxx     0.5455    0.9000    0.6792        40

    accuracy                         0.5243       185
   macro avg     0.3908    0.4155    0.3880       185
weighted avg     0.4605    0.5243    0.4753       185

micro f-score: 0.5243243243243243

========== Train Epoch 13 ==========
Loss: 0.600	Accuracy: 42.16%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6842    0.4062    0.5098        32
         cwx     0.6333    0.5938    0.6129        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.1806    0.5909    0.2766        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     1.0000    0.0625    0.1176        32
         zxx     0.6200    0.7750    0.6889        40

    accuracy                         0.4216       185
   macro avg     0.4454    0.3469    0.3151       185
weighted avg     0.5564    0.4216    0.3964       185

micro f-score: 0.42162162162162165

========== Train Epoch 14 ==========
Loss: 0.560	Accuracy: 49.19%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3514    0.8125    0.4906        32
         cwx     0.6522    0.4688    0.5455        32
         hdx     0.3000    0.2308    0.2609        13
         mtx     0.4286    0.2727    0.3333        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.5682    0.7812    0.6579        32
         zxx     0.7895    0.3750    0.5085        40

    accuracy                         0.4919       185
   macro avg     0.5843    0.4303    0.4186       185
weighted avg     0.5903    0.4919    0.4710       185

micro f-score: 0.4918918918918919

========== Train Epoch 15 ==========
Loss: 0.507	Accuracy: 41.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2571    0.2812    0.2687        32
         cwx     0.2736    0.9062    0.4203        32
         hdx     0.5000    0.0769    0.1333        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.8500    0.5312    0.6538        32
         zxx     0.9545    0.5250    0.6774        40

    accuracy                         0.4162       185
   macro avg     0.4050    0.3315    0.3076       185
weighted avg     0.4804    0.4162    0.3881       185

micro f-score: 0.41621621621621624

========== Train Epoch 16 ==========
Loss: 0.381	Accuracy: 40.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.1562    0.2500        32
         cwx     0.4035    0.7188    0.5169        32
         hdx     1.0000    0.0769    0.1429        13
         mtx     0.3333    0.0455    0.0800        22
         nqx     0.1538    0.7143    0.2532        14
         qtx     0.0000    0.0000    0.0000        32
         zxx     0.6667    0.8500    0.7473        40

    accuracy                         0.4000       185
   macro avg     0.4546    0.3660    0.2843       185
weighted avg     0.4436    0.4000    0.3329       185

micro f-score: 0.4000000000000001

========== Train Epoch 17 ==========
Loss: 0.363	Accuracy: 50.81%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4762    0.3125    0.3774        32
         cwx     0.6207    0.5625    0.5902        32
         hdx     0.1471    0.3846    0.2128        13
         mtx     0.4000    0.0909    0.1481        22
         nqx     0.4444    0.2857    0.3478        14
         qtx     0.5472    0.9062    0.6824        32
         zxx     0.7647    0.6500    0.7027        40

    accuracy                         0.5081       185
   macro avg     0.4858    0.4561    0.4373       185
weighted avg     0.5413    0.5081    0.4962       185

micro f-score: 0.5081081081081081

========== Train Epoch 18 ==========
Loss: 0.321	Accuracy: 36.76%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.5306    0.8125    0.6420        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2037    0.5000    0.2895        22
         nqx     0.1667    0.6429    0.2647        14
         qtx     1.0000    0.1562    0.2703        32
         zxx     0.8947    0.4250    0.5763        40

    accuracy                         0.3676       185
   macro avg     0.3994    0.3624    0.2918       185
weighted avg     0.4950    0.3676    0.3368       185

micro f-score: 0.3675675675675676

========== Train Epoch 19 ==========
Loss: 0.275	Accuracy: 62.16%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4902    0.7812    0.6024        32
         cwx     0.6774    0.6562    0.6667        32
         hdx     0.3704    0.7692    0.5000        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     0.5833    0.5000    0.5385        14
         qtx     0.8500    0.5312    0.6538        32
         zxx     0.7907    0.8500    0.8193        40

    accuracy                         0.6216       185
   macro avg     0.6803    0.5905    0.5525       185
weighted avg     0.7090    0.6216    0.5960       185

micro f-score: 0.6216216216216216

========== Train Epoch 20 ==========
Loss: 0.242	Accuracy: 34.59%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.7917    0.5938    0.6786        32
         hdx     0.1125    0.6923    0.1935        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.5000    0.0714    0.1250        14
         qtx     0.4054    0.9375    0.5660        32
         zxx     1.0000    0.1250    0.2222        40

    accuracy                         0.3459       185
   macro avg     0.4014    0.3457    0.2551       185
weighted avg     0.4690    0.3459    0.2864       185

micro f-score: 0.34594594594594597

========== Train Epoch 21 ==========
Loss: 0.279	Accuracy: 54.59%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6429    0.2812    0.3913        32
         cwx     0.3797    0.9375    0.5405        32
         hdx     0.2143    0.2308    0.2222        13
         mtx     0.7500    0.1364    0.2308        22
         nqx     0.5000    0.5000    0.5000        14
         qtx     0.7097    0.6875    0.6984        32
         zxx     0.9310    0.6750    0.7826        40

    accuracy                         0.5459       185
   macro avg     0.5897    0.4926    0.4808       185
weighted avg     0.6430    0.5459    0.5321       185

micro f-score: 0.5459459459459459

========== Train Epoch 22 ==========
Loss: 0.227	Accuracy: 54.05%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5882    0.3125    0.4082        32
         cwx     0.7500    0.3750    0.5000        32
         hdx     0.2308    0.2308    0.2308        13
         mtx     0.4615    0.2727    0.3429        22
         nqx     0.2564    0.7143    0.3774        14
         qtx     0.7931    0.7188    0.7541        32
         zxx     0.6207    0.9000    0.7347        40

    accuracy                         0.5405       185
   macro avg     0.5287    0.5034    0.4783       185
weighted avg     0.5934    0.5405    0.5319       185

micro f-score: 0.5405405405405406

========== Train Epoch 23 ==========
Loss: 0.167	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4828    0.4375    0.4590        32
         cwx     0.6774    0.6562    0.6667        32
         hdx     0.2727    0.2308    0.2500        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     0.3333    0.2143    0.2609        14
         qtx     0.3523    0.9688    0.5167        32
         zxx     1.0000    0.4000    0.5714        40

    accuracy                         0.4811       185
   macro avg     0.5884    0.4219    0.4017       185
weighted avg     0.6411    0.4811    0.4553       185

micro f-score: 0.4810810810810811

========== Train Epoch 24 ==========
Loss: 0.138	Accuracy: 61.62%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6000    0.4688    0.5263        32
         cwx     0.8519    0.7188    0.7797        32
         hdx     0.3571    0.3846    0.3704        13
         mtx     0.3167    0.8636    0.4634        22
         nqx     1.0000    0.2857    0.4444        14
         qtx     0.8276    0.7500    0.7869        32
         zxx     0.9231    0.6000    0.7273        40

    accuracy                         0.6162       185
   macro avg     0.6966    0.5816    0.5855       185
weighted avg     0.7323    0.6162    0.6340       185

micro f-score: 0.6162162162162163

========== Train Epoch 25 ==========
Loss: 0.106	Accuracy: 59.46%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6667    0.1875    0.2927        32
         cwx     0.7407    0.6250    0.6780        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.8000    0.3636    0.5000        22
         nqx     0.3889    0.5000    0.4375        14
         qtx     0.6410    0.7812    0.7042        32
         zxx     0.5493    0.9750    0.7027        40

    accuracy                         0.5946       185
   macro avg     0.6059    0.5453    0.5331       185
weighted avg     0.6296    0.5946    0.5635       185

micro f-score: 0.5945945945945946

========== Train Epoch 26 ==========
Loss: 0.089	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5556    0.1562    0.2439        32
         cwx     0.3704    0.9375    0.5310        32
         hdx     0.4000    0.1538    0.2222        13
         mtx     0.7778    0.3182    0.4516        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.5490    0.8750    0.6747        32
         zxx     0.9310    0.6750    0.7826        40

    accuracy                         0.5405       185
   macro avg     0.6548    0.4553    0.4342       185
weighted avg     0.6527    0.5405    0.4994       185

micro f-score: 0.5405405405405406

========== Train Epoch 27 ==========
Loss: 0.080	Accuracy: 62.70%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.7059    0.3750    0.4898        32
         cwx     0.6279    0.8438    0.7200        32
         hdx     0.2500    0.3846    0.3030        13
         mtx     0.5455    0.2727    0.3636        22
         nqx     0.3462    0.6429    0.4500        14
         qtx     0.8000    0.7500    0.7742        32
         zxx     0.8684    0.8250    0.8462        40

    accuracy                         0.6270       185
   macro avg     0.5920    0.5848    0.5638       185
weighted avg     0.6655    0.6270    0.6247       185

micro f-score: 0.6270270270270271

========== Train Epoch 28 ==========
Loss: 0.125	Accuracy: 51.89%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5294    0.2812    0.3673        32
         cwx     0.7857    0.3438    0.4783        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.3023    0.5909    0.4000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.8387    0.8125    0.8254        32
         zxx     0.4675    0.9000    0.6154        40

    accuracy                         0.5189       185
   macro avg     0.4653    0.4293    0.4016       185
weighted avg     0.5330    0.5189    0.4784       185

micro f-score: 0.518918918918919

========== Train Epoch 29 ==========
Loss: 0.109	Accuracy: 48.11%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2889    0.8125    0.4262        32
         cwx     0.7143    0.3125    0.4348        32
         hdx     0.3333    0.3077    0.3200        13
         mtx     0.3704    0.4545    0.4082        22
         nqx     1.0000    0.2143    0.3529        14
         qtx     0.8846    0.7188    0.7931        32
         zxx     1.0000    0.3250    0.4906        40

    accuracy                         0.4811       185
   macro avg     0.6559    0.4493    0.4608       185
weighted avg     0.6859    0.4811    0.4899       185

micro f-score: 0.4810810810810811

========== Train Epoch 30 ==========
Loss: 0.149	Accuracy: 37.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2000    0.0625    0.0952        32
         cwx     0.4898    0.7500    0.5926        32
         hdx     0.1818    0.1538    0.1667        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.3048    1.0000    0.4672        32
         zxx     1.0000    0.2500    0.4000        40

    accuracy                         0.3784       185
   macro avg     0.3109    0.3166    0.2460       185
weighted avg     0.4010    0.3784    0.2980       185

micro f-score: 0.37837837837837834

========== Train Epoch 31 ==========
Loss: 0.100	Accuracy: 62.16%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6061    0.6250    0.6154        32
         cwx     0.8182    0.5625    0.6667        32
         hdx     0.2800    0.5385    0.3684        13
         mtx     0.5833    0.3182    0.4118        22
         nqx     0.7500    0.4286    0.5455        14
         qtx     0.6667    0.6875    0.6769        32
         zxx     0.6731    0.8750    0.7609        40

    accuracy                         0.6216       185
   macro avg     0.6253    0.5765    0.5779       185
weighted avg     0.6530    0.6216    0.6195       185

micro f-score: 0.6216216216216216

========== Train Epoch 32 ==========
Loss: 0.092	Accuracy: 48.65%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5333    0.2500    0.3404        32
         cwx     0.3373    0.8750    0.4870        32
         hdx     0.2222    0.3077    0.2581        13
         mtx     0.5556    0.2273    0.3226        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.6667    0.7500    0.7059        32
         zxx     0.8750    0.5250    0.6563        40

    accuracy                         0.4865       185
   macro avg     0.4557    0.4193    0.3957       185
weighted avg     0.5368    0.4865    0.4636       185

micro f-score: 0.4864864864864865

========== Train Epoch 33 ==========
Loss: 0.087	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5556    0.4688    0.5085        32
         cwx     1.0000    0.3750    0.5455        32
         hdx     0.3200    0.6154    0.4211        13
         mtx     0.7143    0.2273    0.3448        22
         nqx     0.7500    0.2143    0.3333        14
         qtx     0.4909    0.8438    0.6207        32
         zxx     0.6182    0.8500    0.7158        40

    accuracy                         0.5622       185
   macro avg     0.6356    0.5135    0.4985       185
weighted avg     0.6518    0.5622    0.5402       185

micro f-score: 0.5621621621621622

========== Train Epoch 34 ==========
Loss: 0.078	Accuracy: 47.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3333    0.0625    0.1053        32
         cwx     1.0000    0.2500    0.4000        32
         hdx     0.4000    0.3077    0.3478        13
         mtx     0.2405    0.8636    0.3762        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.5652    0.8125    0.6667        32
         zxx     0.8056    0.7250    0.7632        40

    accuracy                         0.4757       185
   macro avg     0.4778    0.4316    0.3799       185
weighted avg     0.5593    0.4757    0.4369       185

micro f-score: 0.4756756756756757

========== Train Epoch 35 ==========
Loss: 0.047	Accuracy: 65.41%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5102    0.7812    0.6173        32
         cwx     0.5814    0.7812    0.6667        32
         hdx     0.5455    0.4615    0.5000        13
         mtx     0.5625    0.4091    0.4737        22
         nqx     0.7500    0.2143    0.3333        14
         qtx     0.8065    0.7812    0.7937        32
         zxx     0.9032    0.7000    0.7887        40

    accuracy                         0.6541       185
   macro avg     0.6656    0.5898    0.5962       185
weighted avg     0.6856    0.6541    0.6466       185

micro f-score: 0.654054054054054

========== Train Epoch 36 ==========
Loss: 0.037	Accuracy: 61.08%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6923    0.2812    0.4000        32
         cwx     0.7931    0.7188    0.7541        32
         hdx     0.3077    0.6154    0.4103        13
         mtx     0.4667    0.3182    0.3784        22
         nqx     1.0000    0.1429    0.2500        14
         qtx     0.5283    0.8750    0.6588        32
         zxx     0.7660    0.9000    0.8276        40

    accuracy                         0.6108       185
   macro avg     0.6506    0.5502    0.5256       185
weighted avg     0.6667    0.6108    0.5853       185

micro f-score: 0.6108108108108108

========== Train Epoch 37 ==========
Loss: 0.047	Accuracy: 58.38%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6923    0.2812    0.4000        32
         cwx     0.7188    0.7188    0.7188        32
         hdx     0.3333    0.3077    0.3200        13
         mtx     0.3333    0.4545    0.3846        22
         nqx     0.5000    0.1429    0.2222        14
         qtx     0.5532    0.8125    0.6582        32
         zxx     0.7234    0.8500    0.7816        40

    accuracy                         0.5838       185
   macro avg     0.5506    0.5097    0.4979       185
weighted avg     0.5971    0.5838    0.5614       185

micro f-score: 0.5837837837837838

========== Train Epoch 38 ==========
Loss: 0.032	Accuracy: 60.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4500    0.8438    0.5870        32
         cwx     0.7778    0.6562    0.7119        32
         hdx     0.3333    0.2308    0.2727        13
         mtx     0.6000    0.2727    0.3750        22
         nqx     0.4000    0.5714    0.4706        14
         qtx     0.7917    0.5938    0.6786        32
         zxx     0.7714    0.6750    0.7200        40

    accuracy                         0.6000       185
   macro avg     0.5892    0.5491    0.5451       185
weighted avg     0.6411    0.6000    0.5971       185

micro f-score: 0.6

========== Train Epoch 39 ==========
Loss: 0.032	Accuracy: 55.68%	Cost 35s
              precision    recall  f1-score   support

         bzx     1.0000    0.0312    0.0606        32
         cwx     0.7857    0.6875    0.7333        32
         hdx     0.2083    0.3846    0.2703        13
         mtx     0.3000    0.6818    0.4167        22
         nqx     0.4000    0.1429    0.2105        14
         qtx     0.6136    0.8438    0.7105        32
         zxx     0.9394    0.7750    0.8493        40

    accuracy                         0.5568       185
   macro avg     0.6067    0.5067    0.4645       185
weighted avg     0.6987    0.5568    0.5283       185

micro f-score: 0.5567567567567567

========== Train Epoch 40 ==========
Loss: 0.033	Accuracy: 63.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6129    0.5938    0.6032        32
         cwx     0.7812    0.7812    0.7812        32
         hdx     0.3846    0.3846    0.3846        13
         mtx     0.5385    0.3182    0.4000        22
         nqx     0.5000    0.0714    0.1250        14
         qtx     0.5179    0.9062    0.6591        32
         zxx     0.8158    0.7750    0.7949        40

    accuracy                         0.6324       185
   macro avg     0.5930    0.5472    0.5354       185
weighted avg     0.6360    0.6324    0.6094       185

micro f-score: 0.6324324324324324

========== Train Epoch 41 ==========
Loss: 0.048	Accuracy: 47.03%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.0625    0.1143        32
         cwx     0.8462    0.3438    0.4889        32
         hdx     0.1250    0.0769    0.0952        13
         mtx     0.2039    0.9545    0.3360        22
         nqx     1.0000    0.2143    0.3529        14
         qtx     0.8636    0.5938    0.7037        32
         zxx     0.9091    0.7500    0.8219        40

    accuracy                         0.4703       185
   macro avg     0.6592    0.4280    0.4161       185
weighted avg     0.7163    0.4703    0.4771       185

micro f-score: 0.4702702702702703

========== Train Epoch 42 ==========
Loss: 0.065	Accuracy: 51.35%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.3500    0.8750    0.5000        32
         cwx     0.7600    0.5938    0.6667        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.6667    0.0909    0.1600        22
         nqx     0.3750    0.4286    0.4000        14
         qtx     0.8750    0.4375    0.5833        32
         zxx     0.5909    0.6500    0.6190        40

    accuracy                         0.5135       185
   macro avg     0.5168    0.4394    0.4184       185
weighted avg     0.5788    0.5135    0.4858       185

micro f-score: 0.5135135135135135

========== Train Epoch 43 ==========
Loss: 0.104	Accuracy: 41.62%	Cost 37s
              precision    recall  f1-score   support

         bzx     0.3611    0.4062    0.3824        32
         cwx     0.4643    0.8125    0.5909        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2419    0.6818    0.3571        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.7895    0.4688    0.5882        32
         zxx     1.0000    0.2000    0.3333        40

    accuracy                         0.4162       185
   macro avg     0.4081    0.3670    0.3217       185
weighted avg     0.5243    0.4162    0.3846       185

micro f-score: 0.41621621621621624

========== Train Epoch 44 ==========
Loss: 0.191	Accuracy: 35.68%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3333    0.0625    0.1053        32
         cwx     0.3176    0.8438    0.4615        32
         hdx     0.1400    0.5385    0.2222        13
         mtx     0.5000    0.0455    0.0833        22
         nqx     0.3000    0.2143    0.2500        14
         qtx     0.7391    0.5312    0.6182        32
         zxx     1.0000    0.2250    0.3673        40

    accuracy                         0.3568       185
   macro avg     0.4757    0.3515    0.3011       185
weighted avg     0.5487    0.3568    0.3288       185

micro f-score: 0.3567567567567568

========== Train Epoch 45 ==========
Loss: 0.281	Accuracy: 26.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.0312    0.0606        32
         cwx     0.4667    0.2188    0.2979        32
         hdx     0.0962    0.7692    0.1709        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.4333    0.8125    0.5652        32
         zxx     1.0000    0.1000    0.1818        40

    accuracy                         0.2649       185
   macro avg     0.5709    0.2825    0.1948       185
weighted avg     0.6705    0.2649    0.2214       185

micro f-score: 0.2648648648648649

========== Train Epoch 46 ==========
Loss: 0.213	Accuracy: 41.08%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3500    0.4375    0.3889        32
         cwx     0.8571    0.1875    0.3077        32
         hdx     0.4000    0.1538    0.2222        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.3048    1.0000    0.4672        32
         zxx     0.7692    0.5000    0.6061        40

    accuracy                         0.4108       185
   macro avg     0.6687    0.3422    0.3160       185
weighted avg     0.6505    0.4108    0.3684       185

micro f-score: 0.4108108108108109

========== Train Epoch 47 ==========
Loss: 0.151	Accuracy: 41.62%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4375    0.4375    0.4375        32
         cwx     0.9167    0.3438    0.5000        32
         hdx     0.1538    0.1538    0.1538        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.1687    1.0000    0.2887        14
         qtx     0.9231    0.3750    0.5333        32
         zxx     0.7500    0.6000    0.6667        40

    accuracy                         0.4162       185
   macro avg     0.4785    0.4157    0.3686       185
weighted avg     0.5796    0.4162    0.4312       185

micro f-score: 0.41621621621621624

========== Train Epoch 48 ==========
Loss: 0.121	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3485    0.7188    0.4694        32
         cwx     0.6207    0.5625    0.5902        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.5714    0.1818    0.2759        22
         nqx     0.2857    0.1429    0.1905        14
         qtx     0.4746    0.8750    0.6154        32
         zxx     0.9286    0.3250    0.4815        40

    accuracy                         0.4811       185
   macro avg     0.5090    0.4118    0.3925       185
weighted avg     0.5635    0.4811    0.4498       185

micro f-score: 0.4810810810810811

========== Train Epoch 49 ==========
Loss: 0.076	Accuracy: 54.05%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.4091    0.8438    0.5510        32
         hdx     0.4286    0.2308    0.3000        13
         mtx     0.8333    0.2273    0.3571        22
         nqx     0.5455    0.4286    0.4800        14
         qtx     0.6667    0.7500    0.7059        32
         zxx     0.5932    0.8750    0.7071        40

    accuracy                         0.5405       185
   macro avg     0.4966    0.4793    0.4430       185
weighted avg     0.4848    0.5405    0.4702       185

micro f-score: 0.5405405405405406

========== Train Epoch 50 ==========
Loss: 0.055	Accuracy: 58.92%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5238    0.3438    0.4151        32
         cwx     0.5625    0.8438    0.6750        32
         hdx     0.2000    0.1538    0.1739        13
         mtx     0.4444    0.1818    0.2581        22
         nqx     0.4500    0.6429    0.5294        14
         qtx     0.6250    0.7812    0.6944        32
         zxx     0.8378    0.7750    0.8052        40

    accuracy                         0.5892       185
   macro avg     0.5205    0.5318    0.5073       185
weighted avg     0.5781    0.5892    0.5657       185

micro f-score: 0.5891891891891892

========== Train Epoch 51 ==========
Loss: 0.039	Accuracy: 62.16%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5909    0.4062    0.4815        32
         cwx     0.8000    0.7500    0.7742        32
         hdx     0.3182    0.5385    0.4000        13
         mtx     0.3103    0.4091    0.3529        22
         nqx     0.6000    0.4286    0.5000        14
         qtx     0.7059    0.7500    0.7273        32
         zxx     0.8421    0.8000    0.8205        40

    accuracy                         0.6216       185
   macro avg     0.5953    0.5832    0.5795       185
weighted avg     0.6494    0.6216    0.6283       185

micro f-score: 0.6216216216216216

========== Train Epoch 52 ==========
Loss: 0.028	Accuracy: 64.86%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5862    0.5312    0.5574        32
         cwx     0.7500    0.7500    0.7500        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.6364    0.3182    0.4242        22
         nqx     0.4091    0.6429    0.5000        14
         qtx     0.7059    0.7500    0.7273        32
         zxx     0.7391    0.8500    0.7907        40

    accuracy                         0.6486       185
   macro avg     0.6116    0.6038    0.5952       185
weighted avg     0.6516    0.6486    0.6405       185

micro f-score: 0.6486486486486487

========== Train Epoch 53 ==========
Loss: 0.023	Accuracy: 64.86%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5455    0.5625    0.5538        32
         cwx     0.6842    0.8125    0.7429        32
         hdx     0.3571    0.3846    0.3704        13
         mtx     0.5714    0.3636    0.4444        22
         nqx     0.8000    0.2857    0.4211        14
         qtx     0.6579    0.7812    0.7143        32
         zxx     0.7907    0.8500    0.8193        40

    accuracy                         0.6486       185
   macro avg     0.6295    0.5772    0.5809       185
weighted avg     0.6510    0.6486    0.6357       185

micro f-score: 0.6486486486486487

========== Train Epoch 54 ==========
Loss: 0.024	Accuracy: 68.11%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5938    0.5938    0.5938        32
         cwx     0.7667    0.7188    0.7419        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.6154    0.3636    0.4571        22
         nqx     0.8750    0.5000    0.6364        14
         qtx     0.6829    0.8750    0.7671        32
         zxx     0.7200    0.9000    0.8000        40

    accuracy                         0.6811       185
   macro avg     0.6726    0.6194    0.6304       185
weighted avg     0.6805    0.6811    0.6685       185

micro f-score: 0.6810810810810811

========== Train Epoch 55 ==========
Loss: 0.023	Accuracy: 63.78%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6364    0.4375    0.5185        32
         cwx     0.6757    0.7812    0.7246        32
         hdx     0.5556    0.3846    0.4545        13
         mtx     0.4706    0.3636    0.4103        22
         nqx     0.5000    0.4286    0.4615        14
         qtx     0.7500    0.7500    0.7500        32
         zxx     0.6429    0.9000    0.7500        40

    accuracy                         0.6378       185
   macro avg     0.6044    0.5779    0.5814       185
weighted avg     0.6285    0.6378    0.6226       185

micro f-score: 0.6378378378378379

========== Train Epoch 56 ==========
Loss: 0.023	Accuracy: 63.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5862    0.5312    0.5574        32
         cwx     0.6098    0.7812    0.6849        32
         hdx     0.2667    0.3077    0.2857        13
         mtx     0.6364    0.3182    0.4242        22
         nqx     0.5455    0.4286    0.4800        14
         qtx     0.6500    0.8125    0.7222        32
         zxx     0.8421    0.8000    0.8205        40

    accuracy                         0.6324       185
   macro avg     0.5909    0.5685    0.5679       185
weighted avg     0.6371    0.6324    0.6241       185

micro f-score: 0.6324324324324324

========== Train Epoch 57 ==========
Loss: 0.015	Accuracy: 66.49%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6053    0.7188    0.6571        32
         cwx     0.7586    0.6875    0.7213        32
         hdx     0.3333    0.3846    0.3571        13
         mtx     0.4667    0.3182    0.3784        22
         nqx     0.6364    0.5000    0.5600        14
         qtx     0.7500    0.7500    0.7500        32
         zxx     0.7778    0.8750    0.8235        40

    accuracy                         0.6649       185
   macro avg     0.6183    0.6049    0.6068       185
weighted avg     0.6609    0.6649    0.6587       185

micro f-score: 0.6648648648648648

========== Train Epoch 58 ==========
Loss: 0.021	Accuracy: 63.24%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.4375    0.5283        32
         cwx     0.7742    0.7500    0.7619        32
         hdx     0.4167    0.3846    0.4000        13
         mtx     0.5556    0.2273    0.3226        22
         nqx     0.4706    0.5714    0.5161        14
         qtx     0.6667    0.7500    0.7059        32
         zxx     0.6271    0.9250    0.7475        40

    accuracy                         0.6324       185
   macro avg     0.5968    0.5780    0.5689       185
weighted avg     0.6311    0.6324    0.6124       185

micro f-score: 0.6324324324324324

========== Train Epoch 59 ==========
Loss: 0.017	Accuracy: 67.57%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6364    0.4375    0.5185        32
         cwx     0.6923    0.8438    0.7606        32
         hdx     0.4615    0.4615    0.4615        13
         mtx     0.6154    0.3636    0.4571        22
         nqx     0.6667    0.5714    0.6154        14
         qtx     0.6667    0.8125    0.7324        32
         zxx     0.7660    0.9000    0.8276        40

    accuracy                         0.6757       185
   macro avg     0.6436    0.6272    0.6247       185
weighted avg     0.6668    0.6757    0.6602       185

micro f-score: 0.6756756756756757

========== Train Epoch 60 ==========
Loss: 0.017	Accuracy: 62.70%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.3125    0.4167        32
         cwx     0.7222    0.8125    0.7647        32
         hdx     0.2083    0.3846    0.2703        13
         mtx     0.5385    0.3182    0.4000        22
         nqx     0.7778    0.5000    0.6087        14
         qtx     0.6136    0.8438    0.7105        32
         zxx     0.7907    0.8500    0.8193        40

    accuracy                         0.6270       185
   macro avg     0.6109    0.5745    0.5700       185
weighted avg     0.6477    0.6270    0.6170       185

micro f-score: 0.6270270270270271

========== Train Epoch 61 ==========
Loss: 0.018	Accuracy: 69.73%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5909    0.8125    0.6842        32
         cwx     0.8462    0.6875    0.7586        32
         hdx     0.3750    0.4615    0.4138        13
         mtx     0.5455    0.2727    0.3636        22
         nqx     0.6923    0.6429    0.6667        14
         qtx     0.7297    0.8438    0.7826        32
         zxx     0.8684    0.8250    0.8462        40

    accuracy                         0.6973       185
   macro avg     0.6640    0.6494    0.6451       185
weighted avg     0.7062    0.6973    0.6907       185

micro f-score: 0.6972972972972973

========== Train Epoch 62 ==========
Loss: 0.018	Accuracy: 67.57%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6471    0.6875    0.6667        32
         cwx     0.7857    0.6875    0.7333        32
         hdx     0.3158    0.4615    0.3750        13
         mtx     0.5833    0.3182    0.4118        22
         nqx     0.7273    0.5714    0.6400        14
         qtx     0.7143    0.7812    0.7463        32
         zxx     0.7609    0.8750    0.8140        40

    accuracy                         0.6757       185
   macro avg     0.6478    0.6261    0.6267       185
weighted avg     0.6825    0.6757    0.6710       185

micro f-score: 0.6756756756756757

========== Train Epoch 63 ==========
Loss: 0.013	Accuracy: 67.03%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6061    0.6250    0.6154        32
         cwx     0.7241    0.6562    0.6885        32
         hdx     0.4000    0.4615    0.4286        13
         mtx     0.4706    0.3636    0.4103        22
         nqx     0.7778    0.5000    0.6087        14
         qtx     0.7429    0.8125    0.7761        32
         zxx     0.7660    0.9000    0.8276        40

    accuracy                         0.6703       185
   macro avg     0.6411    0.6170    0.6222       185
weighted avg     0.6671    0.6703    0.6637       185

micro f-score: 0.6702702702702703

========== Train Epoch 64 ==========
Loss: 0.017	Accuracy: 70.27%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5918    0.9062    0.7160        32
         cwx     0.7857    0.6875    0.7333        32
         hdx     0.4545    0.3846    0.4167        13
         mtx     0.8000    0.3636    0.5000        22
         nqx     0.7273    0.5714    0.6400        14
         qtx     0.8000    0.7500    0.7742        32
         zxx     0.7391    0.8500    0.7907        40

    accuracy                         0.7027       185
   macro avg     0.6998    0.6448    0.6530       185
weighted avg     0.7186    0.7027    0.6928       185

micro f-score: 0.7027027027027027

Finished training!!!

Min Loss = 0.013 in epoch 62;
Max Accuracy = 70.27% in epoch 63;
Total Cost 37 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPPB: 1-4                              [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-27                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-40                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-46                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-52                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-59                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-65                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-71                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-77                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-83                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-89                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-96                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-102                  [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-108                  [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



