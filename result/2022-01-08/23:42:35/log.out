dataset_path: /home/djy/dataset/dataset2
pretrained : False 
parallel: False

net: sppb_resnet.resnet34
msg: 
using model: ResNet, resnet34
using device cuda:0
batch_size = 20
epochs = 64
loss_function = CrossEntropyLoss()
optimizer = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)


========== Train Epoch 1 ==========
Loss: 1.885	Accuracy: 29.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3000    0.0938    0.1429        32
         cwx     0.3721    0.5000    0.4267        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2000    0.2273    0.2128        22
         nqx     0.1429    0.0714    0.0952        14
         qtx     0.3333    0.1875    0.2400        32
         zxx     0.3000    0.6000    0.4000        40

    accuracy                         0.2973       185
   macro avg     0.2355    0.2400    0.2168       185
weighted avg     0.2734    0.2973    0.2590       185

micro f-score: 0.2972972972972973

========== Train Epoch 2 ==========
Loss: 1.717	Accuracy: 29.19%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4000    0.1250    0.1905        32
         cwx     0.3333    0.0938    0.1463        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.5000    0.0455    0.0833        22
         nqx     0.1471    0.7143    0.2439        14
         qtx     0.5000    0.1562    0.2381        32
         zxx     0.3690    0.7750    0.5000        40

    accuracy                         0.2919       185
   macro avg     0.3213    0.2728    0.2003       185
weighted avg     0.3637    0.2919    0.2359       185

micro f-score: 0.2918918918918919

========== Train Epoch 3 ==========
Loss: 1.638	Accuracy: 37.30%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4167    0.3125    0.3571        32
         cwx     0.5000    0.1250    0.2000        32
         hdx     0.0909    0.0769    0.0833        13
         mtx     0.2500    0.0455    0.0769        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.3462    0.8438    0.4909        32
         zxx     0.4727    0.6500    0.5474        40

    accuracy                         0.3730       185
   macro avg     0.2966    0.2934    0.2508       185
weighted avg     0.3568    0.3730    0.3146       185

micro f-score: 0.37297297297297294

========== Train Epoch 4 ==========
Loss: 1.455	Accuracy: 35.14%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3478    0.2500    0.2909        32
         cwx     0.3929    0.3438    0.3667        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2000    0.4545    0.2778        22
         nqx     0.3684    0.5000    0.4242        14
         qtx     0.3585    0.5938    0.4471        32
         zxx     0.9091    0.2500    0.3922        40

    accuracy                         0.3514       185
   macro avg     0.3681    0.3417    0.3141       185
weighted avg     0.4384    0.3514    0.3410       185

micro f-score: 0.35135135135135137

========== Train Epoch 5 ==========
Loss: 1.405	Accuracy: 42.16%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3140    0.8438    0.4576        32
         cwx     0.3600    0.2812    0.3158        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.4286    0.4286    0.4286        14
         qtx     0.6667    0.4375    0.5283        32
         zxx     0.5789    0.5500    0.5641        40

    accuracy                         0.4216       185
   macro avg     0.3354    0.3630    0.3278       185
weighted avg     0.3895    0.4216    0.3796       185

micro f-score: 0.42162162162162165

========== Train Epoch 6 ==========
Loss: 1.303	Accuracy: 31.35%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3636    0.2500    0.2963        32
         cwx     0.2697    0.7500    0.3967        32
         hdx     0.0769    0.0769    0.0769        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.1842    0.5000    0.2692        14
         qtx     0.7500    0.1875    0.3000        32
         zxx     0.9231    0.3000    0.4528        40

    accuracy                         0.3135       185
   macro avg     0.3668    0.2949    0.2560       185
weighted avg     0.4582    0.3135    0.2954       185

micro f-score: 0.31351351351351353

========== Train Epoch 7 ==========
Loss: 1.249	Accuracy: 32.97%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.2700    0.8438    0.4091        32
         hdx     0.1667    0.1538    0.1600        13
         mtx     0.4000    0.0909    0.1481        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.4107    0.7188    0.5227        32
         zxx     1.0000    0.1750    0.2979        40

    accuracy                         0.3297       185
   macro avg     0.3211    0.2832    0.2197       185
weighted avg     0.3932    0.3297    0.2544       185

micro f-score: 0.32972972972972975

========== Train Epoch 8 ==========
Loss: 1.092	Accuracy: 32.43%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3958    0.5938    0.4750        32
         cwx     0.4000    0.6250    0.4878        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.2857    0.0909    0.1379        22
         nqx     0.1404    0.5714    0.2254        14
         qtx     1.0000    0.0938    0.1714        32
         zxx     0.6154    0.2000    0.3019        40

    accuracy                         0.3243       185
   macro avg     0.4053    0.3107    0.2571       185
weighted avg     0.4883    0.3243    0.2949       185

micro f-score: 0.32432432432432434

========== Train Epoch 9 ==========
Loss: 1.057	Accuracy: 44.86%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3684    0.4375    0.4000        32
         cwx     0.5238    0.3438    0.4151        32
         hdx     0.1429    0.2308    0.1765        13
         mtx     0.3125    0.2273    0.2632        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.5106    0.7500    0.6076        32
         zxx     0.6216    0.5750    0.5974        40

    accuracy                         0.4486       185
   macro avg     0.4400    0.3969    0.3965       185
weighted avg     0.4697    0.4486    0.4428       185

micro f-score: 0.4486486486486486

========== Train Epoch 10 ==========
Loss: 0.912	Accuracy: 33.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     1.0000    0.0312    0.0606        32
         cwx     0.6842    0.4062    0.5098        32
         hdx     0.0870    0.1538    0.1111        13
         mtx     0.1667    0.1818    0.1739        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.2871    0.9062    0.4361        32
         zxx     0.8125    0.3250    0.4643        40

    accuracy                         0.3351       185
   macro avg     0.4339    0.2863    0.2508       185
weighted avg     0.5426    0.3351    0.3030       185

micro f-score: 0.33513513513513515

========== Train Epoch 11 ==========
Loss: 0.851	Accuracy: 40.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3929    0.3438    0.3667        32
         cwx     0.3659    0.4688    0.4110        32
         hdx     0.2500    0.1538    0.1905        13
         mtx     0.1429    0.1364    0.1395        22
         nqx     0.4000    0.1429    0.2105        14
         qtx     0.7273    0.2500    0.3721        32
         zxx     0.4789    0.8500    0.6126        40

    accuracy                         0.4054       185
   macro avg     0.3940    0.3351    0.3290       185
weighted avg     0.4254    0.4054    0.3772       185

micro f-score: 0.40540540540540543

========== Train Epoch 12 ==========
Loss: 0.944	Accuracy: 45.41%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.2969    0.5938    0.3958        32
         cwx     0.5926    0.5000    0.5424        32
         hdx     0.1250    0.0769    0.0952        13
         mtx     0.3333    0.1364    0.1935        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.5897    0.7188    0.6479        32
         zxx     0.6875    0.5500    0.6111        40

    accuracy                         0.4541       185
   macro avg     0.3750    0.3680    0.3551       185
weighted avg     0.4529    0.4541    0.4362       185

micro f-score: 0.4540540540540541

========== Train Epoch 13 ==========
Loss: 0.778	Accuracy: 43.78%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4062    0.4062    0.4062        32
         cwx     0.6667    0.5000    0.5714        32
         hdx     0.1818    0.1538    0.1667        13
         mtx     0.1972    0.6364    0.3011        22
         nqx     0.3333    0.0714    0.1176        14
         qtx     1.0000    0.2812    0.4390        32
         zxx     0.7429    0.6500    0.6933        40

    accuracy                         0.4378       185
   macro avg     0.5040    0.3856    0.3851       185
weighted avg     0.5806    0.4378    0.4514       185

micro f-score: 0.43783783783783786

========== Train Epoch 14 ==========
Loss: 0.651	Accuracy: 36.76%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2885    0.4688    0.3571        32
         cwx     0.7692    0.3125    0.4444        32
         hdx     0.1190    0.3846    0.1818        13
         mtx     0.2400    0.2727    0.2553        22
         nqx     0.3158    0.4286    0.3636        14
         qtx     0.7333    0.3438    0.4681        32
         zxx     0.7895    0.3750    0.5085        40

    accuracy                         0.3676       185
   macro avg     0.4650    0.3694    0.3684       185
weighted avg     0.5413    0.3676    0.4002       185

micro f-score: 0.3675675675675676

========== Train Epoch 15 ==========
Loss: 0.655	Accuracy: 29.19%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.2381    0.1562    0.1887        32
         cwx     0.2206    0.9375    0.3571        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.0000    0.0000    0.0000        22
         nqx     0.3333    0.0714    0.1176        14
         qtx     0.8750    0.2188    0.3500        32
         zxx     0.7333    0.2750    0.4000        40

    accuracy                         0.2919       185
   macro avg     0.3429    0.2370    0.2019       185
weighted avg     0.4145    0.2919    0.2503       185

micro f-score: 0.2918918918918919

========== Train Epoch 16 ==========
Loss: 0.594	Accuracy: 41.62%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4035    0.7188    0.5169        32
         cwx     0.8000    0.2500    0.3810        32
         hdx     0.1277    0.4615    0.2000        13
         mtx     0.2000    0.1818    0.1905        22
         nqx     1.0000    0.1429    0.2500        14
         qtx     1.0000    0.2812    0.4390        32
         zxx     0.6250    0.6250    0.6250        40

    accuracy                         0.4162       185
   macro avg     0.5937    0.3802    0.3718       185
weighted avg     0.6247    0.4162    0.4220       185

micro f-score: 0.41621621621621624

========== Train Epoch 17 ==========
Loss: 0.544	Accuracy: 52.97%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4211    0.5000    0.4571        32
         cwx     0.8000    0.3750    0.5106        32
         hdx     0.2105    0.3077    0.2500        13
         mtx     0.4000    0.1818    0.2500        22
         nqx     0.2941    0.7143    0.4167        14
         qtx     0.7857    0.6875    0.7333        32
         zxx     0.7317    0.7500    0.7407        40

    accuracy                         0.5297       185
   macro avg     0.5204    0.5023    0.4798       185
weighted avg     0.5899    0.5297    0.5332       185

micro f-score: 0.5297297297297298

========== Train Epoch 18 ==========
Loss: 0.463	Accuracy: 47.57%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5556    0.1562    0.2439        32
         cwx     1.0000    0.2812    0.4390        32
         hdx     0.2857    0.3077    0.2963        13
         mtx     0.2222    0.0909    0.1290        22
         nqx     0.2683    0.7857    0.4000        14
         qtx     0.6471    0.6875    0.6667        32
         zxx     0.5072    0.8750    0.6422        40

    accuracy                         0.4757       185
   macro avg     0.4980    0.4549    0.4024       185
weighted avg     0.5575    0.4757    0.4387       185

micro f-score: 0.4756756756756757

========== Train Epoch 19 ==========
Loss: 0.443	Accuracy: 37.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.5366    0.6875    0.6027        32
         hdx     0.0862    0.3846    0.1408        13
         mtx     0.1250    0.0455    0.0667        22
         nqx     0.3684    0.5000    0.4242        14
         qtx     0.5116    0.6875    0.5867        32
         zxx     0.8667    0.3250    0.4727        40

    accuracy                         0.3784       185
   macro avg     0.3564    0.3757    0.3277       185
weighted avg     0.4175    0.3784    0.3579       185

micro f-score: 0.37837837837837834

========== Train Epoch 20 ==========
Loss: 0.300	Accuracy: 21.62%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     1.0000    0.0312    0.0606        32
         hdx     0.0968    0.9231    0.1752        13
         mtx     0.1379    0.1818    0.1569        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.7391    0.5312    0.6182        32
         zxx     1.0000    0.1500    0.2609        40

    accuracy                         0.2162       185
   macro avg     0.4248    0.2596    0.1817       185
weighted avg     0.5402    0.2162    0.2048       185

micro f-score: 0.21621621621621623

========== Train Epoch 21 ==========
Loss: 0.296	Accuracy: 47.03%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.3214    0.5625    0.4091        32
         cwx     0.9375    0.4688    0.6250        32
         hdx     0.3333    0.1538    0.2105        13
         mtx     0.3750    0.1364    0.2000        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.3766    0.9062    0.5321        32
         zxx     0.9091    0.5000    0.6452        40

    accuracy                         0.4703       185
   macro avg     0.4647    0.3897    0.3746       185
weighted avg     0.5475    0.4703    0.4490       185

micro f-score: 0.4702702702702703

========== Train Epoch 22 ==========
Loss: 0.241	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5909    0.4062    0.4815        32
         cwx     0.9167    0.3438    0.5000        32
         hdx     0.6667    0.1538    0.2500        13
         mtx     0.6667    0.2727    0.3871        22
         nqx     0.2857    0.2857    0.2857        14
         qtx     0.6538    0.5312    0.5862        32
         zxx     0.3838    0.9500    0.5468        40

    accuracy                         0.4919       185
   macro avg     0.5949    0.4205    0.4339       185
weighted avg     0.6046    0.4919    0.4746       185

micro f-score: 0.4918918918918919

========== Train Epoch 23 ==========
Loss: 0.305	Accuracy: 48.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6250    0.1562    0.2500        32
         cwx     0.7143    0.4688    0.5660        32
         hdx     0.2000    0.0769    0.1111        13
         mtx     1.0000    0.0909    0.1667        22
         nqx     0.5000    0.2857    0.3636        14
         qtx     0.3867    0.9062    0.5421        32
         zxx     0.5000    0.8250    0.6226        40

    accuracy                         0.4811       185
   macro avg     0.5609    0.4014    0.3746       185
weighted avg     0.5775    0.4811    0.4247       185

micro f-score: 0.4810810810810811

========== Train Epoch 24 ==========
Loss: 0.225	Accuracy: 50.27%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.6667    0.3750    0.4800        32
         cwx     0.8750    0.4375    0.5833        32
         hdx     0.3333    0.2308    0.2727        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     0.4000    0.2857    0.3333        14
         qtx     0.3750    0.8438    0.5192        32
         zxx     0.5424    0.8000    0.6465        40

    accuracy                         0.5027       185
   macro avg     0.5989    0.4312    0.4174       185
weighted avg     0.6214    0.5027    0.4682       185

micro f-score: 0.5027027027027027

========== Train Epoch 25 ==========
Loss: 0.298	Accuracy: 45.95%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.4386    0.7812    0.5618        32
         hdx     0.2500    0.0769    0.1176        13
         mtx     0.1961    0.4545    0.2740        22
         nqx     0.5000    0.0714    0.1250        14
         qtx     0.6000    0.7500    0.6667        32
         zxx     0.7742    0.6000    0.6761        40

    accuracy                         0.4595       185
   macro avg     0.3941    0.3906    0.3459       185
weighted avg     0.4258    0.4595    0.4090       185

micro f-score: 0.4594594594594595

========== Train Epoch 26 ==========
Loss: 0.225	Accuracy: 50.27%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4211    0.5000    0.4571        32
         cwx     1.0000    0.3750    0.5455        32
         hdx     0.5000    0.3846    0.4348        13
         mtx     0.2917    0.6364    0.4000        22
         nqx     0.6667    0.1429    0.2353        14
         qtx     0.4909    0.8438    0.6207        32
         zxx     0.8947    0.4250    0.5763        40

    accuracy                         0.5027       185
   macro avg     0.6093    0.4725    0.4671       185
weighted avg     0.6444    0.5027    0.5013       185

micro f-score: 0.5027027027027027

========== Train Epoch 27 ==========
Loss: 0.167	Accuracy: 60.54%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6800    0.5312    0.5965        32
         cwx     0.8000    0.6250    0.7018        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.5000    0.2273    0.3125        22
         nqx     0.3125    0.7143    0.4348        14
         qtx     0.6486    0.7500    0.6957        32
         zxx     0.6604    0.8750    0.7527        40

    accuracy                         0.6054       185
   macro avg     0.5621    0.5428    0.5170       185
weighted avg     0.6175    0.6054    0.5865       185

micro f-score: 0.6054054054054054

========== Train Epoch 28 ==========
Loss: 0.145	Accuracy: 50.27%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4643    0.4062    0.4333        32
         cwx     0.6176    0.6562    0.6364        32
         hdx     0.1333    0.3077    0.1860        13
         mtx     0.3333    0.4091    0.3673        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.6000    0.8438    0.7013        32
         zxx     0.9048    0.4750    0.6230        40

    accuracy                         0.5027       185
   macro avg     0.4362    0.4426    0.4210       185
weighted avg     0.5356    0.5027    0.4978       185

micro f-score: 0.5027027027027027

========== Train Epoch 29 ==========
Loss: 0.179	Accuracy: 49.19%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4242    0.4375    0.4308        32
         cwx     0.5769    0.4688    0.5172        32
         hdx     0.1818    0.4615    0.2609        13
         mtx     0.3333    0.0909    0.1429        22
         nqx     0.4375    0.5000    0.4667        14
         qtx     0.6000    0.8438    0.7013        32
         zxx     0.7692    0.5000    0.6061        40

    accuracy                         0.4919       185
   macro avg     0.4747    0.4718    0.4465       185
weighted avg     0.5288    0.4919    0.4870       185

micro f-score: 0.4918918918918919

========== Train Epoch 30 ==========
Loss: 0.153	Accuracy: 60.00%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6667    0.0625    0.1143        32
         cwx     0.6774    0.6562    0.6667        32
         hdx     0.7500    0.2308    0.3529        13
         mtx     0.4118    0.6364    0.5000        22
         nqx     0.3462    0.6429    0.4500        14
         qtx     0.7576    0.7812    0.7692        32
         zxx     0.6852    0.9250    0.7872        40

    accuracy                         0.6000       185
   macro avg     0.6135    0.5621    0.5201       185
weighted avg     0.6395    0.6000    0.5567       185

micro f-score: 0.6

========== Train Epoch 31 ==========
Loss: 0.130	Accuracy: 49.73%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2830    0.9375    0.4348        32
         cwx     0.9375    0.4688    0.6250        32
         hdx     0.3750    0.2308    0.2857        13
         mtx     0.6667    0.2727    0.3871        22
         nqx     0.8333    0.3571    0.5000        14
         qtx     0.8148    0.6875    0.7458        32
         zxx     0.8462    0.2750    0.4151        40

    accuracy                         0.4973       185
   macro avg     0.6795    0.4613    0.4848       185
weighted avg     0.7037    0.4973    0.5060       185

micro f-score: 0.4972972972972973

========== Train Epoch 32 ==========
Loss: 0.105	Accuracy: 57.30%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5758    0.5938    0.5846        32
         cwx     0.4265    0.9062    0.5800        32
         hdx     1.0000    0.0769    0.1429        13
         mtx     0.8000    0.1818    0.2963        22
         nqx     0.4000    0.4286    0.4138        14
         qtx     0.9444    0.5312    0.6800        32
         zxx     0.6667    0.7500    0.7059        40

    accuracy                         0.5730       185
   macro avg     0.6876    0.4955    0.4862       185
weighted avg     0.6765    0.5730    0.5483       185

micro f-score: 0.572972972972973

========== Train Epoch 33 ==========
Loss: 0.112	Accuracy: 57.84%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.6957    0.5000    0.5818        32
         cwx     0.4286    0.9375    0.5882        32
         hdx     0.2000    0.1538    0.1739        13
         mtx     0.5333    0.3636    0.4324        22
         nqx     1.0000    0.1429    0.2500        14
         qtx     0.6486    0.7500    0.6957        32
         zxx     0.8929    0.6250    0.7353        40

    accuracy                         0.5784       185
   macro avg     0.6284    0.4961    0.4939       185
weighted avg     0.6529    0.5784    0.5643       185

micro f-score: 0.5783783783783784

========== Train Epoch 34 ==========
Loss: 0.083	Accuracy: 54.05%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     0.6571    0.7188    0.6866        32
         hdx     0.8000    0.3077    0.4444        13
         mtx     0.7000    0.3182    0.4375        22
         nqx     0.2000    0.7857    0.3188        14
         qtx     0.6667    0.8125    0.7324        32
         zxx     0.7250    0.7250    0.7250        40

    accuracy                         0.5405       185
   macro avg     0.5355    0.5240    0.4778       185
weighted avg     0.5403    0.5405    0.5096       185

micro f-score: 0.5405405405405406

========== Train Epoch 35 ==========
Loss: 0.094	Accuracy: 56.22%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3857    0.8438    0.5294        32
         cwx     0.7500    0.4688    0.5769        32
         hdx     0.6667    0.1538    0.2500        13
         mtx     0.5000    0.3636    0.4211        22
         nqx     0.4286    0.6429    0.5143        14
         qtx     0.9000    0.5625    0.6923        32
         zxx     0.7143    0.6250    0.6667        40

    accuracy                         0.5622       185
   macro avg     0.6207    0.5229    0.5215       185
weighted avg     0.6453    0.5622    0.5618       185

micro f-score: 0.5621621621621622

========== Train Epoch 36 ==========
Loss: 0.156	Accuracy: 47.03%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4000    0.1875    0.2553        32
         cwx     0.6341    0.8125    0.7123        32
         hdx     0.2857    0.1538    0.2000        13
         mtx     0.2222    0.7273    0.3404        22
         nqx     0.1111    0.0714    0.0870        14
         qtx     0.8636    0.5938    0.7037        32
         zxx     0.8947    0.4250    0.5763        40

    accuracy                         0.4703       185
   macro avg     0.4874    0.4245    0.4107       185
weighted avg     0.5766    0.4703    0.4748       185

micro f-score: 0.4702702702702703

========== Train Epoch 37 ==========
Loss: 0.158	Accuracy: 39.46%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5500    0.3438    0.4231        32
         cwx     0.3100    0.9688    0.4697        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     1.0000    0.0909    0.1667        22
         nqx     0.2000    0.5000    0.2857        14
         qtx     0.9286    0.4062    0.5652        32
         zxx     0.6923    0.2250    0.3396        40

    accuracy                         0.3946       185
   macro avg     0.5258    0.3621    0.3214       185
weighted avg     0.5931    0.3946    0.3671       185

micro f-score: 0.3945945945945946

========== Train Epoch 38 ==========
Loss: 0.149	Accuracy: 52.97%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6842    0.4062    0.5098        32
         cwx     0.8824    0.4688    0.6122        32
         hdx     0.2500    0.3077    0.2759        13
         mtx     0.8333    0.2273    0.3571        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.4000    0.8750    0.5490        32
         zxx     0.5789    0.8250    0.6804        40

    accuracy                         0.5297       185
   macro avg     0.5184    0.4443    0.4264       185
weighted avg     0.5820    0.5297    0.4980       185

micro f-score: 0.5297297297297298

========== Train Epoch 39 ==========
Loss: 0.125	Accuracy: 56.22%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3800    0.5938    0.4634        32
         cwx     0.7895    0.4688    0.5882        32
         hdx     0.4000    0.4615    0.4286        13
         mtx     0.5000    0.3636    0.4211        22
         nqx     0.5000    0.0714    0.1250        14
         qtx     0.5833    0.8750    0.7000        32
         zxx     0.7714    0.6750    0.7200        40

    accuracy                         0.5622       185
   macro avg     0.5606    0.5013    0.4923       185
weighted avg     0.5954    0.5622    0.5483       185

micro f-score: 0.5621621621621622

========== Train Epoch 40 ==========
Loss: 0.100	Accuracy: 44.32%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5333    0.2500    0.3404        32
         cwx     0.9167    0.3438    0.5000        32
         hdx     0.1351    0.7692    0.2299        13
         mtx     0.4706    0.3636    0.4103        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.5116    0.6875    0.5867        32
         zxx     0.9565    0.5500    0.6984        40

    accuracy                         0.4432       185
   macro avg     0.6463    0.4336    0.4141       185
weighted avg     0.6873    0.4432    0.4729       185

micro f-score: 0.44324324324324327

========== Train Epoch 41 ==========
Loss: 0.086	Accuracy: 46.49%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.8000    0.1250    0.2162        32
         cwx     1.0000    0.3125    0.4762        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.3103    0.4091    0.3529        22
         nqx     0.2308    0.8571    0.3636        14
         qtx     0.8500    0.5312    0.6538        32
         zxx     0.5000    0.8500    0.6296        40

    accuracy                         0.4649       185
   macro avg     0.5273    0.4407    0.3846       185
weighted avg     0.6209    0.4649    0.4385       185

micro f-score: 0.4648648648648649

========== Train Epoch 42 ==========
Loss: 0.064	Accuracy: 50.27%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.3200    0.2500    0.2807        32
         cwx     0.6667    0.7500    0.7059        32
         hdx     0.4444    0.3077    0.3636        13
         mtx     0.3659    0.6818    0.4762        22
         nqx     0.3077    0.2857    0.2963        14
         qtx     0.5686    0.9062    0.6988        32
         zxx     0.9000    0.2250    0.3600        40

    accuracy                         0.5027       185
   macro avg     0.5105    0.4866    0.4545       185
weighted avg     0.5616    0.5027    0.4740       185

micro f-score: 0.5027027027027027

========== Train Epoch 43 ==========
Loss: 0.071	Accuracy: 57.84%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.4355    0.8438    0.5745        32
         cwx     0.4902    0.7812    0.6024        32
         hdx     0.4000    0.1538    0.2222        13
         mtx     1.0000    0.2727    0.4286        22
         nqx     0.3846    0.3571    0.3704        14
         qtx     0.9130    0.6562    0.7636        32
         zxx     0.8400    0.5250    0.6462        40

    accuracy                         0.5784       185
   macro avg     0.6376    0.5129    0.5154       185
weighted avg     0.6758    0.5784    0.5700       185

micro f-score: 0.5783783783783784

========== Train Epoch 44 ==========
Loss: 0.065	Accuracy: 56.22%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.6000    0.5625    0.5806        32
         cwx     0.9444    0.5312    0.6800        32
         hdx     0.6667    0.1538    0.2500        13
         mtx     0.7500    0.4091    0.5294        22
         nqx     0.3333    0.0714    0.1176        14
         qtx     0.8571    0.5625    0.6792        32
         zxx     0.3980    0.9750    0.5652        40

    accuracy                         0.5622       185
   macro avg     0.6499    0.4665    0.4860       185
weighted avg     0.6627    0.5622    0.5472       185

micro f-score: 0.5621621621621622

========== Train Epoch 45 ==========
Loss: 0.052	Accuracy: 60.00%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5000    0.5000    0.5000        32
         cwx     0.5870    0.8438    0.6923        32
         hdx     0.3750    0.2308    0.2857        13
         mtx     0.7273    0.3636    0.4848        22
         nqx     0.5000    0.5000    0.5000        14
         qtx     0.6136    0.8438    0.7105        32
         zxx     0.7667    0.5750    0.6571        40

    accuracy                         0.6000       185
   macro avg     0.5814    0.5510    0.5472       185
weighted avg     0.6106    0.6000    0.5868       185

micro f-score: 0.6

========== Train Epoch 46 ==========
Loss: 0.045	Accuracy: 55.14%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5000    0.2500    0.3333        32
         cwx     0.3797    0.9375    0.5405        32
         hdx     0.3333    0.0769    0.1250        13
         mtx     0.7143    0.4545    0.5556        22
         nqx     0.4211    0.5714    0.4848        14
         qtx     0.8000    0.7500    0.7742        32
         zxx     0.8750    0.5250    0.6563        40

    accuracy                         0.5514       185
   macro avg     0.5748    0.5093    0.4957       185
weighted avg     0.6200    0.5514    0.5385       185

micro f-score: 0.5513513513513514

========== Train Epoch 47 ==========
Loss: 0.038	Accuracy: 62.70%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.8125    0.4062    0.5417        32
         cwx     0.8947    0.5312    0.6667        32
         hdx     0.2609    0.4615    0.3333        13
         mtx     0.6000    0.5455    0.5714        22
         nqx     0.5000    0.5714    0.5333        14
         qtx     0.5625    0.8438    0.6750        32
         zxx     0.7674    0.8250    0.7952        40

    accuracy                         0.6270       185
   macro avg     0.6283    0.5978    0.5881       185
weighted avg     0.6861    0.6270    0.6294       185

micro f-score: 0.6270270270270271

========== Train Epoch 48 ==========
Loss: 0.055	Accuracy: 51.35%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5000    0.4375    0.4667        32
         cwx     0.8889    0.5000    0.6400        32
         hdx     0.2400    0.4615    0.3158        13
         mtx     0.2500    0.6818    0.3659        22
         nqx     0.0000    0.0000    0.0000        14
         qtx     0.8261    0.5938    0.6909        32
         zxx     0.8065    0.6250    0.7042        40

    accuracy                         0.5135       185
   macro avg     0.5016    0.4714    0.4548       185
weighted avg     0.6041    0.5135    0.5289       185

micro f-score: 0.5135135135135135

========== Train Epoch 49 ==========
Loss: 0.048	Accuracy: 60.00%	Cost 33s
              precision    recall  f1-score   support

         bzx     0.5000    0.3750    0.4286        32
         cwx     0.8333    0.7812    0.8065        32
         hdx     0.3333    0.3846    0.3571        13
         mtx     0.5882    0.4545    0.5128        22
         nqx     0.6250    0.3571    0.4545        14
         qtx     0.5179    0.9062    0.6591        32
         zxx     0.7143    0.6250    0.6667        40

    accuracy                         0.6000       185
   macro avg     0.5874    0.5548    0.5550       185
weighted avg     0.6153    0.6000    0.5923       185

micro f-score: 0.6

========== Train Epoch 50 ==========
Loss: 0.068	Accuracy: 62.70%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.5484    0.5312    0.5397        32
         cwx     0.7500    0.6562    0.7000        32
         hdx     0.5556    0.3846    0.4545        13
         mtx     0.6875    0.5000    0.5789        22
         nqx     0.3478    0.5714    0.4324        14
         qtx     0.6250    0.7812    0.6944        32
         zxx     0.7632    0.7250    0.7436        40

    accuracy                         0.6270       185
   macro avg     0.6111    0.5928    0.5919       185
weighted avg     0.6448    0.6270    0.6288       185

micro f-score: 0.6270270270270271

========== Train Epoch 51 ==========
Loss: 0.104	Accuracy: 40.54%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2762    0.9062    0.4234        32
         cwx     0.4898    0.7500    0.5926        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.5000    0.1364    0.2143        22
         nqx     0.5714    0.2857    0.3810        14
         qtx     0.8235    0.4375    0.5714        32
         zxx     1.0000    0.0250    0.0488        40

    accuracy                         0.4054       185
   macro avg     0.5230    0.3630    0.3188       185
weighted avg     0.5939    0.4054    0.3394       185

micro f-score: 0.40540540540540543

========== Train Epoch 52 ==========
Loss: 0.182	Accuracy: 41.08%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.2979    0.4375    0.3544        32
         cwx     0.4286    0.8438    0.5684        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.5385    0.3182    0.4000        22
         nqx     0.2683    0.7857    0.4000        14
         qtx     0.7500    0.1875    0.3000        32
         zxx     1.0000    0.2750    0.4314        40

    accuracy                         0.4108       185
   macro avg     0.4690    0.4068    0.3506       185
weighted avg     0.5559    0.4108    0.3826       185

micro f-score: 0.4108108108108109

========== Train Epoch 53 ==========
Loss: 0.157	Accuracy: 48.65%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.8571    0.1875    0.3077        32
         cwx     0.6667    0.3750    0.4800        32
         hdx     0.4000    0.1538    0.2222        13
         mtx     1.0000    0.0455    0.0870        22
         nqx     0.4286    0.4286    0.4286        14
         qtx     0.5745    0.8438    0.6835        32
         zxx     0.3871    0.9000    0.5414        40

    accuracy                         0.4865       185
   macro avg     0.6163    0.4192    0.3929       185
weighted avg     0.6261    0.4865    0.4299       185

micro f-score: 0.4864864864864865

========== Train Epoch 54 ==========
Loss: 0.133	Accuracy: 28.11%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.0000    0.0000    0.0000        32
         cwx     1.0000    0.2500    0.4000        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.1438    0.9545    0.2500        22
         nqx     0.6667    0.1429    0.2353        14
         qtx     0.6429    0.2812    0.3913        32
         zxx     0.9231    0.3000    0.4528        40

    accuracy                         0.2811       185
   macro avg     0.4823    0.2755    0.2471       185
weighted avg     0.5513    0.2811    0.2823       185

micro f-score: 0.2810810810810811

========== Train Epoch 55 ==========
Loss: 0.102	Accuracy: 49.19%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3818    0.6562    0.4828        32
         cwx     0.5417    0.8125    0.6500        32
         hdx     0.2424    0.6154    0.3478        13
         mtx     0.5000    0.3636    0.4211        22
         nqx     0.5000    0.0714    0.1250        14
         qtx     0.8333    0.6250    0.7143        32
         zxx     1.0000    0.1750    0.2979        40

    accuracy                         0.4919       185
   macro avg     0.5713    0.4742    0.4341       185
weighted avg     0.6344    0.4919    0.4679       185

micro f-score: 0.4918918918918919

========== Train Epoch 56 ==========
Loss: 0.101	Accuracy: 50.27%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3375    0.8438    0.4821        32
         cwx     0.8235    0.4375    0.5714        32
         hdx     0.2941    0.3846    0.3333        13
         mtx     0.4762    0.4545    0.4651        22
         nqx     1.0000    0.0714    0.1333        14
         qtx     0.7000    0.6562    0.6774        32
         zxx     0.7895    0.3750    0.5085        40

    accuracy                         0.5027       185
   macro avg     0.6315    0.4604    0.4530       185
weighted avg     0.6456    0.5027    0.4982       185

micro f-score: 0.5027027027027027

========== Train Epoch 57 ==========
Loss: 0.103	Accuracy: 54.59%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7500    0.2812    0.4091        32
         cwx     0.8750    0.4375    0.5833        32
         hdx     0.2222    0.4615    0.3000        13
         mtx     0.5385    0.3182    0.4000        22
         nqx     0.5385    0.5000    0.5185        14
         qtx     0.5532    0.8125    0.6582        32
         zxx     0.5614    0.8000    0.6598        40

    accuracy                         0.5459       185
   macro avg     0.5770    0.5159    0.5041       185
weighted avg     0.6186    0.5459    0.5361       185

micro f-score: 0.5459459459459459

========== Train Epoch 58 ==========
Loss: 0.104	Accuracy: 54.05%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.4681    0.6875    0.5570        32
         cwx     0.5217    0.7500    0.6154        32
         hdx     0.2000    0.1538    0.1739        13
         mtx     0.7500    0.1364    0.2308        22
         nqx     0.3333    0.4286    0.3750        14
         qtx     0.9231    0.3750    0.5333        32
         zxx     0.6596    0.7750    0.7126        40

    accuracy                         0.5405       185
   macro avg     0.5508    0.4723    0.4569       185
weighted avg     0.6020    0.5405    0.5172       185

micro f-score: 0.5405405405405406

========== Train Epoch 59 ==========
Loss: 0.066	Accuracy: 52.43%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.5385    0.4375    0.4828        32
         cwx     0.8696    0.6250    0.7273        32
         hdx     0.4286    0.2308    0.3000        13
         mtx     0.2162    0.7273    0.3333        22
         nqx     0.6000    0.2143    0.3158        14
         qtx     0.7273    0.7500    0.7385        32
         zxx     1.0000    0.4250    0.5965        40

    accuracy                         0.5243       185
   macro avg     0.6257    0.4871    0.4992       185
weighted avg     0.6868    0.5243    0.5506       185

micro f-score: 0.5243243243243243

========== Train Epoch 60 ==========
Loss: 0.094	Accuracy: 53.51%	Cost 34s
              precision    recall  f1-score   support

         bzx     0.3846    0.1562    0.2222        32
         cwx     0.7692    0.6250    0.6897        32
         hdx     0.2857    0.4615    0.3529        13
         mtx     0.3659    0.6818    0.4762        22
         nqx     0.8000    0.2857    0.4211        14
         qtx     0.4898    0.7500    0.5926        32
         zxx     0.8333    0.6250    0.7143        40

    accuracy                         0.5351       185
   macro avg     0.5612    0.5122    0.4956       185
weighted avg     0.5886    0.5351    0.5280       185

micro f-score: 0.5351351351351351

========== Train Epoch 61 ==========
Loss: 0.064	Accuracy: 55.14%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.5000    0.0625    0.1111        32
         cwx     0.4355    0.8438    0.5745        32
         hdx     0.0000    0.0000    0.0000        13
         mtx     0.6364    0.3182    0.4242        22
         nqx     0.5000    0.1429    0.2222        14
         qtx     0.7000    0.8750    0.7778        32
         zxx     0.5625    0.9000    0.6923        40

    accuracy                         0.5514       185
   macro avg     0.4763    0.4489    0.4003       185
weighted avg     0.5180    0.5514    0.4701       185

micro f-score: 0.5513513513513514

========== Train Epoch 62 ==========
Loss: 0.074	Accuracy: 54.05%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.4722    0.5312    0.5000        32
         cwx     0.7273    0.7500    0.7385        32
         hdx     0.1250    0.0769    0.0952        13
         mtx     0.3125    0.4545    0.3704        22
         nqx     0.2703    0.7143    0.3922        14
         qtx     0.9500    0.5938    0.7308        32
         zxx     1.0000    0.4750    0.6441        40

    accuracy                         0.5405       185
   macro avg     0.5510    0.5137    0.4959       185
weighted avg     0.6544    0.5405    0.5603       185

micro f-score: 0.5405405405405406

========== Train Epoch 63 ==========
Epoch    63: reducing learning rate of group 0 to 1.0000e-05.
Loss: 0.072	Accuracy: 60.54%	Cost 35s
              precision    recall  f1-score   support

         bzx     0.7500    0.2812    0.4091        32
         cwx     0.4821    0.8438    0.6136        32
         hdx     0.2941    0.3846    0.3333        13
         mtx     1.0000    0.1364    0.2400        22
         nqx     0.5000    0.6429    0.5625        14
         qtx     0.7812    0.7812    0.7812        32
         zxx     0.7234    0.8500    0.7816        40

    accuracy                         0.6054       185
   macro avg     0.6473    0.5600    0.5316       185
weighted avg     0.6821    0.6054    0.5756       185

micro f-score: 0.6054054054054054

========== Train Epoch 64 ==========
Loss: 0.035	Accuracy: 68.65%	Cost 36s
              precision    recall  f1-score   support

         bzx     0.6667    0.5625    0.6102        32
         cwx     0.7353    0.7812    0.7576        32
         hdx     0.3636    0.3077    0.3333        13
         mtx     0.5625    0.4091    0.4737        22
         nqx     0.5833    0.5000    0.5385        14
         qtx     0.7568    0.8750    0.8116        32
         zxx     0.7500    0.9000    0.8182        40

    accuracy                         0.6865       185
   macro avg     0.6312    0.6194    0.6204       185
weighted avg     0.6722    0.6865    0.6744       185

micro f-score: 0.6864864864864865

Finished training!!!

Min Loss = 0.035 in epoch 63;
Max Accuracy = 68.65% in epoch 63;
Total Cost 37 minutes

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 64, 160, 160]        9,408
├─BatchNorm2d: 1-2                       [-1, 64, 160, 160]        128
├─ReLU: 1-3                              [-1, 64, 160, 160]        --
├─SPPB: 1-4                              [-1, 64, 160, 160]        --
|    └─Conv: 2-1                         [-1, 32, 160, 160]        --
|    |    └─Conv2d: 3-1                  [-1, 32, 160, 160]        2,048
|    |    └─BatchNorm2d: 3-2             [-1, 32, 160, 160]        64
|    |    └─ReLU: 3-3                    [-1, 32, 160, 160]        --
|    └─ModuleList: 2                     []                        --
|    |    └─MaxPool2d: 3-4               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-5               [-1, 32, 160, 160]        --
|    |    └─MaxPool2d: 3-6               [-1, 32, 160, 160]        --
|    └─Conv: 2-2                         [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-7                  [-1, 64, 160, 160]        8,192
|    |    └─BatchNorm2d: 3-8             [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-9                    [-1, 64, 160, 160]        --
├─Sequential: 1-5                        [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-3                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-10                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-11            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-12                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-13                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-14            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-15                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-4                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-16                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-17            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-18                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-19                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-20            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-21                   [-1, 64, 160, 160]        --
|    └─BasicBlock: 2-5                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-22                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-23            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-24                   [-1, 64, 160, 160]        --
|    |    └─Conv2d: 3-25                 [-1, 64, 160, 160]        36,864
|    |    └─BatchNorm2d: 3-26            [-1, 64, 160, 160]        128
|    |    └─ReLU: 3-27                   [-1, 64, 160, 160]        --
├─Sequential: 1-6                        [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-6                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-28                 [-1, 128, 80, 80]         73,728
|    |    └─BatchNorm2d: 3-29            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-30                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-31                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-32            [-1, 128, 80, 80]         256
|    |    └─Sequential: 3-33             [-1, 128, 80, 80]         8,448
|    |    └─ReLU: 3-34                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-7                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-35                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-36            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-37                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-38                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-39            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-40                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-8                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-41                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-42            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-43                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-44                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-45            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-46                   [-1, 128, 80, 80]         --
|    └─BasicBlock: 2-9                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-47                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-48            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-49                   [-1, 128, 80, 80]         --
|    |    └─Conv2d: 3-50                 [-1, 128, 80, 80]         147,456
|    |    └─BatchNorm2d: 3-51            [-1, 128, 80, 80]         256
|    |    └─ReLU: 3-52                   [-1, 128, 80, 80]         --
├─Sequential: 1-7                        [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-10                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-53                 [-1, 256, 40, 40]         294,912
|    |    └─BatchNorm2d: 3-54            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-55                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-56                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-57            [-1, 256, 40, 40]         512
|    |    └─Sequential: 3-58             [-1, 256, 40, 40]         33,280
|    |    └─ReLU: 3-59                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-11                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-60                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-61            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-62                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-63                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-64            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-65                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-12                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-66                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-67            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-68                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-69                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-70            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-71                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-13                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-72                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-73            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-74                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-75                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-76            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-77                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-14                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-78                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-79            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-80                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-81                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-82            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-83                   [-1, 256, 40, 40]         --
|    └─BasicBlock: 2-15                  [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-84                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-85            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-86                   [-1, 256, 40, 40]         --
|    |    └─Conv2d: 3-87                 [-1, 256, 40, 40]         589,824
|    |    └─BatchNorm2d: 3-88            [-1, 256, 40, 40]         512
|    |    └─ReLU: 3-89                   [-1, 256, 40, 40]         --
├─Sequential: 1-8                        [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-16                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-90                 [-1, 512, 20, 20]         1,179,648
|    |    └─BatchNorm2d: 3-91            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-92                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-93                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-94            [-1, 512, 20, 20]         1,024
|    |    └─Sequential: 3-95             [-1, 512, 20, 20]         132,096
|    |    └─ReLU: 3-96                   [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-17                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-97                 [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-98            [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-99                   [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-100                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-101           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-102                  [-1, 512, 20, 20]         --
|    └─BasicBlock: 2-18                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-103                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-104           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-105                  [-1, 512, 20, 20]         --
|    |    └─Conv2d: 3-106                [-1, 512, 20, 20]         2,359,296
|    |    └─BatchNorm2d: 3-107           [-1, 512, 20, 20]         1,024
|    |    └─ReLU: 3-108                  [-1, 512, 20, 20]         --
├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --
├─Linear: 1-10                           [-1, 7]                   3,591
==========================================================================================
Total params: 21,298,695
Trainable params: 21,298,695
Non-trainable params: 0
Total mult-adds (G): 29.49
==========================================================================================
Input size (MB): 1.17
Forward/backward pass size (MB): 428.13
Params size (MB): 81.25
Estimated Total Size (MB): 510.55
==========================================================================================



